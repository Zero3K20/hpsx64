/*
	Copyright (C) 2012-2030

    This program is free software: you can redistribute it and/or modify
    it under the terms of the GNU General Public License as published by
    the Free Software Foundation, either version 3 of the License, or
    (at your option) any later version.

    This program is distributed in the hope that it will be useful,
    but WITHOUT ANY WARRANTY; without even the implied warranty of
    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
    GNU General Public License for more details.

    You should have received a copy of the GNU General Public License
    aint32_t with this program.  If not, see <http://www.gnu.org/licenses/>.
*/


// ***TODO***
// 1. If instructions being recompiled are in a cached area and are currently in cache, then pull from cache NOT memory
// 2. make invalidating the recompiled code optional (shouldn't matter after #1 is fixed, unless uncached code area)
// 3. try reducing branches in recompiled code
// 4. 


#include "R5900_Execute.h"
#include "R5900_Recompiler.h"
#include "ps2_system.h"
#include "R5900_Print.h"
#include "PS2DataBus.h"

#include "VU_Recompiler.h"

#include <cassert>

#include <cstddef>


using namespace Playstation2;
using namespace R5900;


#ifdef _DEBUG_VERSION_

#define INLINE_DEBUG_ENABLE

//#define INLINE_DEBUG_SPLIT


//#define INLINE_DEBUG_RECOMPILE
//#define INLINE_DEBUG_RECOMPILE2


#endif


// base the cycle count on the address
//#define USE_ADDRESS_BASED_CYCLE_COUNTS_R5900


#define USE_NEW_R5900_ASSEMBLER_ADDU
#define USE_NEW_R5900_ASSEMBLER_SUBU

#define USE_NEW_R5900_ASSEMBLER_AND
#define USE_NEW_R5900_ASSEMBLER_OR
#define USE_NEW_R5900_ASSEMBLER_XOR
#define USE_NEW_R5900_ASSEMBLER_NOR

#define USE_NEW_R5900_ASSEMBLER_SLT
#define USE_NEW_R5900_ASSEMBLER_SLTU

#define USE_NEW_R5900_ASSEMBLER_ADDIU
#define USE_NEW_R5900_ASSEMBLER_ANDI
#define USE_NEW_R5900_ASSEMBLER_ORI
#define USE_NEW_R5900_ASSEMBLER_XORI

#define USE_NEW_R5900_ASSEMBLER_SLTI
#define USE_NEW_R5900_ASSEMBLER_SLTIU
#define USE_NEW_R5900_ASSEMBLER_LUI

#define USE_NEW_R5900_ASSEMBLER_SLL
#define USE_NEW_R5900_ASSEMBLER_SRL
#define USE_NEW_R5900_ASSEMBLER_SRA
#define USE_NEW_R5900_ASSEMBLER_SLLV
#define USE_NEW_R5900_ASSEMBLER_SRLV
#define USE_NEW_R5900_ASSEMBLER_SRAV

#define USE_NEW_R5900_ASSEMBLER_DADDU
#define USE_NEW_R5900_ASSEMBLER_DADDIU
#define USE_NEW_R5900_ASSEMBLER_DSUBU

#define USE_NEW_R5900_ASSEMBLER_DSLL
#define USE_NEW_R5900_ASSEMBLER_DSRL
#define USE_NEW_R5900_ASSEMBLER_DSRA
#define USE_NEW_R5900_ASSEMBLER_DSLL32
#define USE_NEW_R5900_ASSEMBLER_DSRL32
#define USE_NEW_R5900_ASSEMBLER_DSRA32

#define USE_NEW_R5900_ASSEMBLER_DSLLV
#define USE_NEW_R5900_ASSEMBLER_DSRLV
#define USE_NEW_R5900_ASSEMBLER_DSRAV
#define USE_NEW_R5900_ASSEMBLER_MOVZ
#define USE_NEW_R5900_ASSEMBLER_MOVN


#define USE_NEW_R5900_ASSEMBLER_PADSBH

#define USE_NEW_R5900_ASSEMBLER_PABSH
#define USE_NEW_R5900_ASSEMBLER_PABSW
#define USE_NEW_R5900_ASSEMBLER_PAND
#define USE_NEW_R5900_ASSEMBLER_PXOR
#define USE_NEW_R5900_ASSEMBLER_POR
#define USE_NEW_R5900_ASSEMBLER_PNOR

#define USE_NEW_R5900_ASSEMBLER_PLZCW

#define USE_NEW_R5900_ASSEMBLER_PSLLH
#define USE_NEW_R5900_ASSEMBLER_PSLLW
#define USE_NEW_R5900_ASSEMBLER_PSRLH
#define USE_NEW_R5900_ASSEMBLER_PSRLW
#define USE_NEW_R5900_ASSEMBLER_PSRAH
#define USE_NEW_R5900_ASSEMBLER_PSRAW
#define USE_NEW_R5900_ASSEMBLER_PSLLVW
#define USE_NEW_R5900_ASSEMBLER_PSRLVW
#define USE_NEW_R5900_ASSEMBLER_PSRAVW

#define USE_NEW_R5900_ASSEMBLER_PADDB
#define USE_NEW_R5900_ASSEMBLER_PADDH
#define USE_NEW_R5900_ASSEMBLER_PADDW

#define USE_NEW_R5900_ASSEMBLER_PSUBB
#define USE_NEW_R5900_ASSEMBLER_PSUBH
#define USE_NEW_R5900_ASSEMBLER_PSUBW


#define USE_NEW_R5900_ASSEMBLER_PADDSB
#define USE_NEW_R5900_ASSEMBLER_PADDSH

#define USE_NEW_R5900_ASSEMBLER_PADDUB
#define USE_NEW_R5900_ASSEMBLER_PADDUH

#define USE_NEW_R5900_ASSEMBLER_PSUBSB
#define USE_NEW_R5900_ASSEMBLER_PSUBSH

#define USE_NEW_R5900_ASSEMBLER_PSUBUB
#define USE_NEW_R5900_ASSEMBLER_PSUBUH

#define USE_NEW_R5900_ASSEMBLER_PMAXH
#define USE_NEW_R5900_ASSEMBLER_PMAXW
#define USE_NEW_R5900_ASSEMBLER_PMINH
#define USE_NEW_R5900_ASSEMBLER_PMINW


#define USE_NEW_R5900_ASSEMBLER_PCGTB
#define USE_NEW_R5900_ASSEMBLER_PCGTH
#define USE_NEW_R5900_ASSEMBLER_PCGTW

#define USE_NEW_R5900_ASSEMBLER_PCEQB
#define USE_NEW_R5900_ASSEMBLER_PCEQH
#define USE_NEW_R5900_ASSEMBLER_PCEQW


#define USE_NEW_R5900_ASSEMBLER_PEXTLB
#define USE_NEW_R5900_ASSEMBLER_PEXTLH
#define USE_NEW_R5900_ASSEMBLER_PEXTLW

#define USE_NEW_R5900_ASSEMBLER_PEXTUB
#define USE_NEW_R5900_ASSEMBLER_PEXTUH
#define USE_NEW_R5900_ASSEMBLER_PEXTUW


#define USE_NEW_R5900_ASSEMBLER_PPACB
#define USE_NEW_R5900_ASSEMBLER_PPACH
#define USE_NEW_R5900_ASSEMBLER_PPACW

#define USE_NEW_R5900_ASSEMBLER_PEXT5
#define USE_NEW_R5900_ASSEMBLER_PPAC5


#define USE_NEW_R5900_ASSEMBLER_PINTH
#define USE_NEW_R5900_ASSEMBLER_PINTEH

#define USE_NEW_R5900_ASSEMBLER_PREVH

#define USE_NEW_R5900_ASSEMBLER_PEXEH
#define USE_NEW_R5900_ASSEMBLER_PEXEW

#define USE_NEW_R5900_ASSEMBLER_PROT3W

#define USE_NEW_R5900_ASSEMBLER_PCPYLD
#define USE_NEW_R5900_ASSEMBLER_PCPYUD
#define USE_NEW_R5900_ASSEMBLER_PCPYH

#define USE_NEW_R5900_ASSEMBLER_PEXCH
#define USE_NEW_R5900_ASSEMBLER_PEXCW



#define USE_EXCEPTIONS_R5900_DIV
#define USE_EXCEPTIONS_R5900_PDIVW
#define USE_EXCEPTIONS_R5900_PDIVUW
#define USE_EXCEPTIONS_R5900_PDIVBW


// testing new branch method
#define USE_NEW_BRANCH_CODE_R5900


#define USE_NEW_VECTOR_DISPATCH_VMUL_R5900
#define USE_NEW_VECTOR_DISPATCH_VADD_R5900
#define USE_NEW_VECTOR_DISPATCH_VMADD_R5900
#define USE_NEW_VECTOR_DISPATCH_VABS_R5900
#define USE_NEW_VECTOR_DISPATCH_VMAX_R5900
#define USE_NEW_VECTOR_DISPATCH_VMIN_R5900

#define USE_NEW_VECTOR_DISPATCH_FTOIX_R5900
#define USE_NEW_VECTOR_DISPATCH_ITOFX_R5900

#define USE_NEW_VECTOR_DISPATCH_VLQI_R5900
#define USE_NEW_VECTOR_DISPATCH_VLQD_R5900


// defines for testing float functions
#define ALLOW_AVX2_FMULX4
#define ALLOW_AVX2_FADDX4
#define ALLOW_AVX2_FMADDX4

#define ALLOW_AVX2_MULX1
#define ALLOW_AVX2_ADDX1
#define ALLOW_AVX2_MADDX1

#define USE_NEW_FMUL_AVX2
#define USE_NEW_FADD_AVX2
#define USE_NEW_FMADD_AVX2

#define USE_NEW_VMUL_AVX2
#define USE_NEW_VADD_AVX2
#define USE_NEW_VMADD_AVX2


#define USE_NEW_VFTOIX_AVX2_R5900
#define USE_NEW_VITOFX_AVX2_R5900

#define USE_NEW_FFTOIX_AVX2_R5900


#define USE_NEW_VPREFIX_SEQUENCE_R5900
#define USE_NEW_ADD_SEQUENCE_R5900
#define USE_NEW_ADDI_SEQUENCE_R5900
#define USE_NEW_DADD_SEQUENCE_R5900
#define USE_NEW_DADDI_SEQUENCE_R5900



// try to simulate float 1*x multiplication inaccuracy on ps2
#define ENABLE_MUL_INACCURACY_AVX2
//#define ENABLE_MUL_INACCURACY_AVX512


// use virtual machine to manage vu0 macro mode instead of recompiler
// this define exists in: R5900.cpp, R5900_Recompiler.cpp
//#define ENABLE_VIRTUAL_MACHINE_MACRO_RUN


// enable generating pre-analysis info (disabled for now)
//#define ENABLE_PREANALYZE_BLOCK


#define ALLOW_AVX2_PADSBH
#define ALLOW_AVX2_PABSH
#define ALLOW_AVX2_PABSW
#define ALLOW_AVX2_PAND
#define ALLOW_AVX2_PXOR
#define ALLOW_AVX2_POR
#define ALLOW_AVX2_PNOR

#define ALLOW_AVX2_PSLLH
#define ALLOW_AVX2_PSLLW
#define ALLOW_AVX2_PSRLH
#define ALLOW_AVX2_PSRLW
#define ALLOW_AVX2_PSRAH
#define ALLOW_AVX2_PSRAW

#define ALLOW_AVX2_PSLLVW
#define ALLOW_AVX2_PSRLVW
#define ALLOW_AVX2_PSRAVW


#define ALLOW_AVX2_PMFHL_LH
#define ALLOW_AVX2_PMFHL_LW
#define ALLOW_AVX2_PMFHL_UW
#define ALLOW_AVX2_PMTHL_LW
#define ALLOW_AVX2_PMFHL_SH
#define ALLOW_AVX2_PMFHL_SLW


#define ALLOW_AVX2_PMADDH
#define ALLOW_AVX2_PMADDW
#define ALLOW_AVX2_PMADDUW
#define ALLOW_AVX2_PMSUBH
#define ALLOW_AVX2_PMSUBW

#define ALLOW_AVX2_PMULTH
#define ALLOW_AVX2_PMULTW
#define ALLOW_AVX2_PMULTUW

#define ALLOW_AVX2_PHMADH
#define ALLOW_AVX2_PHMSBH

#define ALLOW_AVX2_PDIVBW

#define ALLOW_AVX2_PADDB
#define ALLOW_AVX2_PADDH
#define ALLOW_AVX2_PADDW
#define ALLOW_AVX2_PSUBB
#define ALLOW_AVX2_PSUBH
#define ALLOW_AVX2_PSUBW

#define ALLOW_AVX2_PADDSB
#define ALLOW_AVX2_PADDSH
#define ALLOW_AVX2_PADDSW
#define ALLOW_AVX2_PSUBSB
#define ALLOW_AVX2_PSUBSH
#define ALLOW_AVX2_PSUBSW

#define ALLOW_AVX2_PADDUB
#define ALLOW_AVX2_PADDUH
#define ALLOW_AVX2_PADDUW
#define ALLOW_AVX2_PSUBUB
#define ALLOW_AVX2_PSUBUH
#define ALLOW_AVX2_PSUBUW

#define ALLOW_AVX2_PMAXH
#define ALLOW_AVX2_PMAXW
#define ALLOW_AVX2_PMINH
#define ALLOW_AVX2_PMINW

#define ALLOW_AVX2_PPACB
#define ALLOW_AVX2_PPACH
#define ALLOW_AVX2_PPACW

#define ALLOW_AVX2_PEXT5
#define ALLOW_AVX2_PPAC5

#define ALLOW_AVX2_PCGTB
#define ALLOW_AVX2_PCGTH
#define ALLOW_AVX2_PCGTW

#define ALLOW_AVX2_PCEQB
#define ALLOW_AVX2_PCEQH
#define ALLOW_AVX2_PCEQW

#define ALLOW_AVX2_PEXTLB
#define ALLOW_AVX2_PEXTLH
#define ALLOW_AVX2_PEXTLW
#define ALLOW_AVX2_PEXTUB
#define ALLOW_AVX2_PEXTUH
#define ALLOW_AVX2_PEXTUW

#define ALLOW_AVX2_PMFLO
#define ALLOW_AVX2_PMFHI
#define ALLOW_AVX2_PINTH
#define ALLOW_AVX2_PINTEH

#define ALLOW_AVX2_PREVH
#define ALLOW_AVX2_PEXEH
#define ALLOW_AVX2_PEXEW
#define ALLOW_AVX2_PROT3W

#define ALLOW_AVX2_PMTHI
#define ALLOW_AVX2_PMTLO

#define ALLOW_AVX2_PCPYLD
#define ALLOW_AVX2_PCPYUD
#define ALLOW_AVX2_PCPYH
#define ALLOW_AVX2_PEXCH
#define ALLOW_AVX2_PEXCW


#define ALLOW_AVX2_QFSRV


// virtual machine defines


#define ENABLE_PS2_VIRTUAL_MACHINE_SB
#define ENABLE_PS2_VIRTUAL_MACHINE_SH
#define ENABLE_PS2_VIRTUAL_MACHINE_SW
#define ENABLE_PS2_VIRTUAL_MACHINE_SD
#define ENABLE_PS2_VIRTUAL_MACHINE_SQ
#define ENABLE_PS2_VIRTUAL_MACHINE_SWC1
#define ENABLE_PS2_VIRTUAL_MACHINE_SQC2
#define ENABLE_PS2_VIRTUAL_MACHINE_SWL
#define ENABLE_PS2_VIRTUAL_MACHINE_SWR
#define ENABLE_PS2_VIRTUAL_MACHINE_SDL
#define ENABLE_PS2_VIRTUAL_MACHINE_SDR


#define ENABLE_PS2_VIRTUAL_MACHINE_LB
#define ENABLE_PS2_VIRTUAL_MACHINE_LH
#define ENABLE_PS2_VIRTUAL_MACHINE_LBU
#define ENABLE_PS2_VIRTUAL_MACHINE_LHU
#define ENABLE_PS2_VIRTUAL_MACHINE_LW
#define ENABLE_PS2_VIRTUAL_MACHINE_LWU
#define ENABLE_PS2_VIRTUAL_MACHINE_LD
#define ENABLE_PS2_VIRTUAL_MACHINE_LQ
#define ENABLE_PS2_VIRTUAL_MACHINE_LQC2
#define ENABLE_PS2_VIRTUAL_MACHINE_LWL
#define ENABLE_PS2_VIRTUAL_MACHINE_LWR
#define ENABLE_PS2_VIRTUAL_MACHINE_LDL
#define ENABLE_PS2_VIRTUAL_MACHINE_LDR
#define ENABLE_PS2_VIRTUAL_MACHINE_LWC1



#define CHECK_EVENT_AFTER_START_LOAD
#define ENABLE_TEST_ALIGNED_LOAD

#define CHECK_EVENT_AFTER_START_STORE
#define ENABLE_TEST_ALIGNED_STORE

//#define CHECK_EVENT_AFTER_START_LOAD_VIRTUAL
//#define CHECK_EVENT_AFTER_START_STORE_VIRTUAL


// enables the storage of exception info in the case of an exception
//#define ENABLE_EXCEPTION_INFO_VIRTUAL
//#define ENABLE_EXCEPTION_INFO_FLOAT




// skips idle cycles
#define ENABLE_R5900_SKIP_IDLE_CYCLES


#define ENABLE_ICACHE

// enables d-cache on R5900
// must be enabled here and in R5900_Execute.cpp, R5900_DCache.h
// note: sometimes this is required
// ***todo*** does not work perfectly yet
//#define ENABLE_R5900_DCACHE


#ifdef ENABLE_R5900_DCACHE

//#define DCACHE_FORCE_MEMPTR

//#define DCACHE_READ_MEMORY
//#define DCACHE_WRITE_MEMORY


#define ENABLE_DCACHE_DATA_READ
#define ENABLE_DCACHE_DATA_WRITE

#define ENABLE_DCACHE_TIMING_LOAD
#define ENABLE_DCACHE_TIMING_STORE

#define ENABLE_BUS_SIMULATION_CACHE_LOAD
#define ENABLE_BUS_SIMULATION_CACHE_STORE

#endif


// enables timing per register for availability
//#define ENABLE_GPR_REGISTER_TIMING

// check if next instruction is depending on current load
#define ENABLE_NEXT_DEPENDENCY_CHECK


// enables forward branching
//#define USE_FORWARD_BRANCH




//#define ENABLE_CPU_IDLE


#define ENABLE_FPU_LATENCY


//#define ENABLE_OPTIMIZED_REG_READS


//#define OPTIMIZE_RO_MULTIPLY_MUL_SSE
#define OPTIMIZE_RO_MULTIPLY_MADD


// after running a compiled block go to the next one
//#define ENABLE_CONNECT_ADJACENT_BLOCKS


#define ENABLE_R5900_BRANCH_PREDICTION
#define ENABLE_R5900_BRANCH_PREDICTION_RECOMPILER
#define ENABLE_R5900_BRANCH_PREDICTION_TRAP
#define ENABLE_R5900_BRANCH_PREDICTION_SYSCALL


//#define ENABLE_AUTO_BRANCH


#define USE_SHORT_LWL_CODE

// possibly int32_ter is better for lwr ??
//#define USE_SHORT_LWR_CODE

#define USE_SHORT_LDL_CODE
#define USE_SHORT_LDR_CODE

#define USE_SHORT_QFSRV_CODE
#define USE_SHORT_SWL_CODE
#define USE_SHORT_SWR_CODE

#define USE_SHORT_SDL_CODE
#define USE_SHORT_SDR_CODE


#define ENABLE_MULTIPLY_LATENCY
#define ENABLE_DIVIDE_LATENCY



#define USE_NEW_LQC2_CODE
#define USE_NEW_LOAD_CODE_LWL
#define USE_NEW_LOAD_CODE_LWR
#define USE_NEW_LOAD_CODE_LDL
#define USE_NEW_LOAD_CODE_LDR
#define USE_NEW_LOAD_CODE



#define USE_NEW_SQC2_CODE
#define USE_NEW_STORE_CODE_SWL
#define USE_NEW_STORE_CODE_SWR
#define USE_NEW_STORE_CODE_SDL
#define USE_NEW_STORE_CODE_SDR
#define USE_NEW_STORE_CODE



#define ENABLE_INLINE_STORE
#define ENABLE_INLINE_LOAD




#define USE_NEW_PADDSW_CODE
#define USE_NEW_PADDUW_CODE
#define USE_NEW_PSUBSW_CODE
#define USE_NEW_PSUBUW_CODE



#define USE_NEW_SYSCALL_CODE


#define USE_NEW_J_CODE
#define USE_NEW_JR_CODE
#define USE_NEW_JAL_CODE
#define USE_NEW_JALR_CODE


#define USE_NEW_BC1T_CODE
#define USE_NEW_BC1TL_CODE
#define USE_NEW_BC1F_CODE
#define USE_NEW_BC1FL_CODE

#define USE_NEW_BEQ_CODE
#define USE_NEW_BNE_CODE
#define USE_NEW_BLTZ_CODE
#define USE_NEW_BGTZ_CODE
#define USE_NEW_BLEZ_CODE
#define USE_NEW_BGEZ_CODE

#define USE_NEW_BLTZAL_CODE
#define USE_NEW_BGEZAL_CODE

#define USE_NEW_BEQL_CODE
#define USE_NEW_BNEL_CODE
#define USE_NEW_BLTZL_CODE
#define USE_NEW_BGTZL_CODE
#define USE_NEW_BLEZL_CODE
#define USE_NEW_BGEZL_CODE

#define USE_NEW_BLTZALL_CODE
#define USE_NEW_BGEZALL_CODE


#define USE_NEW_VLQD_CODE
#define USE_NEW_VLQI_CODE
#define USE_NEW_VSQD_CODE
#define USE_NEW_VSQI_CODE
#define USE_NEW_VILWR_CODE
#define USE_NEW_VISWR_CODE


#define USE_NEW_ADD_CODE
#define USE_NEW_ADDI_CODE
#define USE_NEW_SUB_CODE


#define ALLOW_ENCODING_DELAYSLOT
#define ENCODE_ALL_POSSIBLE_DELAYSLOTS

#define USE_NEW_DADD_CODE
#define USE_NEW_DADDI_CODE
#define USE_NEW_DSUB_CODE

#define USE_NEW_DADDU_CODE
#define USE_NEW_DADDIU_CODE
#define USE_NEW_DSUBU_CODE


#define USE_NEW_MFHI_CODE
#define USE_NEW_MFLO_CODE

#define USE_NEW_MULT_CODE
#define USE_NEW_MULTU_CODE
#define USE_NEW_DIV_CODE
#define USE_NEW_DIVU_CODE

#define USE_NEW_MULT1_CODE
#define USE_NEW_MULTU1_CODE
#define USE_NEW_DIV1_CODE
#define USE_NEW_DIVU1_CODE

#define USE_NEW_MFHI1_CODE
#define USE_NEW_MFLO1_CODE

#define USE_NEW_MADD_CODE
#define USE_NEW_MADD1_CODE
#define USE_NEW_MADDU_CODE
#define USE_NEW_MADDU1_CODE


#define USE_NEW_PAND_CODE
#define USE_NEW_POR_CODE
#define USE_NEW_PXOR_CODE
#define USE_NEW_PNOR_CODE

#define USE_NEW_PCEQB_CODE
#define USE_NEW_PCEQH_CODE
#define USE_NEW_PCEQW_CODE

#define USE_NEW_PCGTB_CODE
#define USE_NEW_PCGTH_CODE
#define USE_NEW_PCGTW_CODE

#define USE_NEW_PMINH_CODE
#define USE_NEW_PMINW_CODE
#define USE_NEW_PMAXH_CODE
#define USE_NEW_PMAXW_CODE

#define USE_NEW_PADDB_CODE
#define USE_NEW_PADDH_CODE
#define USE_NEW_PADDW_CODE

#define USE_NEW_PSUBB_CODE
#define USE_NEW_PSUBH_CODE
#define USE_NEW_PSUBW_CODE

#define USE_NEW_PABSH_CODE
#define USE_NEW_PABSW_CODE

#define USE_NEW_PADDSB_CODE
#define USE_NEW_PADDSH_CODE

#define USE_NEW_PADDUB_CODE
#define USE_NEW_PADDUH_CODE

#define USE_NEW_PSUBSB_CODE
#define USE_NEW_PSUBSH_CODE

#define USE_NEW_PSUBUB_CODE
#define USE_NEW_PSUBUH_CODE

#define USE_NEW_PSLLH_CODE
#define USE_NEW_PSLLW_CODE

#define USE_NEW_PSRAH_CODE

#define USE_NEW_PSRAW_CODE

#define USE_NEW_PSRLH_CODE
#define USE_NEW_PSRLW_CODE

#define USE_NEW_PSLLVW_CODE
#define USE_NEW_PSRAVW_CODE
#define USE_NEW_PSRLVW_CODE

#define USE_NEW_PEXTLB_CODE
#define USE_NEW_PEXTLH_CODE
#define USE_NEW_PEXTLW_CODE
#define USE_NEW_PEXTUB_CODE
#define USE_NEW_PEXTUH_CODE
#define USE_NEW_PEXTUW_CODE
#define USE_NEW_PINTH_CODE
#define USE_NEW_PINTEH_CODE

#define USE_NEW_PREVH_CODE

#define USE_NEW_PEXCH_CODE
#define USE_NEW_PEXCW_CODE
#define USE_NEW_PEXEH_CODE
#define USE_NEW_PEXEW_CODE

#define USE_NEW_PROT3W_CODE

#define USE_NEW_PCPYLD_CODE
#define USE_NEW_PCPYUD_CODE
#define USE_NEW_PCPYH_CODE

#define USE_NEW_PPACB_CODE
#define USE_NEW_PPACH_CODE
#define USE_NEW_PPACW_CODE

#define USE_NEW_QFSRV_CODE

#define USE_NEW_PADSBH_CODE
#define USE_NEW_PLZCW_CODE

#define USE_NEW_PMULTH_CODE
#define USE_NEW_PMULTW_CODE
#define USE_NEW_PMULTUW_CODE

#define USE_NEW_PDIVBW_CODE
#define USE_NEW_PDIVW_CODE
#define USE_NEW_PDIVUW_CODE

#define USE_NEW_PMADDH_CODE
#define USE_NEW_PMADDW_CODE
#define USE_NEW_PMADDUW_CODE
#define USE_NEW_PMSUBH_CODE
#define USE_NEW_PMSUBW_CODE

#define USE_NEW_PHMADH_CODE
#define USE_NEW_PHMSBH_CODE

#define USE_NEW_PMFLO_CODE
#define USE_NEW_PMFHI_CODE


#define USE_NEW_PMTLO_CODE
#define USE_NEW_PMTHI_CODE

#define USE_NEW_PMFHL_LH_CODE
#define USE_NEW_PMFHL_LW_CODE
#define USE_NEW_PMFHL_SH_CODE
#define USE_NEW_PMFHL_SLW_CODE
#define USE_NEW_PMFHL_UW_CODE

#define USE_NEW_PMTHL_LW_CODE

#define USE_NEW_PEXT5_CODE
#define USE_NEW_PPAC5_CODE


#define USE_NEW_ABS_S_CODE
#define USE_NEW_MOV_S_CODE
#define USE_NEW_NEG_S_CODE
#define USE_NEW_MAX_S_CODE
#define USE_NEW_MIN_S_CODE
#define USE_NEW_C_F_S_CODE

#define USE_NEW_C_EQ_S_CODE
#define USE_NEW_C_LT_S_CODE
#define USE_NEW_C_LE_S_CODE


#define USE_NEW_MUL_S_CODE
#define USE_NEW_MULA_S_CODE

#define USE_NEW_DIV_S_CODE


#define USE_NEW_ADD_S_CODE
#define USE_NEW_ADDA_S_CODE


#define USE_NEW_SUB_S_CODE


#define USE_NEW_SUBA_S_CODE


#define USE_NEW_SQRT_S_CODE
#define USE_NEW_RSQRT_S_CODE


#define USE_NEW_CVT_S_W_CODE
#define USE_NEW_CVT_W_S_CODE

#define USE_NEW_MADD_S_CODE
#define USE_NEW_MADDA_S_CODE
#define USE_NEW_MSUB_S_CODE
#define USE_NEW_MSUBA_S_CODE





#define USE_NEW_VNOP_CODE

#define USE_NEW_VABS_CODE

#define USE_NEW_VMAX_CODE
#define USE_NEW_VMIN_CODE



#define USE_NEW_VFTOI0_CODE
#define USE_NEW_VFTOI4_CODE
#define USE_NEW_VFTOI12_CODE
#define USE_NEW_VFTOI15_CODE


#define USE_NEW_VITOF0_CODE
#define USE_NEW_VITOF4_CODE
#define USE_NEW_VITOF12_CODE
#define USE_NEW_VITOF15_CODE



#define USE_NEW_VMOVE_CODE
#define USE_NEW_VMR32_CODE


#define USE_NEW_VIADD_CODE
#define USE_NEW_VIADDI_CODE
#define USE_NEW_VIAND_CODE
#define USE_NEW_VIOR_CODE
#define USE_NEW_VISUB_CODE


#define USE_NEW_VMFIR_CODE
#define USE_NEW_VMTIR_CODE


#define USE_NEW_CFC2_NI_CODE
#define USE_NEW_CTC2_NI_CODE


#define USE_NEW_QMFC2_NI_CODE
#define USE_NEW_QMTC2_NI_CODE


#define USE_NEW_VDIV_CODE
#define USE_NEW_VRSQRT_CODE
#define USE_NEW_VSQRT_CODE


#define USE_NEW_VCLIP_CODE


#define USE_NEW_VADD_CODE
#define USE_NEW_VADDi_CODE
#define USE_NEW_VADDq_CODE
#define USE_NEW_VADDX_CODE
#define USE_NEW_VADDY_CODE
#define USE_NEW_VADDZ_CODE
#define USE_NEW_VADDW_CODE


#define USE_NEW_VADDA_CODE
#define USE_NEW_VADDAi_CODE
#define USE_NEW_VADDAq_CODE
#define USE_NEW_VADDAX_CODE
#define USE_NEW_VADDAY_CODE
#define USE_NEW_VADDAZ_CODE
#define USE_NEW_VADDAW_CODE


#define USE_NEW_VSUB_CODE
#define USE_NEW_VSUBi_CODE
#define USE_NEW_VSUBq_CODE
#define USE_NEW_VSUBX_CODE
#define USE_NEW_VSUBY_CODE
#define USE_NEW_VSUBZ_CODE
#define USE_NEW_VSUBW_CODE

#define USE_NEW_VSUBA_CODE
#define USE_NEW_VSUBAi_CODE
#define USE_NEW_VSUBAq_CODE
#define USE_NEW_VSUBAX_CODE
#define USE_NEW_VSUBAY_CODE
#define USE_NEW_VSUBAZ_CODE
#define USE_NEW_VSUBAW_CODE


#define USE_NEW_VMUL_CODE
#define USE_NEW_VMULi_CODE
#define USE_NEW_VMULq_CODE
#define USE_NEW_VMULX_CODE
#define USE_NEW_VMULY_CODE
#define USE_NEW_VMULZ_CODE
#define USE_NEW_VMULW_CODE


#define USE_NEW_VMULA_CODE
#define USE_NEW_VMULAi_CODE
#define USE_NEW_VMULAq_CODE
#define USE_NEW_VMULAX_CODE
#define USE_NEW_VMULAY_CODE
#define USE_NEW_VMULAZ_CODE
#define USE_NEW_VMULAW_CODE


#define USE_NEW_VMADD_CODE
#define USE_NEW_VMADDi_CODE
#define USE_NEW_VMADDq_CODE
#define USE_NEW_VMADDX_CODE
#define USE_NEW_VMADDY_CODE
#define USE_NEW_VMADDZ_CODE
#define USE_NEW_VMADDW_CODE


#define USE_NEW_VMADDA_CODE
#define USE_NEW_VMADDAi_CODE
#define USE_NEW_VMADDAq_CODE
#define USE_NEW_VMADDAX_CODE
#define USE_NEW_VMADDAY_CODE
#define USE_NEW_VMADDAZ_CODE
#define USE_NEW_VMADDAW_CODE


#define USE_NEW_VMSUB_CODE
#define USE_NEW_VMSUBi_CODE
#define USE_NEW_VMSUBq_CODE
#define USE_NEW_VMSUBX_CODE
#define USE_NEW_VMSUBY_CODE
#define USE_NEW_VMSUBZ_CODE
#define USE_NEW_VMSUBW_CODE


#define USE_NEW_VMSUBA_CODE
#define USE_NEW_VMSUBAi_CODE
#define USE_NEW_VMSUBAq_CODE
#define USE_NEW_VMSUBAX_CODE
#define USE_NEW_VMSUBAY_CODE
#define USE_NEW_VMSUBAZ_CODE
#define USE_NEW_VMSUBAW_CODE


#define USE_NEW_VOPMSUB_CODE
#define USE_NEW_VOPMULA_CODE





#define USE_NEW_ADDU_CODE2
#define USE_NEW_SUBU_CODE2


#define USE_NEW_AND_CODE2
#define USE_NEW_OR_CODE2
#define USE_NEW_XOR_CODE2
#define USE_NEW_NOR_CODE2



#define USE_NEW_SLT_CODE2
#define USE_NEW_SLTU_CODE2


#define USE_NEW_ADDIU_CODE2
#define USE_NEW_ANDI_CODE2
#define USE_NEW_ORI_CODE2
#define USE_NEW_XORI_CODE2

#define USE_NEW_LUI_CODE2


#define USE_NEW_SLTI_CODE2
#define USE_NEW_SLTIU_CODE2




#define USE_NEW_SLL_CODE2
#define USE_NEW_SRL_CODE2
#define USE_NEW_SRA_CODE2

#define USE_NEW_SLLV_CODE2
#define USE_NEW_SRLV_CODE2
#define USE_NEW_SRAV_CODE2


#define USE_NEW_SB_CODE2
#define USE_NEW_SH_CODE2
#define USE_NEW_SW_CODE2
#define USE_NEW_SWR_CODE2
#define USE_NEW_SWL_CODE2
#define USE_NEW_SD_CODE2
#define USE_NEW_SDR_CODE2
#define USE_NEW_SDL_CODE2


//#define USE_NEW_SQ_CODE2
//#define USE_NEW_SQC2_CODE2


#define USE_NEW_LB_CODE2
#define USE_NEW_LH_CODE2
#define USE_NEW_LW_CODE2
#define USE_NEW_LBU_CODE2
#define USE_NEW_LHU_CODE2
#define USE_NEW_LWU_CODE2
#define USE_NEW_LD_CODE2


#define USE_NEW_LWR_CODE2
#define USE_NEW_LWL_CODE2
#define USE_NEW_LDL_CODE2
#define USE_NEW_LDR_CODE2


//#define USE_NEW_LQ_CODE2
//#define USE_NEW_LQC2_CODE2


#define USE_NEW_DADDU_CODE2
#define USE_NEW_DSUBU_CODE2

#define USE_NEW_DADDIU_CODE2

#define USE_NEW_DSLL_CODE2
#define USE_NEW_DSRL_CODE2
#define USE_NEW_DSRA_CODE2

#define USE_NEW_DSLL32_CODE2
#define USE_NEW_DSRL32_CODE2
#define USE_NEW_DSRA32_CODE2

#define USE_NEW_DSLLV_CODE2
#define USE_NEW_DSRLV_CODE2
#define USE_NEW_DSRAV_CODE2

#define USE_NEW_MOVZ_CODE2
#define USE_NEW_MOVN_CODE2


#define USE_NEW_VRINIT_CODE
#define USE_NEW_VRGET_CODE
#define USE_NEW_VRXOR_CODE
#define USE_NEW_VRNEXT_CODE



#define CHECK_EVENT_AFTER_START
//#define CHECK_EVENT_AFTER_START_BRANCH


//#define ENABLE_SINGLE_STEP
//#define ENABLE_SINGLE_STEP_BEFORE


#define CACHE_NOT_IMPLEMENTED


// check that instructions in cached-region were not modified since last recompile
//#define CHECK_CACHED_INSTRUCTIONS


//#define USE_MEMORYPTR_FOR_CACHED_REGION


//#define USE_GETPTR_FOR_CACHED_REGION


// theoretically, anything in BIOS is read-only
//#define DONT_CHECK_BIOS_INSTRUCTIONS



//#define INCLUDE_ICACHE_RELOAD




//#define ALWAYS_USE_MEMORYPTR_FOR_ENCODING


#define ENCODE_SINGLE_RUN_PER_BLOCK


#define UPDATE_BEFORE_RETURN


// crashes unless you do this ?? Compiler dependent?
#define RESERVE_STACK_FRAME_FOR_CALL


//#define ENABLE_AUTONOMOUS_BRANCH_U
//#define ENABLE_AUTONOMOUS_BRANCH_C


//#define VERBOSE_RECOMPILE


static u32* g_pSrcCodePtr;

Debug::Log R5900::Recompiler::debug;

x64Encoder *R5900::Recompiler::e;
x64asm::x64Assembler* R5900::Recompiler::x;


//ICache_Device *R5900::Recompiler::ICache;
R5900::Cpu *R5900::Recompiler::r;
s32 R5900::Recompiler::OpLevel;
u32 R5900::Recompiler::LocalPC;
u32 R5900::Recompiler::Local_LastModifiedReg;
u32 R5900::Recompiler::Local_NextPCModified;

u32 R5900::Recompiler::CurrentCount;

u32 R5900::Recompiler::isBranchDelaySlot;
u32 R5900::Recompiler::isLoadDelaySlot;

u32 R5900::Recompiler::bStopEncodingAfter;
u32 R5900::Recompiler::bStopEncodingBefore;

u32 R5900::Recompiler::NumBlocks_Mask;
u32* R5900::Recompiler::StartAddress;
u32* R5900::Recompiler::LastOffset;

u32* R5900::Recompiler::pSourceCode32;

u64* R5900::Recompiler::pHWRWBitmap64;
u16* R5900::Recompiler::pMacroBitmap16;

u32 R5900::Recompiler::xcomp;
u32 R5900::Recompiler::FInstHist[4];
u32 R5900::Recompiler::LUT_StatInfo[16];

//u32 R5900::Recompiler::Local_DelaySlot;
//u32 R5900::Recompiler::Local_DelayType;
//u32 R5900::Recompiler::Local_DelayCount;
//u32 R5900::Recompiler::Local_DelayCond;
//u32 R5900::Recompiler::Local_Condition;
R5900::Instruction::Format R5900::Recompiler::NextInst;
R5900::Instruction::Format R5900::Recompiler::PrevInst;

//R5900::Recompiler::RDelaySlot R5900::Recompiler::RDelaySlots [ 2 ];
//u32 R5900::Recompiler::DSIndex;
//u32 R5900::Recompiler::RDelaySlots_Valid;

u32 R5900::Recompiler::RunCount;
u32 R5900::Recompiler::RunCount2;

u64 R5900::Recompiler::MemCycles;
u64 R5900::Recompiler::ullLoadCycles;

u64 R5900::Recompiler::LocalCycleCount;
u64 R5900::Recompiler::LocalCycleCount2;
u64 R5900::Recompiler::CacheBlock_CycleCount;

bool R5900::Recompiler::bIsBlockInICache;

u32 R5900::Recompiler::bResetCycleCount;


u32 R5900::Recompiler::CurrentBlock_StartAddress;
u32 R5900::Recompiler::NextBlock_StartAddress;

u32* R5900::Recompiler::pForwardBranchTargets;
u32 R5900::Recompiler::ForwardBranchIndex;

u8** R5900::Recompiler::pPrefix_CodeStart;
u8** R5900::Recompiler::pCodeStart;
u32* R5900::Recompiler::CycleCount;


#ifdef ENABLE_R5900_CHECKSUM
u64* R5900::Recompiler::pChecksum64;
#endif


u32 R5900::Recompiler::ulIndex_Mask;
u32 R5900::Recompiler::MaxStep;
u32 R5900::Recompiler::MaxStep_Shift;
u32 R5900::Recompiler::MaxStep_Mask;

u32 R5900::Recompiler::StartBlockIndex;
u32 R5900::Recompiler::BlockIndex;


// static vars
int R5900::Recompiler::iVectorType;
int R5900::Recompiler::iRecompilerWidth;


u64 R5900::Recompiler::ullLSRegs;

// multi-pass optimization vars //
u64 R5900::Recompiler::ullSrcRegBitmap;
u64 R5900::Recompiler::ullDstRegBitmap;

// the x64 registers that are currently allocated to MIPS registers
u64 R5900::Recompiler::ullTargetAlloc;

// the MIPS registers that are currently allocated to x64 registers
u64 R5900::Recompiler::ullSrcRegAlloc;

// the MIPS registers that are currently allocated to be constants
u64 R5900::Recompiler::ullSrcConstAlloc;

// the MIPS registers that have been modified and not written back yet
u64 R5900::Recompiler::ullSrcRegsModified;

// registers that are on the stack and need to be restored when done
u64 R5900::Recompiler::ullRegsOnStack;

// registers that are needed later on in the code
u64 R5900::Recompiler::ullNeededLater;

u64 R5900::Recompiler::ullSrcRegBitmaps [ 16 ];
u64 R5900::Recompiler::ullDstRegBitmaps [ 16 ];
u64 R5900::Recompiler::ullRegsStillNeeded [ 16 ];

// the actual data stored for the register, either a reg index or a constant value
u64 R5900::Recompiler::ullTargetData [ 32 ];


// lookup that indicates what register each target index corresponds to
const int R5900::Recompiler::iRegPriority [ 13 ] = { RAX, RDX, R8, R9, R10, R11, RBX, RSI, RDI, R12, R13, R14, R15 };

// lookup that indicates if the register requires you to save it on the stack before using it
// 0: no need to save on stack, 1: save and restore on stack
const int R5900::Recompiler::iRegStackSave [ 13 ] = { 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1 };



alignas(16) static const u8 recompiler_qfsrv_shift_table [ 16 * 16 ] = {
	0xf, 0xe, 0xd, 0xc, 0xb, 0xa, 0x9, 0x8, 0x7, 0x6, 0x5, 0x4, 0x3, 0x2, 0x1, 0x0,
	0x0, 0xf, 0xe, 0xd, 0xc, 0xb, 0xa, 0x9, 0x8, 0x7, 0x6, 0x5, 0x4, 0x3, 0x2, 0x1,
	0x1, 0x0, 0xf, 0xe, 0xd, 0xc, 0xb, 0xa, 0x9, 0x8, 0x7, 0x6, 0x5, 0x4, 0x3, 0x2,
	0x2, 0x1, 0x0, 0xf, 0xe, 0xd, 0xc, 0xb, 0xa, 0x9, 0x8, 0x7, 0x6, 0x5, 0x4, 0x3,
	0x3, 0x2, 0x1, 0x0, 0xf, 0xe, 0xd, 0xc, 0xb, 0xa, 0x9, 0x8, 0x7, 0x6, 0x5, 0x4,
	0x4, 0x3, 0x2, 0x1, 0x0, 0xf, 0xe, 0xd, 0xc, 0xb, 0xa, 0x9, 0x8, 0x7, 0x6, 0x5,
	0x5, 0x4, 0x3, 0x2, 0x1, 0x0, 0xf, 0xe, 0xd, 0xc, 0xb, 0xa, 0x9, 0x8, 0x7, 0x6,
	0x6, 0x5, 0x4, 0x3, 0x2, 0x1, 0x0, 0xf, 0xe, 0xd, 0xc, 0xb, 0xa, 0x9, 0x8, 0x7,
	0x7, 0x6, 0x5, 0x4, 0x3, 0x2, 0x1, 0x0, 0xf, 0xe, 0xd, 0xc, 0xb, 0xa, 0x9, 0x8,
	0x8, 0x7, 0x6, 0x5, 0x4, 0x3, 0x2, 0x1, 0x0, 0xf, 0xe, 0xd, 0xc, 0xb, 0xa, 0x9,
	0x9, 0x8, 0x7, 0x6, 0x5, 0x4, 0x3, 0x2, 0x1, 0x0, 0xf, 0xe, 0xd, 0xc, 0xb, 0xa,
	0xa, 0x9, 0x8, 0x7, 0x6, 0x5, 0x4, 0x3, 0x2, 0x1, 0x0, 0xf, 0xe, 0xd, 0xc, 0xb,
	0xb, 0xa, 0x9, 0x8, 0x7, 0x6, 0x5, 0x4, 0x3, 0x2, 0x1, 0x0, 0xf, 0xe, 0xd, 0xc,
	0xc, 0xb, 0xa, 0x9, 0x8, 0x7, 0x6, 0x5, 0x4, 0x3, 0x2, 0x1, 0x0, 0xf, 0xe, 0xd,
	0xd, 0xc, 0xb, 0xa, 0x9, 0x8, 0x7, 0x6, 0x5, 0x4, 0x3, 0x2, 0x1, 0x0, 0xf, 0xe,
	0xe, 0xd, 0xc, 0xb, 0xa, 0x9, 0x8, 0x7, 0x6, 0x5, 0x4, 0x3, 0x2, 0x1, 0x0, 0xf
};

// with the right as dest and left as src
alignas(16) static const u8 recompiler_qfsrv_blend_table [ 16 * 16 ] = {
	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
	0x80, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
	0x80, 0x80, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
	0x80, 0x80, 0x80, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
	0x80, 0x80, 0x80, 0x80, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
	0x80, 0x80, 0x80, 0x80, 0x80, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
	0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
	0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
	0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
	0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
	0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
	0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x00, 0x00, 0x00, 0x00, 0x00,
	0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x00, 0x00, 0x00, 0x00,
	0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x00, 0x00, 0x00,
	0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x00, 0x00,
	0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x00
};


alignas(16) static const u8 recompiler_qfsrv_shift_table_rev [ 16 * 16 ] = {
	0x0, 0x1, 0x2, 0x3, 0x4, 0x5, 0x6, 0x7, 0x8, 0x9, 0xa, 0xb, 0xc, 0xd, 0xe, 0xf,
	0x1, 0x2, 0x3, 0x4, 0x5, 0x6, 0x7, 0x8, 0x9, 0xa, 0xb, 0xc, 0xd, 0xe, 0xf, 0x0,
	0x2, 0x3, 0x4, 0x5, 0x6, 0x7, 0x8, 0x9, 0xa, 0xb, 0xc, 0xd, 0xe, 0xf, 0x0, 0x1,
	0x3, 0x4, 0x5, 0x6, 0x7, 0x8, 0x9, 0xa, 0xb, 0xc, 0xd, 0xe, 0xf, 0x0, 0x1, 0x2,
	0x4, 0x5, 0x6, 0x7, 0x8, 0x9, 0xa, 0xb, 0xc, 0xd, 0xe, 0xf, 0x0, 0x1, 0x2, 0x3,
	0x5, 0x6, 0x7, 0x8, 0x9, 0xa, 0xb, 0xc, 0xd, 0xe, 0xf, 0x0, 0x1, 0x2, 0x3, 0x4,
	0x6, 0x7, 0x8, 0x9, 0xa, 0xb, 0xc, 0xd, 0xe, 0xf, 0x0, 0x1, 0x2, 0x3, 0x4, 0x5,
	0x7, 0x8, 0x9, 0xa, 0xb, 0xc, 0xd, 0xe, 0xf, 0x0, 0x1, 0x2, 0x3, 0x4, 0x5, 0x6,
	0x8, 0x9, 0xa, 0xb, 0xc, 0xd, 0xe, 0xf, 0x0, 0x1, 0x2, 0x3, 0x4, 0x5, 0x6, 0x7,
	0x9, 0xa, 0xb, 0xc, 0xd, 0xe, 0xf, 0x0, 0x1, 0x2, 0x3, 0x4, 0x5, 0x6, 0x7, 0x8,
	0xa, 0xb, 0xc, 0xd, 0xe, 0xf, 0x0, 0x1, 0x2, 0x3, 0x4, 0x5, 0x6, 0x7, 0x8, 0x9,
	0xb, 0xc, 0xd, 0xe, 0xf, 0x0, 0x1, 0x2, 0x3, 0x4, 0x5, 0x6, 0x7, 0x8, 0x9, 0xa,
	0xc, 0xd, 0xe, 0xf, 0x0, 0x1, 0x2, 0x3, 0x4, 0x5, 0x6, 0x7, 0x8, 0x9, 0xa, 0xb,
	0xd, 0xe, 0xf, 0x0, 0x1, 0x2, 0x3, 0x4, 0x5, 0x6, 0x7, 0x8, 0x9, 0xa, 0xb, 0xc,
	0xe, 0xf, 0x0, 0x1, 0x2, 0x3, 0x4, 0x5, 0x6, 0x7, 0x8, 0x9, 0xa, 0xb, 0xc, 0xd,
	0xf, 0x0, 0x1, 0x2, 0x3, 0x4, 0x5, 0x6, 0x7, 0x8, 0x9, 0xa, 0xb, 0xc, 0xd, 0xe
};

// with the right as dest and left as src
alignas(16) static const u8 recompiler_qfsrv_blend_table_rev [ 16 * 16 ] = {
	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x80,
	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x80, 0x80,
	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x80, 0x80, 0x80,
	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x80, 0x80, 0x80, 0x80,
	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x80, 0x80, 0x80, 0x80, 0x80,
	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80,
	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80,
	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80,
	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80,
	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80,
	0x00, 0x00, 0x00, 0x00, 0x00, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80,
	0x00, 0x00, 0x00, 0x00, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80,
	0x00, 0x00, 0x00, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80,
	0x00, 0x00, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80,
	0x00, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80
};


//static u64 recompiler_qfsrv_temp [ 4 ] __attribute__ ((aligned (16)));
alignas(32) static u64 recompiler_r5900_temp [ 4 ];


// lookup table for op shuffles
u8 _op_r5900_shuffle_lut_1 [ 16 ] = {
0x00, // 0x0000
0x00, // 0x0001
0x55, // 0x0010
0x50, // 0x0011

0xa0, // 0x0100
0xa0, // 0x0101
0xa5, // 0x0110
0x00, // 0x0111

0xf0, // 0x1000
0xf0, // 0x1001
0xf5, // 0x1010
0x00, // 0x1011

0xfa, // 0x1100
0x00, // 0x1101
0x00, // 0x1110
0x00, // 0x1111
};

u8 _op_r5900_shuffle_lut_2 [ 16 ] = {
0x00, // 0x0000
0x0d, // 0x0001
0x0d, // 0x0010
0x0d, // 0x0011

0x30, // 0x0100
0x31, // 0x0101
0x34, // 0x0110
0x00, // 0x0111

0xc0, // 0x1000
0xc1, // 0x1001
0xc4, // 0x1010
0x00, // 0x1011

0xd0, // 0x1100
0x00, // 0x1101
0x00, // 0x1110
0x00, // 0x1111
};

u8 _op_r5900_add_shuffle_lut_2 [ 16 ] = {
0x00, // 0x0000
0x0a, // 0x0001
0x0a, // 0x0010
0x08, // 0x0011

0x20, // 0x0100
0x20, // 0x0101
0x20, // 0x0110
0x00, // 0x0111

0x80, // 0x1000
0x80, // 0x1001
0x80, // 0x1010
0x00, // 0x1011

0x80, // 0x1100
0x00, // 0x1101
0x00, // 0x1110
0x00, // 0x1111
};


void R5900::Recompiler::Exit_Recompiler(u32 PC, s64 CycleOffset)
{
	r->NextPC = PC;
	r->CycleCount += CycleOffset;

	return;
}




bool R5900::Recompiler::isCOP1(R5900::Instruction::Format i)
{
	if (i.Opcode == 0x11) return true;
	return false;
}

bool R5900::Recompiler::isFloat_ADD(R5900::Instruction::Format i)
{
	if (i.Opcode == 0x11)
	{
		if ((i.Rs == 0x10) && (i.Funct == 0x0)) return true;
	}

	return false;
}

bool R5900::Recompiler::isFloat_ADDA(R5900::Instruction::Format i)
{
	if (i.Opcode == 0x11)
	{
		if ((i.Rs == 0x10) && (i.Funct == 0x18)) return true;
	}

	return false;
}

bool R5900::Recompiler::isFloat_SUB(R5900::Instruction::Format i)
{
	if (i.Opcode == 0x11)
	{
		if ((i.Rs == 0x10) && (i.Funct == 0x01)) return true;
	}

	return false;
}

bool R5900::Recompiler::isFloat_SUBA(R5900::Instruction::Format i)
{
	if (i.Opcode == 0x11)
	{
		if ((i.Rs == 0x10) && (i.Funct == 0x19)) return true;
	}

	return false;
}

bool R5900::Recompiler::isFloat_MUL(R5900::Instruction::Format i)
{
	if (i.Opcode == 0x11)
	{
		if ((i.Rs == 0x10) && (i.Funct == 0x02)) return true;
	}

	return false;
}

bool R5900::Recompiler::isFloat_MULA(R5900::Instruction::Format i)
{
	if (i.Opcode == 0x11)
	{
		if ((i.Rs == 0x10) && (i.Funct == 0x1a)) return true;
	}

	return false;
}

bool R5900::Recompiler::isFloat_MADD(R5900::Instruction::Format i)
{
	if (i.Opcode == 0x11)
	{
		if ((i.Rs == 0x10) && (i.Funct == 0x1c)) return true;
	}

	return false;
}
bool R5900::Recompiler::isFloat_MADDA(R5900::Instruction::Format i)
{
	if (i.Opcode == 0x11)
	{
		if ((i.Rs == 0x10) && (i.Funct == 0x1e)) return true;
	}

	return false;
}
bool R5900::Recompiler::isFloat_MSUB(R5900::Instruction::Format i)
{
	if (i.Opcode == 0x11)
	{
		if ((i.Rs == 0x10) && (i.Funct == 0x1d)) return true;
	}

	return false;
}
bool R5900::Recompiler::isFloat_MSUBA(R5900::Instruction::Format i)
{
	if (i.Opcode == 0x11)
	{
		if ((i.Rs == 0x10) && (i.Funct == 0x1f)) return true;
	}

	return false;
}


bool R5900::Recompiler::isADD(R5900::Instruction::Format i)
{
	// ADD,ADDI,ADDQ,ADDBC
	return ((i.Funct == 0x28) || (i.Funct == 0x22) || (i.Funct == 0x20) || ((i.Funct & 0x3c) == 0x00));
}

bool R5900::Recompiler::isADDi(R5900::Instruction::Format i)
{
	// ADDI
	return ((i.Funct == 0x22));
}

bool R5900::Recompiler::isADDq(R5900::Instruction::Format i)
{
	// ADDQ
	return ((i.Funct == 0x20));
}

bool R5900::Recompiler::isADDBC(R5900::Instruction::Format i)
{
	// ADDBC
	return (((i.Funct & 0x3c) == 0x00));
}

bool R5900::Recompiler::isADDA(R5900::Instruction::Format i)
{
	// ADDA,ADDAI,ADDAQ,ADDABC
	return ((i.Imm11 == 0x2bc) || (i.Imm11 == 0x23e) || (i.Imm11 == 0x23c) || ((i.Imm11 & 0x7fc) == 0x03c));
}

bool R5900::Recompiler::isADDAi(R5900::Instruction::Format i)
{
	// ADDAI
	return ((i.Imm11 == 0x23e));
}
bool R5900::Recompiler::isADDAq(R5900::Instruction::Format i)
{
	// ADDAQ
	return ((i.Imm11 == 0x23c));
}
bool R5900::Recompiler::isADDABC(R5900::Instruction::Format i)
{
	// ADDABC
	return (((i.Imm11 & 0x7fc) == 0x03c));
}

bool R5900::Recompiler::isSUB(R5900::Instruction::Format i)
{
	// SUB,SUBI,SUBQ,SUBBC
	return ((i.Funct == 0x2c) || (i.Funct == 0x26) || (i.Funct == 0x24) || ((i.Funct & 0x3c) == 0x04));
}

bool R5900::Recompiler::isSUBi(R5900::Instruction::Format i)
{
	// SUBI
	return ((i.Funct == 0x26));
}
bool R5900::Recompiler::isSUBq(R5900::Instruction::Format i)
{
	// SUBQ
	return ((i.Funct == 0x24));
}
bool R5900::Recompiler::isSUBBC(R5900::Instruction::Format i)
{
	// SUBBC
	return (((i.Funct & 0x3c) == 0x04));
}

bool R5900::Recompiler::isSUBA(R5900::Instruction::Format i)
{
	// SUBA,SUBAI,SUBAQ,SUBABC
	return ((i.Imm11 == 0x2fc) || (i.Imm11 == 0x27e) || (i.Imm11 == 0x27c) || ((i.Imm11 & 0x7fc) == 0x07c));
}

bool R5900::Recompiler::isSUBAi(R5900::Instruction::Format i)
{
	// SUBAI
	return ((i.Imm11 == 0x27e));
}
bool R5900::Recompiler::isSUBAq(R5900::Instruction::Format i)
{
	// SUBAQ
	return ((i.Imm11 == 0x27c));
}
bool R5900::Recompiler::isSUBABC(R5900::Instruction::Format i)
{
	// SUBABC
	return (((i.Imm11 & 0x7fc) == 0x07c));
}



bool R5900::Recompiler::isMUL(R5900::Instruction::Format i)
{
	// MUL,MULI,MULQ,MULBC
	return ((i.Funct == 0x2a) || (i.Funct == 0x1e) || (i.Funct == 0x1c) || ((i.Funct & 0x3c) == 0x18));
}

bool R5900::Recompiler::isMULi(R5900::Instruction::Format i)
{
	// MULI
	return ((i.Funct == 0x1e));
}

bool R5900::Recompiler::isMULq(R5900::Instruction::Format i)
{
	// MULQ
	return ((i.Funct == 0x1c));
}

bool R5900::Recompiler::isMULBC(R5900::Instruction::Format i)
{
	// MULBC
	return (((i.Funct & 0x3c) == 0x18));
}

bool R5900::Recompiler::isMULA(R5900::Instruction::Format i)
{
	// MULA,MULAI,MULAQ,MULABC,OPMULA
	return ((i.Imm11 == 0x2be) || (i.Imm11 == 0x1fe) || (i.Imm11 == 0x1fc) || ((i.Imm11 & 0x7fc) == 0x1bc) || (i.Imm11 == 0x2fe));
}

bool R5900::Recompiler::isMULAi(R5900::Instruction::Format i)
{
	// MULAI
	return ((i.Imm11 == 0x1fe));
}

bool R5900::Recompiler::isMULAq(R5900::Instruction::Format i)
{
	// MULAQ
	return ((i.Imm11 == 0x1fc));
}

bool R5900::Recompiler::isMULABC(R5900::Instruction::Format i)
{
	// MULABC
	return (((i.Imm11 & 0x7fc) == 0x1bc));
}


bool R5900::Recompiler::isMADD(R5900::Instruction::Format i)
{
	// MADD,MADDI,MADDQ,MADDBC
	return ((i.Funct == 0x29) || (i.Funct == 0x23) || (i.Funct == 0x21) || ((i.Funct & 0x3c) == 0x08));
}

bool R5900::Recompiler::isMADDi(R5900::Instruction::Format i)
{
	// MADDI
	return ((i.Funct == 0x23));
}
bool R5900::Recompiler::isMADDq(R5900::Instruction::Format i)
{
	// MADDQ
	return ((i.Funct == 0x21));
}
bool R5900::Recompiler::isMADDBC(R5900::Instruction::Format i)
{
	// MADDBC
	return (((i.Funct & 0x3c) == 0x08));
}

bool R5900::Recompiler::isMADDA(R5900::Instruction::Format i)
{
	// MADDA,MADDAI,MADDAQ,MADDABC
	return ((i.Imm11 == 0x2bd) || (i.Imm11 == 0x23f) || (i.Imm11 == 0x23d) || ((i.Imm11 & 0x7fc) == 0x0bc));
}

bool R5900::Recompiler::isMADDAi(R5900::Instruction::Format i)
{
	// MADDAI
	return ((i.Imm11 == 0x23f));
}
bool R5900::Recompiler::isMADDAq(R5900::Instruction::Format i)
{
	// MADDAQ
	return ((i.Imm11 == 0x23d));
}
bool R5900::Recompiler::isMADDABC(R5900::Instruction::Format i)
{
	// MADDABC
	return (((i.Imm11 & 0x7fc) == 0x0bc));
}

bool R5900::Recompiler::isMSUB(R5900::Instruction::Format i)
{
	// MSUB,MSUBI,MSUBQ,MSUBBC,OPMSUB
	return ((i.Funct == 0x2d) || (i.Funct == 0x27) || (i.Funct == 0x25) || ((i.Funct & 0x3c) == 0x0c) || (i.Funct == 0x2e));
}

bool R5900::Recompiler::isMSUBi(R5900::Instruction::Format i)
{
	// MSUBI
	return ((i.Funct == 0x27));
}
bool R5900::Recompiler::isMSUBq(R5900::Instruction::Format i)
{
	// MSUBQ
	return ((i.Funct == 0x25));
}
bool R5900::Recompiler::isMSUBBC(R5900::Instruction::Format i)
{
	// MSUBBC
	return (((i.Funct & 0x3c) == 0x0c));
}


bool R5900::Recompiler::isMSUBA(R5900::Instruction::Format i)
{
	// MSUBA,MSUBAI,MSUBAQ,MSUBABC
	return ((i.Imm11 == 0x2fd) || (i.Imm11 == 0x27f) || (i.Imm11 == 0x27d) || ((i.Imm11 & 0x7fc) == 0x0fc));
}

bool R5900::Recompiler::isMSUBAi(R5900::Instruction::Format i)
{
	// MSUBAI
	return ((i.Imm11 == 0x27f));
}
bool R5900::Recompiler::isMSUBAq(R5900::Instruction::Format i)
{
	// MSUBAQ
	return ((i.Imm11 == 0x27d));
}
bool R5900::Recompiler::isMSUBABC(R5900::Instruction::Format i)
{
	// MSUBABC
	return (((i.Imm11 & 0x7fc) == 0x0fc));
}


bool R5900::Recompiler::isOPMULA(R5900::Instruction::Format i)
{
	// OPMULA
	return ((i.Imm11 == 0x2fe));
}

bool R5900::Recompiler::isOPMSUB(R5900::Instruction::Format i)
{
	// OPMSUB
	return ((i.Funct == 0x2e));
}



// returns -1 if there was a problem, otherwise returns number of instructions recompiled
// level 2 recompiler
// returns the next address after level 2 block, returns -1 on error
u32 R5900::Recompiler::Recompile2 ( u32 ulBeginAddress )
{
	// the index used for looping
	int iIdx;
	int iRegIdx;
	
	// maximum number of level2 recompiled instructions in this run
	u32 ulMaxRun2;
	
	// the real number of instructions in the level 2 recompilation run
	u32 ulRealRun2;
	
	// the current address
	u32 ulAddress;
	
	Instruction::Format inst;
	u32* pSrcCodePtr;
	
	int iRet;
	
	u64 ullCombineBitmap;
	u64 ullCurAlloc;
	u64 ullBitmap;
	
	// this depends on the size of the cache blocks for the processor
	//ulMaxRun2 = MaxStep - ( ( ulBeginAddress >> MaxStep_Shift ) & MaxStep_Mask );
	ulMaxRun2 = MaxStep - ( ( ulBeginAddress >> 2 ) & MaxStep_Mask );
	
	// first go through and get the source and destination registers //
	
	// start from the begin address
	ulAddress = ulBeginAddress;
	
	// get the pointer into the instructions
	// this should get pointer to the instruction
	pSrcCodePtr = RGetPointer ( ulAddress );
	
	// set oplevel to preprocess info
	OpLevel = -1;

#ifdef VERBOSE_RECOMPILE
	cout << "\nRecompile2: starting pass1.";
#endif
#ifdef INLINE_DEBUG_RECOMPILE2
	debug << "\r\nRECOMPILE2: Starting pass1.";
	debug << " ADDR:" << hex << ulAddress;
	debug << " MAXRUN=" << dec << ulMaxRun2;
	debug << " SHIFT=" << MaxStep_Shift;
	debug << " MASK=" << MaxStep_Mask;
#endif
	
	for ( iIdx = 0; iIdx < ulMaxRun2; iIdx++ )
	{
		// get the instruction
		inst.Value = *pSrcCodePtr++;
		
		// init src and dst reg bitmaps
		ullSrcRegBitmap = 0;
		ullDstRegBitmap = 0;
		
#ifdef VERBOSE_RECOMPILE
cout << "\n ASM2: " << R5900::Instruction::Print::PrintInstruction ( inst.Value ).c_str ();
#endif
#ifdef INLINE_DEBUG_RECOMPILE2
	debug << "\r\n ASM2: " << R5900::Instruction::Print::PrintInstruction ( inst.Value ).c_str ();
	debug << " ADDR:" << hex << ulAddress;
#endif

		// get the source and dest register bitmaps
		iRet = Recompile ( inst, ulAddress );

#ifdef VERBOSE_RECOMPILE
cout << " iRet=" << dec << iRet;
#endif
#ifdef INLINE_DEBUG_RECOMPILE2
	debug << " iRet=" << dec << iRet;
#endif
		
		if ( iRet < 0 ) break;

#ifdef VERBOSE_RECOMPILE
cout << " SrcBmp=" << hex << ullSrcRegBitmap;
cout << " DstBmp=" << hex << ullDstRegBitmap;
#endif
#ifdef INLINE_DEBUG_RECOMPILE2
	debug << " SrcBmp=" << hex << ullSrcRegBitmap;
	debug << " DstBmp=" << hex << ullDstRegBitmap;
#endif
		
		// store the bitmap data for this instruction
		ullSrcRegBitmaps [ iIdx ] = ullSrcRegBitmap;
		ullDstRegBitmaps [ iIdx ] = ullDstRegBitmap;
	}
	
	// set the actual number of instructions to be recompiled at level 2
	ulRealRun2 = iIdx;
	
	// if fewer than 2 instructions can be recompiled, there's no benefit
	if ( ulRealRun2 < 2 )
	{
		// before returning, set oplevel back to what it was
		OpLevel = 2;
		
		return -1;
	}
	
	ullCombineBitmap = 0;
	
	// fill in the bitmap for registers that are needed
	for ( iIdx = ulRealRun2 - 1; iIdx >= 0; iIdx-- )
	{
		ullRegsStillNeeded [ iIdx ] = ullCombineBitmap;
		
		ullCombineBitmap |= ullSrcRegBitmaps [ iIdx ];
	}
	
	
	// start from the begin address
	ulAddress = ulBeginAddress;
	
	// get the pointer into the instructions
	// this should get pointer to the instruction
	pSrcCodePtr = RGetPointer ( ulAddress );
	
	// set oplevel to encode the actual instruction
	OpLevel = 2;
	
	// init bitmaps for allocation
	ullTargetAlloc = 0;
	ullSrcRegAlloc = 0;
	ullSrcConstAlloc = 0;
	
	// set r0 as a constant zero
	Alloc_Const ( 0, 0 );
	
	// now clear regs modified, including r0 modified bit
	ullSrcRegsModified = 0;
	
	// clear any regs on stack
	ullRegsOnStack = 0;


#ifdef VERBOSE_RECOMPILE
	cout << "\nRecompile2: starting pass2.";
#endif
#ifdef INLINE_DEBUG_RECOMPILE2
	debug << "\nRecompile2: starting pass2.";
	debug << " MAXRUN=" << dec << ulRealRun2;
#endif
	
	// encode run //
	
	LocalCycleCount2 = LocalCycleCount;
	
	RunCount2 = 0;
	
	// encode the instructions ??
	for ( iIdx = 0; iIdx < ulRealRun2; iIdx++ )
	{
		// get the instruction
		inst.Value = *pSrcCodePtr++;
		
		// set the registers that are still needed later
		ullNeededLater = ullRegsStillNeeded [ iIdx ];
		
		// set the source and dest registers on source machine
		ullSrcRegBitmap = ullSrcRegBitmaps [ iIdx ];
		ullDstRegBitmap = ullDstRegBitmaps [ iIdx ];
		
#ifdef VERBOSE_RECOMPILE
cout << "\n ASM2: " << R5900::Instruction::Print::PrintInstruction ( inst.Value ).c_str ();
#endif
#ifdef INLINE_DEBUG_RECOMPILE2
	debug << "\r\n ASM2: " << R5900::Instruction::Print::PrintInstruction ( inst.Value ).c_str ();
	debug << " ADDR:" << hex << ulAddress;
#endif

		// encode the instruction
		iRet = Recompile ( inst, ulAddress );

#ifdef VERBOSE_RECOMPILE
cout << " iRet=" << dec << iRet;
#endif
#ifdef INLINE_DEBUG_RECOMPILE2
	debug << " iRet=" << dec << iRet;
#endif
		
		if ( iRet <= 0 )
		{
			break;
		}
		
		// automatically remove register allocations that are no int32_ter needed (except r0)
		// *** todo ***
//#ifdef INLINE_DEBUG_RECOMPILE2
//	debug << " ullCurAlloc=" << hex << ullCurAlloc;
//	debug << " ullNeededLater=" << hex << ullNeededLater;
//#endif
		ullCurAlloc = ( ullSrcRegAlloc ) & ~1;
		while ( ullCurAlloc & ~( ullNeededLater ) )
		{
			// get the next register that is no int32_ter needed
			ullBitmap = ullCurAlloc & ~( ullNeededLater );
			ullBitmap &= -ullBitmap;
			
			// get its index
			//iRegIdx = __builtin_ctz( ullBitmap );
			iRegIdx = ctz64(ullBitmap);

			// remove it and remove from bitmap
			DisposeReg( iRegIdx );
			ullCurAlloc &= ~( 1ull << iRegIdx );
		}
		
		// update to the next address
		ulAddress += 4;
		
		// used by load/store/etc
		RunCount2++;
		
		// update cycles
		LocalCycleCount2 += MemCycles;
	}
	

	// if fewer than 2 instructions can be recompiled, there's no benefit
	if ( iIdx < 2 )
	{
		// before returning, set oplevel back to what it was
		OpLevel = 2;
		
		return -1;
	}

#ifdef VERBOSE_RECOMPILE
cout << "\n ***L2 ENCODED***";
#endif
#ifdef INLINE_DEBUG_RECOMPILE2
	debug << "\r\n ***L2 ENCODED***";
#endif

	// write back all registers
	WriteBackModifiedRegs ();

//#ifdef VERBOSE_RECOMPILE
//cout << "\n Restoring regs from stack";
//#endif
//#ifdef INLINE_DEBUG_RECOMPILE2
//	debug << "\r\n Restoring regs from stack";
//#endif
	
	// restore regs from stack
	RestoreRegsFromStack ();
	
	// return the number of instructions that got recompiled at level-2
	return iIdx;
}

// check for branch,jump,syscall, or anything that breaks a static load dependency check
bool R5900::Recompiler::Check_StaticDependencyOk ( R5900::Instruction::Format i )
{
	switch ( i.Opcode )
	{
		// j,jal don't have source regs
		case 0x2:
		case 0x3:
			return 0;
			break;
			
		// LUI uses only rt as source reg
		case 0xf:
			return 1;
			break;
			
		// cop0
		case 0x10:
			// mtc0 is rt
			if ( i.Rs == 4 )
			{
				return 1;
			}
			break;
			
		// cop1
		case 0x11:
			// mtc1 and ctc1 are rt
			if ( i.Rs == 4 || i.Rs == 6 )
			{
				return 1;
			}
			break;
			
		// cop2
		case 0x12:
			// qmtc2 and ctc2 are rt
			if ( i.Rs == 5 || i.Rs == 6 )
			{
				return ( 1ull << i.Rt );
			}
			break;
			
		// beq is rs and rt
		case 0x4:
		
		// bne is rs and rt
		case 0x5:
		
		// beql is rs and rt
		case 0x14:
		
		// bnel is rs and rt
		case 0x15:
		
		// SQ is rs and rt
		case 0x1f:
			return 0;
			break;
			
		// special
		case 0:
			// rows 0,3,4,7 are ok
			if ( ( i.Opcode >> 3 ) == 0 || ( i.Opcode >> 3 ) == 3 || ( i.Opcode >> 3 ) == 4 || ( i.Opcode >> 3 ) == 7 )
			{
				return 1;
			}
			
			// row 6 not ok
			if ( ( i.Opcode >> 3 ) == 6 )
			{
				return 0;
			}
			
			switch( i.Funct )
			{
				// syscall
				case 0xc:
				
				// break
				case 0xd:
				
				// sync
				case 0xf:
					return 0;
				
				// jr is rs only
				case 0x8:
				
				// jalr is rs only
				case 0x9:
					return 0;
					break;
					
				// mfhi
				case 0x10:
				
				// mflo
				case 0x12:
				
				// mfsa
				case 0x28:
				
				// mthi is rs only
				case 0x11:
				
				// mtlo is rs only
				case 0x13:
				
				// mtsa is rs only
				case 0x29:
					return 1;
					break;
					
				// remainder is rs and rt
				default:
					return 1;
					break;
			}
			
			break;
			
		// regimm is rs only
		case 0x1:
			if ( i.Rt >= 0x18 )
			{
				return 1;
			}
			break;
		
		// daddiu is rs only
		case 0x19:
			return 1;
			break;
			
		// addi
		case 0x8:
		
		// daddi is rs only
		case 0x18:
			
		// blez is rs only
		case 0x6:
		
		// bgtz is rs only
		case 0x7:
		
		// blezl is rs only
		case 0x16:
		
		// bgtzl is rs only
		case 0x17:
		
		// ldl is rs only
		case 0x1a:
		
		// ldr is rs only
		case 0x1b:
		
		// lq is rs only
		case 0x1e:
		
		// cache is rs only
		case 0x2f:
		
		// pref
		case 0x33:
		
		// swc1 is rs only
		case 0x39:
			return 0;
			break;
			
		// mmi
		case 0x1c:
			return 1;
			
			// mmix
			switch ( i.Funct )
			{
				// mmi0
				case 0x8:
					return 1;
					break;
					
				// mmi2
				case 0x9:
					return 1;
					break;
					
				// mmi1
				case 0x28:
					return 1;
					break;
					
				// mmi3
				case 0x29:
					return 1;
					break;
			}
			
			// mt is ok
			if ( ( i.Funct & 0x1 ) == 1 )
			{
				return 1;
			}
			
			break;
			
		default:
			// rest of rows 1 are ok
			if ( ( i.Opcode >> 3 ) == 1 )
			{
				return 0;
			}
			
			// rows 4 and after are not ok
			if ( ( i.Opcode >> 3 ) >= 4 )
			{
				return 0;
			}
			
			break;
			
	}
	
	return 0;
}

// get the GPR source registers for an instruction (GPR regs only)
uint64_t R5900::Recompiler::GetGPR_SrcRegs ( R5900::Instruction::Format i )
{
	switch ( i.Opcode )
	{
		// j,jal don't have source regs
		case 0x2:
		case 0x3:
			return 0;
			break;
			
		// LUI uses only rt as source reg
		case 0xf:
			return ( 1ull << i.Rt );
			break;
			
		// cop0
		case 0x10:
			// mtc0 is rt
			if ( i.Rs == 4 )
			{
				return ( 1ull << i.Rt );
			}
			break;
			
		// cop1
		case 0x11:
			// mtc1 and ctc1 are rt
			if ( i.Rs == 4 || i.Rs == 6 )
			{
				return ( 1ull << i.Rt );
			}
			break;
			
		// cop2
		case 0x12:
			// qmtc2 and ctc2 are rt
			if ( i.Rs == 5 || i.Rs == 6 )
			{
				return ( 1ull << i.Rt );
			}
			break;
			
		// beq is rs and rt
		case 0x4:
		
		// bne is rs and rt
		case 0x5:
		
		// beql is rs and rt
		case 0x14:
		
		// bnel is rs and rt
		case 0x15:
		
		// SQ is rs and rt
		case 0x1f:
			return ( 1ull << i.Rs ) | ( 1ull << i.Rt );
			break;
			
		// special
		case 0:
			// rows 0,3,4,6,7 are rs and rt
			if ( ( i.Opcode >> 3 ) == 0 || ( i.Opcode >> 3 ) == 3 || ( i.Opcode >> 3 ) == 4 || ( i.Opcode >> 3 ) == 6 || ( i.Opcode >> 3 ) == 7 )
			{
				return ( 1ull << i.Rs ) | ( 1ull << i.Rt );
			}
			
			switch( i.Funct )
			{
				// syscall
				case 0xc:
				
				// break
				case 0xd:
				
				// sync
				case 0xf:
				
				// mfhi
				case 0x10:
				
				// mflo
				case 0x12:
				
				// mfsa
				case 0x28:
					return 0;
					break;
					
				// jr is rs only
				case 0x8:
				
				// jalr is rs only
				case 0x9:
				
				// mthi is rs only
				case 0x11:
				
				// mtlo is rs only
				case 0x13:
				
				// mtsa is rs only
				case 0x29:
					return ( 1ull << i.Rs );
					break;
					
				// remainder is rs and rt
				default:
					return ( 1ull << i.Rs ) | ( 1ull << i.Rt );
					break;
			}
			
			break;
			
		// regimm is rs only
		case 0x1:
		
		// blez is rs only
		case 0x6:
		
		// bgtz is rs only
		case 0x7:
		
		// blezl is rs only
		case 0x16:
		
		// bgtzl is rs only
		case 0x17:
		
		// daddi is rs only
		case 0x18:
			
		// daddiu is rs only
		case 0x19:
		
		// ldl is rs only
		case 0x1a:
		
		// ldr is rs only
		case 0x1b:
		
		// lq is rs only
		case 0x1e:
		
		// cache is rs only
		case 0x2f:
		
		// pref
		case 0x33:
		
		// swc1 is rs only
		case 0x39:
			return ( 1ull << i.Rs );
			break;
			
		// mmi
		case 0x1c:
			// lower-right corner is rt
			if ( ( i.Funct >> 3 ) >= 6 && ( i.Funct & 0x7 ) >= 4 )
			{
				return ( 1ull << i.Rt );
			}
			
			// plzcw is rs
			if ( i.Funct == 0x4 )
			{
				return ( 1ull << i.Rs );
			}
			
			// rest on rows 0,3,4 are rs and rt
			if ( ( i.Funct >> 3 ) == 0 || ( i.Funct >> 3 ) == 3 || ( i.Funct >> 3 ) == 4 )
			{
				return ( 1ull << i.Rs ) | ( 1ull << i.Rt );
			}
			
			// mmix
			switch ( i.Funct )
			{
				// mmi0
				case 0x8:
					// less than 0x1c is both, otherwise just rt
					if ( i.Shift < 0x1c )
					{
						return ( 1ull << i.Rs ) | ( 1ull << i.Rt );
					}
					else
					{
						return ( 1ull << i.Rt );
					}
					
					break;
					
				// mmi2
				case 0x9:
					// lower-right corner is just rt, otherwise both
					if ( ( i.Shift & 0x3 ) >= 2 && ( i.Shift >> 2 ) >= 6 )
					{
						return ( 1ull << i.Rt );
					}
					else
					{
						return ( 1ull << i.Rs ) | ( 1ull << i.Rt );
					}
					
					break;
					
				// mmi1
				case 0x28:
					// pabsw and pabsh are rt, otherwise rs and rt
					if ( i.Shift == 1 || i.Shift == 5 )
					{
						return ( 1ull << i.Rt );
					}
					else
					{
						return ( 1ull << i.Rs ) | ( 1ull << i.Rt );
					}
					break;
					
				// mmi3
				case 0x29:
					// pmthi/pmtlo are just rs
					if ( i.Shift == 8 || i.Shift == 9 )
					{
						return ( 1ull << i.Rs );
					}
					
					// lower-right corner is just rt, otherwise both
					if ( ( i.Shift & 0x3 ) >= 2 && ( i.Shift >> 2 ) >= 6 )
					{
						return ( 1ull << i.Rt );
					}
					else
					{
						return ( 1ull << i.Rs ) | ( 1ull << i.Rt );
					}
					break;
			}
			
			// mt is rs as source
			if ( ( i.Funct & 0x1 ) == 1 )
			{
				return ( 1ull << i.Rs );
			}
			
			break;
			
		default:
			// rows 1,4,6 are rs only
			if ( ( i.Opcode >> 3 ) == 1 || ( i.Opcode >> 3 ) == 4 || ( i.Opcode >> 3 ) == 6 )
			{
				return ( 1ull << i.Rs );
			}
			
			break;
			
	}
	
	return 0;
}


uint64_t R5900::Recompiler::GetCop1_SrcRegs ( R5900::Instruction::Format i0 )
{
	if ( i0.Opcode == 0x39 )
	{
		return ( 1ull << i0.Ft );
	}
	
	if ( i0.Opcode == 0x11 )
	{
		// cop1 instruction //
		if ( !i0.Rs )
		{
			// mfc1 //
			return ( 1ull << i0.Fs );
		}
		else if ( i0.Rs >= 0x10 )
		{
			switch ( i0.Funct )
			{
				case 0x05:
				case 0x06:
				case 0x07:
				case 0x24:
					return ( 1ull << i0.Fs );
					break;
					
				default:
					return ( 1ull << i0.Fs ) | ( 1ull << i0.Ft );
					break;
			}
		}
	}
	
	return 0;
}


// dispose the old register but reassign the new register to the same register on target device
// returns -1 on error, otherwise returns the register on target device
int R5900::Recompiler::RenameReg ( int iNewSrcRegIdx, int iOldSrcRegIdx )
{
	int iIdx;
	int iRegIdx;
	
#ifdef INLINE_DEBUG_RECOMPILE2
	debug << "\r\nR5900::Recompiler::RenameReg";
#endif

	// if the same register, then return the register on target device
	if ( iNewSrcRegIdx == iOldSrcRegIdx )
	{
#ifdef INLINE_DEBUG_RECOMPILE2
	debug << " REGS-MATCH";
#endif

		// make sure it is a register
		if ( ullSrcRegAlloc & ( 1ull << iOldSrcRegIdx ) )
		{
			// if register has been renamed, then it has been modified ??
			ullSrcRegsModified |= ( 1ull << iNewSrcRegIdx );
			
			// return the actual register on target device
			iIdx = ullTargetData [ iOldSrcRegIdx ];
			return iRegPriority [ iIdx ];
		}
		else
		{
#ifdef INLINE_DEBUG_RECOMPILE2
	debug << " ERROR";
#endif

			// error ??
			return -1;
		}
	}
	
	// deallocate the old source register assigned to the target device register
	iIdx = DisposeReg ( iOldSrcRegIdx );
	
	// new source register is not a constant
	ullSrcConstAlloc &= ~( 1ull << iNewSrcRegIdx );
	
	// assign that register to the new source device register
	ullTargetData [ iNewSrcRegIdx ] = iIdx;
	ullSrcRegAlloc |= ( 1ull << iNewSrcRegIdx );
	ullTargetAlloc |= ( 1ull << iIdx );
	
	// if register has been renamed, then it has been modified ??
	ullSrcRegsModified |= ( 1ull << iNewSrcRegIdx );
	
#ifdef INLINE_DEBUG_RECOMPILE2
	debug << " ullSrcRegsModified=" << hex << ullSrcRegsModified;
	debug << " TargetReg=" << dec << iRegPriority [ iIdx ];
#endif

	// return the actual register on the target device
	return iRegPriority [ iIdx ];
}



// returns -1 on error, returns id of register (not the actual register) on target device otherwise
int R5900::Recompiler::DisposeReg ( int iSrcRegIdx )
{
	int iRealRegIdx;
	u64 ullValue;
	
#ifdef INLINE_DEBUG_RECOMPILE2
	debug << "\r\nR5900::Recompiler::DisposeReg";
	debug << " MIPSReg#" << dec << iSrcRegIdx;
#endif

	// check that register id is valid
	if ( iSrcRegIdx < 0 )
	{
#ifdef INLINE_DEBUG_RECOMPILE2
	debug << " ERROR-INVALID-ID";
#endif

		return -1;
	}
	
	// check if register is allocated
	if ( ! isAlloc( iSrcRegIdx ) )
	{
#ifdef INLINE_DEBUG_RECOMPILE2
	debug << " ERROR-NOT-ALLOCATED";
#endif

		// register not allocated, so nothing to do
		return -1;
	}
	
	// check if register is modified (means needs write back)
	if ( ullSrcRegsModified & ( 1ull << iSrcRegIdx ) )
	{
		// check if constant or not
		if ( isConst( iSrcRegIdx ) )
		{
#ifdef INLINE_DEBUG_RECOMPILE2
	debug << " WRITE-BACK-CONST";
	debug << " Value=" << hex << ullTargetData [ iSrcRegIdx ];
#endif
			ullValue = ullTargetData [ iSrcRegIdx ];

			if ( ( ( ullValue >> 31 ) != 0ull ) && ( ( ullValue >> 31 ) != 0x1ffffffffull ) )
			{
				e->MovReg64ImmX ( RCX, ullValue );
				e->MovMemReg64 ( &r->GPR [ iSrcRegIdx ].sq0, RCX );
			}
			else
			{
				// *** todo *** write back constant
				//e->MovMemImm64 ( &r->GPR [ iSrcRegIdx ].sq0, ullTargetData [ iSrcRegIdx ] );
				e->MovMemImm64 ( &r->GPR [ iSrcRegIdx ].sq0, ullValue );
			}
		}
		else
		{
#ifdef INLINE_DEBUG_RECOMPILE2
	debug << " WRITE-BACK-REG";
#endif

			// *** todo *** write back register
			iRealRegIdx = iRegPriority [ ullTargetData [ iSrcRegIdx ] ];
			e->MovMemReg64 ( &r->GPR [ iSrcRegIdx ].sq0, iRealRegIdx );
		}
	}
	
	// clear modified bitmap
	ullSrcRegsModified &= ~( 1ull << iSrcRegIdx );
	
	// check if register
	if ( isReg( iSrcRegIdx ) )
	{
		// clear target bitmap
		ullTargetAlloc &= ~( 1ull << ( ullTargetData [ iSrcRegIdx ] ) );
	}
	
	// clear reg bitmap
	ullSrcRegAlloc &= ~( 1ull << iSrcRegIdx );
	
	// clear const bitmap
	ullSrcConstAlloc &= ~( 1ull << iSrcRegIdx );
	
#ifdef INLINE_DEBUG_RECOMPILE2
	debug << " RETURN=" << dec << ullTargetData [ iSrcRegIdx ];
#endif

	// return the old target register id
	return ullTargetData [ iSrcRegIdx ];
}

bool R5900::Recompiler::isAlloc ( int iSrcRegIdx )
{
	if ( ( ullSrcConstAlloc | ullSrcRegAlloc ) & ( 1ull << iSrcRegIdx ) )
	{
		return true;
	}
	
	return false;
}

bool R5900::Recompiler::isLarge ( u64 ullValue )
{
	if ( ( ( ullValue >> 31 ) != 0ull ) && ( ( ullValue >> 31 ) != 0x1ffffffffull ) )
	{
		return true;
	}
	
	return false;
}

bool R5900::Recompiler::isConst ( int iSrcRegIdx )
{
	// check if register is a constant
	if ( ullSrcConstAlloc & ( 1ull << iSrcRegIdx ) )
	{
		return true;
	}
	
	return false;
}

bool R5900::Recompiler::isReg ( int iSrcRegIdx )
{
	if ( ullSrcRegAlloc & ( 1ull << iSrcRegIdx ) )
	{
		return true;
	}
	
	return false;
}

bool R5900::Recompiler::isDisposable( int iSrcRegIdx )
{
	if ( ullNeededLater & ( 1ull << iSrcRegIdx ) )
	{
		return false;
	}
	else
	{
		return true;
	}
}


bool R5900::Recompiler::isBothAlloc ( int iSrcRegIdx1, int iSrcRegIdx2 )
{
	u64 ullBitmap;
	
	ullBitmap = ( 1ull << iSrcRegIdx1 ) | ( 1ull << iSrcRegIdx2 );
	
	if ( ( ( ullSrcConstAlloc | ullSrcRegAlloc ) & ullBitmap ) == ullBitmap )
	{
		return true;
	}
	
	return false;
}

bool R5900::Recompiler::isBothConst ( int iSrcRegIdx1, int iSrcRegIdx2 )
{
	u64 ullBitmap;
	
	ullBitmap = ( 1ull << iSrcRegIdx1 ) | ( 1ull << iSrcRegIdx2 );
	
	if ( ( ullSrcConstAlloc & ullBitmap ) == ullBitmap )
	{
		return true;
	}
	
	return false;
}

bool R5900::Recompiler::isBothReg ( int iSrcRegIdx1, int iSrcRegIdx2 )
{
	u64 ullBitmap;
	
	ullBitmap = ( 1ull << iSrcRegIdx1 ) | ( 1ull << iSrcRegIdx2 );
	
	if ( ( ullSrcRegAlloc & ullBitmap ) == ullBitmap )
	{
		return true;
	}
	
	return false;
}

bool R5900::Recompiler::isBothDisposable( int iSrcRegIdx1, int iSrcRegIdx2 )
{
	u64 ullBitmap;
	
	ullBitmap = ( 1ull << iSrcRegIdx1 ) | ( 1ull << iSrcRegIdx2 );
	
	if ( ! ( ullNeededLater & ullBitmap ) )
	{
		return false;
	}
	else
	{
		return true;
	}
}


// ---------------------------------------------

bool R5900::Recompiler::isEitherAlloc ( int iSrcRegIdx1, int iSrcRegIdx2 )
{
	u64 ullBitmap;
	
	ullBitmap = ( 1ull << iSrcRegIdx1 ) | ( 1ull << iSrcRegIdx2 );
	
	if ( ( ullSrcConstAlloc | ullSrcRegAlloc ) & ullBitmap )
	{
		return true;
	}
	
	return false;
}

bool R5900::Recompiler::isEitherConst ( int iSrcRegIdx1, int iSrcRegIdx2 )
{
	u64 ullBitmap;
	
	ullBitmap = ( 1ull << iSrcRegIdx1 ) | ( 1ull << iSrcRegIdx2 );
	
	if ( ullSrcConstAlloc & ullBitmap )
	{
		return true;
	}
	
	return false;
}

bool R5900::Recompiler::isEitherReg ( int iSrcRegIdx1, int iSrcRegIdx2 )
{
	u64 ullBitmap;
	
	ullBitmap = ( 1ull << iSrcRegIdx1 ) | ( 1ull << iSrcRegIdx2 );
	
	if ( ullSrcRegAlloc & ullBitmap )
	{
		return true;
	}
	
	return false;
}

bool R5900::Recompiler::isEitherDisposable( int iSrcRegIdx1, int iSrcRegIdx2 )
{
	u64 ullBitmap;
	
	ullBitmap = ( 1ull << iSrcRegIdx1 ) | ( 1ull << iSrcRegIdx2 );
	
	if ( ( ullNeededLater & ullBitmap ) == ullBitmap )
	{
		return false;
	}
	
	return true;
}



int R5900::Recompiler::SelectAlloc ( int iSrcRegIdx1, int iSrcRegIdx2 )
{
	u64 ullBitmap;
	ullBitmap = ( 1ull << iSrcRegIdx1 ) | ( 1ull << iSrcRegIdx2 );
	ullBitmap &= ( ullSrcRegAlloc | ullSrcConstAlloc );
	ullBitmap &= -ullBitmap;
	//return __builtin_ctz( ullBitmap );
	return ctz64(ullBitmap);
}

int R5900::Recompiler::SelectConst ( int iSrcRegIdx1, int iSrcRegIdx2 )
{
	u64 ullBitmap;
	ullBitmap = ( 1ull << iSrcRegIdx1 ) | ( 1ull << iSrcRegIdx2 );
	ullBitmap &= ullSrcConstAlloc;
	ullBitmap &= -ullBitmap;
	//return __builtin_ctz( ullBitmap );
	return ctz64(ullBitmap);
}

int R5900::Recompiler::SelectReg ( int iSrcRegIdx1, int iSrcRegIdx2 )
{
	u64 ullBitmap;
	ullBitmap = ( 1ull << iSrcRegIdx1 ) | ( 1ull << iSrcRegIdx2 );
	ullBitmap &= ullSrcRegAlloc;
	ullBitmap &= -ullBitmap;
	//return __builtin_ctz( ullBitmap );
	return ctz64(ullBitmap);
}

int R5900::Recompiler::SelectDisposable( int iSrcRegIdx1, int iSrcRegIdx2 )
{
	u64 ullBitmap;
	ullBitmap = ( 1ull << iSrcRegIdx1 ) | ( 1ull << iSrcRegIdx2 );
	ullBitmap &= ~ullNeededLater;
	ullBitmap &= -ullBitmap;
	//return __builtin_ctz( ullBitmap );
	return ctz64(ullBitmap);
}


int R5900::Recompiler::SelectNotAlloc ( int iSrcRegIdx1, int iSrcRegIdx2 )
{
	u64 ullBitmap;
	ullBitmap = ( 1ull << iSrcRegIdx1 ) | ( 1ull << iSrcRegIdx2 );
	ullBitmap &= ~( ullSrcRegAlloc | ullSrcConstAlloc );
	ullBitmap &= -ullBitmap;
	//return __builtin_ctz( ullBitmap );
	return ctz64(ullBitmap);
}

int R5900::Recompiler::SelectNotDisposable( int iSrcRegIdx1, int iSrcRegIdx2 )
{
	u64 ullBitmap;
	ullBitmap = ( 1ull << iSrcRegIdx1 ) | ( 1ull << iSrcRegIdx2 );
	ullBitmap &= ullNeededLater;
	ullBitmap &= -ullBitmap;
	//return __builtin_ctz( ullBitmap );
	return ctz64(ullBitmap);
}



// returns -1 if error, otherwise returns index of register on target platform
// iSrcRegIdx: index of register on source platform (for example, MIPS)
int R5900::Recompiler::Alloc_SrcReg ( int iSrcRegIdx )
{
	u64 ullBitmap;
	int iIdx, iRegIdx;
	
#ifdef INLINE_DEBUG_RECOMPILE2
	debug << "\r\nSTART->R5900::Recompiler::Alloc_SrcReg";
#endif

	// make sure register id is valid
	if ( iSrcRegIdx < 0 )
	{
		return -1;
	}
	
	
	// check if register is already allocated
	if ( ullSrcRegAlloc & ( 1ull << iSrcRegIdx ) )
	{
		// return the index or register on the target platform
		//__builtin_ctz ();
		return iRegPriority [ ullTargetData [ iSrcRegIdx ] ];
	}
	
	// get the next available register on target //
	
	// there are currently 13 available registers, so make sure there is one available
	//if ( ( ullTargetAlloc & 0x1fff ) == 0x1fff )
	if ( ( ullTargetAlloc & c_ulUsableRegsBitmap ) == c_ulUsableRegsBitmap )
	{
#ifdef INLINE_DEBUG_RECOMPILE2
	debug << "\r\n***ERROR*** NO MORE REGISTERS";
#endif

		cout << "\nERROR: no more registers on r5900 recompile L2.\n";

		// no more registers available
		return -1;
	}
	
	// get the next target register available
	ullBitmap = ~ullTargetAlloc;
	ullBitmap &= -ullBitmap;
	
	// get the index it is allocated to on target
	// *** gcc specific code *** //
	//iIdx = __builtin_ctz( ullBitmap );
	iIdx = ctz64(ullBitmap);


	
	// get the actual register to use from the index
	iRegIdx = iRegPriority [ iIdx ];
	
	// if the register needs to be saved, push it onto stack unless it is already saved
	if ( iRegStackSave [ iIdx ] )
	{
		if ( ! ( ullRegsOnStack & ( 1ull << iIdx ) ) )
		{
#ifdef INLINE_DEBUG_RECOMPILE2
	debug << " SAVING-ONSTACK x64Reg#" << dec << iRegIdx;
#endif

			// push the register onto the stack //
			e->PushReg64( iRegIdx );
			
			// mark register as being on the stack
			ullRegsOnStack |= ( 1ull << iIdx );
		}
	}
	
	// check if register is a constant
	if ( ullSrcConstAlloc & ( 1ull << iSrcRegIdx ) )
	{
		//return -1;
		e->MovReg64ImmX ( iRegIdx, ullTargetData [ iSrcRegIdx ] );
	}
	else
	{
		// load in the source register (only for Alloc_SrcReg)
		e->MovRegMem64 ( iRegIdx, & r->GPR [ iSrcRegIdx ].sq0 );
	}


	// set that register as allocated to a variable reg
	ullSrcRegAlloc |= ( 1ull << iSrcRegIdx );
	
	// .. not a constant
	ullSrcConstAlloc &= ~( 1ull << iSrcRegIdx );
	
	// and allocated on target
	ullTargetAlloc |= ullBitmap;
	
	// set the index it is allocated to on target
	ullTargetData [ iSrcRegIdx ] = iIdx;

	
#ifdef INLINE_DEBUG_RECOMPILE2
	debug << " x64Reg#" << dec << iRegIdx << " -> " << " MIPSReg#" << dec << iSrcRegIdx;
#endif
	
#ifdef INLINE_DEBUG_RECOMPILE2
	debug << "\r\nEND->R5900::Recompiler::Alloc_SrcReg";
	debug << " return=" << dec << iRegIdx;
#endif

	// done
	return iRegIdx;
}


int R5900::Recompiler::Alloc_DstReg ( int iSrcRegIdx )
{
	u64 ullBitmap;
	int iIdx, iRegIdx;
	
#ifdef INLINE_DEBUG_RECOMPILE2
	debug << "\r\nSTART->R5900::Recompiler::Alloc_DstReg";
	debug << " ullTargetAlloc=" << hex << ullTargetAlloc;
#endif

	// make sure register id is valid
	if ( iSrcRegIdx < 0 )
	{
		return -1;
	}
	
	// check if register is a constant
	//if ( ullSrcConstAlloc & ( 1 << iSrcRegIdx ) )
	//{
	//	return -1;
	//}
	
	// check if register is already allocated
	if ( ullSrcRegAlloc & ( 1ull << iSrcRegIdx ) )
	{
		// register is already allocated as a register //
		
		// make sure register is set as being modified (might have been a source reg previously)
		ullSrcRegsModified |= ( 1ull << iSrcRegIdx );
		
		// return the index or register on the target platform
		//__builtin_ctz ();
		return iRegPriority [ ullTargetData [ iSrcRegIdx ] ];
	}
	
	// get the next available register on target //
	
	// there are currently 13 available registers, so make sure there is one available
	//if ( ( ullTargetAlloc & 0x1fff ) == 0x1fff )
	if ( ( ullTargetAlloc & c_ulUsableRegsBitmap ) == c_ulUsableRegsBitmap )
	{
#ifdef INLINE_DEBUG_RECOMPILE2
	debug << "\r\n***ERROR*** NO MORE REGISTERS";
#endif

		cout << "\nERROR: no more registers on r5900 recompile L2.\n";

		// no more registers available
		return -1;
	}
	
	// get the next target register available
	ullBitmap = ~ullTargetAlloc;
	ullBitmap &= -ullBitmap;
	
	// get the index it is allocated to on target
	// *** gcc specific code *** //
	//iIdx = __builtin_ctz( ullBitmap );
	iIdx = ctz64(ullBitmap);

	// set the register as modified, since it is a destination register
	ullSrcRegsModified |= ( 1ull << iSrcRegIdx );
	
	// set that register as allocated to a variable reg
	ullSrcRegAlloc |= ( 1ull << iSrcRegIdx );
	
	// .. not a constant
	ullSrcConstAlloc &= ~( 1ull << iSrcRegIdx );
	
	// and allocated on target
	ullTargetAlloc |= ullBitmap;
	
	// set the index it is allocated to on target
	ullTargetData [ iSrcRegIdx ] = iIdx;
		
	// get the actual register to use from the index
	iRegIdx = iRegPriority [ iIdx ];
	
#ifdef INLINE_DEBUG_RECOMPILE2
	debug << " x64Reg#" << dec << iRegIdx << " -> " << "MIPSReg#" << iSrcRegIdx;
#endif

	// if the register needs to be saved, push it onto stack unless it is already saved
	if ( iRegStackSave [ iIdx ] )
	{
		if ( ! ( ullRegsOnStack & ( 1ull << iIdx ) ) )
		{
#ifdef INLINE_DEBUG_RECOMPILE2
	debug << " SAVING-ONSTACK x64Reg#" << dec << iRegIdx;
#endif

			// push the register onto the stack //
			e->PushReg64( iRegIdx );
			
			// mark register as being on the stack
			ullRegsOnStack |= ( 1ull << iIdx );
		}
	}
	
#ifdef INLINE_DEBUG_RECOMPILE2
	debug << " RETURN=" << dec << iRegIdx;
	debug << "\r\nEND->R5900::Recompiler::Alloc_DstReg";
#endif

	// done
	return iRegIdx;
}


// returns -1 if error, otherwise returns 1
// iSrcRegIdx: index of register on source platform (for example, MIPS)
int R5900::Recompiler::Alloc_Const ( int iSrcRegIdx, u64 ullValue )
{
	u64 ullBitmap;
	int iIdx, iRegIdx;
	
#ifdef INLINE_DEBUG_RECOMPILE2
	debug << "\r\nSTART->R5900::Recompiler::Alloc_Const";
#endif

	/*
	if ( ( ( ullValue >> 32 ) != 0 ) && ( ( ullValue >> 32 ) != 0xffffffffull ) )
	{
#ifdef INLINE_DEBUG_RECOMPILE2
	debug << "\r\n***ERROR: Constant is 64-bits: " << hex << iSrcRegIdx << ullValue;
#endif

		cout << "\n***ERROR: Constant is 64-bits: " << hex << iSrcRegIdx << ullValue;
	}
	*/

	// if reg is allocated, then deallocate it
	// check if register is already allocated
	if ( ullSrcRegAlloc & ( 1ull << iSrcRegIdx ) )
	{
#ifdef INLINE_DEBUG_RECOMPILE2
	debug << " Reg#" << dec << iSrcRegIdx << " already allocated as REGISTER. Deallocating.";
#endif
		// remove from allocation on target
		// get index of register on target
		iIdx = ullTargetData [ iSrcRegIdx ];
		
		// remove from target reg bitmap
		ullTargetAlloc &= ~( 1ull << iIdx );
		
		// clear the bit in source reg bitmap
		ullSrcRegAlloc &= ~( 1ull << iSrcRegIdx );
	}

#ifdef INLINE_DEBUG_RECOMPILE2
	debug << " Allocating Const#" << dec << iSrcRegIdx << " with value: " << hex << ullValue;
#endif
	
	// set register as a constant
	ullSrcConstAlloc |= ( 1ull << iSrcRegIdx );
	
	// set the constants as modified on source device (they need to be written back)
	ullSrcRegsModified |= ( 1ull << iSrcRegIdx );
	
	// set the value of the constant
	ullTargetData [ iSrcRegIdx ] = ullValue;

#ifdef INLINE_DEBUG_RECOMPILE2
	debug << "\r\nEND->R5900::Recompiler::Alloc_Const";
	debug << " return=" << dec << iSrcRegIdx;
#endif
	
	return iSrcRegIdx;
}

// write back any constants and registers that were modified in the run
void R5900::Recompiler::WriteBackModifiedRegs ()
{
	u64 ullBitmap;
	int iSrcRegIdx;
	int iRegIdx;
	
	u64 ullSrcRegsModified2;
	u64 ullValue;
	
#ifdef INLINE_DEBUG_RECOMPILE2
	debug << "\r\nSTART->R5900::Recompiler::WriteBackModifiedRegs";
#endif
	
	ullSrcRegsModified2 = ullSrcRegsModified;
	
	// loop while there are source device registers (and/or constants) that need to be written back
	while ( ullSrcRegsModified2 )
	{
#ifdef INLINE_DEBUG_RECOMPILE2
	debug << "\r\nullSrcRegsModified2=" << hex << ullSrcRegsModified2;
#endif

		ullBitmap = ullSrcRegsModified2 & -ullSrcRegsModified2;
		
		// get the next register on source device
		//iSrcRegIdx = __builtin_ctz( ullBitmap );
		iSrcRegIdx = ctz64(ullBitmap);

#ifdef INLINE_DEBUG_RECOMPILE2
	debug << " iSrcRegIdx=" << dec << iSrcRegIdx;
#endif
		
		// check if it is a register or constant
		if ( ullSrcConstAlloc & ( 1ull << iSrcRegIdx ) )
		{
#ifdef INLINE_DEBUG_RECOMPILE2
	debug << " Writing back Constant#" << dec << iSrcRegIdx;
	debug << " Value:" << hex << ullTargetData [ iSrcRegIdx ];
#endif

			ullValue = ullTargetData [ iSrcRegIdx ];

			// write back constant //
			if ( ( ( ullValue >> 31 ) != 0ull ) && ( ( ullValue >> 31 ) != 0x1ffffffffull ) )
			{
				e->MovReg64ImmX ( RCX, ullValue );
				e->MovMemReg64 ( &r->GPR [ iSrcRegIdx ].sq0, RCX );
			}
			else
			{
				// *** todo *** write back constant
				//e->MovMemImm64 ( &r->GPR [ iSrcRegIdx ].sq0, ullTargetData [ iSrcRegIdx ] );
				e->MovMemImm64 ( &r->GPR [ iSrcRegIdx ].sq0, ullValue );
			}
		}
		else if ( ullSrcRegAlloc & ( 1ull << iSrcRegIdx ) )
		{
#ifdef INLINE_DEBUG_RECOMPILE2
	debug << " Writing back Register#" << dec << iSrcRegIdx;
#endif

			// write back register //
			iRegIdx = iRegPriority [ ullTargetData [ iSrcRegIdx ] ];
			e->MovMemReg64 ( & r->GPR [ iSrcRegIdx ].sq0, iRegIdx );
		}
		
		// remove from bitmaps
		ullSrcRegsModified2 &= ~ullBitmap;
		//ullSrcConstAlloc &= ~ullBitmap;
		//ullSrcRegAlloc &= ~ullBitmap;
	}
	
	//ullSrcRegsModified = 0;
	//ullSrcConstAlloc = 1;
	//ullSrcRegAlloc = 0;
	
#ifdef INLINE_DEBUG_RECOMPILE2
	debug << "\r\nEND->R5900::Recompiler::WriteBackModifiedRegs";
#endif
}

// restore any registers that were saved on the stack to process the run
void R5900::Recompiler::RestoreRegsFromStack ()
{
	u64 ullBitmap;
	int iRegIdx;
	int iIdx;
	
	u64 ullRegsOnStack2;
	
#ifdef INLINE_DEBUG_RECOMPILE2
	debug << "\r\nSTART->R5900::Recompiler::RestoreRegsFromStack";
#endif

	ullRegsOnStack2 = ullRegsOnStack;

	// loop while there are still registers on the stack
	while ( ullRegsOnStack2 )
	{
#ifdef INLINE_DEBUG_RECOMPILE2
	debug << "\r\nullRegsOnStack2=" << hex << ullRegsOnStack2;
#endif

		// get the next register
		//ullBitmap = ullRegsOnStack2 & -ullRegsOnStack2;
		
		// get it's target device index
		//iRegIdx = __builtin_ctz( ullBitmap );
		//iRegIdx = __builtin_clz( ullRegsOnStack2 );
		iRegIdx = clz64(ullRegsOnStack2);
		iRegIdx = 31 - iRegIdx;

		iIdx = iRegPriority [ iRegIdx ];

#ifdef INLINE_DEBUG_RECOMPILE2
	debug << " Restoring x64REG#" << dec << iIdx;
#endif

		// pop register from the stack
		e->PopReg64( iIdx );
		
		// remove register from bitmap
		//ullRegsOnStack2 &= ~ullBitmap;
		ullRegsOnStack2 &= ~( 1 << iRegIdx );
	}
	
	//ullRegsOnStack = 0;
	
#ifdef INLINE_DEBUG_RECOMPILE2
	debug << "\r\nEND->R5900::Recompiler::RestoreRegsFromStack";
#endif
}




// constructor
// NumberOfBlocks MUST be a power of 2, so 1 would mean 2, 2 would mean 4
R5900::Recompiler::Recompiler ( Cpu* R5900Cpu, u32 NumberOfBlocks, u32 BlockSize_PowerOfTwo, u32 MaxIStep_Shift )
{
#ifdef INLINE_DEBUG_ENABLE

#ifdef INLINE_DEBUG_SPLIT
	// put debug output into a separate file
	debug.SetSplit ( true );
	debug.SetCombine ( false );
#endif

	debug.Create( "PS2_R5900Recompiler_Log.txt" );
#endif
	
	BlockSize = 1 << BlockSize_PowerOfTwo;
	
	MaxStep_Shift = MaxIStep_Shift;
	MaxStep = 1 << MaxIStep_Shift;
	MaxStep_Mask = MaxStep - 1;
	
	NumBlocks = 1 << NumberOfBlocks;
	NumBlocks_Mask = NumBlocks - 1;
	
	// need a mask for referencing each encoded instruction
	ulIndex_Mask = 1 << ( NumberOfBlocks + MaxIStep_Shift );
	ulIndex_Mask -= 1;
	
	// allocate variables
	//StartAddress = new u32 [ NumBlocks ];
	//RunCount = new u8 [ NumBlocks ];
	//MaxCycles = new u64 [ NumBlocks ];
	//Instructions = new u32 [ NumBlocks * MaxStep ];

	x = new x64asm::x64Assembler();
	
	// only need to compare the starting address of the entire block
	StartAddress = new u32[NumBlocks];
	LastOffset = new u32[NumBlocks];

	pSourceCode32 = new u32[NumBlocks * MaxStep];

	// need to know which loads/stores might be a hw reg read/write
	pHWRWBitmap64 = new u64[NumBlocks];
	pMacroBitmap16 = new u16[NumBlocks];

#ifdef ENABLE_R5900_CHECKSUM
	// 64-bit checksum of the source - final check to determine if recompile is really needed
	pChecksum64 = new u64[NumBlocks];
#endif


	pCodeStart = new u8 * [NumBlocks * MaxStep];
	CycleCount = new u32[NumBlocks * MaxStep];
	//EndAddress = new u32 [ NumBlocks * MaxStep ];


#ifdef VERBOSE_R5900_RECOMPILER_ALLOC
	std::cout << "\nR5900 Recompiler: Allocating space for pCodeStart (bytes): " << dec << (NumBlocks * MaxStep * sizeof(u8*));
	std::cout << "\nR5900 Recompiler: Allocating space for CycleCount (bytes): " << dec << (NumBlocks * MaxStep * sizeof(u32));
#endif


	pForwardBranchTargets = new u32 [ MaxStep ];
	
	// used internally by recompiler (in case it branches to a load/store or another branch, etc, then need to go to prefix instead)
	pPrefix_CodeStart = new u8* [ NumBlocks * MaxStep ];


#ifdef VERBOSE_R5900_RECOMPILER_ALLOC

	std::cout << "\nR5900 Recompiler: Allocating space for pPrefix_CodeStart (bytes): " << dec << (NumBlocks * MaxStep * sizeof(u8*));

#endif

	
	// create the encoder
	//e = new x64Encoder ( BlockSize_PowerOfTwo, NumBlocks );
	InstanceEncoder = new x64Encoder ( BlockSize_PowerOfTwo, NumBlocks );
	
	e = InstanceEncoder;
	
	/*
	// set the "alternate stream" with the code to clear a block
	// which should just simply return 1 (meaning to recompile the block)
	e->SwitchToAlternateStream ();
	e->MovReg32ImmX ( RAX, 1 );
	e->Ret ();
	
	// we're done in the "alternate stream"
	e->SwitchToLiveStream ();
	
	// I'd like to know the size of the code
	cout << "\nSize of alternate stream in bytes: " << dec << e->lAlternateStreamSize << " Alt Stream=" << hex << e->ullAlternateStream;
	
	// reset all the blocks
	//for ( int i = 0; i < NumBlocks; i++ ) InitBlock ( i );
	for ( int i = 0; i < NumBlocks; i++ ) e->Emit_AltStreamToBlock8 ( i );
	*/
	
	//cout << "\nAfter clear, live code stream=" << hex << (((u64*)e->LiveCodeArea) [ 0 ]);
	//cout << "\n#2=" << hex << ((u64*)e->LiveCodeArea) [ ( ( (NumBlocks-1) & e->lCodeBlockSize_Mask ) << e->lCodeBlockSize_PowerOfTwo ) >> 3 ];
	//cout << " offset=" << hex << ( ( ( 2 & e->lCodeBlockSize_Mask ) << e->lCodeBlockSize_PowerOfTwo ) >> 3 );
	
	// testing
	//pCodeStart [ 0x27e4 >> 2 ] = 0x5373b36;
	
	//ICache = IC;
	r = R5900Cpu;
	
	Reset ();
}


// destructor
R5900::Recompiler::~Recompiler ()
{
	delete e;
	
	delete StartAddress;
	delete LastOffset;

delete pSourceCode32;

delete pHWRWBitmap64;
delete pMacroBitmap16;

delete pPrefix_CodeStart;
delete pCodeStart;
delete CycleCount;
delete pForwardBranchTargets;

}


void R5900::Recompiler::Reset()
{
	//memset ( this, 0, sizeof( Recompiler ) );	
	// initialize the address and instruction so it is known that it does not refer to anything
	memset(pForwardBranchTargets, 0x00, sizeof(u32) * MaxStep);
	memset(pPrefix_CodeStart, 0x00, sizeof(u8*) * NumBlocks * MaxStep);
	memset(StartAddress, 0xff, sizeof(u32) * NumBlocks);
	memset(pCodeStart, 0x00, sizeof(u8*) * NumBlocks * MaxStep);
	memset(CycleCount, 0x00, sizeof(u32) * NumBlocks * MaxStep);

	memset(pSourceCode32, 0x00, sizeof(u32) * NumBlocks * MaxStep);

	// set the hwrw bitmaps to by default use the normal load/store vs virtual machine load/store
	memset(pHWRWBitmap64, 0xff, sizeof(u64) * NumBlocks);
	memset(pMacroBitmap16, 0xff, sizeof(u16) * NumBlocks);

#ifdef ENABLE_R5900_CHECKSUM
	memset(pChecksum64, 0xff, sizeof(u64) * NumBlocks);
#endif


#ifdef ENABLE_ICACHE
	// reset invalidate arrays
	r->Bus->Reset_Invalidate();
#endif
}



/**
 * @fn static void Calc_Checksum( VU *v )
 * @brief calculate checksum for source of recompiled code and store into "ullChecksum"
 * @param v is a pointer into the CPU object state that holds the source code that was recompiled
 * @return 64-bit checksum calculated from source cpu code mem at the current point in time
 */
u64 R5900::Recompiler::Calc_Checksum(u32 StartAddress)
{
	u32* pSrcPtr32;
	u64 ullAddress;
	u64 ullCode;
	u64 ullCurChecksum;

	u64 ullLoopCount;

	// the starting address needs to be on a block boundary
	StartAddress = (StartAddress >> (2 + MaxStep_Shift)) << (2 + MaxStep_Shift);

	// get pointer into the vu memory starting from beginning
	//pSrcPtr32 = RGetPointer ( r, StartAddress );
	pSrcPtr32 = &r->Bus->MainMemory.b32[(StartAddress & Playstation2::DataBus::MainMemory_Mask) >> 2];

	// init checksum
	ullCurChecksum = 0;

	// determine if this is vu0 or vu1
	// get the size of vu code mem based vu number etc
	ullLoopCount = 16;

	// calculate the check sum
	for (ullAddress = 0; ullAddress < ullLoopCount; ullAddress++)
	{
		// get the source code value
		ullCode = (u64)(*pSrcPtr32++);

		// multiply by the address
		ullCode *= (ullAddress + 1);

		ullCurChecksum += ullCode;
	}

	// go ahead and return check sum
	return ullCurChecksum;
}


// determine if instruction is nop
bool R5900::Recompiler::isNop(R5900::Instruction::Format i)
{
	if (!i.Value) return true;


	return false;
}

// determine if instruction is a branch or not
bool R5900::Recompiler::isBranch(R5900::Instruction::Format i)
{
	// opcode cols 4-7
	if ((i.Opcode & 0x7) >= 0x4)
	{
		// normal branches in opcode row 0
		if ((i.Opcode >> 3) == 0)
		{
			// this is branch
			return true;
		}

		// likely branches in opcode row 2
		if ((i.Opcode >> 3) == 2)
		{
			// this is branch likely
			return true;
		}
	}

	// opcode regimm
	if (i.Opcode == 1)
	{
		// regimm rt rows 0 and 2
		if (
			((i.Rt >> 3) == 0x0)
			||
			((i.Rt >> 3) == 0x2)
			)
		{
			// these are branches
			// the normal branches in rt cols 0 and 1, likely branches in rt cols 2 and 3
			return true;
		}
	}

	// cop0,cop1,cop2
	// opcode row 2 cols 0,1,2
	if ((i.Opcode & 0x7) <= 0x2)
	{
		if ((i.Opcode >> 3) == 2)
		{
			// cop0,1,2
			// bc is rs=0x8
			if (i.Rs == 0x8)
			{
				// normal branches in rt cols 0,1 likely branches in cols 2,3
				return true;
			}
		}
	}

	return false;
}

bool R5900::Recompiler::isBranchLikely(R5900::Instruction::Format i)
{
	// opcode cols 4-7
	if ((i.Opcode & 0x7) >= 0x4)
	{
		// likely branches in opcode row 2
		if ((i.Opcode >> 3) == 2)
		{
			// this is branch likely
			return true;
		}
	}

	// opcode regimm
	if (i.Opcode == 1)
	{
		// regimm rt rows 0 and 2
		if (
			((i.Rt >> 3) == 0x0)
			||
			((i.Rt >> 3) == 0x2)
			)
		{
			// these are branches
			// the normal branches in rt cols 0 and 1, likely branches in rt cols 2 and 3
			if (
				((i.Rt & 0x7) == 0x2)
				||
				((i.Rt & 0x7) == 0x3)
				)
			{
				return true;
			}
		}
	}

	// cop0,cop1,cop2
	// opcode row 2 cols 0,1,2
	if ((i.Opcode & 0x7) <= 0x2)
	{
		if ((i.Opcode >> 3) == 2)
		{
			// cop0,1,2
			// bc is rs=0x8
			if (i.Rs == 0x8)
			{
				// normal branches in rt cols 0,1 likely branches in rt cols 2,3
				if (
					((i.Rt & 0x7) == 0x2)
					||
					((i.Rt & 0x7) == 0x3)
					)
				{
					return true;
				}
			}
		}
	}

	return false;
}

// determine if instruction is a jump or not
bool R5900::Recompiler::isJump(R5900::Instruction::Format i)
{
	// opcode cols 0
	if (!(i.Opcode >> 3))
	{
		// jumps are in row 2,3
		if ((i.Opcode & 0x7) == 2)
		{
			return true;
		}

		if ((i.Opcode & 0x7) == 3)
		{
			return true;
		}
	}

	if (!i.Opcode)
	{
		if ((i.Funct >> 3) == 0x1)
		{
			if ((i.Funct & 0x7) <= 1)
			{
				return true;
			}
		}
	}

	return false;
}

// determine if instruction is a branch or jump not
bool R5900::Recompiler::isBranchOrJump(R5900::Instruction::Format i)
{
	if (
		isBranch(i)
		||
		isJump(i)
		)
	{
		return true;
	}

	return false;
}

// returns 1 if it is ok to have instruction in branch delay slot when recompiling, zero otherwise
bool R5900::Recompiler::isBranchDelayOk ( u32 ulInstruction, u32 Address )
{
#ifdef ENCODE_ALL_POSSIBLE_DELAYSLOTS

	u32 ulOpcode, ulFunction;
	
	ulOpcode = ulInstruction >> 26;
	
	
	// second row starting at second column is ok
	if ( ulOpcode >= 0x9 && ulOpcode <= 0xf )
	{

		// constant instructions that will never interrupt //
		//cout << "\nAddress=" << hex << Address << " Opcode=" << ulOpcode;
		return true;
	}
	
	
	
	// for R5900, DADDIU is ok //
	if ( ulOpcode == 0x19 )
	{
		return true;
	}
	
	
	
	// check special instructions
	if ( !ulOpcode )
	{
		ulFunction = ulInstruction & 0x3f;
		
		// first row is mostly ok
		if ( ( ( ulFunction >> 3 ) == 0 ) && ( ulFunction != 1 ) && ( ulFunction != 5 ) )
		{
			return true;
		}
		
		// row 4 is ok except for column 0 and column 2
		if ( ( ulFunction >> 3 ) == 4 && ulFunction != 0x20 && ulFunction != 0x22 )
		{
			return true;
		}
		
		// in row 5 for R3000A columns 2 and 3 are ok
		if ( ulFunction == 0x2a || ulFunction == 0x2b )
		{
			return true;
		}
		
		
		// in row 5 for R5900 columns 5 and 7 are ok //
		if ( ulFunction == 0x2d || ulFunction == 0x2f )
		{
			return true;
		}
		
		
		// for R5900, on row 2 MOVZ and MOVN are ok //
		if ( ulFunction == 0xa || ulFunction == 0xb )
		{
			return true;
		}
		
		
		// for R5900, on row 3 DSLLV, DSRLV, DSRAV or ok //
		if ( ulFunction == 0x14 || ulFunction == 0x16 || ulFunction == 0x17 )
		{
			return true;
		}
		
		// in last row for R5900, all is ok except columns 1 and 5 //
		if ( ( ulFunction >> 3 ) == 7 && ulFunction != 0x39 && ulFunction != 0x3d )
		{
			return true;
		}
		
	}
	
	// will leave out all store instructions for now to play it safe //
	
#else
	if ( !ulInstruction ) return true;
#endif
	
	return false;
}


u32 R5900::Recompiler::CloseOpLevel ( u32 OptLevel, u32 Address )
{
	switch  ( OptLevel )
	{
		case 0:
			break;
			
		case 1:
			// write back last modified register if in load delay slot
			//if ( isLoadDelaySlot )
			//{
				e->MovMemImm32 ( (s32*) &r->LastModifiedRegister, Local_LastModifiedReg );
			//}
			
			// write back "NextPC" if there was no SYSCALL
			if ( !Local_NextPCModified )
			{
				e->MovMemImm32 ( (int32_t*) & r->NextPC, Address );
			}
			break;
			
		case 2:
			// write back last modified register if in load delay slot
			//if ( isLoadDelaySlot )
			//{
				e->MovMemImm32 ( (s32*) &r->LastModifiedRegister, Local_LastModifiedReg );
			//}
			
			// write back "NextPC" if there was no SYSCALL
			if ( !Local_NextPCModified )
			{
				e->MovMemImm32 ( (int32_t*) & r->NextPC, Address );
			}
			break;
	}

	return true;
}


// if block has no recompiled code, then it should return 1 (meaning to recompile the instruction(s))
u32 R5900::Recompiler::InitBlock ( u32 Block )
{
	// set the encoder to use
	e = InstanceEncoder;

	// start encoding in block
	e->StartCodeBlock ( Block );
	
	// set return value 1 (return value for X64 goes in register A)
	e->LoadImm32 ( RAX, 1 );
	
	// return
	e->x64EncodeReturn ();
	
	// done encoding in block
	e->EndCodeBlock ();

	return true;
}



u32* R5900::Recompiler::RGetPointer ( u32 Address )
{

	
#ifdef VERBOSE_RECOMPILE
cout << "\nRGetPointer: NON-CACHED";
#endif

	// address is NOT cache-able //
	
	if ( ( Address & 0x1fc00000 ) == 0x1fc00000 )
	{
		// cached bios region //
		return & r->Bus->BIOS.b32 [ ( Address & r->Bus->BIOS_Mask ) >> 2 ];
	}
	
	// cached ram region //
	return & r->Bus->MainMemory.b32 [ ( Address & r->Bus->MainMemory_Mask ) >> 2 ];
}


// returns the bitmap for the source registers for instruction
// if the instruction is not supported, then it will return -1ULL
u64 R5900::Recompiler::GetSourceRegs ( R5900::Instruction::Format i, u32 Address )
{
	/*
	if ( !i.Value )
	{
		return 0;
	}
	*/
	
	// "special"
	if ( !i.Opcode )
	{
		return ( ( 1ULL << i.Rs ) | ( 1ULL << i.Rt ) );
	}
	
	// regimm
	if ( i.Opcode == 1 )
	{
		// rs is source reg //
		
		return ( 1ULL << i.Rs );
	}
	
	// j, jal
	if ( i.Opcode <= 3 )
	{
		return 0;
	}
	
	// beq, bne, blez, bgtz
	if ( ( i.Opcode >> 3 ) == 0 )
	{
		return ( ( 1ULL << i.Rs ) | ( 1ULL << i.Rt ) );
	}
	
	// immediates
	if ( ( i.Opcode >> 3 ) == 1 )
	{
		return ( 1ULL << i.Rs );
	}
	
	// stores
	if ( ( i.Opcode >> 3 ) == 5 )
	{
		return 0;
	}
	
	// loads
	if ( ( i.Opcode >> 3 ) == 4 )
	{
		return ( 1ULL << i.Rs );
	}
	
	return -1ULL;
	
	/*
	// check for "special"
	if ( !i.Opcode )
	{
		// rs,rt are source regs //
		
		// not including syscall or break, but these shouldn't cause problems
		if ( ( i.Funct == 12 ) || ( i.Funct == 13 ) )
		{
			return 0;
		}
		
		//if ( ( i.Funct >> 3 ) == 0 )
		//{
		//	return -1;
		//}
		
		return ( ( 1ULL << i.Rs ) | ( 1ULL << i.Rt ) );
	}
	
	// stores are cleared to go (runs load delay before the store)
	if ( ( i.Opcode >> 3 ) == 5 )
	{
		return 0;
	}
	
	// check for regimm, immediates, loads
	if ( ( i.Opcode == 1 ) || ( ( i.Opcode >> 3 ) == 1 ) || ( ( i.Opcode >> 3 ) == 4 ) )
	{
		// rs is source reg //
		
		return ( 1ULL << i.Rs );
	}
	
	// any other instructions are not cleared to go
	return -1ULL;
	*/
}


// returns the bitmap for the destination registers for instruction
// if the instruction is not supported, then it will return -1ULL
u64 R5900::Recompiler::Get_DelaySlot_DestRegs ( R5900::Instruction::Format i )
{
	
	/*
	// check for "special"
	if ( !i.Opcode )
	{
		// rd is dest reg //
		
		// not including syscall or break, but these shouldn't cause problems
		if ( ( i.Funct == 12 ) || ( i.Funct == 13 ) )
		{
			return 0;
		}
		
		
		return ( 1ULL << i.Rd );
	}
	
	// check for regimm
	if ( ( i.Opcode == 1 ) )
	{
		// rd is dest reg //
		
		if ( i.Rt >= 16 )
		{
			return ( 1ULL << 31 );
		}
	}
	
	// check for jal
	if ( i.Opcode == 3 )
	{
		return ( 1ULL << 31 );
	}
	
	// immediates
	if ( ( i.Opcode >> 3 ) == 1 )
	{
		return ( 1ULL << i.Rt );
	}
	*/
	
	// loads
	/*
	if ( ( i.Opcode >> 3 ) == 4 )
	{
		// rt is dest reg //
		
		return ( 1ULL << i.Rt );
	}
	*/
	
	
	
	// any other instructions are not cleared to go
	return 0;
}


/*
u64 R5900::Recompiler::ReturnZero ( void )
{
	return 0;
}


u64 R5900::Recompiler::ReturnOne ( void )
{
	return 1;
}


u64 R5900::Recompiler::ReturnTwo ( void )
{
	return 2;
}
*/




// returns number of instructions that were recompiled
u32 R5900::Recompiler::Recompile ( u32 BeginAddress )
{
	u32 Address, Block;
	s32 ret, Cycles;
	R5900::Instruction::Format inst;
	s32 reti;
	
	//u32 StartBlockIndex, BlockIndex, SaveBlockIndex;
	
	// number of instructions in current run
	//u32 RunCount;
	
	u32 RecompileCount;
	u32 MaxCount;
	
	//u32 ProjectedMaxCount;
	
	//u32 Snapshot_Address [ 4 ];
	//u32 Snapshot_RecompileCount [ 4 ];
	
	//static u64 MemCycles;
	u32 SetCycles;
	
	//u32* pInstrPtr;
	
	u32* pSrcCodePtr;
	u32* pNextCode;
	
	//u32* pCmpCodePtr;
	//u32* pSaveCodePtr;
	//u32* pSaveCmpPtr;
	
	u32 SaveReg0;
	u32 ulCacheLineCount;
	
	//u64 LocalCycleCount, CacheBlock_CycleCount;
	
	int RetJumpCounter;
	
	//char* ReturnFromCacheReload;
	
	int i;
	
	int iFillIndex;
	
	uint32_t First_LastModifiedReg;
	
	s32 MaxBlocks;
	
	u32 NextAddress;
	
	u64 ullSrcRegsBitmap, ullResultRegs, ullNextReg, ullNextRegIdx;
	
	
#ifdef VERBOSE_RECOMPILE
cout << "\nrecompile: starting recompile.";
#endif
#ifdef INLINE_DEBUG_RECOMPILE
	debug << "\r\nSTART->R5900::Recompiler::Recompile";
	debug << " BeginADDR=" << hex << BeginAddress;
#endif


	// need to first clear forward branch targets for the block
	memset ( pForwardBranchTargets, 0x00, sizeof( u32 ) * MaxStep );
	
	// initialize forward branch index
	// note: Will need a larger branch index table in the encoder object for larger code blocks than 128 instructions
	//ForwardBranchIndex = c_ulForwardBranchIndex_Start;


	// mask address
	// don't do this
	//StartAddress &= c_iAddress_Mask;
	
	// haven't crossed any cache lines yet
	ulCacheLineCount = 0;
	
	// set the encoder to use
	e = InstanceEncoder;
	
	// the starting address needs to be on a block boundary
	BeginAddress = ( BeginAddress >> ( 2 + MaxStep_Shift ) ) << ( 2 + MaxStep_Shift );
	
	// save the address?
	Address = BeginAddress;
	
	// set the start address for the current block so recompiler can access it
	CurrentBlock_StartAddress = BeginAddress;
	
	// set the start address for the next block also
	NextBlock_StartAddress = CurrentBlock_StartAddress + ( 1 << ( 2 + MaxStep_Shift ) );
	
	// set the current optimization level
	OpLevel = OptimizeLevel;
	
	// get the block to encode in
	// new formula
	//Block = ( BeginAddress >> 2 ) & NumBlocks_Mask;
	Block = ( BeginAddress >> ( 2 + MaxStep_Shift ) ) & NumBlocks_Mask;
	
	
	// set block initially to cache
	//DoNotCache [ Block ] = 0;
	
	// start in code block
	e->StartCodeBlock ( Block );
	
	// set the start address for code block
	// address must actually match exactly. No mask
	StartAddress [ Block ] = BeginAddress;

#ifdef ENABLE_R5900_CHECKSUM
	// also, go ahead and set the checksum for the block here
	pChecksum64 [ Block ] = Calc_Checksum( BeginAddress );
#endif
	
	// set the instruction
	//Instructions [ Block ] = *((u32*) SrcCode);
	//pInstrPtr = & ( Instructions [ Block << MaxStep_Shift ] );
	
	
	// start cycles at zero
	Cycles = 0;
	
	// start PC
	//LocalPC = r->PC;
	
	
	// init count of recompiled instructions
	RecompileCount = 0;
	
	
	// want to stop at cache boundaries (would need extra code there anyways)
	// this is handled in loop now
	//MaxCount = MaxStep - ( ( Address >> 2 ) & MaxStep_Mask );
	//if ( MaxCount <= 0 ) MaxCount = 1;
	// set the maximum number of instructions to encode
	MaxCount = MaxStep;
	
	
	// NextPC has not been modified yet
	Local_NextPCModified = false;
	
	// some instructions need to stop encoding either before or after the instruction, at least for now
	// if stopping before, it keeps the instruction if there is nothing before it in the run
	bStopEncodingAfter = false;
	bStopEncodingBefore = false;
	
	// don't reset the cycle count yet
	bResetCycleCount = false;


	
	// should set local last modified register to 255
	Local_LastModifiedReg = 255;
	
	reti = 1;
	
	
	

	// clear delay slot
	//RDelaySlots [ 0 ].Value = 0;
	//RDelaySlots [ 1 ].Value = 0;

	// clear delay slot valid bits
	//RDelaySlots_Valid = 0;
	

	
	/////////////////////////////////////////////////////
	// note: multiply and divide require cycle count to be updated first
	// since they take more than one cycle to complete
	// same for mfhi and mflo, because they are interlocked
	// same for COP2 instructions
	// same for load and store
	// do the same for jumps and branches
	//////////////////////////////////////////////////////

	
	
	// get the starting block to store instruction addresses and cycle counts
	StartBlockIndex = ( Address >> 2 ) & ulIndex_Mask;
	BlockIndex = StartBlockIndex;

	// zero out code start addresses
	for ( i = 0; i < MaxStep; i++ )
	{
		pCodeStart [ StartBlockIndex + i ] = NULL;
		pForwardBranchTargets [ i ] = -1;
	}
	
	// instruction count for current run
	RunCount = 0;
	ullLSRegs = 0;
	
	// current delay slot index
	//DSIndex = 0;
	
	// each instruction takes at least one cycle
	//if ( !MemCycles ) MemCycles = 1;
	
	
	// this should get pointer to the instruction
	// ***TODO***: if instructions are in a cached area and are cached, then they need to be pulled from cache
	// meaning that this would technically be currently INCORRECT
	pSrcCodePtr = RGetPointer ( Address );
	
	// get the cycles per instruction
	// *** TODO FOR PS2 *** 
#ifdef ENABLE_ICACHE
	// if linking, then should not subtract the MemCycle, otherwise subtract the time to read the first instruction if exiting from recompiler
	// if linking, then should not subtract the ExeCycle for last instruction, otherwise should subtract it when exiting from recompiler
	if ( ICache_Device::isCached ( Address ) )
	{
		// address is cached //
		bIsBlockInICache = true;
		
		// one cycle to execute each instruction (unless reloading cache block)
		MemCycles = 1;
		//MemCycles = 0;

		ullLoadCycles = 0;
	}
	else
	{
		// address is NOT cache-able //
		bIsBlockInICache = false;
		
		// time to execute the instruction starts with the time to read it from memory
		if ( ( Address & 0x1fc00000 ) == 0x1fc00000 )
		{
			// bios region //
			MemCycles = Playstation2::DataBus::c_iBIOS_Read_Latency;

			ullLoadCycles = Playstation2::DataBus::c_iBIOS_Read_Latency;
		}
		else
		{
			// ram region //
			MemCycles = Playstation2::DataBus::c_iRAM_Read_Latency;

			ullLoadCycles = Playstation2::DataBus::c_iRAM_Read_Latency;
		}
		
		// should be plus 1 like in the interpreter
		MemCycles += 1;
	}
#endif
	
	
	// *** todo ***
	// looks like cycles are set to 1 in interpreter, need to fix
	//MemCycles = 1;


	// need to keep track of cycles for run
	//LocalCycleCount = MemCycles - 1;
	//CacheBlock_CycleCount = 0;
	LocalCycleCount = 0;

	// need to know of any other jumps to return
	RetJumpCounter = 0;





	for( iFillIndex = 0; iFillIndex < MaxStep; iFillIndex++ )
	{

#ifdef VERBOSE_RECOMPILE
cout << "\nRecompiler: iFillIndex=" << dec << iFillIndex << " MaxStep=" << MaxStep;
#endif
#ifdef INLINE_DEBUG_RECOMPILE
	debug << "\r\nRecompiler: iFillIndex=" << dec << iFillIndex << " MaxStep=" << MaxStep;
#endif

	if ( !pCodeStart [ StartBlockIndex + iFillIndex ] )
	{
#ifdef VERBOSE_RECOMPILE
cout << "\nRecompiler: !pCodeStart";
#endif
#ifdef INLINE_DEBUG_RECOMPILE
	debug << "\r\nRecompiler: !pCodeStart";
#endif

	// need to keep track of cycles for run
	LocalCycleCount = 0;

	// need to know of any other jumps to return
	RetJumpCounter = 0;
	

	// instruction count for current run
	RunCount = 0;
	ullLSRegs = 0;

	
	// current delay slot index
	//DSIndex = 0;
	
	
	// save the address?
	//Address = BeginAddress;
	Address = BeginAddress + ( iFillIndex << 2 );
	
	// set the current optimization level
	OpLevel = OptimizeLevel;
	
	// haven't crossed any cache lines yet
	ulCacheLineCount = 0;
	
	// start cycles at zero
	Cycles = 0;
	
	
	
	// init count of recompiled instructions
	RecompileCount = 0;
	
	
	// want to stop at cache boundaries (would need extra code there anyways)
	// this is handled in loop now
	// set the maximum number of instructions to encode
	//MaxCount = MaxStep;
	MaxCount = MaxStep - iFillIndex;
	
	BlockIndex = StartBlockIndex + iFillIndex;
	
	// NextPC has not been modified yet
	Local_NextPCModified = false;
	
	// some instructions need to stop encoding either before or after the instruction, at least for now
	// if stopping before, it keeps the instruction if there is nothing before it in the run
	bStopEncodingAfter = false;
	bStopEncodingBefore = false;
	
	// don't reset the cycle count yet
	bResetCycleCount = false;


	
	// should set local last modified register to 255
	Local_LastModifiedReg = 255;
	
	reti = 1;
	
	
	// this should get pointer to the instruction
	pSrcCodePtr = RGetPointer ( Address );

	// clear pre-analysis stats
	memset(LUT_StatInfo, 0, sizeof(LUT_StatInfo));



#ifdef INLINE_DEBUG_RECOMPILE
	debug << " START-ADDR=" << hex << Address;
	debug << " MaxCount=" << dec << MaxCount;
#endif
	
#ifdef VERBOSE_RECOMPILE
cout << "\nRecompiler: Starting loop";
#endif
#ifdef INLINE_DEBUG_RECOMPILE
	debug << "\r\nRecompiler: Starting loop";
#endif
	
	
	
#ifdef VERBOSE_RECOMPILE
cout << "\nRecompiler: Starting loop";
#endif

	// for loads
	// 1. check that there are no events. If so, update Cycles,NextPC, then return
	// 2. check for synchronous interrupt
	// 3. check that there are no conflicts. If so, put load in delay slot, update Cycles,NextPC, then return
	// 4. encode load, then encode load delay slot
	// 5. if going across cache line and next line is not loaded, then put load in delay slot and return
	// 6. if it is a store in the delay slot, then can just process normally as if there is no delay slot and immediately load
	
	// for stores
	// 1. check that there are no events. If so, update Cycles,NextPC, then return
	// 2. check for synchronous interrupt
	// 3. encode store
	
	// for jumps/branches
	// 1. check that there are no events. If so, update Cycles,NextPC, then return
	// 2. check for synchronous interrupt (for jumps that might have them)
	// 3. check that there are no loads,stores,branches,delay slots, in the delay slot. If so, put branch/jump in delay slot, update Cycles,NextPC, then return
	// 4. encode jump/branch then encode delay slot
	// 5. if branching backwards within same block, if cached then make sure cache-block is loaded and then jump, implement forward jumps later?
	// 6. if not branching within same block or forward jumping before implementation, then update Cycles,NextPC, then return
	// 7. if going across cache blocks and next block not loaded, then put in delay slot and return
	
	// other delay slot instructions
	// 1. check that there are no conflicts with delay slot. If so, update Cycles,NextPC, then return
	// 2. encode instruction then encode delay slot
	// 3. if going across cache blocks and next block not loaded, then put in delay slot and return
	
	// finding source registers
	// special instructions can use rs,rt as source registers
	// stores use rs,rt as source registers
	// immediates and loads use only rs as source register



	// go ahead and set any
	
	
	//for ( i = 0; i < MaxCount; i++ )
	for ( i = iFillIndex; i < MaxStep; i++ )
	{
#ifdef VERBOSE_RECOMPILE
cout << "\nRecompiling: ADDR=" << hex << Address;
#endif


		// set the forward jumps before starting the instruction block
		// the forward jump should always be set here even if it has to redo the instruction
		Set_FJMPs ( Address );

		// set source address in encoder
		e->x64CurrentSourceAddress = Address;
		
		// start encoding a MIPS instruction
		e->StartInstructionBlock ();
		


			
		
#ifdef VERBOSE_RECOMPILE
cout << " INSTR#" << dec << i;
//cout << " LOC=" << hex << ((u64) e->Get_CodeBlock_CurrentPtr ());
cout << " CycleDiff=" << dec << LocalCycleCount;
#endif


		
		// get the instruction
		//inst.Value = *((u32*) SrcCode);
		inst.Value = *pSrcCodePtr;
		
		// get the next instruction
		// note: this does not work if the next address is in a new cache block and the region is cached
		//NextInst.Value = *(pSrcCodePtr + 1);
		if (((Address >> 2) & 0xf) == 0xf)
		{
			NextInst.Value = -1;
		}
		else
		{
			NextInst.Value = *(pSrcCodePtr + 1);
		}


		// get the previous instruction
		PrevInst.Value = 0;
		if (i)
		{
			PrevInst.Value = *(pSrcCodePtr - 1);
		}



		// store the instruction as being the source instruction that is being encoded
		pSourceCode32[StartBlockIndex + i] = inst.Value;


#ifdef USE_ADDRESS_BASED_CYCLE_COUNTS_R5900
		// set the cycle# based on address
		LocalCycleCount = (Address & 0x01ffffff) >> 2;

		// adjust based on the cycles to execute each instruction
		LocalCycleCount *= MemCycles;
#endif



		// temporary alerts //

		
		if ( inst.Opcode == 0x12 )
		{
			// alert on vdiv
			if ( ( inst.Imm11 == 0x3bc ) && ( NextInst.Imm11 != 0x3bf ) )
			{
#ifdef VERBOSE_VDIV_WO_WAITQ
				cout << "\nhps2x64: RECOMPILER: encountered VDIV w/o WAITQ at address:" << hex << Address;
				cout << "\n" << R5900::Instruction::Print::PrintInstruction ( inst.Value ).c_str ();
				cout << "\n" << R5900::Instruction::Print::PrintInstruction ( *(pSrcCodePtr + 1) ).c_str ();
				cout << "\n" << R5900::Instruction::Print::PrintInstruction ( *(pSrcCodePtr + 2) ).c_str ();
				cout << "\n" << R5900::Instruction::Print::PrintInstruction ( *(pSrcCodePtr + 3) ).c_str ();
				cout << "\n" << R5900::Instruction::Print::PrintInstruction ( *(pSrcCodePtr + 4) ).c_str ();
				cout << "\n" << R5900::Instruction::Print::PrintInstruction ( *(pSrcCodePtr + 5) ).c_str ();
				cout << "\n" << R5900::Instruction::Print::PrintInstruction ( *(pSrcCodePtr + 6) ).c_str ();
				cout << "\n" << R5900::Instruction::Print::PrintInstruction ( *(pSrcCodePtr + 7) ).c_str ();
#endif
			}

			// alert on vsqrt
			if ( ( inst.Imm11 == 0x3bd ) && ( NextInst.Imm11 != 0x3bf ) )
			{
#ifdef VERBOSE_VSQRT_WO_WAITQ
				cout << "\nhps2x64: RECOMPILER: encountered VSQRT w/o WAITQ at address:" << hex << Address;
				cout << "\n" << R5900::Instruction::Print::PrintInstruction ( inst.Value ).c_str ();
				cout << "\n" << R5900::Instruction::Print::PrintInstruction ( *(pSrcCodePtr + 1) ).c_str ();
				cout << "\n" << R5900::Instruction::Print::PrintInstruction ( *(pSrcCodePtr + 2) ).c_str ();
				cout << "\n" << R5900::Instruction::Print::PrintInstruction ( *(pSrcCodePtr + 3) ).c_str ();
				cout << "\n" << R5900::Instruction::Print::PrintInstruction ( *(pSrcCodePtr + 4) ).c_str ();
				cout << "\n" << R5900::Instruction::Print::PrintInstruction ( *(pSrcCodePtr + 5) ).c_str ();
				cout << "\n" << R5900::Instruction::Print::PrintInstruction ( *(pSrcCodePtr + 6) ).c_str ();
				cout << "\n" << R5900::Instruction::Print::PrintInstruction ( *(pSrcCodePtr + 7) ).c_str ();
#endif
			}


			// alert on vrsqrt
			if ( ( inst.Imm11 == 0x3be ) && ( NextInst.Imm11 != 0x3bf ) )
			{
#ifdef VERBOSE_VRSQRT_WO_WAITQ
				cout << "\nhps2x64: RECOMPILER: encountered VRSQRT w/o WAITQ at address:" << hex << Address;
				cout << "\n" << R5900::Instruction::Print::PrintInstruction ( inst.Value ).c_str ();
				cout << "\n" << R5900::Instruction::Print::PrintInstruction ( *(pSrcCodePtr + 1) ).c_str ();
				cout << "\n" << R5900::Instruction::Print::PrintInstruction ( *(pSrcCodePtr + 2) ).c_str ();
				cout << "\n" << R5900::Instruction::Print::PrintInstruction ( *(pSrcCodePtr + 3) ).c_str ();
				cout << "\n" << R5900::Instruction::Print::PrintInstruction ( *(pSrcCodePtr + 4) ).c_str ();
				cout << "\n" << R5900::Instruction::Print::PrintInstruction ( *(pSrcCodePtr + 5) ).c_str ();
				cout << "\n" << R5900::Instruction::Print::PrintInstruction ( *(pSrcCodePtr + 6) ).c_str ();
				cout << "\n" << R5900::Instruction::Print::PrintInstruction ( *(pSrcCodePtr + 7) ).c_str ();
#endif
			}

		}


		

		g_pSrcCodePtr = pSrcCodePtr;
		
			// not in cached region //
			
			// still need to check against edge of block
			if ( ! ( ( Address + 4 ) & ( MaxStep_Mask << 2 ) ) )
			{
				// this can actually happen, so need to prevent optimizations there
				NextInst.Value = -1;
			}
		
		


#ifdef VERBOSE_RECOMPILE
cout << " OL=" << OpLevel;
#endif

		// check if a forward branch target needs to be set
		//if ( pForwardBranchTargets [ BlockIndex & MaxStep_Mask ] )
		//{
		//	// set the branch target
		//	e->SetJmpTarget ( pForwardBranchTargets [ BlockIndex & MaxStep_Mask ] );
		//}
		
		// this is internal to recompiler and says where heading for instruction starts at
		//pPrefix_CodeStart [ BlockIndex & MaxStep_Mask ] = e->Get_CodeBlock_CurrentPtr ();
		pPrefix_CodeStart [ BlockIndex ] = (u8*) e->Get_CodeBlock_CurrentPtr ();
		
		// this can be changed by the instruction being recompiled to point to where the starting entry point should be for instruction instead of prefix
		pCodeStart [ BlockIndex ] = (u8*) e->Get_CodeBlock_CurrentPtr ();
		
	
			// must add one to the cycle offset for starting point because the interpreter adds an extra cycle at the end of run
			//CycleCount [ BlockIndex ] = LocalCycleCount + 1;
			CycleCount [ BlockIndex ] = LocalCycleCount;
		
		
		//EndAddress [ BlockIndex ] = -1;
		
		
		if ( inst.Value )
		{
		
		if ( OpLevel == 2 )
		{
			ret = R5900::Recompiler::Recompile2( Address );
			
			Local_NextPCModified = false;
			bStopEncodingBefore = false;
			bStopEncodingAfter = false;

			// if encoding was successful, then do a forward jump
			// of course, meaning that more than just one instruction was encoded
			if ( ret > 1 )
			{
				// forward jump
				FJMP( Address, Address + ( ret << 2 ) );

				// act like it was all just one instruction for testing
				ret = 1;
			}
			
#ifdef VERBOSE_RECOMPILE
cout << "\nRecompiler: Recompile2 returns: " << dec << ret;
#endif
#ifdef INLINE_DEBUG_RECOMPILE
	debug << "\r\nRecompiler: Recompile2 returns: " << dec << ret;
#endif
		}
		else
		{
			
#ifdef ENABLE_GPR_REGISTER_TIMING
			// get the source registers for instruction
			ullSrcRegsBitmap = GetGPR_SrcRegs( inst );
			
			// check if a source reg might be loading from bus
			ullResultRegs = ullLSRegs & ullSrcRegsBitmap;
			while ( ullResultRegs )
			{
				ullNextReg = ullResultRegs & -ullResultRegs;
				
				ullNextRegIdx = __builtin_ctz( ullNextReg );
				
				// put in code to check for the register
				e->MovRegMem64 ( RAX, (int64_t*) & r->CycleCount );
				e->AddReg64ImmX ( RAX, LocalCycleCount );
				//e->MovRegReg64 ( RCX, RAX );
				e->SubRegMem64 ( RAX, (int64_t*) & r->ullReg_BusyUntilCycle [ ullNextRegIdx ] );
				
				e->Cqo ();
				e->AndRegReg64 ( RAX, RDX );
				e->SubMemReg64 ( (int64_t*) & r->CycleCount, RAX );
				
				
				// remove register
				ullResultRegs ^= ullNextReg;
			}
#endif

			// set the output buffer for assembler
			x->set_output_buffer(e->Get_CodeBlock_CurrentPtr());

			// recompile the instruction
			ret = R5900::Recompiler::Recompile ( inst, Address );
		
			// update offset in code block
			if (x->get_size())
			{
				e->Update_CodeBlock_CurrentPtr(x->get_size());
			}


#ifdef INLINE_DEBUG_RECOMPILE
	debug << "\r\nRecompiler: Recompile1 returns: " << dec << ret;
#endif

#ifdef VERBOSE_RECOMPILE
cout << " ret=" << ret;
//cout << " ENC0=" << hex << (((u64*) (pCodeStart [ BlockIndex ])) [ 0 ]);
//cout << " ENC1=" << hex << (((u64*) (pCodeStart [ BlockIndex ])) [ 1 ]);
cout << " ASM: " << R5900::Instruction::Print::PrintInstruction ( inst.Value ).c_str ();
#endif
#ifdef INLINE_DEBUG_RECOMPILE
	debug << " ASM: " << R5900::Instruction::Print::PrintInstruction ( inst.Value ).c_str ();
	debug << " ADDR:" << hex << Address;
#endif

		}	// end if ( OpLevel == 2 ) else
		
		}
		else
		{

			ret = 1;

		}	// end if ( inst.Value ) else

		
#ifdef VERBOSE_RECOMPILE
cout << " ret=" << ret;
//cout << " ENC0=" << hex << (((u64*) (pCodeStart [ BlockIndex ])) [ 0 ]);
//cout << " ENC1=" << hex << (((u64*) (pCodeStart [ BlockIndex ])) [ 1 ]);
cout << " ASM: " << R5900::Instruction::Print::PrintInstruction ( inst.Value ).c_str ();
cout << " IDX: " << dec << R5900::Instruction::Lookup::FindByInstruction ( inst.Value );
#endif

		if ( ret <= 0 )
		{
			// there was a problem, and recompiling is done
			
			// need to undo whatever we did for this instruction
			e->UndoInstructionBlock ();
			Local_NextPCModified = false;
			
//cout << "\nUndo: Address=" << hex << Address;
			
			// TODO: if no instructions have been encoded yet, then just try again with a lower optimization level
			if ( OpLevel > 0 )
			{
//cout << "\nNext Op Level down";

				// could not encode the instruction at optimization level, so go down a level and try again
				OpLevel--;
				
#ifdef INLINE_DEBUG_RECOMPILE2
	debug << "\r\nREDO@OPLEVEL=" << OpLevel;
#endif

				//Address -= 4;
				
				// at this point, this should be the last instruction since we had to go down an op level
				// this shouldn't be so, actually
				//MaxCount = 1;
				
				// here we need to reset and redo the instruction
				bStopEncodingBefore = false;
				bStopEncodingAfter = false;
				Local_NextPCModified = false;
				
				bResetCycleCount = false;
				
				// redo the instruction
				i--;
				continue;
			}
			else
			{
			
				cout << "\nhps2x64: R5900: Recompiler: Error: Unable to encode instruction.";
				
				// mark block as unable to recompile if there were no instructions recompiled at all
				//if ( !Cycles ) DoNotCache [ Block ] = 1;
				
				// done
				break;
			}
		}
		
#ifdef ENABLE_SINGLE_STEP_BEFORE
			if ( !OpLevel )
			{
				bStopEncodingBefore = true;
			}
#endif
		
		
			// if this is not the first instruction, then it can halt encoding before it
			if ( RunCount && bStopEncodingBefore )
			{
#ifdef VERBOSE_RECOMPILE
cout << " bStopEncodingBefore";
#endif
#ifdef INLINE_DEBUG_RECOMPILE
	debug << " bStopEncodingBefore";
#endif

#ifdef ENCODE_SINGLE_RUN_PER_BLOCK
				// first need to take back the instruction just encoded
				e->UndoInstructionBlock ();

				// check if we are in a new icache block //
				//if ( ! ( Address & 0xf ) )
				//{
				//	// in a new cache block, so must also clear branch to take back the instruction completely
				//	e->BranchOffset [ 64 + ( i >> 2 ) ] = -1;
				//}
				

				
#ifdef UPDATE_BEFORE_RETURN
				// run count has not been updated yet for the instruction to stop encoding before
				if ( RunCount > 1 )
				{
#ifdef INLINE_DEBUG_RECOMPILE
	debug << " Terminate@ADDR=" << hex << Address;
#endif

					// check that NextPC was not modified
					// doesn't matter here except that RunCount>=1 so it is not first instruction in run, which is handled above
					// next pc was not modified because that will be handled differently now
					//if ( RunCount > 1 && !Local_NextPCModified )
					//{
						// update NextPC
						e->MovMemImm32 ( (int32_t*) & r->NextPC, Address );
						
					//}
					
					// update CPU CycleCount
					// here is is returning, so subtract the cycles to read the first instruction and the cycles to execute the last
					e->AddMem64ImmX((int64_t*)&r->CycleCount, LocalCycleCount - ullLoadCycles - EXECUTE_CYCLES);

				}	// end if ( RunCount > 1 )
#endif

#ifdef VERBOSE_RECOMPILE
cout << " RETURN";
#endif
#ifdef INLINE_DEBUG_RECOMPILE
	debug << " RETURN";
#endif

				// return;
				reti &= e->x64EncodeReturn ();


				
				// set the current optimization level
				// note: don't do this here, because the optimization level might have been changed by current instruction
				//OpLevel = OptimizeLevel;
				
				// reset flags
				bStopEncodingBefore = false;
				bStopEncodingAfter = false;
				Local_NextPCModified = false;
				
				bResetCycleCount = false;
				
				// starting a new run
				RunCount = 0;
				ullLSRegs = 0;
				
				// restart cycle count back to zero
				LocalCycleCount = 0;
				
				// clear delay slots
				//RDelaySlots [ 0 ].Value = 0;
				//RDelaySlots [ 1 ].Value = 0;
				
				//LocalCycleCount = MemCycles - 1;
				//CacheBlock_CycleCount = 0;
				
				// need to redo this instruction at this address
				// since I needed to insert the code to stop the block at this point
				i--;
				continue;
#else

				// do not encode instruction and done encoding
				e->UndoInstructionBlock ();
				Local_NextPCModified = false;
				break;
#endif
			} // end if ( RunCount && bStopEncodingBefore )

			
#ifdef USE_NEW_BRANCH_CODE_R5900
			// make sure not the first instruction in the run (so previous instruction can be loaded)
			if (RunCount)
			{
				// disable for cop0 and cop2 for now
				if (
					PrevInst.Opcode != OPCOP0
					&&
					PrevInst.Opcode != OPCOP2
					)
				{
					if (isBranchOrJump(PrevInst))
					{
						if (r->DelaySlot0_Recompiler)
						{
							//cout << "\nR5900::Recompiler | Delay Slot Encoded:";
							//cout << " BR: " << R5900::Instruction::Print::PrintInstruction(PrevInst.Value).c_str();
							//cout << " DS: " << R5900::Instruction::Print::PrintInstruction(inst.Value).c_str();


							// previous instruction was a branch or jump
							// so this is the delay slot

							// load PC
							// todo - need to specify if this is branch or jump specifically
							//e->MovReg32ImmX(RCX, Address - 4);
							if (r->DelaySlot0_TargetAddr != -1)
							{
								e->MovReg32ImmX(RCX, r->DelaySlot0_TargetAddr);
							}
							else
							{
								// jr/jalr delay slot //
								e->MovRegMem32(RCX, (int32_t*)&r->DelaySlot0.Data);
							}

							// load cycle offset
#ifdef ENABLE_R5900_BRANCH_PREDICTION_RECOMPILER
							e->MovReg32ImmX(RDX, r->DelaySlot0_BranchTakenCycles + LocalCycleCount);
#else
							e->MovReg32ImmX(RDX, LocalCycleCount);
#endif


							// test if taking the jump
							e->BtrMem32Imm((int32_t*)&r->Status.isSomethingBusy, 9);

							// jump if it is branching
							//e->Jmp_B(r->DelaySlot0_Recompiler);
							e->JMP_B(Exit_Recompiler);

						}	// end if (r->DelaySlot0_Recompiler)

						r->DelaySlot0_Recompiler = nullptr;
					}

				}
			}
#endif

			
			// instruction successfully encoded from MIPS into x64
			e->EndInstructionBlock ();
			

			// ret should be nonzero here //
			assert(ret);


			// update number of instructions that have been recompiled
			//RecompileCount++;
			RecompileCount += ret;
			
			// update to next instruction
			//pSrcCodePtr++;
			pSrcCodePtr += ret;
			
			// add number of cycles encoded
			Cycles += ret;
			
			// update address
			//Address += 4;
			Address += ( ret << 2 );

			// update instruction count for run
			//RunCount++;
			RunCount += ret;
			
			// go to next block index
			//BlockIndex++;
			BlockIndex += ret;
			
			// update the cycles for run
			LocalCycleCount += (ullLoadCycles + EXECUTE_CYCLES) * ret;
			
			// need to update i also since some instructions might have been skipped over with OpLevel 2
			i += ( ret - 1 );

#ifdef ENABLE_SINGLE_STEP
			//if ( ( NextInst.Opcode == 35 ) && ( inst.Opcode == 15 ) )
			//{
				//if ( ( (Address-4) > 0x1a6200 ) && ( (Address-4) < 0x1a6300 ) )
				//{
					//cout << "\n\n***PC=" << hex << (Address-4) << "***\n\n";
				
			bStopEncodingAfter = true;
				//}
			//}
#endif

			// reset the optimization level for next instruction
			OpLevel = OptimizeLevel;
			



		
		// if directed to stop encoding after the instruction, then do so
		if ( bStopEncodingAfter )
		{
#ifdef VERBOSE_RECOMPILE
cout << " bStopEncodingAfter";
#endif
#ifdef INLINE_DEBUG_RECOMPILE
	debug << " bStopEncodingAfter";
#endif

#ifdef ENCODE_SINGLE_RUN_PER_BLOCK


#ifdef UPDATE_BEFORE_RETURN
			// run count has already been updated at this point, but still on instruction#1
			if ( RunCount > 1 )
			{
#ifdef INLINE_DEBUG_RECOMPILE
	debug << " Terminate@ADDR=" << hex << Address;
#endif

				// there is more than one instruction in run //
				
				// check that NextPC was not modified and that this is not an isolated instruction
				// actually just need to check if NextPC was modified by the encoded instruction
				if ( !Local_NextPCModified )
				{
#ifdef INLINE_DEBUG_RECOMPILE
	debug << " SET-NEXTPC";
#endif

					// update NextPC
					e->MovMemImm32 ( (int32_t*) & r->NextPC, Address );
				}
				
				// update CycleCount
				e->AddMem64ImmX ( (int64_t*) & r->CycleCount, LocalCycleCount - ullLoadCycles - EXECUTE_CYCLES );
			}
#endif

				
#ifdef VERBOSE_RECOMPILE
cout << " RETURN";
#endif
#ifdef INLINE_DEBUG_RECOMPILE
	debug << " RETURN";
#endif

			// return;
			reti &= e->x64EncodeReturn ();


			// set the current optimization level
			OpLevel = OptimizeLevel;
			
			// reset flags
			bStopEncodingBefore = false;
			bStopEncodingAfter = false;
			Local_NextPCModified = false;
			
			bResetCycleCount = false;
			
			// clear delay slots
			//RDelaySlots [ 0 ].Value = 0;
			//RDelaySlots [ 1 ].Value = 0;
			
			// starting a new run
			RunCount = 0;
			ullLSRegs = 0;
			
			// restart cycle count to zero
			LocalCycleCount = 0;
			
			
#else

				break;
#endif
		} // if ( bStopEncodingAfter )
			
			
			
		// reset flags
		bStopEncodingBefore = false;
		bStopEncodingAfter = false;
		Local_NextPCModified = false;
		
		bResetCycleCount = false;
		

	} // end for ( int i = 0; i < MaxStep; i++, Address += 4 )

#ifdef VERBOSE_RECOMPILE
cout << "\nRecompiler: Done with loop";
#endif


	// also need to set forward branches to the end
	Set_FJMPs ( Address );


	// debug
	//cout << "\nR5900 RECOMPILER CONNECT ADJACENT ADDR:" << hex << Address;
	//cout << " BLOCKADDR:" << (u64)e->Get_CodeBlock_CurrentPtr();
	//cout << " STARTBLOCKADDR:" << (u64)e->Get_CodeBlock_StartPtr();
	//cout << " ENDBLOCKADDR:" << (u64)e->Get_CodeBlock_EndPtr();
	//cout << " NEXTBLOCKADDR:" << (u64)e->Get_XCodeBlock_StartPtr((Block + 1) & NumBlocks_Mask);

#ifdef ENABLE_CONNECT_ADJACENT_BLOCKS

#ifdef CONNECT_BLOCKS_ONLY_IN_ICACHE
	if (bIsBlockInICache)
#endif
	{
		if (!Local_NextPCModified)
		{
			if (!isBranchOrJump(inst))
			{

				// load nextpc and cyclecount diff

				e->MovReg32ImmX(RCX, Address);
				e->MovReg32ImmX(RDX, LocalCycleCount - ullLoadCycles - EXECUTE_CYCLES);

				//e->JMP(Exit_Recompiler);

				// step 3: if next block is cached, check that it is in i-cache
				if (bIsBlockInICache)
				{
					// get the cache line that address should be at
					u32 ICacheBlockIndex = (Address >> 6) & 0x7f;

					// make room for the way
					ICacheBlockIndex <<= 1;

					e->MovRegMem32(RAX, (int32_t*)&r->ICache.PFN[ICacheBlockIndex + 0]);
					e->CmpReg32ImmX(RAX, (Address & 0x1fffffc0));
					e->CmovNERegMem32(RAX, (int32_t*)&r->ICache.PFN[ICacheBlockIndex + 1]);
					e->CmpReg32ImmX(RAX, (Address & 0x1fffffc0));

					e->CmovERegMem32(RAX, (int32_t*)&StartAddress[(Block + 1) & NumBlocks_Mask]);
					e->CmpReg32ImmX(RAX, Address);
					//e->JMP_NE(Exit_Recompiler);

				}
				else
				{
					// step 2: check if next block has the correct source address
					e->CmpMem32ImmX((int32_t*)&StartAddress[(Block + 1) & NumBlocks_Mask], Address);
					//e->JMP_NE(Exit_Recompiler);

				}

				e->JMP_NE(Exit_Recompiler);

#ifdef CONNECT_BLOCKS_CHECK_EVENTS
				// get updated CycleCount value for CPU
				e->MovRegMem64(RAX, (int64_t*)&r->CycleCount);
				//e->AddReg64ImmX(RAX, ullCycles_Compare);
				//e->AddReg64ImmX(RAX, LocalCycleCount - (MemCycles - 1));
				//e->AddReg64ImmX ( RAX, LocalCycleCount - MemCycles );
				e->AddRegReg64(RAX, RDX);


				// want check that there are no events pending //

				// get the current cycle count and compare with next event cycle
				// note: actually need to either offset the next event cycle and correct when done or
				// or need to offset the next even cycle into another variable and check against that one
				e->CmpRegMem64(RAX, (int64_t*)&Playstation2::System::_SYSTEM->NextEvent_Cycle);

				// branch if current cycle is greater (or equal?) than next event cycle
				// changing this so that it branches if not returning
				// note: should probably be below or equal then jump, since the interpreter adds one to cycle
				e->JMP_AE(Exit_Recompiler);
#endif

				// update the cycle count
				e->AddMem64ImmX((int64_t*)&r->CycleCount, LocalCycleCount);

				// update PC in case of load/store to virtual mem interrupt ?
				e->MovMemImm32((int32_t*)&r->PC, Address);
				e->MovMemImm32((int32_t*)&r->NextPC, Address + 4);

				e->JMP(e->Get_XCodeBlock_StartPtr((Block + 1) & NumBlocks_Mask));
				//e->JmpMem64((int64_t*)&pCodeStart[BlockIndex]);
			}

		}	// end if (!Local_NextPCModified)
	}

#endif	// end ENABLE_CONNECT_ADJACENT_BLOCKS



#ifdef ENCODE_SINGLE_RUN_PER_BLOCK
	// at end of block need to return ok //
	
	// encode return if it has not already been encoded at end of block
	if ( RunCount > 1 )
	{
	
#ifdef UPDATE_BEFORE_RETURN

#ifdef INLINE_DEBUG_RECOMPILE
	debug << " Terminate@ADDR=" << hex << Address;
#endif

		// check that NextPC was not modified and that this is not an isolated instruction
		if ( !Local_NextPCModified )
		{
#ifdef INLINE_DEBUG_RECOMPILE
	debug << " SET-NEXTPC";
#endif

			// update NextPC
			e->MovMemImm32 ( (int32_t*) & r->NextPC, Address );
		}
		
		// update CycleCount
		// after update need to put in the minus MemCycles
		// if returning, then -MemCycles and -ExeCycles
		e->AddMem64ImmX ( (int64_t*) & r->CycleCount, LocalCycleCount - ullLoadCycles - EXECUTE_CYCLES );

#endif

	} // end if ( RunCount > 1 )

#ifdef VERBOSE_RECOMPILE
cout << "\nulCacheLineCount=" << dec << ulCacheLineCount;
#endif


#ifdef VERBOSE_RECOMPILE
cout << "\nRecompiler: Encoding RETURN";
#endif
#ifdef INLINE_DEBUG_RECOMPILE
	debug << " RETURN";
#endif


	// return;
	reti &= e->x64EncodeReturn ();
	
#endif

	}
	
	}

	
	// done encoding block
	e->EndCodeBlock ();
	
	// address is now encoded
	
	
	if ( !reti )
	{
		cout << "\nRecompiler: Out of space in code block.";
	}

#ifdef VERBOSE_RECOMPILE
//cout << "\n(when all done)TEST0=" << hex << (((u64*) (pCodeStart [ 0x27e4 >> 2 ])) [ 0 ]);
//cout << " TEST1=" << hex << (((u64*) (pCodeStart [ 0x27e4 >> 2 ])) [ 1 ]);
#endif

	
	return reti;
	//return RecompileCount;
}



// code generation //

// generate the instruction prefix to check for any pending events
// will also update NextPC,CycleCount (CPU) and return if there is an event
// will also update CycleCount (System) on a load or store
int32_t R5900::Recompiler::Generate_Prefix_EventCheck ( u32 Address, bool bIsBranchOrJump )
{
	int32_t ret;
	
	// get updated CycleCount value for CPU
	e->MovRegMem64 ( RAX, (int64_t*) & r->CycleCount );
	e->AddReg64ImmX ( RAX, LocalCycleCount );
	
	
	// want check that there are no events pending //
	
	// get the current cycle count and compare with next event cycle
	// note: actually need to either offset the next event cycle and correct when done or
	// or need to offset the next even cycle into another variable and check against that one
	e->CmpRegMem64 ( RAX, (int64_t*) & Playstation2::System::_SYSTEM->NextEvent_Cycle );
	
	// branch if current cycle is greater (or equal?) than next event cycle
	// changing this so that it branches if not returning
	//e->Jmp_A ( 0, 100 + RetJumpCounter++ );
	e->Jmp8_B ( 0, 0 );
	
	// update NextPC
	e->MovMemImm32 ( (int32_t*) & r->NextPC, Address );
	
	// update CPU CycleCount
	e->MovMemReg64 ( (int64_t*) & r->CycleCount, RAX );
	
	// done for now - return
	ret = e->Ret ();
	
	// jump to here to continue execution in code block
	e->SetJmpTarget8 ( 0 );
	
	// if it is a branch or a jump, then no need to update the System CycleCount
	if ( !bIsBranchOrJump )
	{
		// since we have not reached the next event cycle, should write back the current system cycle
		// so that the correct cycle# gets seen when the store is executed
		// no need to update the CPU cycle count until either a branch/jump is encountered or returning
		// this way, there is no need to reset the current cycle number tally unless a branch/jump is encountered
		ret = e->MovMemReg64 ( (int64_t*) & Playstation2::System::_SYSTEM->CycleCount, RAX );
	}

	return ret;
}


int32_t R5900::Recompiler::Generate_Virtual_Store(R5900::Instruction::Format i, u32 Address, u32 BitTest, void* StoreFunctionToCall)
{
	int32_t ret = 0;

	// this is the number of Cycles to update CycleCount if this instruction does NOT execute successfully
	u64 ullCycles_Compare = LocalCycleCount - ullLoadCycles;
	u64 ullCycles_OnError = LocalCycleCount;

#ifdef CHECK_EVENT_AFTER_START_STORE_VIRTUAL
	if (RunCount)
	{
		// part 1: first check for event //

		// get updated CycleCount value for CPU
		e->MovRegMem64(RAX, (int64_t*)&r->CycleCount);
		e->AddReg64ImmX(RAX, ullCycles_Compare);
		//e->AddReg64ImmX(RAX, LocalCycleCount - (MemCycles - 1));
		//e->AddReg64ImmX ( RAX, LocalCycleCount - MemCycles );


		// want check that there are no events pending //

		// get the current cycle count and compare with next event cycle
		// note: actually need to either offset the next event cycle and correct when done or
		// or need to offset the next even cycle into another variable and check against that one
		e->CmpRegMem64(RAX, (int64_t*)&Playstation2::System::_SYSTEM->NextEvent_Cycle);

		// branch if current cycle is greater (or equal?) than next event cycle
		// changing this so that it branches if not returning
		// note: should probably be below or equal then jump, since the interpreter adds one to cycle
		e->Jmp8_B(0, 0);
		//e->Jmp_AE(0, 2);


		// update NextPC
		e->MovMemImm32((int32_t*)&r->NextPC, Address);

		// update CPU CycleCount
		// did not actually execute this instruction, so before return do -MemCycles and -ExeCycles
		//e->MovMemReg64 ( (int64_t*) & r->CycleCount, RAX );
		e->AddMem64ImmX((int64_t*)&r->CycleCount, ullCycles_OnError);
		//e->AddMem64ImmX((int64_t*)&r->CycleCount, LocalCycleCount - MemCycles);
		//e->AddMem64ImmX ( (int64_t*) & r->CycleCount, LocalCycleCount - MemCycles - ExeCycles );

		// done for now - return
		e->Ret();


		e->SetJmpTarget8(0);

		// since we have not reached the next event cycle, should write back the current system cycle
		// so that the correct cycle# gets seen when the store is executed
		// no need to update the CPU cycle count until either a branch/jump is encountered or returning
		// this way, there is no need to reset the current cycle number tally unless a branch/jump is encountered
		e->MovMemReg64((int64_t*)&Playstation2::System::_SYSTEM->CycleCount, RAX);

		// part 2: check for synchronous interrupt //

		// this is where the entry point should be if this is the first instruction in the run
		pCodeStart[BlockIndex] = (u8*)e->Get_CodeBlock_CurrentPtr();
	}
#endif	// end #ifdef CHECK_EVENT_AFTER_START_STORE_VIRTUAL


#ifdef ENABLE_EXCEPTION_INFO_VIRTUAL
	//e->MovReg64ImmX(8, ((u64)Address) | (ullCycles_OnError << 32));
	e->MovReg64ImmX(8, (u64)Address);
#endif


	if (i.Base)
	{
		//u32 StoreAddress = r->GPR [ i.Base ].s + i.sOffset;
		e->MovRegFromMem32(RDX, &r->GPR[i.Base].sw0);

		//e->MovReg64ImmX(RCX, 0x200000000ull);
		//e->XorRegReg32(RCX, RCX);

		// mask address
		//e->AndReg32ImmX(RDX, 0x5fffffff);

		// set the correct bit in address for ps2 r5900 bus
		//e->BtsRegImm64(RDX, 33);
	}
	else
	{
		e->XorRegReg32(RDX, RDX);

		//e->MovReg64ImmX(RCX, 0x200000000ull);
		//e->BtsRegImm64(RDX, 33);
	}


	// get the value to store //

	if (i.Rt || (i.Opcode == OPSQC2) || (i.Opcode == OPSWC1))
	{
		switch (i.Opcode)
		{
		case OPSB:
			e->MovRegMem32(RAX, &r->GPR[i.Rt].sw0);
			break;
		case OPSH:
			e->MovRegMem32(RAX, &r->GPR[i.Rt].sw0);
			break;
		case OPSWL:
#ifdef USE_SHORT_SWL_CODE
			e->MovRegMem32(RAX, &r->GPR[i.Rt].sw0);
			break;
#endif
		case OPSWR:
#ifdef USE_SHORT_SWR_CODE
			e->MovRegMem32(RAX, &r->GPR[i.Rt].sw0);
			break;
#endif
		case OPSW:
			e->MovRegMem32(RAX, &r->GPR[i.Rt].sw0);
			break;
		case OPSWC1:
			e->MovRegMem32(RAX, &r->CPR1[i.Rt].s);
			break;
		case OPSDL:
#ifdef USE_SHORT_SDL_CODE
			e->MovRegMem64(RAX, &r->GPR[i.Rt].sq0);
			break;
#endif
		case OPSDR:
#ifdef USE_SHORT_SDR_CODE
			e->MovRegMem64(RAX, &r->GPR[i.Rt].sq0);
			break;
#endif
		case OPSD:
			e->MovRegMem64(RAX, &r->GPR[i.Rt].s);
			break;
		case OPSQ:
			e->movdqa_regmem(RAX, (void*)&r->GPR[i.Rt].s);
			break;
		case OPSQC2:
			e->movdqa_regmem(RAX, (void*)&VU0::_VU0->vf[i.Ft].sq0);
			break;
		}
	}
	else
	{
		switch (i.Opcode)
		{
		case OPSQ:
			e->pxorregreg(RAX, RAX);
			break;

		default:
			e->XorRegReg32(RAX, RAX);
			break;

		}

	}


	// store the value //
	e->BtsRegImm64(RDX, Playstation2::DataBus::BUS_R5900_TRANSFER_BIT);

	switch (i.Opcode)
	{
	case OPSB:
		ret = e->MovRegToMem8(RAX, RDX, NO_INDEX, SCALE_NONE, i.sOffset);
		break;
	case OPSH:
		ret = e->MovRegToMem16(RAX, RDX, NO_INDEX, SCALE_NONE, i.sOffset);
		break;
	case OPSWL:
#ifdef USE_SHORT_SWL_CODE
		e->LeaRegRegImm64(8, RDX, i.sOffset);
		//e->AndReg32ImmX(8, ~0x3);
		e->AndReg64ImmX(8, ~0x3);

		e->MovRegFromMem32(9, 8, NO_INDEX, SCALE_NONE, -4);
		e->MovRegToMem32(RAX, RDX, NO_INDEX, SCALE_NONE, -3 + i.sOffset);
		ret = e->MovRegToMem32(9, 8, NO_INDEX, SCALE_NONE, -4);
		break;
#endif
	case OPSWR:
#ifdef USE_SHORT_SWR_CODE
		e->LeaRegRegImm64(8, RDX, i.sOffset);
		//e->AndReg32ImmX(8, ~0x3);
		e->AndReg64ImmX(8, ~0x3);

		e->MovRegFromMem32(9, 8, NO_INDEX, SCALE_NONE, 4);
		e->MovRegToMem32(RAX, RDX, NO_INDEX, SCALE_NONE, 0 + i.sOffset);
		ret = e->MovRegToMem32(9, 8, NO_INDEX, SCALE_NONE, 4);
		break;
#endif
	case OPSW:
		ret = e->MovRegToMem32(RAX, RDX, NO_INDEX, SCALE_NONE, i.sOffset);
		break;
	case OPSWC1:
		ret = e->MovRegToMem32(RAX, RDX, NO_INDEX, SCALE_NONE, i.sOffset);
		break;
	case OPSDL:
#ifdef USE_SHORT_SDL_CODE
		e->LeaRegRegImm64(8, RDX, i.sOffset);
		//e->AndReg32ImmX(8, ~0x7);
		e->AndReg64ImmX(8, ~0x7);

		e->MovRegFromMem64(9, 8, NO_INDEX, SCALE_NONE, -8);
		e->MovRegToMem64(RAX, RDX, NO_INDEX, SCALE_NONE, -7 + i.sOffset);
		ret = e->MovRegToMem64(9, 8, NO_INDEX, SCALE_NONE, -8);
		break;
#endif
	case OPSDR:
#ifdef USE_SHORT_SDR_CODE
		e->LeaRegRegImm64(8, RDX, i.sOffset);
		//e->AndReg32ImmX(8, ~0x7);
		e->AndReg64ImmX(8, ~0x7);

		e->MovRegFromMem64(9, 8, NO_INDEX, SCALE_NONE, 8);
		e->MovRegToMem64(RAX, RDX, NO_INDEX, SCALE_NONE, 0 + i.sOffset);
		ret = e->MovRegToMem64(9, 8, NO_INDEX, SCALE_NONE, 8);
		break;
#endif
	case OPSD:
		ret = e->MovRegToMem64(RAX, RDX, NO_INDEX, SCALE_NONE, i.sOffset);
		break;
	case OPSQ:
		//e->AddReg32ImmX(RDX, i.sOffset);
		//e->AndReg32ImmX(RDX, ~0xf);
		e->AddReg64ImmX(RDX, i.sOffset);
		e->AndReg64ImmX(RDX, ~0xf);

		// ***TODO*** movdqa below does not work with R10 as base
		//ret = e->movdqa_to_mem128(RAX, RDX, RCX, SCALE_NONE, i.sOffset);
		ret = e->movdqa_to_mem128(RAX, RDX, NO_INDEX, SCALE_NONE, 0);
		break;
	case OPSQC2:
		// ***TODO*** THIS COULD CAUSE AN UNALIGNED exception unless alignment is checked above
		// ***TODO*** movdqa below does not work with R10 as base
		ret = e->movdqa_to_mem128(RAX, RDX, NO_INDEX, SCALE_NONE, i.sOffset);
		break;
	}

	return ret;
}



int32_t R5900::Recompiler::Generate_Cached_Store(R5900::Instruction::Format i, u32 Address, u32 BitTest, void* LoadFunctionToCall)
{
	int32_t ret = 0;


#ifdef ENABLE_EXCEPTION_INFO_CACHED
	//e->MovReg64ImmX(8, ((u64)Address) | (ullCycles_OnError << 32));
	e->MovReg64ImmX(8, (u64)Address);
#endif

	// get physical address -> rcx
	e->MovRegFromMem32(RCX, &r->GPR[i.Base].sw0);
	e->AddReg32ImmX(RCX, i.sOffset);
	e->AndReg32ImmX(RCX, 0x5fffffff);

	// get the cache line index -> rax
	e->MovRegReg32(RAX, RCX);
	e->ShrRegImm32(RAX, 6);
	e->AndReg32ImmX(RAX, 0x3f);
	e->AddRegReg32(RAX, RAX);

	// get current cycle# -> r9
	e->MovRegMem64(8, (int64_t*)&r->CycleCount);
	e->LeaRegRegImm64(9, 8, LocalCycleCount);

	// get pointer into DCache
	e->LeaRegMem64(11, (void*)&r->DCache);

	// get PFN -> rdx
	e->MovRegReg32(10, RCX);
	e->AndReg32ImmX(10, 0x5fffffc0);

	// check if any of the PFNs match the physical address
	e->CmpRegMem32(10, 11, RAX, SCALE_FOUR, offsetof(DCache_Device, PFN) + 0);
	e->Jmp8_E(0, 0);

	// inc the way (low bit rax)
	e->IncReg32(RAX);

	// check the other PFN
	e->CmpRegMem32(10, 11, RAX, SCALE_FOUR, offsetof(DCache_Device, PFN) + 0);
	e->Jmp8_E(0, 1);

	// jump if cache already loaded

	// need to reload cache //

	// restore the cache line index
	e->DecReg32(RAX);


	// get the way from LRFs
	e->MovRegReg32(RDX, RAX);
	e->XorRegMem8(RAX, 11, RDX, SCALE_NONE, offsetof(DCache_Device, LRF) + 0);
	e->XorRegMem8(RAX, 11, RDX, SCALE_NONE, offsetof(DCache_Device, LRF) + 1);


	// set valid for the way
	e->MovMemImm8(1, 11, RAX, SCALE_NONE, offsetof(DCache_Device, Valid));

	// update LRF for the way
	e->XorMemImm8(1, 11, RAX, SCALE_NONE, offsetof(DCache_Device, LRF));

	// save previous pfn -> r8
	e->MovRegFromMem32(8, 11, RAX, SCALE_FOUR, offsetof(DCache_Device, PFN));

	// store PFN for the way
	e->MovRegToMem32(10, 11, RAX, SCALE_FOUR, offsetof(DCache_Device, PFN));

	// check if cache line is dirty, if so then write back
	e->MovRegFromMem8(RDX, 11, RAX, SCALE_FOUR, offsetof(DCache_Device, Dirty));

	// note: set dirty for the way if storing
	e->MovMemImm8(1, 11, RAX, SCALE_NONE, offsetof(DCache_Device, Dirty));

	// this is a READ, so cache-line is going to be clean. otherwise comment this out
	//e->MovMemImm8(0, 11, RAX, SCALE_NONE, offsetof(DCache_Device, Dirty));

	// pre-shift the index
	e->ShlRegImm32(RAX, 3);

	e->OrRegReg8(RDX, RDX);
	e->Jmp8_E(0, 2);

	// load dirty cache line
	e->movdqa_to_mem128(RAX, 11, RAX, SCALE_EIGHT, offsetof(DCache_Device, Data) + 0);
	e->movdqa_to_mem128(RBX, 11, RAX, SCALE_EIGHT, offsetof(DCache_Device, Data) + 16);
	e->movdqa_to_mem128(RCX, 11, RAX, SCALE_EIGHT, offsetof(DCache_Device, Data) + 32);
	e->movdqa_to_mem128(RDX, 11, RAX, SCALE_EIGHT, offsetof(DCache_Device, Data) + 48);

	// write-back dirty cache line
	e->BtsRegImm64(8, 33);
	e->movdqa_to_mem128(RAX, 8, NO_INDEX, SCALE_NONE, 0);
	e->movdqa_to_mem128(RBX, 8, NO_INDEX, SCALE_NONE, 16);
	e->movdqa_to_mem128(RCX, 8, NO_INDEX, SCALE_NONE, 32);
	e->movdqa_to_mem128(RDX, 8, NO_INDEX, SCALE_NONE, 48);


	e->SetJmpTarget8(2);

	// load cache line -> a,b,c,d
	// mask address first
	e->BtsRegImm64(10, 33);
	e->movdqa_from_mem128(RAX, 10, NO_INDEX, SCALE_NONE, 0);
	e->movdqa_from_mem128(RBX, 10, NO_INDEX, SCALE_NONE, 16);
	e->movdqa_from_mem128(RCX, 10, NO_INDEX, SCALE_NONE, 32);
	e->movdqa_from_mem128(RDX, 10, NO_INDEX, SCALE_NONE, 48);

	// write cache line
	e->movdqa_to_mem128(RAX, 11, RAX, SCALE_EIGHT, offsetof(DCache_Device, Data) + 0);
	e->movdqa_to_mem128(RBX, 11, RAX, SCALE_EIGHT, offsetof(DCache_Device, Data) + 16);
	e->movdqa_to_mem128(RCX, 11, RAX, SCALE_EIGHT, offsetof(DCache_Device, Data) + 32);
	e->movdqa_to_mem128(RDX, 11, RAX, SCALE_EIGHT, offsetof(DCache_Device, Data) + 48);

	// check against the cycle# of the last d-cache miss
	// blocks on miss under miss until the last miss is handled ?
	e->MovRegReg64(RDX, 9);
	e->SubRegMem64(RDX, (int64_t*)&r->LoadFromBus_BusyUntilCycle);
	//e->Cqo();
	e->SbbRegReg64(10, 10);
	e->AndRegReg64(RDX, 10);
	//e->SubRegReg64(8, RDX);
	//e->MovMemReg64((int64_t*)&r->CycleCount, 8);
	e->SubMemReg64((int64_t*)&r->CycleCount, RDX);

	// set busy until
	e->LeaRegRegImm64(RDX, 9, r->Bus->c_iRAM_Read_Latency);
	e->MovRegToMem64(RDX, 11, RAX, SCALE_NONE, offsetof(DCache_Device, busyUntilCycles64));

	// set the last miss busy until cycle#
	e->MovMemReg64((int64_t*)&r->LoadFromBus_BusyUntilCycle, RDX);

	// set the gpr register busy until if gpr register - but not for store
	//if ((i.Opcode != OPLQC2) && (i.Opcode != OPLWC1))
	//{
	//	e->MovMemReg64((int64_t*)&r->ullReg_BusyUntilCycle[i.Rt], RDX);
	//}


	// if not gpr (COP1/COP2), then do blocking load


	e->Jmp8_E(0, 3);


	// continue if cache aleady loaded (cache line index -> rax, way -> rdx)
	e->SetJmpTarget8(0);
	e->SetJmpTarget8(1);

	// check against the cycle# of the last miss on this cache-line
	e->MovRegFromMem64(10, 11, RAX, SCALE_EIGHT, offsetof(DCache_Device, busyUntilCycles64));
	e->SubRegReg64(9, 10);
	//e->Cqo();
	e->SbbRegReg64(10, 10);
	e->AndRegReg64(9, 10);
	//e->SubRegReg64(8, 9);
	//e->MovMemReg64((int64_t*)&r->CycleCount, 8);
	e->SubMemReg64((int64_t*)&r->CycleCount, 9);

	// note: set dirty for the way if storing
	e->MovMemImm8(1, 11, RAX, SCALE_NONE, offsetof(DCache_Device, Dirty));

	// pre-shift the index
	e->ShlRegImm32(RAX, 3);


	// bring it all together
	e->SetJmpTarget8(3);

	// perform load from cache

	// get offset in cache-line
	e->MovRegReg32(RDX, RCX);


	switch (i.Opcode)
	{
	case OPLWL:
	case OPLWR:
		e->MovRegReg32(8, RDX);
		e->AndReg32ImmX(RDX, 0x3c);
		break;

	case OPLDL:
	case OPLDR:
		e->MovRegReg32(8, RDX);
		e->AndReg32ImmX(RDX, 0x38);
		break;

	case OPLQ:
		e->AndReg32ImmX(RDX, 0x30);
		break;

	default:
		e->AndReg32ImmX(RDX, 0x3f);
		break;
	}



	// add to base address
	e->AddRegReg32(RDX, 11);


	// store the value to memory //


	// store the value
	switch (i.Opcode)
	{
	case OPSB:
		e->MovRegMem32(RCX, &r->GPR[i.Rt].sw0);
		//e->MovRegToMem8(RAX, RDX, RCX, SCALE_NONE, 0);
		ret = e->MovRegToMem8(RCX, RDX, RAX, SCALE_EIGHT, offsetof(DCache_Device, Data));
		break;
	case OPSH:
		e->MovRegMem32(RCX, &r->GPR[i.Rt].sw0);
		//e->MovRegToMem16(RAX, RDX, RCX, SCALE_NONE, 0);
		ret = e->MovRegToMem16(RCX, RDX, RAX, SCALE_EIGHT, offsetof(DCache_Device, Data));
		break;
	case OPSWL:
#ifdef USE_SHORT_SWL_CODE
		e->MovRegMem32(RCX, &r->GPR[i.Rt].sw0);
		//e->MovRegReg32(8, RDX);
		//e->AndReg32ImmX(RDX, ~0x3);

		e->MovRegFromMem32(9, RDX, RAX, SCALE_EIGHT, offsetof(DCache_Device, Data) - 4);
		e->MovRegToMem32(RCX, 8, RAX, SCALE_EIGHT, offsetof(DCache_Device, Data) - 3);
		e->MovRegToMem32(9, RDX, RAX, SCALE_EIGHT, offsetof(DCache_Device, Data) - 4);

		break;
#endif
	case OPSWR:
#ifdef USE_SHORT_SWR_CODE
		e->MovRegMem32(RCX, &r->GPR[i.Rt].sw0);
		//e->MovRegReg32(8, RDX);
		//e->AndReg32ImmX(RDX, ~0x3);

		e->MovRegFromMem32(9, RDX, RAX, SCALE_EIGHT, offsetof(DCache_Device, Data) + 4);
		e->MovRegToMem32(RCX, 8, RAX, SCALE_EIGHT, offsetof(DCache_Device, Data) + 0);
		e->MovRegToMem32(9, RDX, RAX, SCALE_EIGHT, offsetof(DCache_Device, Data) + 4);

		break;
#endif
	case OPSW:
		e->MovRegMem32(RCX, &r->GPR[i.Rt].sw0);
		//e->MovRegToMem32(RAX, RDX, RCX, SCALE_NONE, 0);
		ret = e->MovRegToMem16(RCX, RDX, RAX, SCALE_EIGHT, offsetof(DCache_Device, Data));
		break;
	case OPSWC1:
		e->MovRegMem32(RCX, &r->CPR1[i.Rt].s);
		//e->MovRegToMem32(RAX, RDX, RCX, SCALE_NONE, 0);
		ret = e->MovRegToMem32(RCX, RDX, RAX, SCALE_EIGHT, offsetof(DCache_Device, Data));
		break;
	case OPSDL:
#ifdef USE_SHORT_SDL_CODE
		e->MovRegMem64(RCX, &r->GPR[i.Rt].sq0);
		//e->MovRegReg32(8, RDX);
		//e->AndReg32ImmX(RDX, ~0x7);

		e->MovRegFromMem64(9, RDX, RAX, SCALE_EIGHT, offsetof(DCache_Device, Data) - 8);
		e->MovRegToMem64(RCX, 8, RAX, SCALE_EIGHT, offsetof(DCache_Device, Data) - 7);
		e->MovRegToMem64(9, RDX, RAX, SCALE_EIGHT, offsetof(DCache_Device, Data) - 8);

		break;
#endif
	case OPSDR:
#ifdef USE_SHORT_SDR_CODE
		e->MovRegMem64(RCX, &r->GPR[i.Rt].sq0);
		//e->MovRegReg32(8, RDX);
		//e->AndReg32ImmX(RDX, ~0x7);

		e->MovRegFromMem64(9, RDX, RAX, SCALE_EIGHT, offsetof(DCache_Device, Data) + 8);
		e->MovRegToMem64(RCX, 8, RAX, SCALE_EIGHT, offsetof(DCache_Device, Data) + 0);
		e->MovRegToMem64(9, RDX, RAX, SCALE_EIGHT, offsetof(DCache_Device, Data) + 8);

		break;
#endif
	case OPSD:
		e->MovRegMem64(RCX, &r->GPR[i.Rt].s);
		//e->MovRegToMem64(RAX, RDX, RCX, SCALE_NONE, 0);
		ret = e->MovRegToMem64(RCX, RDX, RAX, SCALE_EIGHT, offsetof(DCache_Device, Data));
		break;
	case OPSQ:
		e->movdqa_regmem(RCX, (void*)&r->GPR[i.Rt].s);
		//e->AndReg32ImmX(RDX, ~0xf);
		// ***TODO*** movdqa below does not work with R10 as base
		//e->MovRegReg64 ( RAX, 10 );
		//e->movdqa_to_mem128(RAX, RDX, RCX, SCALE_NONE, 0);
		ret = e->movdqa_to_mem128(RCX, RDX, RAX, SCALE_EIGHT, offsetof(DCache_Device, Data));
		break;
	case OPSQC2:
		e->movdqa_regmem(RCX, (void*)&VU0::_VU0->vf[i.Ft].sq0);
		// ***TODO*** movdqa below does not work with R10 as base
		//e->MovRegReg64 ( RAX, 10 );
		//e->movdqa_to_mem128(RAX, RDX, RCX, SCALE_NONE, 0);
		ret = e->movdqa_to_mem128(RCX, RDX, RAX, SCALE_EIGHT, offsetof(DCache_Device, Data));
		break;
	}


	return ret;
}



// BitTest should be 1 for SH, 3 for SW, 0 for SB, etc
int32_t R5900::Recompiler::Generate_Normal_Store ( R5900::Instruction::Format i, u32 Address, u32 BitTest, void* StoreFunctionToCall )
{
	int32_t ret;
	
	// this is the number of Cycles to update CycleCount if this instruction does NOT execute successfully
	u64 ullCycles_Compare = LocalCycleCount - ullLoadCycles;
	u64 ullCycles_OnError = LocalCycleCount;

	bool bPerformInlineStore = false;
	
	// set register as being recompiled into load/store
	// also needs to be reset when the runcount gets reset
	ullLSRegs |= ( 1ull << i.Rt );
	
	// part 1: first check for event //
	
#ifdef CHECK_EVENT_AFTER_START_STORE
	//if ( RunCount )
	{
	// get updated CycleCount value for CPU (the value as it would be after instruction executed)
	e->MovRegMem64 ( RAX, (int64_t*) & r->CycleCount );
	e->AddReg64ImmX ( RAX, ullCycles_Compare);
	
	
	// want check that there are no events pending //
	
	// get the current cycle count and compare with next event cycle
	// note: actually need to either offset the next event cycle and correct when done or
	// or need to offset the next even cycle into another variable and check against that one
	e->CmpRegMem64 ( RAX, (int64_t*) & Playstation2::System::_SYSTEM->NextEvent_Cycle );
	
	// branch if current cycle is greater (or equal?) than next event cycle
	// changing this so that it branches if not returning
	// note: should probably be below or equal then jump, since the interpreter adds one to cycle
	//e->Jmp_AE ( 0, 2 );
	
	e->MovRegImm32(RCX, Address);
	e->MovRegImm32(RDX, ullCycles_OnError);
	e->JMP_AE((void*)Exit_Recompiler);

	// since we have not reached the next event cycle, should write back the current system cycle
	// so that the correct cycle# gets seen when the store is executed
	// no need to update the CPU cycle count until either a branch/jump is encountered or returning
	// this way, there is no need to reset the current cycle number tally unless a branch/jump is encountered
	//e->DecReg64 ( RAX );
	e->MovMemReg64 ( (int64_t*) & Playstation2::System::_SYSTEM->CycleCount, RAX );
	
	// part 2: check for synchronous interrupt //
	
	// this is where the entry point should be if this is the first instruction in the run
	pCodeStart [ BlockIndex ] = (u8*) e->Get_CodeBlock_CurrentPtr ();
	}
#endif
	
	// get the store address
	//u32 StoreAddress = r->GPR [ i.Base ].s + i.sOffset;
	e->MovRegFromMem32 ( RCX, &r->GPR [ i.Base ].sw0 );
	e->AddReg32ImmX ( RCX, i.sOffset );

	// check for synchronous interrupt

#ifdef ENABLE_TEST_ALIGNED_STORE
	// if there is a synchronous interrupt possible, then check for it
	if ( BitTest )
	{
		// if ( StoreAddress & 0x1 )
		e->TestReg32ImmX ( RCX, BitTest );

		// branch if NOT zero
		//e->Jmp8_E ( 0, 0 );
		e->Jmp_NE ( 0, 3 );
		
	}
#endif
	
	// part 3: execute the store //
	
#ifdef ENABLE_INLINE_STORE

	// exclusions for testing
	switch ( i.Opcode )
	{
		case OPSB:
		case OPSH:
		case OPSW:
		case OPSWC1:
		case OPSD:
		case OPSWL:
		case OPSWR:
		case OPSDL:
		case OPSDR:
		case OPSQ:
		case OPSQC2:
			bPerformInlineStore = true;
			break;
		
			
		default:
			bPerformInlineStore = false;
			break;
	}
	
	if ( bPerformInlineStore )
	{

	// RCX has the address
	// RDX has the value to store
	
	// get the index into the device pointer array
	e->MovRegReg32 ( RAX, RCX );
	e->ShrRegImm32 ( RAX, 22 );
	//e->AddRegReg32 ( RAX, RAX );
	e->ShlRegImm32 ( RAX, 2 );
	
	// get the pointer into the device pointer array
	//e->MovRegImm64 ( 9, (u64) & Playstation2::DataBus::LUT_DataBus_Write );
	e->LeaRegMem64 ( 9, & Playstation2::DataBus::LUT_DataBus_Write );
	
	
	switch ( i.Opcode )
	{
		case OPSQ:
		case OPSQC2:
			// load the pointer into the device into RCX
			// save RCX into R9 first, though
			//e->MovRegReg32 ( 9, RCX );
			e->MovRegFromMem64 ( RDX, 9, RAX, SCALE_EIGHT, 0 );
			
			// jump if zero
			//e->CmpReg64ImmX ( RDX, 0 );
			e->OrRegReg64 ( RDX, RDX );
			break;
			
		default:
			// load the pointer into the device into RCX
			// save RCX into R9 first, though
			//e->MovRegReg32 ( 9, RCX );
			e->MovRegFromMem64 ( RDX, 9, RAX, SCALE_EIGHT, 0 );
			
			// jump if zero
			//e->CmpReg64ImmX ( 10, 0 );
			e->OrRegReg64 ( RDX, RDX );
			break;
	}
	
	
	//e->Jmp_E ( 0, 0 );
	//e->Jmp8_E ( 0, 0 );
	
#ifdef ENABLE_R5900_DCACHE
	// if simulating DCache, then need to add latency before calling load function
	//e->Jmp_E ( 0, 16 );
	
	// not loading, data goes to store buffer - no latency
	e->Jmp_E ( 0, 0 );
#else
	// if not simulating DCache, no need to add latency, just call load function
	e->Jmp8_E ( 0, 0 );
#endif

#ifdef ENABLE_R5900_DCACHE
	e->MovRegReg32 ( 10, RCX );
#endif

	// mask address
	e->AndRegMem32 ( RCX, 9, RAX, SCALE_EIGHT, 8 );

#ifdef ENABLE_R5900_DCACHE
	// check if this is scratch-pad or un-cached/accelerated
	// save address in RAX
	e->TestReg32ImmX ( 10, 0x60000000 );
	e->Jmp_NE ( 0, 10 );
	
	// data is cached in DCache //
	
	// get mask address for comparison -> R10
	e->AndReg32ImmX ( 10, 0x1fffffc0 );
	
	
	// check if cache-hit or cache-miss //
	
	// mask address with appropriate mask from lookup
	
	// get the base index -> RAX
	e->MovRegReg32 ( RAX, RCX );
	e->ShrRegImm32 ( RAX, 6 );
	e->AndReg32ImmX ( RAX, 0x3f );
	e->AddRegReg32 ( RAX, RAX );

	// CycleCount -> R8
	e->MovRegMem64 ( 8, (int64_t*) & r->CycleCount );
	e->AddReg64ImmX ( 8, LocalCycleCount - MemCycles );
	
	// check for cache-hit #1
	e->LeaRegMem64 ( 9, (void*) & r->DCache.PFN );
	e->CmpRegMem32 ( 10, 9, RAX, SCALE_FOUR, 0 );
	e->Jmp_E ( 0, 11 );
	
	// if it's a hit, then the hit code needs to know what index the hit is at
	e->IncReg32 ( RAX );
	
	// check for cache-hit #2
	e->CmpRegMem32 ( 10, 9, RAX, SCALE_FOUR, 0 );
	e->Jmp_E ( 0, 12 );
	
	// cache-miss //
	
	// get next index -> RAX
	// get xor LRF -> R10
	e->DecReg32 ( RAX );
	e->LeaRegMem64 ( 9, (void*) & r->DCache.LRF );
	e->MovRegFromMem8 ( 11, 9, RAX, SCALE_NONE, 0 );
	e->XorRegMem8 ( 11, 9, RAX, SCALE_NONE, 1 );
	e->LeaRegMem64 ( 9, (void*) & r->DCache.Valid );
	e->MovRegFromMem16 ( 9, 9, RAX, SCALE_NONE, 0 );
	e->CmpReg16ImmX ( 9, 0x0101 );
	e->CmovERegReg32 ( 9, 11 );
	e->AndReg32ImmX ( 9, 1 );
	e->OrRegReg32 ( RAX, 9 );
	
	// mark as valid
	e->LeaRegMem64 ( 9, (void*) & r->DCache.Valid );
	e->MovMemImm8 ( 1, 9, RAX, SCALE_NONE, 0 );
	
	// calculate bus time //
	
	
#ifdef ENABLE_DCACHE_TIMING_STORE
	// LoadFromBus_BusyUntilCycle -> R9
	e->MovRegMem64 ( 9, (int64_t*) & r->LoadFromBus_BusyUntilCycle );
	
	// if ( r->CycleCount < r->LoadFromBus_BusyUntilCycle )
	// handle condition #1 -> r->CycleCount = r->LoadFromBus_BusyUntilCycle + r->Bus->c_iRAM_Read_Latency + r->c_ullCacheRefill_CycleTime;
	e->CmpRegReg64 ( 8, 9 );
	
	if ( ( i.Opcode == OPSWC1 ) || ( i.Opcode == OPSQC2 ) )
	{
		// always blocking load //
		e->CmovBRegReg64 ( 8, 9 );
		
#ifdef ENABLE_BUS_SIMULATION_CACHE_STORE
		e->MovRegMem64 ( 11, (int64_t*) & r->Bus->BusyUntil_Cycle );
		e->AddReg64ImmX ( 8, r->Bus->c_iRAM_Read_Latency );
		e->CmpRegReg64 ( 8, 11 );
		e->CmovBRegReg64 ( 8, 11 );
		e->AddReg64ImmX ( 8, r->c_ullCacheRefill_CycleTime );
		e->MovMemReg64 ( (int64_t*) & r->Bus->BusyUntil_Cycle, 8 );
#else
		e->AddReg64ImmX ( 8, r->Bus->c_iRAM_Read_Latency + r->c_ullCacheRefill_CycleTime );
#endif
	}
	else
	{
#ifdef ENABLE_BUS_SIMULATION_CACHE_STORE
		e->MovRegMem64 ( 11, (int64_t*) & r->Bus->BusyUntil_Cycle );
		e->Jmp8_AE ( 0, 20 );
		e->AddReg64ImmX ( 8, r->Bus->c_iRAM_Read_Latency );
		e->CmpRegReg64 ( 8, 11 );
		e->CmovBRegReg64 ( 8, 11 );
		e->AddReg64ImmX ( 8, r->c_ullCacheRefill_CycleTime );
		e->MovMemReg64 ( (int64_t*) & r->Bus->BusyUntil_Cycle, 8 );
		e->Jmp8 ( 0, 21 );
		
		e->SetJmpTarget8 ( 20 );
		e->AddReg64ImmX ( 9, r->Bus->c_iRAM_Read_Latency );
		e->CmpRegReg64 ( 9, 11 );
		e->CmovBRegReg64 ( 9, 11 );
		e->AddReg64ImmX ( 9, r->c_ullCacheRefill_CycleTime );
		e->MovMemReg64 ( (int64_t*) & r->Bus->BusyUntil_Cycle, 9 );
		
		// write-back R9
		e->MovMemReg64 ( (int64_t*) & r->LoadFromBus_BusyUntilCycle, 9 );
		e->LeaRegMem64 ( 11, (void*) & r->RefillDCache_BusyUntilCycle );
		e->MovRegToMem64 ( 9, 11, RAX, SCALE_EIGHT, 0 );
#else
		e->LeaRegRegImm64 ( 11, 9, r->Bus->c_iRAM_Read_Latency + r->c_ullCacheRefill_CycleTime );
		e->CmovBRegReg64 ( 8, 11 );
		
		// handle condition #2 -> r->LoadFromBus_BusyUntilCycle = r->CycleCount + r->Bus->c_iRAM_Read_Latency + r->c_ullCacheRefill_CycleTime
		e->LeaRegRegImm64 ( 11, 8, r->Bus->c_iRAM_Read_Latency + r->c_ullCacheRefill_CycleTime );
		e->CmovAERegReg64 ( 9, 11 );
		
		// write-back R9
		e->MovMemReg64 ( (int64_t*) & r->LoadFromBus_BusyUntilCycle, 9 );
		
		// -> r->RefillDCache_BusyUntilCycle [ ulIndex ] = r->LoadFromBus_BusyUntilCycle;
		// ptr r->RefillDCache_BusyUntilCycle -> R10
		// r->RefillDCache_BusyUntilCycle [ ulIndex ] -> R10
		e->LeaRegMem64 ( 9, (void*) & r->RefillDCache_BusyUntilCycle );
		e->CmovBRegMem64 ( 11, 9, RAX, SCALE_EIGHT, 0 );
		
		// write-back R8, R9, R11
		// write-back R11
		e->MovRegToMem64 ( 11, 9, RAX, SCALE_EIGHT, 0 );
#endif

#ifdef ENABLE_BUS_SIMULATION_CACHE_STORE
		e->SetJmpTarget8 ( 21 );
#endif
	}
	
	// write-back R8
	e->SubReg64ImmX ( 8, LocalCycleCount - MemCycles );
	e->MovMemReg64 ( (int64_t*) & r->CycleCount, 8 );
#endif

	// get pointer to dirty bit before shifting index ??
	// save index in -> R8
	e->MovRegReg32 ( 8, RAX );
	
	// get cache-line pointer + index -> RAX
	e->LeaRegMem64 ( 9, (void*) & r->DCache.Data );
	e->ShlRegImm32 ( RAX, 6 );
	e->AddRegReg64 ( RAX, 9 );

	// get masked PFN RAM offset -> R9
	e->LeaRegMem64 ( 11, (void*) & r->DCache.PFN );
	e->MovRegFromMem32 ( 9, 11, 8, SCALE_FOUR, 0 );
	e->AndReg32ImmX ( 9, (int32_t) ( r->Bus->MainMemory_Mask & 0x1fffffc0 ) );
	
	// update PFN
	e->MovRegToMem32 ( 10, 11, 8, SCALE_FOUR, 0 );
	
	// update LRF
	e->LeaRegMem64 ( 11, (void*) & r->DCache.LRF );
	e->XorMemImm8 ( 1, 11, 8, SCALE_NONE, 0 );
	
	// check if cache-line is dirty
	e->LeaRegMem64 ( 10, (void*) & r->DCache.Dirty );
	e->XorRegReg32 ( 11, 11 );
	e->CmpRegMem8 ( 11, 10, 8, SCALE_NONE, 0 );
	
	// set dirty
	e->MovMemImm8 ( 1, 10, 8, SCALE_NONE, 0 );
	
	e->Jmp8_E ( 0, 15 );
	
	// cache-line is dirty and needs write-back //
	
	
	
#ifdef ENABLE_DCACHE_DATA_WRITE
	// get write-back pointer -> R11
	e->LeaRegMem64 ( 11, (void*) & r->Bus->MainMemory.b8 );
	
	// write-back
	e->movdqa_from_mem128 ( RAX, RAX, NO_INDEX, SCALE_NONE, 0 );
	e->movdqa_from_mem128 ( RBX, RAX, NO_INDEX, SCALE_NONE, 16 );
	e->movdqa_from_mem128 ( RCX, RAX, NO_INDEX, SCALE_NONE, 32 );
	e->movdqa_from_mem128 ( RDX, RAX, NO_INDEX, SCALE_NONE, 48 );
	e->movdqa_to_mem128 ( RAX, 11, 9, SCALE_NONE, 0 );
	e->movdqa_to_mem128 ( RBX, 11, 9, SCALE_NONE, 16 );
	e->movdqa_to_mem128 ( RCX, 11, 9, SCALE_NONE, 32 );
	e->movdqa_to_mem128 ( RDX, 11, 9, SCALE_NONE, 48 );
#endif
	
	// get invalidate pointer -> R11
	e->LeaRegMem64 ( 11, (void*) & r->Bus->InvalidArray );
	
	// invalidate (using RCX again below)
	//e->MovRegReg32 ( 8, RCX );
	e->ShrRegImm32 ( 9, 6 );
	e->MovMemImm8 ( 1, 11, 9, SCALE_NONE, 0 );
	
	// reload cache-line from device //
	if ( !e->SetJmpTarget8 ( 15 ) ) { cout << "\nProblem setting jump target #15\n"; }
	
	// device pointer is already in -> RDX
	// reload
	e->MovRegReg32 ( 8, RCX );
	e->AndReg32ImmX ( 8, 0x1fffffc0 );
#ifdef ENABLE_DCACHE_DATA_READ
	e->movdqa_from_mem128 ( RAX, RDX, 8, SCALE_NONE, 0 );
	e->movdqa_from_mem128 ( RBX, RDX, 8, SCALE_NONE, 16 );
	e->movdqa_from_mem128 ( RCX, RDX, 8, SCALE_NONE, 32 );
	e->movdqa_from_mem128 ( RDX, RDX, 8, SCALE_NONE, 48 );
	e->movdqa_to_mem128 ( RAX, RAX, NO_INDEX, SCALE_NONE, 0 );
	e->movdqa_to_mem128 ( RBX, RAX, NO_INDEX, SCALE_NONE, 16 );
	e->movdqa_to_mem128 ( RCX, RAX, NO_INDEX, SCALE_NONE, 32 );
	e->movdqa_to_mem128 ( RDX, RAX, NO_INDEX, SCALE_NONE, 48 );
#endif
	
	
#ifdef DCACHE_WRITE_MEMORY
	// get memory pointer
#else
	// get cache-line pointer -> mask address -> proceed
	e->MovRegReg64 ( RDX, RAX );
	e->AndReg32ImmX ( RCX, 0x3f );
#endif
	
	e->Jmp ( 0, 14 );
	
	// cache-hit //
	if ( !e->SetJmpTarget ( 11 ) ) { cout << "\nProblem setting jump target #11\n"; }
	if ( !e->SetJmpTarget ( 12 ) ) { cout << "\nProblem setting jump target #12\n"; }
	
#ifdef ENABLE_DCACHE_TIMING_STORE
	// calculate the bus time
	//e->MovRegMem64 ( 8, (int64_t*) & r->CycleCount );
	e->LeaRegMem64 ( 9, (void*) & r->RefillDCache_BusyUntilCycle );
	e->MovRegFromMem64 ( 9, 9, RAX, SCALE_EIGHT, 0 );
	e->CmpRegReg64 ( 8, 9 );
	e->CmovBRegReg64 ( 8, 9 );
	e->SubReg64ImmX ( 8, LocalCycleCount - MemCycles );
	e->MovMemReg64 ( (int64_t*) & r->CycleCount, 8 );
#endif
	
	// mark cache-line as dirty
	e->LeaRegMem64 ( 10, (void*) & r->DCache.Dirty );
	e->MovMemImm8 ( 1, 10, RAX, SCALE_NONE, 0 );
	
#ifdef DCACHE_WRITE_MEMORY
	// get memory pointer
#else
	// get cache-line pointer -> RDX
	// index should be in -> RAX
	e->ShlRegImm32 ( RAX, 6 );
	e->LeaRegMem64 ( RDX, (void*) & r->DCache.Data );
	e->AddRegReg64 ( RDX, RAX );
	
	// only 64-bytes in cache line - mask address
	e->AndReg32ImmX ( RCX, 0x3f );
#endif
	
	// get invalidate pointer -> R11
	//e->LeaRegMem64 ( 11, (void*) & r->Bus->InvalidArray );
	
	// proceed to load the value from cache
	e->Jmp8 ( 0, 13 );
	
	// data is un-cached or accelerated or scratch-pad //
	if ( !e->SetJmpTarget ( 10 ) ) { cout << "\nProblem setting jump target #10\n"; }
	
#endif
	
	
	
#ifdef ENABLE_MEMORY_INVALIDATE
	// get pointer into invalidate array
	e->MovRegFromMem64 ( 11, 9, RAX, SCALE_EIGHT, 16 );

	// testing
	//e->MovMemReg32 ( & r->testvar [ 0 ], 11 );
	//e->MovMemReg32 ( & r->testvar [ 1 ], RCX );
	
	// also need to invalidate recompiler cache
	e->MovRegReg32 ( 10, RCX );
	e->ShrRegImm32 ( 10, 2 + r->Bus->c_iInvalidate_Shift );
	e->MovMemImm8 ( 1, 11, 10, SCALE_NONE, 0 );
#endif

	// testing
	//e->MovMemReg32 ( & r->testvar [ 2 ], RCX );
	//e->MovMemReg32 ( & r->testvar [ 3 ], RDX );
	
	
#ifdef ENABLE_R5900_DCACHE
	if ( !e->SetJmpTarget ( 16 ) ) { cout << "\nProblem setting jump target #16\n"; }

	/*
#ifdef ENABLE_DCACHE_TIMING_STORE
	// calculate the latency for the device and update cycle count //
	
	// get the device latency -> R10
	e->MovRegFromMem32 ( 10, 9, RAX, SCALE_EIGHT, 12 );
	
	// get CycleCount -> R8
	// get LoadFromBus_BusyUntilCycle -> R9
	e->MovRegMem64 ( 8, (int64_t*) & r->CycleCount );
	e->AddReg64ImmX ( 8, LocalCycleCount - ( MemCycles - 1 ) );
	e->MovRegMem64 ( 9, (int64_t*) & r->LoadFromBus_BusyUntilCycle );
	e->CmpRegReg64 ( 8, 9 );
	
	if ( ( i.Opcode == OPSWC1 ) || ( i.Opcode == OPSQC2 ) )
	{
		// always blocking load //
		e->CmovBRegReg64 ( 8, 9 );
		e->AddRegReg64 ( 8, 10 );
	}
	else
	{
		// r->CycleCount = r->LoadFromBus_BusyUntilCycle + r->Bus->GetLatency();
		e->LeaRegRegReg64 ( RAX, 9, 10 );
		e->CmovBRegReg64 ( 8, RAX );
		
		// r->LoadFromBus_BusyUntilCycle = r->CycleCount + r->Bus->GetLatency();
		e->LeaRegRegReg64 ( RAX, 8, 10 );
		e->CmovAERegReg64 ( 9, RAX );
		
		// write-back R8, R9
		e->MovMemReg64 ( (int64_t*) & r->LoadFromBus_BusyUntilCycle, 9 );
	}
	
	// write-back R8
	e->SubReg64ImmX ( 8, LocalCycleCount - ( MemCycles - 1 ) );
	e->MovMemReg64 ( (int64_t*) & r->CycleCount, 8 );
#endif
	
	// jump again if device is a register
	e->OrRegReg64 ( RDX, RDX );
	e->Jmp8_E ( 0, 0 );
	*/

	// proceed to load value
	if ( !e->SetJmpTarget8 ( 13 ) ) { cout << "\nProblem setting jump target #13\n"; }
	if ( !e->SetJmpTarget ( 14 ) ) { cout << "\nProblem setting jump target #14\n"; }
#endif

	
	// store the value
	switch ( i.Opcode )
	{
		case OPSB:
			e->MovRegMem32 ( RAX, &r->GPR [ i.Rt ].sw0 );
			e->MovRegToMem8 ( RAX, RDX, RCX, SCALE_NONE, 0 );
			break;
		case OPSH:
			e->MovRegMem32 ( RAX, &r->GPR [ i.Rt ].sw0 );
			e->MovRegToMem16 ( RAX, RDX, RCX, SCALE_NONE, 0 );
			break;
		case OPSWL:
#ifdef USE_SHORT_SWL_CODE
			e->MovRegMem32 ( RAX, &r->GPR [ i.Rt ].sw0 );
			e->MovRegReg32 ( 8, RCX );
			e->AndReg32ImmX ( RCX, ~0x3 );

			e->MovRegFromMem32 ( 9, RDX, RCX, SCALE_NONE, -4 );
			e->MovRegToMem32 ( RAX, RDX, 8, SCALE_NONE, -3 );
			e->MovRegToMem32 ( 9, RDX, RCX, SCALE_NONE, -4 );

			/*
			e->MovRegMem32(RAX, &r->GPR[i.Rt].sw0);
			e->MovRegReg32(8, RCX);
			e->AndReg32ImmX(8, ~0x3);

			e->NotReg32(RCX);
			e->AndReg32ImmX(RCX, 0x3);
			e->ShlRegImm32(RCX, 3);

			e->MovRegImm32(9, -1);
			e->ShrRegReg32(RAX);
			e->ShrRegReg32(9);
			e->NotReg32(9);
			e->AndRegMem32(9, RDX, 8, SCALE_NONE, 0);
			e->OrRegReg32(RAX, 9);

			e->MovRegToMem32(RAX, RDX, 8, SCALE_NONE, 0);
			*/
			break;
#endif
		case OPSWR:
#ifdef USE_SHORT_SWR_CODE
			e->MovRegMem32 ( RAX, &r->GPR [ i.Rt ].sw0 );
			e->MovRegReg32 ( 8, RCX );
			e->AndReg32ImmX ( RCX, ~0x3 );

			e->MovRegFromMem32 ( 9, RDX, RCX, SCALE_NONE, 4 );
			e->MovRegToMem32 ( RAX, RDX, 8, SCALE_NONE, 0 );
			e->MovRegToMem32 ( 9, RDX, RCX, SCALE_NONE, 4 );

			/*
			e->MovRegMem32(RAX, &r->GPR[i.Rt].sw0);
			e->MovRegReg32(8, RCX);
			e->AndReg32ImmX(8, ~0x3);

			e->AndReg32ImmX(RCX, 0x3);
			e->ShlRegImm32(RCX, 3);

			e->MovRegImm32(9, -1);
			e->ShlRegReg32(RAX);
			e->ShlRegReg32(9);
			e->NotReg32(9);
			e->AndRegMem32(9, RDX, 8, SCALE_NONE, 0);
			e->OrRegReg32(RAX, 9);

			e->MovRegToMem32(RAX, RDX, 8, SCALE_NONE, 0);
			*/
			break;
#endif
		case OPSW:
			e->MovRegMem32 ( RAX, &r->GPR [ i.Rt ].sw0 );
			e->MovRegToMem32 ( RAX, RDX, RCX, SCALE_NONE, 0 );
			break;
		case OPSWC1:
			e->MovRegMem32 ( RAX, &r->CPR1 [ i.Rt ].s );
			e->MovRegToMem32 ( RAX, RDX, RCX, SCALE_NONE, 0 );
			break;
		case OPSDL:
#ifdef USE_SHORT_SDL_CODE
			e->MovRegMem64 ( RAX, &r->GPR [ i.Rt ].sq0 );
			e->MovRegReg32 ( 8, RCX );
			e->AndReg32ImmX ( RCX, ~0x7 );
			//e->AndRegMem32 ( 8, 9, RAX, SCALE_EIGHT, 8 );

			e->MovRegFromMem64 ( 9, RDX, RCX, SCALE_NONE, -8 );
			e->MovRegToMem64 ( RAX, RDX, 8, SCALE_NONE, -7 );
			e->MovRegToMem64 ( 9, RDX, RCX, SCALE_NONE, -8 );

			/*
			e->MovRegMem64(RAX, &r->GPR[i.Rt].sq0);
			e->MovRegReg32(8, RCX);
			e->AndReg32ImmX(8, ~0x7);

			e->NotReg32(RCX);
			e->AndReg32ImmX(RCX, 0x7);
			e->ShlRegImm32(RCX, 3);

			e->MovRegImm64(9, -1);
			e->ShrRegReg64(RAX);
			e->ShrRegReg64(9);
			e->NotReg64(9);
			e->AndRegMem64(9, RDX, 8, SCALE_NONE, 0);
			e->OrRegReg64(RAX, 9);

			e->MovRegToMem64(RAX, RDX, 8, SCALE_NONE, 0);
			*/
			break;
#endif
		case OPSDR:
#ifdef USE_SHORT_SDR_CODE
			e->MovRegMem64 ( RAX, &r->GPR [ i.Rt ].sq0 );
			e->MovRegReg32 ( 8, RCX );
			e->AndReg32ImmX ( RCX, ~0x7 );
			//e->AndRegMem32 ( 8, 9, RAX, SCALE_EIGHT, 8 );

			e->MovRegFromMem64 ( 9, RDX, RCX, SCALE_NONE, 8 );
			e->MovRegToMem64 ( RAX, RDX, 8, SCALE_NONE, 0 );
			e->MovRegToMem64 ( 9, RDX, RCX, SCALE_NONE, 8 );

			/*
			e->MovRegMem64(RAX, &r->GPR[i.Rt].sq0);
			e->MovRegReg32(8, RCX);
			e->AndReg32ImmX(8, ~0x7);

			e->AndReg32ImmX(RCX, 0x7);
			e->ShlRegImm32(RCX, 3);

			e->MovRegImm64(9, -1ll);
			e->ShlRegReg64(RAX);
			e->ShlRegReg64(9);
			e->NotReg64(9);
			e->AndRegMem64(9, RDX, 8, SCALE_NONE, 0);
			e->OrRegReg64(RAX, 9);

			e->MovRegToMem64(RAX, RDX, 8, SCALE_NONE, 0);
			*/

			break;
#endif
		case OPSD:
			e->MovRegMem64 ( RAX, &r->GPR [ i.Rt ].s );
			e->MovRegToMem64 ( RAX, RDX, RCX, SCALE_NONE, 0 );
			break;
		case OPSQ:
			e->movdqa_regmem ( RAX, (void*) &r->GPR [ i.Rt ].s );
			e->AndReg32ImmX ( RCX, ~0xf );
			// ***TODO*** movdqa below does not work with R10 as base
			//e->MovRegReg64 ( RAX, 10 );
			e->movdqa_to_mem128 ( RAX, RDX, RCX, SCALE_NONE, 0 );
			break;
		case OPSQC2:
			e->movdqa_regmem ( RAX, (void*) & VU0::_VU0->vf [ i.Ft ].sq0 );
			// ***TODO*** movdqa below does not work with R10 as base
			//e->MovRegReg64 ( RAX, 10 );
			e->movdqa_to_mem128 ( RAX, RDX, RCX, SCALE_NONE, 0 );
			break;
	}
	
	

	// testing
	//e->MovRegMem32 ( RCX, & r->Bus->MainMemory.b32 [ ( /*Address*/ 0x588 & r->Bus->MainMemory_Mask ) >> 2 ] );
	//e->MovMemReg32 ( & r->testvar [ 4 ], RCX );
	
	e->Jmp8 ( 0, 1 );
	
	
	} // end if ( bPerformInlineStore )
	else
	{
	e->Jmp8 ( 0, 0 );
	}
#else
	e->Jmp8 ( 0, 0 );
#endif

	// if synchronous interrupt is possible, then handle it here
	
#ifdef ENABLE_TEST_ALIGNED_STORE
	if ( BitTest )
	{
		if ( !e->SetJmpTarget ( 3 ) ) { cout << "\nProblem setting jump target #3\n"; }
		
		// update CycleCount, set PC, then jump to synchronous interrupt
		// here the instruction is exectued, so -MemCycles, NOT -ExeCycles, but possibly +TrapCycles?
		//e->MovMemReg64 ( (int64_t*) & r->CycleCount, RAX );
		e->AddMem64ImmX ( (int64_t*) & r->CycleCount, LocalCycleCount );
		//e->AddMem64ImmX ( (int64_t*) & r->CycleCount, LocalCycleCount - MemCycles );
		
		// set pc
		e->MovMemImm32 ( (int32_t*) & r->PC, Address );
		
		//r->ProcessSynchronousInterrupt ( Cpu::EXC_ADES );
		e->JMP ( (void*) Cpu::ProcessSynchronousInterrupt_t<Cpu::EXC_ADES> );
		
	}
#endif	// end #ifdef ENABLE_TEST_ALIGNED_STORE


	// continue processing store from here //
#ifdef ENABLE_R5900_DCACHE
	e->SetJmpTarget ( 0 );
#else
	if ( !e->SetJmpTarget8 ( 0 ) ) { cout << "\nProblem setting jump target #0\n"; }
#endif
	
	// call the function to store value //

	switch ( i.Opcode )
	{
		case OPSQ:
			// get address of value to store
			e->LeaRegMem64 ( RDX, &r->GPR [ i.Rt ].s );
			
			break;

		case OPSQC2:
			// get address of value to store
			e->LeaRegMem64 ( RDX, & VU0::_VU0->vf [ i.Ft ].sq0 );
			
			break;
			
		case OPSWC1:
			// get the value to store from COP1 register
			e->MovRegMem32 ( RDX, &r->CPR1 [ i.Rt ].s );
			break;
			
		case OPSD:
			// get the value to store (64-bit)
			e->MovRegMem64 ( RDX, &r->GPR [ i.Rt ].s );
			break;
			
		case OPSWL:
			// temporarily save store address
			e->MovRegReg32 ( RDX, RCX );
			
			e->NotReg32 ( RCX );
			e->AndReg32ImmX ( RCX, 3 );
			//e->XorReg32ImmX ( RCX, 3 );
			e->ShlRegImm32 ( RCX, 3 );
			e->MovReg32ImmX ( RAX, -1 );
			e->ShrRegReg32 ( RAX );
			e->MovRegReg32 ( 8, RAX );
			e->MovRegMem32 ( RAX, &r->GPR [ i.Rt ].sw0 );
			e->ShrRegReg32 ( RAX );
			e->MovRegReg32 ( RCX, RDX );
			e->MovRegReg32 ( RDX, RAX );
		
			// clear bottom two bits of address
			e->AndReg32ImmX ( RCX, ~0x3 );
			
			break;
			
		case OPSWR:
			// temporarily save store address
			e->MovRegReg32 ( RDX, RCX );
			
			//e->NotReg32 ( RCX );
			e->AndReg32ImmX ( RCX, 3 );
			//e->XorReg32ImmX ( RCX, 3 );
			e->ShlRegImm32 ( RCX, 3 );
			e->MovReg32ImmX ( RAX, -1 );
			e->ShlRegReg32 ( RAX );
			e->MovRegReg32 ( 8, RAX );
			e->MovRegMem32 ( RAX, &r->GPR [ i.Rt ].sw0 );
			e->ShlRegReg32 ( RAX );
			e->MovRegReg32 ( RCX, RDX );
			e->MovRegReg32 ( RDX, RAX );
		
			// clear bottom two bits of address
			e->AndReg32ImmX ( RCX, ~0x3 );
			break;

		case OPSDL:
			// temporarily save store address
			e->MovRegReg32 ( RDX, RCX );
			
			e->NotReg32 ( RCX );
			e->AndReg32ImmX ( RCX, 7 );
			//e->XorReg32ImmX ( RCX, 3 );
			e->ShlRegImm32 ( RCX, 3 );
			e->MovReg64ImmX ( RAX, -1 );
			e->ShrRegReg64 ( RAX );
			e->MovRegReg64 ( 8, RAX );
			e->MovRegMem64 ( RAX, &r->GPR [ i.Rt ].sq0 );
			e->ShrRegReg64 ( RAX );
			e->MovRegReg32 ( RCX, RDX );
			e->MovRegReg64 ( RDX, RAX );
		
			// clear bottom three bits of address
			e->AndReg32ImmX ( RCX, ~0x7 );
			
			break;
			
		case OPSDR:
			// temporarily save store address
			e->MovRegReg32 ( RDX, RCX );
			
			//e->NotReg32 ( RCX );
			e->AndReg32ImmX ( RCX, 7 );
			//e->XorReg32ImmX ( RCX, 3 );
			e->ShlRegImm32 ( RCX, 3 );
			e->MovReg64ImmX ( RAX, -1 );
			e->ShlRegReg64 ( RAX );
			e->MovRegReg64 ( 8, RAX );
			e->MovRegMem64 ( RAX, &r->GPR [ i.Rt ].sq0 );
			e->ShlRegReg64 ( RAX );
			e->MovRegReg32 ( RCX, RDX );
			e->MovRegReg64 ( RDX, RAX );
		
			// clear bottom three bits of address
			e->AndReg32ImmX ( RCX, ~0x7 );
			break;

			
		default:
			// get the value to store (32-bit)
			e->MovRegMem32 ( RDX, &r->GPR [ i.Rt ].sw0 );
			
			break;
			
	}
	
#ifdef RESERVE_STACK_FRAME_FOR_CALL
	e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

	ret = e->Call ( StoreFunctionToCall );

#ifdef RESERVE_STACK_FRAME_FOR_CALL
	ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

	if ( !e->SetJmpTarget8 ( 1 ) ) { cout << "\nProblem setting jump target #1\n"; }


	return ret;
}



int32_t R5900::Recompiler::Generate_Normal_Store_L2 ( Instruction::Format i, u32 Address, u32 BitTest, u32 BaseAddress )
{
	int32_t ret;
	bool bPerformInlineStore;
	
	u8* pMemoryDevice8;
	u32 ulMask;
	u32 ulLatency;
	u8* pInvalidateDevice8;
	u32 ulDeviceTestMask;
	u32 Dummy;
	
	u64 lConst;
	
	int Rt;
	
	u32 StoreAddress;




	// get the store address
	//u32 StoreAddress = r->GPR [ i.Base ].s + i.sOffset;
	//e->MovRegFromMem32 ( RDX, &r->GPR [ i.Base ].s );
	//e->AddReg32ImmX ( RDX, i.sOffset );
	BaseAddress += ( (s32) i.sOffset );


	pMemoryDevice8 = (u8*) Playstation2::DataBus::LUT_DataBus_Write [ BaseAddress >> 22 ].pMemoryDevice;
	pInvalidateDevice8 = Playstation2::DataBus::LUT_DataBus_Write [ BaseAddress >> 22 ].pInvalidateDevice;
	ulMask = Playstation2::DataBus::LUT_DataBus_Write [ BaseAddress >> 22 ].ulMask;
	//ulLatency = Playstation2::DataBus::LUT_DataBus_Write [ BaseAddress >> 22 ].ulLatency;
	//ulDeviceTestMask = Playstation2::DataBus::LUT_DataBus_Write [ BaseAddress >> 22 ].ulDeviceTest;
	
	
	// check for synchronous interrupt
	
	// if there is a synchronous interrupt possible, then check for it
	if ( BaseAddress & BitTest )
	{
		return 0;
	}

	if ( !pMemoryDevice8 )
	{
		return 0;
	}
	
	//if ( BaseAddress & ulDeviceTestMask )
	//{
	//	return 0;
	//}


	if ( i.Opcode == OPSQ )
	{
		return 0;
	}
	
	if ( i.Opcode == OPSQC2 )
	{
		return 0;
	}

	if ( i.Opcode == OPSWC1 )
	{
		return 0;
	}
	
	
	// part 1: first check for event //
	
#ifdef CHECK_EVENT_AFTER_START
	if ( RunCount2 )
	{
	// get updated CycleCount value for CPU (the value as it would be after instruction executed)
	e->MovRegMem64 ( RCX, (int64_t*) & r->CycleCount );
	e->AddReg64ImmX ( RCX, LocalCycleCount2 - ( MemCycles - 1 ) );
	//e->AddReg64ImmX ( RAX, LocalCycleCount - MemCycles );
	
	
	// want check that there are no events pending //
	
	// get the current cycle count and compare with next event cycle
	// note: actually need to either offset the next event cycle and correct when done or
	// or need to offset the next even cycle into another variable and check against that one
	e->CmpRegMem64 ( RCX, (int64_t*) & Playstation2::System::_SYSTEM->NextEvent_Cycle );
	
	// branch if current cycle is greater (or equal?) than next event cycle
	// changing this so that it branches if not returning
	// note: should probably be below or equal then jump, since the interpreter adds one to cycle
	e->Jmp_B ( 0, 0 );
	//e->Jmp8_AE ( 0, 0 );
	//e->Jmp_AE ( 0, 0 );
	

	// update NextPC
	e->MovMemImm32 ( (int32_t*) & r->NextPC, Address );
	
	// update CPU CycleCount
	//e->MovMemReg64 ( (int64_t*) & r->CycleCount, RAX );
	e->AddMem64ImmX ( (int64_t*) & r->CycleCount, LocalCycleCount2 - MemCycles );
	//e->AddMem64ImmX ( (int64_t*) & r->CycleCount, LocalCycleCount - MemCycles - ExeCycles );
	
	WriteBackModifiedRegs ();
	
	RestoreRegsFromStack ();
	
	// done for now - return
	e->Ret ();


	//if ( !e->SetJmpTarget8 ( 0 ) )
	if ( !e->SetJmpTarget ( 0 ) )
	{
		cout << "\nhps1x64: R3000A: Recompiler: short branch0 too far!";
	}

	
	// since we have not reached the next event cycle, should write back the current system cycle
	// so that the correct cycle# gets seen when the store is executed
	// no need to update the CPU cycle count until either a branch/jump is encountered or returning
	// this way, there is no need to reset the current cycle number tally unless a branch/jump is encountered
	//e->DecReg64 ( RAX );
	e->MovMemReg64 ( (int64_t*) & Playstation2::System::_SYSTEM->CycleCount, RCX );
	
	// part 2: check for synchronous interrupt //
	
	// this is where the entry point should be if this is the first instruction in the run
	//pCodeStart [ BlockIndex ] = e->Get_CodeBlock_CurrentPtr ();
	}
#endif
	

	
	// part 3: execute the store //
			

		
	// check isc
	//e->MovRegMem32 ( RAX, & r->CPR0.Status.Value );
	//e->BtRegImm32 ( RAX, 16 );
	//e->BtMemImm32 ( & r->CPR0.Status.Value, 16 );
	//e->Jmp8_AE ( 0, 6 );
	//e->Jmp8 ( 0, 6 );
	
	
	//e->MovMemImm32 ( & r->ICache.ICacheBlockSource [ ( BaseAddress >> 4 ) & 0xff ], -1 );


	//e->Jmp8 ( 0, 5 );


	//if ( !e->SetJmpTarget8 ( 7 ) )
	//{
	//	cout << "\nhps1x64: R3000A: Recompiler: short branch7 too far!";
	//}




	//if ( !e->SetJmpTarget ( 6 ) )
	//if ( !e->SetJmpTarget8 ( 6 ) )
	//{
	//	cout << "\nhps1x64: R3000A: Recompiler: short branch6 too far!";
	//}
	

	
	StoreAddress = BaseAddress & ulMask;

	
	
	
	switch ( i.Opcode )
	{
			/*
		case OPSWC2:
			// get the value to store from COP1 register
			e->MovRegMem32 ( RCX, &r->COP2.CPR2.Regs [ i.Rt ] );
			break;
			
		case OPSWL:
			
			e->MovRegMem32 ( RCX, &r->GPR [ i.Rt ].s );
			//e->MovRegReg32 ( 8, RDX );
		
			// clear bottom two bits of address
			//e->AndReg32ImmX ( RDX, ~0x3 );
			//StoreAddress &= ~0x3;
			
			break;
			
		case OPSWR:
			e->MovRegMem32 ( RCX, &r->GPR [ i.Rt ].s );
			//e->MovRegReg32 ( 8, RDX );
		
			// clear bottom two bits of address
			//e->AndReg32ImmX ( RDX, ~0x3 );
			//StoreAddress &= ~0x3;
			break;
			*/

		default:
			// get the value to store (32-bit)
			if ( isConst( i.Rt ) )
			{
				lConst = GetConst( i.Rt );
			}
			else
			{
				Rt = Alloc_SrcReg ( i.Rt );
			}
			//e->MovRegMem32 ( RCX, &r->GPR [ i.Rt ].s );
			
			break;
			
	}

	
	// store the value
	switch ( i.Opcode )
	{
		case OPSB:
			//e->MovRegToMem8 ( RDX, 10, RCX, SCALE_NONE, 0 );
			//e->MovRegToMem8 ( RCX, 10, RDX, SCALE_NONE, 0 );
			if ( isConst( i.Rt ) )
			{
				e->MovMemImm8 ( (char*) & pMemoryDevice8 [ StoreAddress ], lConst );
			}
			else
			{
				e->MovMemReg8 ( (char*) & pMemoryDevice8 [ StoreAddress ], Rt );
			}
			break;
		case OPSH:
			//e->MovRegToMem16 ( RDX, 10, RCX, SCALE_NONE, 0 );
			//e->MovRegToMem16 ( RCX, 10, RDX, SCALE_NONE, 0 );
			if ( isConst( i.Rt ) )
			{
				e->MovMemImm16 ( (short*) ( & pMemoryDevice8 [ StoreAddress ] ), lConst );
			}
			else
			{
				e->MovMemReg16 ( (short*) ( & pMemoryDevice8 [ StoreAddress ] ), Rt );
			}
			break;
		case OPSWL:
			if ( ( StoreAddress & 3 ) == 3 )
			{
				if ( isConst( i.Rt ) )
				{
					e->MovMemImm32( (int32_t*) ( & pMemoryDevice8 [ StoreAddress & ~3 ] ), lConst );
				}
				else
				{
					e->MovMemReg32( (int32_t*) ( & pMemoryDevice8 [ StoreAddress & ~3 ] ), Rt );
				}
			}
			else
			{
				e->MovRegMem32 ( RCX, (int32_t*) ( & pMemoryDevice8 [ ( StoreAddress & ~3 ) - 4 ] ) );
				if ( isConst( i.Rt ) )
				{
					e->MovMemImm32 ( (int32_t*) ( & pMemoryDevice8 [ StoreAddress - 3 ] ), lConst );
				}
				else
				{
					e->MovMemReg32 ( (int32_t*) ( & pMemoryDevice8 [ StoreAddress - 3 ] ), Rt );
				}
				e->MovMemReg32 ( (int32_t*) ( & pMemoryDevice8 [ ( StoreAddress & ~3 ) - 4 ] ), RCX );
			}
			break;
		case OPSWR:
			if ( ( StoreAddress & 3 ) == 0 )
			{
				if ( isConst( i.Rt ) )
				{
					e->MovMemImm32( (int32_t*) ( & pMemoryDevice8 [ StoreAddress & ~3 ] ), lConst );
				}
				else
				{
					e->MovMemReg32( (int32_t*) ( & pMemoryDevice8 [ StoreAddress & ~3 ] ), Rt );
				}
			}
			else
			{
				e->MovRegMem32 ( RCX, (int32_t*) ( & pMemoryDevice8 [ ( StoreAddress & ~3 ) + 4 ] ) );
				if ( isConst( i.Rt ) )
				{
					e->MovMemImm32 ( (int32_t*) ( & pMemoryDevice8 [ StoreAddress - 0 ] ), lConst );
				}
				else
				{
					e->MovMemReg32 ( (int32_t*) ( & pMemoryDevice8 [ StoreAddress - 0 ] ), Rt );
				}
				e->MovMemReg32 ( (int32_t*) ( & pMemoryDevice8 [ ( StoreAddress & ~3 ) + 4 ] ), RCX );
			}
			break;
		case OPSW:
			if ( isConst( i.Rt ) )
			{
				e->MovMemImm32( (int32_t*) ( & pMemoryDevice8 [ StoreAddress ] ), lConst );
			}
			else
			{
				e->MovMemReg32( (int32_t*) ( & pMemoryDevice8 [ StoreAddress ] ), Rt );
			}
			break;
		case OPSD:
			if ( isConst( i.Rt ) )
			{
				e->MovMemImm64( (int64_t*) ( & pMemoryDevice8 [ StoreAddress ] ), lConst );
			}
			else
			{
				e->MovMemReg64( (int64_t*) ( & pMemoryDevice8 [ StoreAddress ] ), Rt );
			}
			break;
		case OPSDL:
			//e->MovRegFromMem64 ( RAX, 10, RCX, SCALE_NONE, -8 );
			//e->MovRegToMem64 ( RDX, 10, 8, SCALE_NONE, -7 );
			//e->MovRegToMem64 ( RAX, 10, RCX, SCALE_NONE, -8 );
			e->MovRegMem64 ( RCX, (int64_t*) ( & pMemoryDevice8 [ ( StoreAddress & ~7 ) - 8 ] ) );
			if ( isConst( i.Rt ) )
			{
				e->MovMemImm64 ( (int64_t*) ( & pMemoryDevice8 [ StoreAddress - 7 ] ), lConst );
			}
			else
			{
				e->MovMemReg64 ( (int64_t*) ( & pMemoryDevice8 [ StoreAddress - 7 ] ), Rt );
			}
			e->MovMemReg64 ( (int64_t*) ( & pMemoryDevice8 [ ( StoreAddress & ~7 ) - 8 ] ), RCX );
			break;
		case OPSDR:
			//e->MovRegFromMem64 ( RAX, 10, RCX, SCALE_NONE, 8 );
			//e->MovRegToMem64 ( RDX, 10, 8, SCALE_NONE, 0 );
			//e->MovRegToMem64 ( RAX, 10, RCX, SCALE_NONE, 8 );
			e->MovRegMem64 ( RCX, (int64_t*) ( & pMemoryDevice8 [ ( StoreAddress & ~7 ) + 8 ] ) );
			if ( isConst( i.Rt ) )
			{
				e->MovMemImm64 ( (int64_t*) ( & pMemoryDevice8 [ StoreAddress - 0 ] ), lConst );
			}
			else
			{
				e->MovMemReg64 ( (int64_t*) ( & pMemoryDevice8 [ StoreAddress - 0 ] ), Rt );
			}
			e->MovMemReg64 ( (int64_t*) ( & pMemoryDevice8 [ ( StoreAddress & ~7 ) + 8 ] ), RCX );
			break;
		//case OPSWC2:
		//	e->MovMemReg32( (int32_t*) ( & pMemoryDevice8 [ StoreAddress ] ), RCX );
		//	break;
	}
	
#ifdef ENABLE_MEMORY_INVALIDATE
	// also need to invalidate cache
	//e->ShrRegImm32 ( RDX, 2 + r->Bus->c_iInvalidate_Shift );
	//e->MovMemImm8 ( 1, 11, RDX, SCALE_NONE, 0 );
	e->MovMemImm8 ( (char*) & pInvalidateDevice8 [ StoreAddress >> ( 2 + r->Bus->c_iInvalidate_Shift ) ], 1 );
#endif
	
	// add additional latency
	//e->AddMem64ImmX ( (int64_t*) & r->CycleCount, ulLatency );

	





	//if ( !e->SetJmpTarget8 ( 2 ) )
	//{
	//	cout << "\nhps1x64: R3000A: Recompiler: short branch2 too far!";
	//}
	//if ( !e->SetJmpTarget8 ( 5 ) )
	//{
	//	cout << "\nhps1x64: R3000A: Recompiler: short branch5 too far!";
	//}
	
//cout << "\nRecompile L2 Store: ADDR=" << hex << Address << " BaseAddr=" << BaseAddress << " StoreAddr=" << StoreAddress << " Const=" << lConst << dec << " Rt=" << Rt << " i.Rt=" << i.Rt;
	
	return 1;
}





int32_t R5900::Recompiler::Generate_Cached_Load(R5900::Instruction::Format i, u32 Address, u32 BitTest, void* LoadFunctionToCall)
{
	int32_t ret = 0;

	// this is the number of Cycles to update CycleCount if this instruction does NOT execute successfully
	uint64_t ullCycles_Compare = LocalCycleCount - ullLoadCycles;
	uint64_t ullCycles_OnError = LocalCycleCount;

#ifdef ENABLE_EXCEPTION_INFO_CACHED
	//e->MovReg64ImmX(8, ((u64)Address) | (ullCycles_OnError << 32));
	e->MovReg64ImmX(8, (u64)Address);
#endif

	// get physical address -> rcx
	e->MovRegFromMem32(RCX, &r->GPR[i.Base].sw0);
	e->AddReg32ImmX(RCX, i.sOffset);
	e->AndReg32ImmX(RCX, 0x5fffffff);

	// get the cache line index -> rax
	e->MovRegReg32(RAX, RCX);
	e->ShrRegImm32(RAX, 6);
	e->AndReg32ImmX(RAX, 0x3f);
	e->AddRegReg32(RAX, RAX);

	// get current cycle# -> r9
	e->MovRegMem64(8, (int64_t*)&r->CycleCount);
	e->LeaRegRegImm64(9, 8, LocalCycleCount);

	// get pointer into DCache
	e->LeaRegMem64(11, (void*)&r->DCache);

	// get PFN -> r10
	e->MovRegReg32(10, RCX);
	e->AndReg32ImmX(10, 0x5fffffc0);
	
	// check if any of the PFNs match the physical address
	e->CmpRegMem32(10, 11, RAX, SCALE_FOUR, offsetof(DCache_Device, PFN) + 0);
	e->Jmp_E(0, 0);

	// inc the way (low bit rax)
	e->IncReg32(RAX);

	// check the other PFN
	e->CmpRegMem32(10, 11, RAX, SCALE_FOUR, offsetof(DCache_Device, PFN) + 0);
	e->Jmp_E(0, 1);

	// jump if cache already loaded

	// need to reload cache //

	// restore the cache line index
	e->DecReg32(RAX);


	// get the way from LRFs
	e->MovRegReg32(RDX, RAX);
	e->XorRegMem8(RAX, 11, RDX, SCALE_NONE, offsetof(DCache_Device, LRF) + 0);
	e->XorRegMem8(RAX, 11, RDX, SCALE_NONE, offsetof(DCache_Device, LRF) + 1);


	// set valid for the way
	e->MovMemImm8(1, 11, RAX, SCALE_NONE, offsetof(DCache_Device, Valid));

	// update LRF for the way
	e->XorMemImm8(1, 11, RAX, SCALE_NONE, offsetof(DCache_Device, LRF));

	// need to get the previous PFN before overwriting it -> r8
	e->MovRegFromMem32(8, 11, RAX, SCALE_FOUR, offsetof(DCache_Device, PFN));

	// store PFN for the way
	e->MovRegToMem32(10, 11, RAX, SCALE_FOUR, offsetof(DCache_Device, PFN));


	// check if cache line is dirty, if so then write back
	e->MovRegFromMem8(RDX, 11, RAX, SCALE_FOUR, offsetof(DCache_Device, Dirty));

	// note: set dirty for the way if storing
	//e->MovMemImm8(1, 11, RAX, SCALE_NONE, offsetof(DCache_Device, Dirty));

	// this is a READ, so cache-line is going to be clean. otherwise comment this out
	e->MovMemImm8(0, 11, RAX, SCALE_NONE, offsetof(DCache_Device, Dirty));

	// pre-shift the index
	e->ShlRegImm32(RAX, 3);

	e->OrRegReg8(RDX, RDX);
	e->Jmp8_E(0, 2);

	// load dirty cache line
	e->movdqa_to_mem128(RAX, 11, RAX, SCALE_EIGHT, offsetof(DCache_Device, Data) + 0);
	e->movdqa_to_mem128(RBX, 11, RAX, SCALE_EIGHT, offsetof(DCache_Device, Data) + 16);
	e->movdqa_to_mem128(RCX, 11, RAX, SCALE_EIGHT, offsetof(DCache_Device, Data) + 32);
	e->movdqa_to_mem128(RDX, 11, RAX, SCALE_EIGHT, offsetof(DCache_Device, Data) + 48);

	// write-back dirty cache line
	e->BtsRegImm64(8, 33);
	e->movdqa_to_mem128(RAX, 8, NO_INDEX, SCALE_NONE, 0);
	e->movdqa_to_mem128(RBX, 8, NO_INDEX, SCALE_NONE, 16);
	e->movdqa_to_mem128(RCX, 8, NO_INDEX, SCALE_NONE, 32);
	e->movdqa_to_mem128(RDX, 8, NO_INDEX, SCALE_NONE, 48);


	e->SetJmpTarget8(2);

	// load cache line -> a,b,c,d
	// mask address first
	e->BtsRegImm64(10, 33);
	e->movdqa_from_mem128(RAX, 10, NO_INDEX, SCALE_NONE, 0);
	e->movdqa_from_mem128(RBX, 10, NO_INDEX, SCALE_NONE, 16);
	e->movdqa_from_mem128(RCX, 10, NO_INDEX, SCALE_NONE, 32);
	e->movdqa_from_mem128(RDX, 10, NO_INDEX, SCALE_NONE, 48);

	// write cache line
	e->movdqa_to_mem128(RAX, 11, RAX, SCALE_EIGHT, offsetof(DCache_Device, Data) + 0);
	e->movdqa_to_mem128(RBX, 11, RAX, SCALE_EIGHT, offsetof(DCache_Device, Data) + 16);
	e->movdqa_to_mem128(RCX, 11, RAX, SCALE_EIGHT, offsetof(DCache_Device, Data) + 32);
	e->movdqa_to_mem128(RDX, 11, RAX, SCALE_EIGHT, offsetof(DCache_Device, Data) + 48);

	// check against the cycle# of the last d-cache miss
	// blocks on miss under miss until the last miss is handled ?
	e->MovRegReg64(RDX, 9);
	e->SubRegMem64(RDX, (int64_t*)&r->LoadFromBus_BusyUntilCycle);
	//e->Cqo();
	e->SbbRegReg64(10, 10);
	e->AndRegReg64(RDX, 10);
	//e->SubRegReg64(8, RDX);
	//e->MovMemReg64((int64_t*)&r->CycleCount, 8);
	e->SubMemReg64((int64_t*)&r->CycleCount, RDX);

	// set busy until
	e->LeaRegRegImm64(RDX, 9, r->Bus->c_iRAM_Read_Latency);
	e->MovRegToMem64(RDX, 11, RAX, SCALE_NONE, offsetof(DCache_Device, busyUntilCycles64));

	// set the last miss busy until cycle#
	e->MovMemReg64((int64_t*)&r->LoadFromBus_BusyUntilCycle, RDX);

	// set the gpr register busy until if gpr register
	if ((i.Opcode != OPLQC2) && (i.Opcode != OPLWC1))
	{
		e->MovMemReg64((int64_t*)&r->ullReg_BusyUntilCycle[i.Rt], RDX);
	}


	// if not gpr (COP1/COP2), then do blocking load


	e->Jmp8_E(0, 3);


	// continue if cache aleady loaded (cache line index -> rax, way -> rdx)
	e->SetJmpTarget(0);
	e->SetJmpTarget(1);

	// check against the cycle# of the last miss on this cache-line
	e->MovRegFromMem64(10, 11, RAX, SCALE_EIGHT, offsetof(DCache_Device, busyUntilCycles64));
	e->SubRegReg64(9, 10);
	//e->Cqo();
	e->SbbRegReg64(10, 10);
	e->AndRegReg64(9, 10);
	//e->SubRegReg64(8, 9);
	//e->MovMemReg64((int64_t*)&r->CycleCount, 8);
	e->SubMemReg64((int64_t*)&r->CycleCount, 9);


	// pre-shift the index
	e->ShlRegImm32(RAX, 3);


	// bring it all together
	e->SetJmpTarget8(3);

	// perform load from cache

	// get offset in cache-line
	e->MovRegReg32(RDX, RCX);


	switch (i.Opcode)
	{
	case OPLWL:
	case OPLWR:
		e->AndReg32ImmX(RDX, 0x3c);
		break;

	case OPLDL:
	case OPLDR:
		e->AndReg32ImmX(RDX, 0x38);
		break;

	case OPLQ:
		e->AndReg32ImmX(RDX, 0x30);
		break;

	default:
		e->AndReg32ImmX(RDX, 0x3f);
		break;
	}



	// add to base address
	e->AddRegReg32(RDX, 11);


	// load the value from memory //

	switch (i.Opcode)
	{
	case OPLB:
		ret = e->MovsxReg64Mem8(RAX, RDX, RAX, SCALE_EIGHT, offsetof(DCache_Device, Data));
		break;
	case OPLBU:
		ret = e->MovzxReg32Mem8(RAX, RDX, RAX, SCALE_EIGHT, offsetof(DCache_Device, Data));
		break;
	case OPLH:
		ret = e->MovsxReg64Mem16(RAX, RDX, RAX, SCALE_EIGHT, offsetof(DCache_Device, Data));
		break;
	case OPLHU:
		ret = e->MovzxReg32Mem16(RAX, RDX, RAX, SCALE_EIGHT, offsetof(DCache_Device, Data));
		break;
	case OPLW:
		ret = e->MovsxdReg64Mem32(RAX, RDX, RAX, SCALE_EIGHT, offsetof(DCache_Device, Data));
		break;
	case OPLWL:
	case OPLWR:
		//e->AddReg32ImmX(RCX, i.sOffset);
		//e->MovRegReg32(RAX, RCX);
		//e->AndReg32ImmX(RAX, ~3);

		ret = e->MovRegFromMem32(RAX, RDX, RAX, SCALE_EIGHT, offsetof(DCache_Device, Data));
		break;
	case OPLWU:
	case OPLWC1:
		ret = e->MovRegFromMem32(RAX, RDX, RAX, SCALE_EIGHT, offsetof(DCache_Device, Data));
		break;
	case OPLDL:
	case OPLDR:
		//e->AddReg32ImmX(RCX, i.sOffset);
		//e->MovRegReg32(RAX, RCX);
		//e->AndReg32ImmX(RAX, ~7);

		ret = e->MovRegFromMem64(RAX, RDX, RAX, SCALE_EIGHT, offsetof(DCache_Device, Data));
		break;
	case OPLD:
		ret = e->MovRegFromMem64(RAX, RDX, RAX, SCALE_EIGHT, offsetof(DCache_Device, Data));
		break;
	case OPLQ:
		//e->AddReg32ImmX(RCX, i.sOffset);
		//e->AndReg32ImmX(RCX, ~0xf);

		ret = e->movdqa_from_mem128(RAX, RDX, RAX, SCALE_EIGHT, offsetof(DCache_Device, Data));
		break;
	case OPLQC2:
		ret = e->movdqa_from_mem128(RAX, RDX, RAX, SCALE_EIGHT, offsetof(DCache_Device, Data));
		break;
	}

	return ret;
}


// BitTest should be 1 for LH, 3 for LW, 0 for LB, etc
int32_t R5900::Recompiler::Generate_Virtual_Load(R5900::Instruction::Format i, u32 Address, u32 BitTest, void* LoadFunctionToCall)
{
	int32_t ret = 0;

	// this is the number of Cycles to update CycleCount if this instruction does NOT execute successfully
	u64 ullCycles_Compare = LocalCycleCount - ullLoadCycles;
	u64 ullCycles_OnError = LocalCycleCount;

#ifdef CHECK_EVENT_AFTER_START_LOAD_VIRTUAL
	if (RunCount)
	{
		// part 1: first check for event //

		// get updated CycleCount value for CPU
		e->MovRegMem64(RAX, (int64_t*)&r->CycleCount);
		e->AddReg64ImmX(RAX, ullCycles_Compare);
		//e->AddReg64ImmX(RAX, LocalCycleCount - (MemCycles - 1));
		//e->AddReg64ImmX ( RAX, LocalCycleCount - MemCycles );


		// want check that there are no events pending //

		// get the current cycle count and compare with next event cycle
		// note: actually need to either offset the next event cycle and correct when done or
		// or need to offset the next even cycle into another variable and check against that one
		e->CmpRegMem64(RAX, (int64_t*)&Playstation2::System::_SYSTEM->NextEvent_Cycle);

		// branch if current cycle is greater (or equal?) than next event cycle
		// changing this so that it branches if not returning
		// note: should probably be below or equal then jump, since the interpreter adds one to cycle
		e->Jmp8_B ( 0, 0 );
		//e->Jmp_AE(0, 2);


		// update NextPC
		e->MovMemImm32((int32_t*)&r->NextPC, Address);

		// update CPU CycleCount
		// did not actually execute this instruction, so before return do -MemCycles and -ExeCycles
		//e->MovMemReg64 ( (int64_t*) & r->CycleCount, RAX );
		e->AddMem64ImmX((int64_t*)&r->CycleCount, ullCycles_OnError);
		//e->AddMem64ImmX ( (int64_t*) & r->CycleCount, LocalCycleCount - MemCycles - ExeCycles );

		// done for now - return
		e->Ret();


		e->SetJmpTarget8(0);

		// since we have not reached the next event cycle, should write back the current system cycle
		// so that the correct cycle# gets seen when the store is executed
		// no need to update the CPU cycle count until either a branch/jump is encountered or returning
		// this way, there is no need to reset the current cycle number tally unless a branch/jump is encountered
		e->MovMemReg64((int64_t*)&Playstation2::System::_SYSTEM->CycleCount, RAX);

		// part 2: check for synchronous interrupt //

		// this is where the entry point should be if this is the first instruction in the run
		pCodeStart[BlockIndex] = (u8*)e->Get_CodeBlock_CurrentPtr();
	}
#endif	// end #ifdef CHECK_EVENT_AFTER_START_LOAD_VIRTUAL


#ifdef ENABLE_EXCEPTION_INFO_VIRTUAL
	//e->MovReg64ImmX(8, ((u64)Address) | (ullCycles_OnError << 32));
	e->MovReg64ImmX(8, (u64)Address);
#endif


	if (i.Base)
	{
		//u32 StoreAddress = r->GPR [ i.Base ].s + i.sOffset;
		e->MovRegFromMem32(RCX, &r->GPR[i.Base].sw0);

		//e->MovReg64ImmX(RDX, 0x200000000ull);
		//e->XorRegReg32(RDX, RDX);

		// mask address
		//e->AndReg32ImmX(RCX, 0x5fffffff);

		// set the correct bit in address for ps2 r5900 bus
		//e->BtsRegImm64(RCX, 33);
	}
	else
	{
		e->XorRegReg32(RCX, RCX);
		//e->MovReg64ImmX(RDX, 0x200000000ull);
		//e->BtsRegImm64(RCX, 33);
	}

	// load the value from memory //
	e->BtsRegImm64(RCX, Playstation2::DataBus::BUS_R5900_TRANSFER_BIT);

	switch (i.Opcode)
	{
	case OPLB:
		ret = e->MovsxReg64Mem8(RAX, RCX, NO_INDEX, SCALE_NONE, i.sOffset);
		break;
	case OPLBU:
		ret = e->MovzxReg32Mem8(RAX, RCX, NO_INDEX, SCALE_NONE, i.sOffset);
		break;
	case OPLH:
		ret = e->MovsxReg64Mem16(RAX, RCX, NO_INDEX, SCALE_NONE, i.sOffset);
		break;
	case OPLHU:
		ret = e->MovzxReg32Mem16(RAX, RCX, NO_INDEX, SCALE_NONE, i.sOffset);
		break;
	case OPLW:
		ret = e->MovsxdReg64Mem32(RAX, RCX, NO_INDEX, SCALE_NONE, i.sOffset);
		break;
	case OPLWL:
	case OPLWR:
		//e->AddReg32ImmX(RCX, i.sOffset);
		//e->MovRegReg32(RAX, RCX);
		//e->AndReg32ImmX(RAX, ~3);
		e->AddReg64ImmX(RCX, i.sOffset);
		e->MovRegReg64(RAX, RCX);
		e->AndReg64ImmX(RAX, ~3);

		ret = e->MovRegFromMem32(RAX, RAX, NO_INDEX, SCALE_NONE, 0);
		break;
	case OPLWU:
	case OPLWC1:
		ret = e->MovRegFromMem32(RAX, RCX, NO_INDEX, SCALE_NONE, i.sOffset);
		break;
	case OPLDL:
	case OPLDR:
		//e->AddReg32ImmX(RCX, i.sOffset);
		//e->MovRegReg32(RAX, RCX);
		//e->AndReg32ImmX(RAX, ~7);
		e->AddReg64ImmX(RCX, i.sOffset);
		e->MovRegReg64(RAX, RCX);
		e->AndReg64ImmX(RAX, ~7);

		ret = e->MovRegFromMem64(RAX, RAX, NO_INDEX, SCALE_NONE, 0);
		break;
	case OPLD:
		ret = e->MovRegFromMem64(RAX, RCX, NO_INDEX, SCALE_NONE, i.sOffset);
		break;
	case OPLQ:
		//e->AddReg32ImmX(RCX, i.sOffset);
		//e->AndReg32ImmX(RCX, ~0xf);
		e->AddReg64ImmX(RCX, i.sOffset);
		e->AndReg64ImmX(RCX, ~0xf);

		//e->movdqa_from_mem128(RAX, RDX, RCX, SCALE_NONE, i.sOffset);
		ret = e->movdqa_from_mem128(RAX, RCX, NO_INDEX, SCALE_NONE, 0);
		break;
	case OPLQC2:
		ret = e->movdqa_from_mem128(RAX, RCX, NO_INDEX, SCALE_NONE, i.sOffset);
		break;
	}

	return ret;
}



int32_t R5900::Recompiler::Generate_Basic_Load(R5900::Instruction::Format i, u32 Address, u32 BitTest, void* LoadFunctionToCall)
{
	int32_t ret;

	// this is the number of Cycles to update CycleCount if this instruction does NOT execute successfully
	u64 ullCycles_Compare = LocalCycleCount - ullLoadCycles;
	u64 ullCycles_OnError = LocalCycleCount;

	char* pJumpTarget;

	u32 MaxAddress, InstCount, DependCount;
	R5900::Instruction::Format oCheckInst;

	bool bPerformInlineLoad = false;

	// set register as being recompiled into load/store
	// also needs to be reset when the runcount gets reset
	ullLSRegs |= (1ull << i.Rt);


#ifdef CHECK_EVENT_AFTER_START_LOAD
	//if ( RunCount )
	{
		// part 1: first check for event //

		// get updated CycleCount value for CPU
		e->MovRegMem64(RAX, (int64_t*)&r->CycleCount);
		e->AddReg64ImmX(RAX, ullCycles_Compare);


		// want check that there are no events pending //

		// get the current cycle count and compare with next event cycle
		// note: actually need to either offset the next event cycle and correct when done or
		// or need to offset the next even cycle into another variable and check against that one
		e->CmpRegMem64(RAX, (int64_t*)&Playstation2::System::_SYSTEM->NextEvent_Cycle);

		// branch if current cycle is greater (or equal?) than next event cycle
		// changing this so that it branches if not returning
		// note: should probably be below or equal then jump, since the interpreter adds one to cycle
		//e->Jmp_AE ( 0, 2 );

		e->MovRegImm32(RCX, Address);
		e->MovRegImm32(RDX, ullCycles_OnError);
		e->JMP_AE((void*)Exit_Recompiler);


		// since we have not reached the next event cycle, should write back the current system cycle
		// so that the correct cycle# gets seen when the store is executed
		// no need to update the CPU cycle count until either a branch/jump is encountered or returning
		// this way, there is no need to reset the current cycle number tally unless a branch/jump is encountered
		e->MovMemReg64((int64_t*)&Playstation2::System::_SYSTEM->CycleCount, RAX);

		// part 2: check for synchronous interrupt //

		// this is where the entry point should be if this is the first instruction in the run
		pCodeStart[BlockIndex] = (u8*)e->Get_CodeBlock_CurrentPtr();
	}
#endif

	// get the store address
	//u32 StoreAddress = r->GPR [ i.Base ].s + i.sOffset;
	e->MovRegFromMem32(RAX, &r->GPR[i.Base].sw0);
	e->AddReg32ImmX(RAX, i.sOffset);

	// check for synchronous interrupt

#ifdef ENABLE_TEST_ALIGNED_LOAD
	// if there is a synchronous interrupt possible, then check for it
	if (BitTest)
	{
		// if ( StoreAddress & 0x1 )
		e->TestReg32ImmX(RAX, BitTest);

		e->MovRegImm32(RCX, Address);
		e->MovRegImm32(RDX, LocalCycleCount);
		e->JMP_NE((void*)Cpu::ProcessSynchronousInterrupt2_t<Cpu::EXC_ADEL>);

	}
#endif	// end #ifdef ENABLE_TEST_ALIGNED_LOAD

	// address argument is in RCX
	e->MovRegReg32(RCX, RAX);

	switch (i.Opcode)
	{
	case OPLQ:
		// if LQ 128-bit load, then clear bottom four bits of address
		e->AndReg32ImmX(RCX, ~0xf);
		break;

	case OPLWL:
	case OPLWR:
		//e->AndReg32ImmX ( RCX, ~0x3 );
		break;

	case OPLDL:
	case OPLDR:
		//e->AndReg32ImmX ( RCX, ~0x7 );
		break;

	default:
		break;
	}

	// part 3: execute the load //


	switch (i.Opcode)
	{
	case OPLQ:
		// if LQ 128-bit load, then clear bottom four bits of address
		//e->AndReg32ImmX ( RCX, ~0xf );
		break;

	case OPLWL:
	case OPLWR:
		e->AndReg32ImmX(RCX, ~0x3);
		break;

	case OPLDL:
	case OPLDR:
		e->AndReg32ImmX(RCX, ~0x7);
		break;

	default:
		break;
	}

#ifdef RESERVE_STACK_FRAME_FOR_CALL
	e->SubReg64ImmX(RSP, c_lSEH_StackSize);
#endif

	ret = e->Call(LoadFunctionToCall);

#ifdef RESERVE_STACK_FRAME_FOR_CALL
	ret = e->AddReg64ImmX(RSP, c_lSEH_StackSize);
#endif

	if (i.Rt)
	{
		switch (i.Opcode)
		{
		case OPLQ:
		case OPLQC2:
			e->movdqa_from_mem128(RAX, RAX, NO_INDEX, 0, 0);
			break;

		default:
			break;
		}

		// reload address if needed
		switch (i.Opcode)
		{
		case OPLWL:
		case OPLWR:
		case OPLDL:
		case OPLDR:
			e->MovRegFromMem32(RCX, &r->GPR[i.Base].sw0);
			e->AddReg32ImmX(RCX, i.sOffset);
			break;

			// opcodes like lb and lh need to be sign extended! //
		case OPLB:
			//e->Cbw();
			e->MovsxReg64Reg8(RAX, RAX);
			break;
		case OPLH:
			//e->Cwde();
			e->MovsxReg64Reg16(RAX, RAX);
			break;
		case OPLW:
			e->Cdqe();
			break;

		case OPLBU:
			e->MovzxReg32Reg8(RAX, RAX);
			break;

		case OPLHU:
			e->MovzxReg32Reg16(RAX, RAX);
			break;

		case OPLWU:
			e->OrRegReg32(RAX, RAX);
			break;
		}

	}	// if (i.Rt)

	// note: result gets stored to register from RAX after return

	return ret;
}




// BitTest should be 1 for LH, 3 for LW, 0 for LB, etc
int32_t R5900::Recompiler::Generate_Normal_Load ( R5900::Instruction::Format i, u32 Address, u32 BitTest, void* LoadFunctionToCall )
{
	int32_t ret;
	
	// this is the number of Cycles to update CycleCount if this instruction does NOT execute successfully
	u64 ullCycles_Compare = LocalCycleCount - ullLoadCycles;
	u64 ullCycles_OnError = LocalCycleCount;

	char *pJumpTarget;
	
	u32 MaxAddress, InstCount, DependCount;
	R5900::Instruction::Format oCheckInst;
	
	bool bPerformInlineLoad = false;
	
	// set register as being recompiled into load/store
	// also needs to be reset when the runcount gets reset
	ullLSRegs |= ( 1ull << i.Rt );
	
#ifdef ENABLE_NEXT_DEPENDENCY_CHECK
	// check it is a non-blocking load
	DependCount = 0;
	if ( ( i.Opcode != OPLWC1 ) && ( i.Opcode != OPLQC2 ) )
	{
		
		// get start address in the next cache-line
		MaxAddress = ( Address + 64 ) & ~63;
		
		// get remaining number of instructions in cache-line
		InstCount = ( ( MaxAddress - Address ) >> 2 ) - 1;
		
		// get the count before dependency is hit
		if ( InstCount )
		{
			for ( int iIdx = 0; iIdx < InstCount; iIdx++ )
			{
				oCheckInst.Value = g_pSrcCodePtr [ iIdx + 1 ];
				
				// check if next instruction has a dependency
				if ( GetGPR_SrcRegs( oCheckInst ) & ( 1 << i.Rt ) )
				{
					DependCount = iIdx + 1;
					break;
				}
				
				if ( ! Check_StaticDependencyOk ( oCheckInst ) )
				{
					break;
				}
			}
		}
	}
#endif
	
#ifdef CHECK_EVENT_AFTER_START_LOAD
	//if ( RunCount )
	{
	// part 1: first check for event //
	
	// get updated CycleCount value for CPU
	e->MovRegMem64 ( RAX, (int64_t*) & r->CycleCount );
	e->AddReg64ImmX(RAX, ullCycles_Compare);
	
	
	// want check that there are no events pending //
	
	// get the current cycle count and compare with next event cycle
	// note: actually need to either offset the next event cycle and correct when done or
	// or need to offset the next even cycle into another variable and check against that one
	e->CmpRegMem64 ( RAX, (int64_t*) & Playstation2::System::_SYSTEM->NextEvent_Cycle );
	
	// branch if current cycle is greater (or equal?) than next event cycle
	// changing this so that it branches if not returning
	// note: should probably be below or equal then jump, since the interpreter adds one to cycle
	//e->Jmp_AE ( 0, 2 );

	e->MovRegImm32(RCX, Address);
	e->MovRegImm32(RDX, ullCycles_OnError);
	e->JMP_AE((void*)Exit_Recompiler);

	
	// since we have not reached the next event cycle, should write back the current system cycle
	// so that the correct cycle# gets seen when the store is executed
	// no need to update the CPU cycle count until either a branch/jump is encountered or returning
	// this way, there is no need to reset the current cycle number tally unless a branch/jump is encountered
	e->MovMemReg64 ( (int64_t*) & Playstation2::System::_SYSTEM->CycleCount, RAX );
	
	// part 2: check for synchronous interrupt //
	
	// this is where the entry point should be if this is the first instruction in the run
	pCodeStart [ BlockIndex ] = (u8*) e->Get_CodeBlock_CurrentPtr ();
	}
#endif
	
	// get the store address
	//u32 StoreAddress = r->GPR [ i.Base ].s + i.sOffset;
	e->MovRegFromMem32 ( RCX, &r->GPR [ i.Base ].sw0 );
	e->AddReg32ImmX ( RCX, i.sOffset );

	// check for synchronous interrupt
	
#ifdef ENABLE_TEST_ALIGNED_LOAD
	// if there is a synchronous interrupt possible, then check for it
	if ( BitTest )
	{
		// if ( StoreAddress & 0x1 )
		e->TestReg32ImmX ( RCX, BitTest );

		// branch if zero
		//e->Jmp8_E ( 0, 0 );
		e->Jmp_NE ( 0, 3 );
		
	}
#endif	// end #ifdef ENABLE_TEST_ALIGNED_LOAD
	
	switch ( i.Opcode )
	{
		case OPLQ:
			// if LQ 128-bit load, then clear bottom four bits of address
			e->AndReg32ImmX ( RCX, ~0xf );
			break;
			
		case OPLWL:
		case OPLWR:
			//e->AndReg32ImmX ( RCX, ~0x3 );
			break;
			
		case OPLDL:
		case OPLDR:
			//e->AndReg32ImmX ( RCX, ~0x7 );
			break;
			
		default:
			break;
	}
	
	// part 3: execute the load //


#ifdef ENABLE_INLINE_LOAD

	// exclusions for testing
	switch ( i.Opcode )
	{
		case OPLB:
		case OPLH:
		case OPLW:
		case OPLBU:
		case OPLHU:
		case OPLWU:
		case OPLWC1:
		case OPLD:
		case OPLWL:
		case OPLWR:
		case OPLDL:
		case OPLDR:
		case OPLQ:
		case OPLQC2:
			bPerformInlineLoad = true;
			break;
			
		default:
			bPerformInlineLoad = false;
			break;
	}
	
	if ( bPerformInlineLoad )
	{

	// RCX has the address
	// RDX has the value to store
	
	// get the index into the device pointer array
	e->MovRegReg32 ( RAX, RCX );
	e->ShrRegImm32 ( RAX, 22 );
	//e->AddRegReg32 ( RAX, RAX );
	e->ShlRegImm32 ( RAX, 2 );
	
	// get the pointer into the device pointer array
	//e->MovRegImm64 ( 9, (u64) & Playstation2::DataBus::LUT_DataBus_Read );
	e->LeaRegMem64 ( 9, & Playstation2::DataBus::LUT_DataBus_Read );
	
	// load the pointer into the device into RCX
	// save RCX into R9 first, though
	//e->MovRegReg32 ( 9, RCX );
	e->MovRegFromMem64 ( RDX, 9, RAX, SCALE_EIGHT, 0 );
	
	// jump if zero
	//e->CmpReg64ImmX ( RDX, 0 );
	//e->Jmp_E ( 0, 0 );
	e->OrRegReg64 ( RDX, RDX );
	
#ifdef ENABLE_R5900_DCACHE
	// if simulating DCache, then need to add latency before calling load function
	e->Jmp_E ( 0, 16 );
#else
	// if not simulating DCache, no need to add latency, just call load function
	e->Jmp8_E ( 0, 0 );
#endif
	
#ifdef ENABLE_R5900_DCACHE
	e->MovRegReg32 ( 10, RCX );
#endif

	// mask address
	e->AndRegMem32 ( RCX, 9, RAX, SCALE_EIGHT, 8 );

#ifdef ENABLE_R5900_DCACHE
	// test section x
	// start x
	// check if this is scratch-pad or un-cached/accelerated
	// save address in RAX
	e->TestReg32ImmX ( 10, 0x60000000 );
	e->Jmp_NE ( 0, 10 );
	//e->Jmp_NE ( 0, 14 );
	
	// data is cached in DCache //
	
	// get mask address for comparison -> R10
	e->AndReg32ImmX ( 10, 0x1fffffc0 );
	
	
	// check if cache-hit or cache-miss //
	
	// mask address with appropriate mask from lookup
	
	// get the base index -> RAX
	e->MovRegReg32 ( RAX, RCX );
	e->ShrRegImm32 ( RAX, 6 );
	e->AndReg32ImmX ( RAX, 0x3f );
	e->AddRegReg32 ( RAX, RAX );

	// CycleCount -> R8
	e->MovRegMem64 ( 8, (int64_t*) & r->CycleCount );
	e->AddReg64ImmX ( 8, LocalCycleCount - MemCycles );
	
	// check for cache-hit #1
	e->LeaRegMem64 ( 9, (void*) & r->DCache.PFN );
	e->CmpRegMem32 ( 10, 9, RAX, SCALE_FOUR, 0 );
	e->Jmp_E ( 0, 11 );
	
	// if it's a hit, then the hit code needs to know what index the hit is at
	e->IncReg32 ( RAX );
	
	// check for cache-hit #2
	e->CmpRegMem32 ( 10, 9, RAX, SCALE_FOUR, 0 );
	e->Jmp_E ( 0, 12 );
	
	// cache-miss //
	
	// testing
	//e->MovMemImm32 ( (int32_t*) & r->testvar [ 0 ], 0 );
	
	// get next index -> RAX
	// get xor LRF -> R10
	e->DecReg32 ( RAX );
	e->LeaRegMem64 ( 9, (void*) & r->DCache.LRF );
	e->MovRegFromMem8 ( 11, 9, RAX, SCALE_NONE, 0 );
	e->XorRegMem8 ( 11, 9, RAX, SCALE_NONE, 1 );
	e->LeaRegMem64 ( 9, (void*) & r->DCache.Valid );
	e->MovRegFromMem16 ( 9, 9, RAX, SCALE_NONE, 0 );
	e->CmpReg16ImmX ( 9, 0x0101 );
	e->CmovERegReg32 ( 9, 11 );
	e->AndReg32ImmX ( 9, 1 );
	e->OrRegReg32 ( RAX, 9 );
	
	
	// mark as valid
	e->LeaRegMem64 ( 9, (void*) & r->DCache.Valid );
	e->MovMemImm8 ( 1, 9, RAX, SCALE_NONE, 0 );
	
	// calculate bus time //
	
#ifdef ENABLE_DCACHE_TIMING_LOAD
	// LoadFromBus_BusyUntilCycle -> R9
	e->MovRegMem64 ( 9, (int64_t*) & r->LoadFromBus_BusyUntilCycle );
	
	// if ( r->CycleCount < r->LoadFromBus_BusyUntilCycle )
	// handle condition #1 -> r->CycleCount = r->LoadFromBus_BusyUntilCycle + r->Bus->c_iRAM_Read_Latency + r->c_ullCacheRefill_CycleTime;
	e->CmpRegReg64 ( 8, 9 );
	
	if ( ( i.Opcode == OPLWC1 ) || ( i.Opcode == OPLQC2 )
#ifdef ENABLE_NEXT_DEPENDENCY_CHECK
		//|| ( ( GetGPR_SrcRegs( NextInst ) & ( 1 << i.Rt ) ) && ( NextInst.Value != -1 ) )
		|| ( DependCount < ( r->Bus->c_iRAM_Read_Latency + r->c_ullCacheRefill_CycleTime ) )
#endif
	)
	{
		// always blocking load //
		e->CmovBRegReg64 ( 8, 9 );
		
#ifdef ENABLE_BUS_SIMULATION_CACHE_LOAD
		e->MovRegMem64 ( 11, (int64_t*) & r->Bus->BusyUntil_Cycle );
		e->AddReg64ImmX ( 8, r->Bus->c_iRAM_Read_Latency );
		e->CmpRegReg64 ( 8, 11 );
		e->CmovBRegReg64 ( 8, 11 );
		e->AddReg64ImmX ( 8, r->c_ullCacheRefill_CycleTime - DependCount );
		e->MovMemReg64 ( (int64_t*) & r->Bus->BusyUntil_Cycle, 8 );
#else
		//e->AddReg64ImmX ( 8, r->Bus->c_iRAM_Read_Latency + r->c_ullCacheRefill_CycleTime );
		e->AddReg64ImmX ( 8, r->Bus->c_iRAM_Read_Latency + r->c_ullCacheRefill_CycleTime - DependCount );
#endif
	}
	else
	{
#ifdef ENABLE_BUS_SIMULATION_CACHE_LOAD
		e->MovRegMem64 ( 11, (int64_t*) & r->Bus->BusyUntil_Cycle );
		e->Jmp8_AE ( 0, 20 );
		e->AddReg64ImmX ( 8, r->Bus->c_iRAM_Read_Latency );
		e->CmpRegReg64 ( 8, 11 );
		e->CmovBRegReg64 ( 8, 11 );
		e->AddReg64ImmX ( 8, r->c_ullCacheRefill_CycleTime );
		e->MovMemReg64 ( (int64_t*) & r->Bus->BusyUntil_Cycle, 8 );
		e->Jmp8 ( 0, 21 );
		
		e->SetJmpTarget8 ( 20 );
		e->AddReg64ImmX ( 9, r->Bus->c_iRAM_Read_Latency );
		e->CmpRegReg64 ( 9, 11 );
		e->CmovBRegReg64 ( 9, 11 );
		e->AddReg64ImmX ( 9, r->c_ullCacheRefill_CycleTime );
		e->MovMemReg64 ( (int64_t*) & r->Bus->BusyUntil_Cycle, 9 );
		
		// write-back R9
		e->MovMemReg64 ( (int64_t*) & r->LoadFromBus_BusyUntilCycle, 9 );
		e->LeaRegMem64 ( 11, (void*) & r->RefillDCache_BusyUntilCycle );
		e->MovRegToMem64 ( 9, 11, RAX, SCALE_EIGHT, 0 );
#else
		e->LeaRegRegImm64 ( 11, 9, r->Bus->c_iRAM_Read_Latency + r->c_ullCacheRefill_CycleTime );
		e->CmovBRegReg64 ( 8, 11 );
		
		// handle condition #2 -> r->LoadFromBus_BusyUntilCycle = r->CycleCount + r->Bus->c_iRAM_Read_Latency + r->c_ullCacheRefill_CycleTime
		e->LeaRegRegImm64 ( 11, 8, r->Bus->c_iRAM_Read_Latency + r->c_ullCacheRefill_CycleTime );
		e->CmovAERegReg64 ( 9, 11 );
		
		// write-back R9
		e->MovMemReg64 ( (int64_t*) & r->LoadFromBus_BusyUntilCycle, 9 );
		
		// -> r->RefillDCache_BusyUntilCycle [ ulIndex ] = r->LoadFromBus_BusyUntilCycle;
		// ptr r->RefillDCache_BusyUntilCycle -> R10
		// r->RefillDCache_BusyUntilCycle [ ulIndex ] -> R10
		e->LeaRegMem64 ( 9, (void*) & r->RefillDCache_BusyUntilCycle );
		e->CmovBRegMem64 ( 11, 9, RAX, SCALE_EIGHT, 0 );
		
		// write-back R8, R9, R11
		// write-back R11
		e->MovRegToMem64 ( 11, 9, RAX, SCALE_EIGHT, 0 );
#endif

#ifdef ENABLE_BUS_SIMULATION_CACHE_LOAD
		e->SetJmpTarget8 ( 21 );
#endif
	}
	
	// write-back R8
	e->SubReg64ImmX ( 8, LocalCycleCount - MemCycles );
	e->MovMemReg64 ( (int64_t*) & r->CycleCount, 8 );
	
#endif	// ENABLE_DCACHE_TIMING_LOAD

	// test section
	// start
	// get pointer to dirty bit before shifting index ??
	// save index in -> R8
	e->MovRegReg32 ( 8, RAX );
	
	// get cache-line pointer + index -> RAX
	e->LeaRegMem64 ( 9, (void*) & r->DCache.Data );
	e->ShlRegImm32 ( RAX, 6 );
	e->AddRegReg64 ( RAX, 9 );

	// update LRF
	e->LeaRegMem64 ( 11, (void*) & r->DCache.LRF );
	e->XorMemImm8 ( 1, 11, 8, SCALE_NONE, 0 );
	
	// get masked PFN RAM offset -> R9
	e->LeaRegMem64 ( 11, (void*) & r->DCache.PFN );
	e->MovRegFromMem32 ( 9, 11, 8, SCALE_FOUR, 0 );
	
	// R9 could be a bios address *todo*
	e->AndReg32ImmX ( 9, (int32_t) ( r->Bus->MainMemory_Mask & 0x1fffffc0 ) );

	
	// update PFN
	//e->AndReg32ImmX ( 8, 0x3f );
	//e->LeaRegMem64 ( 11, (void*) & r->DCache.PFN );
	//e->MovRegImm32 ( 10, 0xdeadbeef );
	e->MovRegToMem32 ( 10, 11, 8, SCALE_FOUR, 0 );
	
	// testing
	//e->MovMemReg32 ( (int32_t*) & r->testvar [ 2 ], 8 );
	//e->MovMemReg32 ( (int32_t*) & r->testvar [ 3 ], 11 );
	
	// check if cache-line is dirty
	e->LeaRegMem64 ( 10, (void*) & r->DCache.Dirty );
	e->XorRegReg32 ( 11, 11 );
	e->CmpRegMem8 ( 11, 10, 8, SCALE_NONE, 0 );
	e->Jmp8_E ( 0, 15 );
	
	// cache-line is dirty and needs write-back //
	
	// testing
	//e->MovMemReg32 ( (int32_t*) & r->testvar [ 4 ], 8 );
	//e->MovMemReg32 ( (int32_t*) & r->testvar [ 5 ], 10 );
	
	// clear dirty - this is different when loading than when storing
	e->MovMemImm8 ( 0, 10, 8, SCALE_NONE, 0 );
	
	// test section end
	
#ifdef ENABLE_DCACHE_DATA_WRITE
	// get write-back pointer -> R11
	e->LeaRegMem64 ( 11, (void*) & r->Bus->MainMemory.b8 );
	
	// write-back
	e->movdqa_from_mem128 ( RAX, RAX, NO_INDEX, SCALE_NONE, 0 );
	e->movdqa_from_mem128 ( RBX, RAX, NO_INDEX, SCALE_NONE, 16 );
	e->movdqa_from_mem128 ( RCX, RAX, NO_INDEX, SCALE_NONE, 32 );
	e->movdqa_from_mem128 ( RDX, RAX, NO_INDEX, SCALE_NONE, 48 );
	e->movdqa_to_mem128 ( RAX, 11, 9, SCALE_NONE, 0 );
	e->movdqa_to_mem128 ( RBX, 11, 9, SCALE_NONE, 16 );
	e->movdqa_to_mem128 ( RCX, 11, 9, SCALE_NONE, 32 );
	e->movdqa_to_mem128 ( RDX, 11, 9, SCALE_NONE, 48 );
	
#endif
	
	// get invalidate pointer -> R11
	e->LeaRegMem64 ( 11, (void*) & r->Bus->InvalidArray );
	
	// invalidate (using RCX again below)
	//e->MovRegReg32 ( 8, RCX );
	e->ShrRegImm32 ( 9, 6 );
	e->MovMemImm8 ( 1, 11, 9, SCALE_NONE, 0 );
	
	// reload cache-line from device //
	if ( !e->SetJmpTarget8 ( 15 ) ) { cout << "\nProblem setting jump target #15\n"; }

	// testing
	//e->MovMemReg32 ( (int32_t*) & r->testvar [ 2 ], RAX );
	
	// device pointer is already in -> RDX
	// reload
#ifdef ENABLE_DCACHE_DATA_READ
	e->MovRegReg32 ( 8, RCX );
	e->AndReg32ImmX ( 8, 0x1fffffc0 );
	
	e->movdqa_from_mem128 ( RAX, RDX, 8, SCALE_NONE, 0 );
	e->movdqa_from_mem128 ( RBX, RDX, 8, SCALE_NONE, 16 );
	e->movdqa_from_mem128 ( RCX, RDX, 8, SCALE_NONE, 32 );
	e->movdqa_from_mem128 ( RDX, RDX, 8, SCALE_NONE, 48 );
	e->movdqa_to_mem128 ( RAX, RAX, NO_INDEX, SCALE_NONE, 0 );
	e->movdqa_to_mem128 ( RBX, RAX, NO_INDEX, SCALE_NONE, 16 );
	e->movdqa_to_mem128 ( RCX, RAX, NO_INDEX, SCALE_NONE, 32 );
	e->movdqa_to_mem128 ( RDX, RAX, NO_INDEX, SCALE_NONE, 48 );
#endif
	
	// testing
	/*
	e->MovRegFromMem32 ( 8, RDX, 8, SCALE_NONE, 8 );
	//e->MovRegFromMem32 ( RDX, RAX, RAX, SCALE_NONE, 8 );
	e->movdqa_regmem ( RAX, & r->Bus->BIOS.b32 [ 0x438c0 >> 2 ] );
	e->movdqu_memreg ( & r->testvar [ 0 ], RAX );
	//e->MovMemReg32 ( & r->testvar [ 2 ], RAX );
	//e->MovMemReg32 ( & r->testvar [ 3 ], RCX );
	e->MovMemReg32 ( & r->testvar [ 4 ], RDX );
	e->MovMemReg32 ( & r->testvar [ 5 ], 8 );
	e->AddRegReg64 ( RAX, RAX );
	*/
	
#ifdef DCACHE_READ_MEMORY
	// get memory pointer
#else
	// get cache-line pointer -> mask address -> proceed
	e->MovRegReg64 ( RDX, RAX );
	e->AndReg32ImmX ( RCX, 0x3f );
#endif
	
	
	e->Jmp ( 0, 14 );
	
	// cache-hit //
	if ( !e->SetJmpTarget ( 11 ) ) { cout << "\nProblem setting jump target #11\n"; }
	if ( !e->SetJmpTarget ( 12 ) ) { cout << "\nProblem setting jump target #12\n"; }

	// testing
	//e->MovMemImm32 ( & r->testvar [ 0 ], 1 );
	
#ifdef ENABLE_DCACHE_TIMING_LOAD
	// calculate the bus time
	//e->MovRegMem64 ( 8, (int64_t*) & r->CycleCount );
	e->LeaRegMem64 ( 9, (void*) & r->RefillDCache_BusyUntilCycle );
	e->MovRegFromMem64 ( 9, 9, RAX, SCALE_EIGHT, 0 );
	e->CmpRegReg64 ( 8, 9 );
	e->CmovBRegReg64 ( 8, 9 );
	e->SubReg64ImmX ( 8, LocalCycleCount - MemCycles );
	e->MovMemReg64 ( (int64_t*) & r->CycleCount, 8 );
#endif
	
	// mark cache-line as dirty
	//e->LeaRegMem64 ( 10, (void*) & r->DCache.Dirty );
	//e->MovMemImm8 ( 1, 10, RAX, SCALE_NONE, 0 );
	
#ifdef DCACHE_READ_MEMORY
	// get memory pointer
#else
	// get cache-line pointer -> RDX
	// index should be in -> RAX
	e->ShlRegImm32 ( RAX, 6 );
	e->LeaRegMem64 ( RDX, (void*) & r->DCache.Data );
	e->AddRegReg64 ( RDX, RAX );
	
	// only 64-bytes in cache line - mask address
	e->AndReg32ImmX ( RCX, 0x3f );
#endif

	// testing
	/*
	e->MovMemReg32 ( & r->testvar [ 1 ], RAX );
	e->MovMemReg32 ( & r->testvar [ 2 ], RCX );
	e->MovMemReg32 ( & r->testvar [ 3 ], RDX );
	e->MovMemReg32 ( & r->testvar [ 4 ], 8 );
	*/
	
	// get invalidate pointer -> R11
	//e->LeaRegMem64 ( 11, (void*) & r->Bus->InvalidArray );
	
	// proceed to load the value from cache
	e->Jmp8 ( 0, 13 );
	
	// data is un-cached or accelerated or scratch-pad //
	if ( !e->SetJmpTarget ( 10 ) ) { cout << "\nProblem setting jump target #10\n"; }
	
#endif
	
	
	pJumpTarget = e->Get_CodeBlock_CurrentPtr ();

	// testing
	//e->MovMemReg32 ( & r->testvar [ 2 ], RCX );
	//e->MovMemReg32 ( & r->testvar [ 3 ], RDX );
	
#ifdef ENABLE_R5900_DCACHE
	if ( !e->SetJmpTarget ( 16 ) ) { cout << "\nProblem setting jump target #16\n"; }

	// calculate the latency for the device and update cycle count //
	
#ifdef ENABLE_DCACHE_TIMING_LOAD
	// get the device latency -> R10
	e->MovRegFromMem32 ( 10, 9, RAX, SCALE_EIGHT, 12 );
	
	// get CycleCount -> R8
	// get LoadFromBus_BusyUntilCycle -> R9
	e->MovRegMem64 ( 8, (int64_t*) & r->CycleCount );
	e->AddReg64ImmX ( 8, LocalCycleCount - MemCycles );
	e->MovRegMem64 ( 9, (int64_t*) & r->LoadFromBus_BusyUntilCycle );
	e->CmpRegReg64 ( 8, 9 );
	
	if ( ( i.Opcode == OPLWC1 ) || ( i.Opcode == OPLQC2 )
#ifdef ENABLE_NEXT_DEPENDENCY_CHECK
		|| ( ( GetGPR_SrcRegs( NextInst ) & ( 1 << i.Rt ) ) && ( NextInst.Value != -1 ) )
#endif
		)
	{
		// always blocking load //
		e->CmovBRegReg64 ( 8, 9 );
		e->AddRegReg64 ( 8, 10 );
	}
	else
	{
		// r->CycleCount = r->LoadFromBus_BusyUntilCycle + r->Bus->GetLatency();
		e->LeaRegRegReg64 ( RAX, 9, 10 );
		e->CmovBRegReg64 ( 8, RAX );
		
		// r->LoadFromBus_BusyUntilCycle = r->CycleCount + r->Bus->GetLatency();
		e->LeaRegRegReg64 ( RAX, 8, 10 );
		e->CmovAERegReg64 ( 9, RAX );
		
		// write-back R8, R9
		e->MovMemReg64 ( (int64_t*) & r->LoadFromBus_BusyUntilCycle, 9 );
		
#ifdef ENABLE_GPR_REGISTER_TIMING
		// the extra code involved here doesn't appear to work well
		// write-back LoadFromBus_BusyUntilCycle to reg BusyUntil cycle
		e->MovMemReg64 ( (int64_t*) & r->ullReg_BusyUntilCycle [ i.Rt ], 9 );
#endif
	}
	
	// write-back R8
	e->SubReg64ImmX ( 8, LocalCycleCount - MemCycles );
	e->MovMemReg64 ( (int64_t*) & r->CycleCount, 8 );
#endif
	
	// jump again if device is a register
	e->OrRegReg64 ( RDX, RDX );
	e->Jmp8_E ( 0, 0 );

	// proceed to load value
	if ( !e->SetJmpTarget8 ( 13 ) ) { cout << "\nProblem setting jump target #13\n"; }
	if ( !e->SetJmpTarget ( 14 ) ) { cout << "\nProblem setting jump target #14\n"; }
#endif

	// testing
	//e->MovMemReg32 ( & r->testvar [ 6 ], RCX );
	//e->MovMemReg32 ( & r->testvar [ 7 ], RDX );
	//e->LeaRegMem64 ( RAX, (int64_t*) & r->Bus->BIOS.b32 [ 0x438c0 >> 2 ] );
	//e->MovMemReg32 ( & r->testvar [ 1 ], RAX );
	
	
	// store the value
	switch ( i.Opcode )
	{
		case OPLB:
			e->MovsxReg64Mem8 ( RAX, RDX, RCX, SCALE_NONE, 0 );
			break;
		case OPLBU:
			//e->MovRegFromMem8 ( RAX, RDX, RCX, SCALE_NONE, 0 );
			e->MovzxReg32Mem8 ( RAX, RDX, RCX, SCALE_NONE, 0 );
			break;
		//case OPLB:
		//case OPLBU:
		//	e->MovRegFromMem8 ( RAX, RDX, RCX, SCALE_NONE, 0 );
		//	//e->MovzxReg32Mem8 ( RAX, RDX, RCX, SCALE_NONE, 0 );
		//	break;
		case OPLH:
			e->MovsxReg64Mem16 ( RAX, RDX, RCX, SCALE_NONE, 0 );
			break;
		case OPLHU:
			//e->MovRegFromMem16 ( RAX, RDX, RCX, SCALE_NONE, 0 );
			e->MovzxReg32Mem16 ( RAX, RDX, RCX, SCALE_NONE, 0 );
			break;
		//case OPLH:
		//case OPLHU:
		//	e->MovRegFromMem16 ( RAX, RDX, RCX, SCALE_NONE, 0 );
		//	//e->MovzxReg32Mem16 ( RAX, RDX, RCX, SCALE_NONE, 0 );
		//	break;
		case OPLW:
			e->MovsxdReg64Mem32 ( RAX, RDX, RCX, SCALE_NONE, 0 );
			break;
		case OPLWL:
		case OPLWR:
			//e->AndRegReg32 ( RDX, 8 );
			//e->NotReg32 ( 8 );
			//e->AndRegMem32 ( 8, RDX, RCX, SCALE_NONE, 0 );
			//e->OrRegReg32 ( RDX, 8 );
			e->MovRegReg32 ( RAX, RCX );
			e->AndReg32ImmX ( RAX, ~3 );
			e->MovRegFromMem32 ( RAX, RDX, RAX, SCALE_NONE, 0 );
			break;
		//case OPLW:
		case OPLWU:
		case OPLWC1:
			e->MovRegFromMem32 ( RAX, RDX, RCX, SCALE_NONE, 0 );
			break;
		case OPLDL:
		case OPLDR:
			//e->AndRegReg64 ( RDX, 8 );
			//e->NotReg64 ( 8 );
			//e->AndRegMem64 ( 8, 10, RCX, SCALE_NONE, 0 );
			//e->OrRegReg64 ( RDX, 8 );
			e->MovRegReg32 ( RAX, RCX );
			e->AndReg32ImmX ( RAX, ~7 );
			e->MovRegFromMem64 ( RAX, RDX, RAX, SCALE_NONE, 0 );
			break;
		case OPLD:
			e->MovRegFromMem64 ( RAX, RDX, RCX, SCALE_NONE, 0 );
			break;
		case OPLQ:
			//e->movdqa_regmem ( RAX, (void*) &r->GPR [ i.Rt ].s );
			//e->MovRegReg64 ( RAX, 10 );
			e->movdqa_from_mem128 ( RAX, RDX, RCX, SCALE_NONE, 0 );
			break;
		case OPLQC2:
			//e->movdqa_regmem ( RAX, (void*) & VU0::_VU0->vf [ i.Ft ].sq0 );
			//e->MovRegReg64 ( RAX, 10 );
			e->movdqa_from_mem128 ( RAX, RDX, RCX, SCALE_NONE, 0 );
			break;
	}

	// testing
	//e->MovRegMem32 ( RCX, & r->Bus->MainMemory.b32 [ ( /*Address*/ 0x588 & r->Bus->MainMemory_Mask ) >> 2 ] );
	//e->MovMemReg32 ( (int32_t*) & r->testvar [ 6 ], RAX );
	//e->MovMemReg32 ( (int32_t*) & r->testvar [ 7 ], RCX );
	//e->MovMemReg32 ( (int32_t*) & r->testvar [ 8 ], RDX );
	
	e->Jmp ( 0, 1 );
	
	
	} // end if ( bPerformInlineStore )
	else
	{
	e->Jmp8 ( 0, 0 );
	}
#else
	e->Jmp8 ( 0, 0 );
#endif


#ifdef ENABLE_TEST_ALIGNED_LOAD
	if ( BitTest )
	{
		// continue processing store from here //
		e->SetJmpTarget ( 3 );
		
		// update CycleCount, set PC, then jump to synchronous interrupt
		// here executed the instruction but had a trap, so -MemCycles, NOT -ExeCycles, possibly +TrapCycles?
		e->AddMem64ImmX((int64_t*)&r->CycleCount, LocalCycleCount);
		
		// set pc
		e->MovMemImm32 ( (int32_t*) & r->PC, Address );
		
		//r->ProcessSynchronousInterrupt ( Cpu::EXC_ADES );
		e->JMP ( (void*) Cpu::ProcessSynchronousInterrupt_t<Cpu::EXC_ADEL> );
		
	}
#endif	// end #ifdef ENABLE_TEST_ALIGNED_LOAD

	if ( !e->SetJmpTarget8 ( 0 ) ) { cout << "\nProblem setting jump target #0\n"; }
	
#ifdef ENABLE_OPTIMIZED_REG_READS
	// *** check if optimized register read *** //
	
	// get address to list of register pointers
	e->MovRegFromMem64 ( RDX, 9, RAX, SCALE_EIGHT, 24 );
	
	// if can optimize reg read, then perform read like normal
	e->OrRegReg64 ( RDX, RDX );
	e->Jmp8_E ( 0, 5 );
	
	// mask address with 0xffff
	e->MovzxReg32Reg16 ( RAX, RCX );
	//e->MovRegReg32 ( RAX, RCX );
	//e->AndReg32ImmX ( RAX, 0xffff );
	
	// get just the pointer to the register (divide by 16)
	e->ShrRegImm32 ( RAX, 4 );
	
	// load the pointer
	e->MovRegFromMem64 ( RDX, RDX, RAX, SCALE_EIGHT, 0 );

	e->OrRegReg64 ( RDX, RDX );
	e->Jmp8_E ( 0, 6 );
	
	// mask the address to get offset into register
	e->AndReg32ImmX ( RCX, 0x7 );
	//e->XorRegReg32 ( RCX, RCX );
	
	e->JMP ( pJumpTarget );
	
	e->SetJmpTarget8 ( 5 );
	e->SetJmpTarget8 ( 6 );

#endif


	
	// *** perform non-optimized register read *** //

	switch ( i.Opcode )
	{
		case OPLQ:
			// if LQ 128-bit load, then clear bottom four bits of address
			//e->AndReg32ImmX ( RCX, ~0xf );
			break;
			
		case OPLWL:
		case OPLWR:
			e->AndReg32ImmX ( RCX, ~0x3 );
			break;
			
		case OPLDL:
		case OPLDR:
			e->AndReg32ImmX ( RCX, ~0x7 );
			break;
			
		default:
			break;
	}
	
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

	ret = e->Call ( LoadFunctionToCall );

#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

	if ( i.Rt )
	{
		switch ( i.Opcode )
		{
			case OPLQ:
			case OPLQC2:
				e->movdqa_from_mem128 ( RAX, RAX, NO_INDEX, 0, 0 );
				break;
				
			default:
				break;
		}

		// reload address if needed
		switch ( i.Opcode )
		{
			case OPLWL:
			case OPLWR:
			case OPLDL:
			case OPLDR:
				e->MovRegFromMem32 ( RCX, &r->GPR [ i.Base ].sw0 );
				e->AddReg32ImmX ( RCX, i.sOffset );
				break;
				
			// opcodes like lb and lh need to be sign extended! //
			case OPLB:
				//e->Cbw();
				e->MovsxReg64Reg8 ( RAX, RAX );
				break;
			case OPLH:
				//e->Cwde();
				e->MovsxReg64Reg16 ( RAX, RAX );
				break;
			case OPLW:
				e->Cdqe();
				break;
				
			case OPLBU:
				e->MovzxReg32Reg8 ( RAX, RAX );
				break;
				
			case OPLHU:
				e->MovzxReg32Reg16 ( RAX, RAX );
				break;
				
			case OPLWU:
				e->OrRegReg32 ( RAX, RAX );
				break;
		}
	}	// if ( i.Rt )




	e->SetJmpTarget ( 1 );

	// part 4: store the result //
	

	return ret;
}




//--------------------

// jump forward
void R5900::Recompiler::FJMP ( int32_t AddressFrom, int32_t AddressTo )
{
	int iOffsetFrom, iOffsetTo;

	// get instruction offset
	iOffsetFrom = ( AddressFrom >> 2 ) & 0xf;

	// get where to jump to
	iOffsetTo = ( AddressTo >> 2 ) & 0xf;

	// set a int32_t jump to the index to use
	e->Jmp ( 0, c_ulForwardBranchIndex_Start + iOffsetFrom );

	// set index in table of jumps to the address
	//iCount = iForwardJumpIdxs [ iOffset ] [ 0 ];
	pForwardBranchTargets [ iOffsetFrom ] = iOffsetTo;

//cout << "\nSet forward branch from Address " << hex << AddressFrom << " to " << AddressTo << " with offsets from " << dec << iOffsetFrom << " to " << iOffsetTo;
}

// set the forward jumps for the address to jump to current position
void R5900::Recompiler::Set_FJMPs ( int32_t AddressTo )
{
	int iOffsetTo;

	// get where to jump to
	iOffsetTo = ( AddressTo >> 2 ) & 0xf;

	// loop through branch targets checking for this target
	// note: for R3000A the 16 would be a 4
	for ( int iIdx = 0; iIdx < 16; iIdx++ )
	{
		if ( pForwardBranchTargets [ iIdx ] == iOffsetTo )
		{
			// set the forward branch target
			e->SetJmpTarget ( iIdx + c_ulForwardBranchIndex_Start );

			// now this has been already set and cleared from jump target list
			// even if the next instruction has to regenerate at a different optimization level...
			// the forward jump is still already set to the correct position theoretically
			pForwardBranchTargets [ iIdx ] = -1;

	//cout << "\nAddressing branch from offset " << dec << iIdx << " to offset " << iOffsetTo;
		}
	}
	
}

// get the count of instructions that can be included in a combined load
// iMaxCount - number of instructions in pInstructionList before you reach cache boundary or list end
// pInstructionList - pointer to the instructions to test for combined load
int R5900::Recompiler::Get_CombinedLoadCount ( R5900::Instruction::Format i, int32_t Address, R5900::Instruction::Format* pInstructionList )
{
	int iIdx;
	int iMaxCount;
	R5900::Instruction::Format i2;

	iMaxCount = 16 - ( ( Address >> 2 ) & 0xf );

	for ( iIdx = 0; iIdx < iMaxCount; iIdx++ )
	{
		i2 = pInstructionList [ iIdx ];

		// make sure the base registers match
		if ( i2.Base != i.Base )
		{
			// only works if the base registers are all the same
			return iIdx;
		}

		switch( i2.Opcode )
		{
			// supported
			case OPLD:
				// make sure that offset is divisible by 8
				if ( i2.sOffset & 0x7 )
				{
					// won't bother to combine these
					return iIdx;
				}

			case OPLW:
			case OPLWU:
				// make sure that offset is divisible by 4
				if ( i2.sOffset & 0x3 )
				{
					// won't bother to combine these
					return iIdx;
				}


			case OPLH:
			case OPLHU:
				// make sure that offset is divisible by 2
				if ( i2.sOffset & 0x1 )
				{
					// won't bother to combine these
					return iIdx;
				}

			case OPLB:
			case OPLBU:

			case OPLQ:

				// make sure that the base and Rt are not the same
				if ( i2.Base == i.Rt )
				{
					// can't combine the loads if the base gets overwritten
					return iIdx;
				}

				// otherwise, include this load in the combined load

				break;

			// supported
			case OPLWC1:
				// make sure that offset is divisible by 4
				if ( i2.sOffset & 0x3 )
				{
					// won't bother to combine these
					return iIdx;
				}

				// include this load in the combined load
				break;

			// not supported yet
			case OPLQC2:
			case OPLWL:
			case OPLWR:
			case OPLDL:
			case OPLDR:
				return iIdx;
				break;

			default:
				return iIdx;
				break;

		}	// end switch( i2.Opcode )

	}	// end for ( iIdx = 0; iIdx < iMaxCount; iIdx++ )

	return iIdx;
}

// get the max width of instructions in the combined load
// iLoadCount - number of instructions in the combined load (returned from Get_CombinedLoadCount)
// pLoadList - pointer to the instructions in the combined load
int32_t R5900::Recompiler::Get_CombinedLoadMaxWidthMask ( int iLoadCount, R5900::Instruction::Format* pLoadList )
{
	int iIdx;
	int32_t iMaxWidth;
	R5900::Instruction::Format i;

	iMaxWidth = 0;
	for ( iIdx = 0; iIdx < iLoadCount; iIdx++ )
	{
		i = pLoadList [ iIdx ];
		switch( i.Opcode )
		{
			// supported
			case OPLB:
			case OPLBU:
			case OPLQ:
				break;

			case OPLH:
			case OPLHU:
				iMaxWidth |= 0x1;
				break;

			case OPLW:
			case OPLWU:
				iMaxWidth |= 0x3;
				break;

			case OPLD:
				iMaxWidth |= 0x7;
				break;

			// supported
			case OPLWC1:
				iMaxWidth |= 0x3;
				break;

			// not supported yet
			case OPLQC2:
			case OPLWL:
			case OPLWR:
			case OPLDL:
			case OPLDR:
				break;

			default:
				break;

		}	// end switch( i.Opcode )

	}	// end for ( iIdx = 0; iIdx < iLoadCount; iIdx++ )

	return iMaxWidth;
}


int32_t R5900::Recompiler::Generate_Combined_Load ( R5900::Instruction::Format i, u32 Address, u32 BitTest, void* LoadFunctionToCall, int iLoadCount, R5900::Instruction::Format* pLoadList )
{
	int32_t ret;
	R5900::Instruction::Format i2;
	
	char *pJumpTarget;
	
	u32 MaxAddress, InstCount, DependCount;
	R5900::Instruction::Format oCheckInst;
	
	bool bPerformInlineLoad = false;
	
	// set register as being recompiled into load/store
	// also needs to be reset when the runcount gets reset
	ullLSRegs |= ( 1ull << i.Rt );
	
	
#ifdef CHECK_EVENT_AFTER_START
	if ( RunCount )
	{
	// part 1: first check for event //
	
	// get updated CycleCount value for CPU
	e->MovRegMem64 ( RAX, (int64_t*) & r->CycleCount );
	e->AddReg64ImmX ( RAX, LocalCycleCount - ( MemCycles - 1 ) );
	//e->AddReg64ImmX ( RAX, LocalCycleCount - MemCycles );
	
	
	// want check that there are no events pending //
	
	// get the current cycle count and compare with next event cycle
	// note: actually need to either offset the next event cycle and correct when done or
	// or need to offset the next even cycle into another variable and check against that one
	e->CmpRegMem64 ( RAX, (int64_t*) & Playstation2::System::_SYSTEM->NextEvent_Cycle );
	
	// branch if current cycle is greater (or equal?) than next event cycle
	// changing this so that it branches if not returning
	// note: should probably be below or equal then jump, since the interpreter adds one to cycle
	//e->Jmp8_B ( 0, 0 );
	e->Jmp_AE ( 0, 2 );

	
	
	// since we have not reached the next event cycle, should write back the current system cycle
	// so that the correct cycle# gets seen when the store is executed
	// no need to update the CPU cycle count until either a branch/jump is encountered or returning
	// this way, there is no need to reset the current cycle number tally unless a branch/jump is encountered
	e->MovMemReg64 ( (int64_t*) & Playstation2::System::_SYSTEM->CycleCount, RAX );
	
	// part 2: check for synchronous interrupt //
	
	// this is where the entry point should be if this is the first instruction in the run
	pCodeStart [ BlockIndex ] = (u8*) e->Get_CodeBlock_CurrentPtr ();
	}
#endif
	
	// get the load address
	//u32 StoreAddress = r->GPR [ i.Base ].s + i.sOffset;
	e->MovRegFromMem32 ( RCX, &r->GPR [ i.Base ].sw0 );

	// note: the offset is constant for this one
	// but still need to check the first load for a synchronous interrupt
	//e->AddReg32ImmX ( RCX, i.sOffset );

	// check for synchronous interrupt
	
	// if there is a synchronous interrupt possible, then check for it
	if ( BitTest )
	{
		// if ( StoreAddress & 0x1 )
		e->TestReg32ImmX ( RCX, BitTest );

		// branch if zero
		//e->Jmp8_E ( 0, 0 );
		e->Jmp_NE ( 0, 3 );
		
	}
	
	/*
	switch ( i.Opcode )
	{
		case OPLQ:
			// if LQ 128-bit load, then clear bottom four bits of address
			e->AndReg32ImmX ( RCX, ~0xf );
			break;
			
			
		default:
			break;
	}
	*/
	
	// part 3: execute the load //


#ifdef ENABLE_INLINE_LOAD

	// exclusions for testing
	switch ( i.Opcode )
	{
		case OPLB:
		case OPLH:
		case OPLW:
		case OPLBU:
		case OPLHU:
		case OPLWU:
		case OPLWC1:
		case OPLD:
		case OPLWL:
		case OPLWR:
		case OPLDL:
		case OPLDR:
		case OPLQ:
		case OPLQC2:
			bPerformInlineLoad = true;
			break;
			
		default:
			bPerformInlineLoad = false;
			break;
	}
	
	if ( bPerformInlineLoad )
	{

	// RCX has the address
	// RDX has the value to store
	
	// get the index into the device pointer array
	e->MovRegReg32 ( RAX, RCX );
	e->ShrRegImm32 ( RAX, 22 );
	//e->AddRegReg32 ( RAX, RAX );
	e->ShlRegImm32 ( RAX, 2 );
	
	// get the pointer into the device pointer array
	//e->MovRegImm64 ( 9, (u64) & Playstation2::DataBus::LUT_DataBus_Read );
	e->LeaRegMem64 ( 9, & Playstation2::DataBus::LUT_DataBus_Read );
	
	// load the pointer into the device into RCX
	// save RCX into R9 first, though
	//e->MovRegReg32 ( 9, RCX );
	e->MovRegFromMem64 ( RDX, 9, RAX, SCALE_EIGHT, 0 );
	
	// jump if pointer into RAM device is zero
	//e->CmpReg64ImmX ( RDX, 0 );
	//e->Jmp_E ( 0, 0 );
	e->OrRegReg64 ( RDX, RDX );
	e->Jmp_E ( 0, 0 );

	

	// mask address with the mask for that RAM/ROM device
	e->AndRegMem32 ( RCX, 9, RAX, SCALE_EIGHT, 8 );

	
	
	//pJumpTarget = e->Get_CodeBlock_CurrentPtr ();

	// testing
	//e->MovMemReg32 ( & r->testvar [ 2 ], RCX );
	//e->MovMemReg32 ( & r->testvar [ 3 ], RDX );
	

	// testing
	//e->MovMemReg32 ( & r->testvar [ 6 ], RCX );
	//e->MovMemReg32 ( & r->testvar [ 7 ], RDX );
	//e->LeaRegMem64 ( RAX, (int64_t*) & r->Bus->BIOS.b32 [ 0x438c0 >> 2 ] );
	//e->MovMemReg32 ( & r->testvar [ 1 ], RAX );
	

	// loop and load multiple values //

	for ( int iIdx = 0; iIdx < iLoadCount; iIdx++ )
	{

		i2 = pLoadList [ iIdx ];

		// only need to load the value if lwc1 or Rt!=0
		if ( ( i2.Opcode == OPLWC1 ) || ( i2.Rt != 0 ) )
		{
	
	// load the value
	switch ( i2.Opcode )
	{
		case OPLB:
			//e->MovsxReg64Mem8 ( RAX, RDX, RCX, SCALE_NONE, 0 );
			e->MovsxReg64Mem8 ( RAX, RDX, RCX, SCALE_NONE, i2.sOffset );
			e->MovMemReg64 ( & r->GPR [ i2.Rt ].sq0, RAX );
			break;
		case OPLBU:
			//e->MovzxReg32Mem8 ( RAX, RDX, RCX, SCALE_NONE, 0 );
			e->MovzxReg32Mem8 ( RAX, RDX, RCX, SCALE_NONE, i2.sOffset );
			e->MovMemReg64 ( & r->GPR [ i2.Rt ].sq0, RAX );
			break;
		case OPLH:
			//e->MovsxReg64Mem16 ( RAX, RDX, RCX, SCALE_NONE, 0 );
			e->MovsxReg64Mem16 ( RAX, RDX, RCX, SCALE_NONE, i2.sOffset );
			e->MovMemReg64 ( & r->GPR [ i2.Rt ].sq0, RAX );
			break;
		case OPLHU:
			//e->MovRegFromMem16 ( RAX, RDX, RCX, SCALE_NONE, 0 );
			e->MovzxReg32Mem16 ( RAX, RDX, RCX, SCALE_NONE, i2.sOffset );
			e->MovMemReg64 ( & r->GPR [ i2.Rt ].sq0, RAX );
			break;
		case OPLW:
			//e->MovsxdReg64Mem32 ( RAX, RDX, RCX, SCALE_NONE, 0 );
			e->MovsxdReg64Mem32 ( RAX, RDX, RCX, SCALE_NONE, i2.sOffset );
			e->MovMemReg64 ( & r->GPR [ i2.Rt ].sq0, RAX );
			break;
		case OPLWU:
			//e->MovRegFromMem32 ( RAX, RDX, RCX, SCALE_NONE, 0 );
			e->MovRegFromMem32 ( RAX, RDX, RCX, SCALE_NONE, i2.sOffset );
			e->MovMemReg64 ( & r->GPR [ i2.Rt ].sq0, RAX );
			break;
		case OPLWC1:
			//e->MovRegFromMem32 ( RAX, RDX, RCX, SCALE_NONE, 0 );
			e->MovRegFromMem32 ( RAX, RDX, RCX, SCALE_NONE, i2.sOffset );
			e->MovMemReg32 ( & r->CPR1 [ i2.Rt ].s, RAX );
			break;
		case OPLD:
			//e->MovRegFromMem64 ( RAX, RDX, RCX, SCALE_NONE, 0 );
			e->MovRegFromMem64 ( RAX, RDX, RCX, SCALE_NONE, i2.sOffset );
			e->MovMemReg64 ( & r->GPR [ i2.Rt ].sq0, RAX );
			break;

		case OPLQ:
			e->LeaRegRegImm64 ( RAX, RCX, i2.sOffset );
			e->AndReg32ImmX ( RAX, ~0xf );
			e->movdqa_from_mem128 ( RAX, RDX, RAX, SCALE_NONE, 0 );
			e->movdqa_memreg ( & r->GPR [ i2.Rt ].s, RAX );
			break;


		// note: unsure whether to include these now or later
		case OPLQC2:
			e->movdqa_from_mem128 ( RAX, RDX, RCX, SCALE_NONE, 0 );
			e->movdqa_memreg ( & VU0::_VU0->vf [ i2.Ft ].sq0, RAX );
			break;

		// note: LWL,LWR,LDL,LDR excluded from combined load for now
		case OPLWL:
		case OPLWR:
			e->MovRegReg32 ( RAX, RCX );
			e->AndReg32ImmX ( RAX, ~3 );
			e->MovRegFromMem32 ( RAX, RDX, RAX, SCALE_NONE, 0 );
			break;
		case OPLDL:
		case OPLDR:
			e->MovRegReg32 ( RAX, RCX );
			e->AndReg32ImmX ( RAX, ~7 );
			e->MovRegFromMem64 ( RAX, RDX, RAX, SCALE_NONE, 0 );
			break;

	}	// end switch ( i2.Opcode )

		}	// end if ( ( i2.Opcode == OPLWC1 ) || ( i2.Rt != 0 ) )

	}	// end for ( int iIdx = 0; iIdx < iLoadCount; iIdx++ )

	// testing
	//e->MovRegMem32 ( RCX, & r->Bus->MainMemory.b32 [ ( /*Address*/ 0x588 & r->Bus->MainMemory_Mask ) >> 2 ] );
	//e->MovMemReg32 ( (int32_t*) & r->testvar [ 6 ], RAX );
	//e->MovMemReg32 ( (int32_t*) & r->testvar [ 7 ], RCX );
	//e->MovMemReg32 ( (int32_t*) & r->testvar [ 8 ], RDX );


	// after loading the values, update cycles, update PC, and return //
	//***todo*** branch to the next address to execute if possible (if so, then don't update cycles or pc here)

#ifdef USE_FORWARD_BRANCH

	// use the forward branch to jump to the correct address after doing multiple instructions
	FJMP( Address, Address + ( iLoadCount << 2 ) );

#else

	// update NextPC
	e->MovMemImm32 ( (int32_t*) & r->NextPC, Address + ( iLoadCount << 2 ) );

	// update cycles (need to check math)
	e->AddMem64ImmX ( (int64_t*) & r->CycleCount, LocalCycleCount + ( MemCycles * iLoadCount ) - 1 );

	// done for now - return
	// ***todo*** in the future, skip updating pc and cycles and set forward jump to the correct code
	e->Ret ();
	//e->Jmp ( 0, 1 );

#endif
	
	
	} // end if ( bPerformInlineStore )
	else
	{
	e->Jmp8 ( 0, 0 );
	}
#else
	e->Jmp8 ( 0, 0 );
#endif

#ifdef CHECK_EVENT_AFTER_START

	// there is an event before first load, so need to return //

	if ( RunCount )
	{
	e->SetJmpTarget ( 2 );

	// update NextPC
	e->MovMemImm32 ( (int32_t*) & r->NextPC, Address );
	
	// update CPU CycleCount
	// ***TODO*** check math
	// did not actually execute this instruction, so before return do -MemCycles and -ExeCycles
	//e->MovMemReg64 ( (int64_t*) & r->CycleCount, RAX );
	e->AddMem64ImmX ( (int64_t*) & r->CycleCount, LocalCycleCount - MemCycles );
	//e->AddMem64ImmX ( (int64_t*) & r->CycleCount, LocalCycleCount - MemCycles - ExeCycles );
	
	// done for now - return
	e->Ret ();
	}
#endif

	if ( BitTest )
	{
		// continue processing store from here //
		e->SetJmpTarget ( 3 );
		
		// update CycleCount, set PC, then jump to synchronous interrupt
		// here executed the instruction but had a trap, so -MemCycles, NOT -ExeCycles, possibly +TrapCycles?
		//e->MovMemReg64 ( (int64_t*) & r->CycleCount, RAX );
		e->AddMem64ImmX ( (int64_t*) & r->CycleCount, LocalCycleCount );
		//e->AddMem64ImmX ( (int64_t*) & r->CycleCount, LocalCycleCount - MemCycles );
		
		// set pc
		e->MovMemImm32 ( (int32_t*) & r->PC, Address );
		
		//r->ProcessSynchronousInterrupt ( Cpu::EXC_ADES );
		e->JMP ( (void*) Cpu::ProcessSynchronousInterrupt_t<Cpu::EXC_ADEL> );
		
	}


	// the address is for a register here, so it is more complicated //

	//if ( !e->SetJmpTarget8 ( 0 ) ) { cout << "\nProblem setting short jump target #0\n"; }
	if ( !e->SetJmpTarget ( 0 ) ) { cout << "\nProblem setting int32_t jump target #0\n"; }

	
	// *** perform non-optimized register read *** //

	// if not adding first offset for multi-load, then need to add it for single load
	e->AddReg32ImmX ( RCX, i.sOffset );

	switch ( i.Opcode )
	{
		case OPLQ:
			// if LQ 128-bit load, then clear bottom four bits of address
			e->AndReg32ImmX ( RCX, ~0xf );
			break;
			
		case OPLWL:
		case OPLWR:
			e->AndReg32ImmX ( RCX, ~0x3 );
			break;
			
		case OPLDL:
		case OPLDR:
			e->AndReg32ImmX ( RCX, ~0x7 );
			break;
			
		default:
			break;
	}
	
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

	ret = e->Call ( LoadFunctionToCall );

#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

	if ( i.Rt )
	{
		switch ( i.Opcode )
		{
			case OPLQ:
			case OPLQC2:
				e->movdqa_from_mem128 ( RAX, RAX, NO_INDEX, 0, 0 );
				break;
				
			default:
				break;
		}

		// reload address if needed
		switch ( i.Opcode )
		{
			case OPLWL:
			case OPLWR:
			case OPLDL:
			case OPLDR:
				e->MovRegFromMem32 ( RCX, &r->GPR [ i.Base ].sw0 );
				e->AddReg32ImmX ( RCX, i.sOffset );
				break;
				
			// opcodes like lb and lh need to be sign extended! //
			case OPLB:
				//e->Cbw();
				e->MovsxReg64Reg8 ( RAX, RAX );
				break;
			case OPLH:
				//e->Cwde();
				e->MovsxReg64Reg16 ( RAX, RAX );
				break;
			case OPLW:
				e->Cdqe();
				break;
				
			case OPLBU:
				e->MovzxReg32Reg8 ( RAX, RAX );
				break;
				
			case OPLHU:
				e->MovzxReg32Reg16 ( RAX, RAX );
				break;
				
			case OPLWU:
				e->OrRegReg32 ( RAX, RAX );
				break;
		}
	}	// if ( i.Rt )




	e->SetJmpTarget ( 1 );

	// part 4: store the result //
	

	return ret;
}



// ||--------------------------------------------------

// get the count of instructions that can be included in a combined load
// iMaxCount - number of instructions in pInstructionList before you reach cache boundary or list end
// pInstructionList - pointer to the instructions to test for combined load
int R5900::Recompiler::Get_CombinedStoreCount ( R5900::Instruction::Format i, int32_t Address, R5900::Instruction::Format* pInstructionList )
{
	int iIdx;
	int iMaxCount;
	R5900::Instruction::Format i2;

	iMaxCount = 16 - ( ( Address >> 2 ) & 0xf );

	for ( iIdx = 0; iIdx < iMaxCount; iIdx++ )
	{
		i2 = pInstructionList [ iIdx ];

		// make sure the base registers match
		if ( i2.Base != i.Base )
		{
			// only works if the base registers are all the same
			return iIdx;
		}

		switch( i2.Opcode )
		{
			// supported
			case OPSD:
				// make sure that offset is divisible by 8
				if ( i2.sOffset & 0x7 )
				{
					// won't bother to combine these
					return iIdx;
				}

			case OPSW:
			//case OPLWU:
				// make sure that offset is divisible by 4
				if ( i2.sOffset & 0x3 )
				{
					// won't bother to combine these
					return iIdx;
				}


			case OPSH:
			//case OPLHU:
				// make sure that offset is divisible by 2
				if ( i2.sOffset & 0x1 )
				{
					// won't bother to combine these
					return iIdx;
				}

			case OPSB:
			//case OPLBU:

			case OPSQ:

				// make sure that the base and Rt are not the same
				//if ( i2.Base == i.Rt )
				//{
				//	// can't combine the loads if the base gets overwritten
				//	return iIdx;
				//}

				// otherwise, include this load in the combined load

				break;

			// supported
			case OPSWC1:
				// make sure that offset is divisible by 4
				if ( i2.sOffset & 0x3 )
				{
					// won't bother to combine these
					return iIdx;
				}

				// include this load in the combined load
				break;

			// not supported yet
			case OPSQC2:
			case OPSWL:
			case OPSWR:
			case OPSDL:
			case OPSDR:
				return iIdx;
				break;

			default:
				return iIdx;
				break;

		}	// end switch( i2.Opcode )

	}	// end for ( iIdx = 0; iIdx < iMaxCount; iIdx++ )

	return iIdx;
}

// get the max width of instructions in the combined load
// iLoadCount - number of instructions in the combined load (returned from Get_CombinedLoadCount)
// pLoadList - pointer to the instructions in the combined load
int32_t R5900::Recompiler::Get_CombinedStoreMaxWidthMask ( int iLoadCount, R5900::Instruction::Format* pLoadList )
{
	int iIdx;
	int32_t iMaxWidth;
	R5900::Instruction::Format i;

	iMaxWidth = 0;
	for ( iIdx = 0; iIdx < iLoadCount; iIdx++ )
	{
		i = pLoadList [ iIdx ];
		switch( i.Opcode )
		{
			// supported
			case OPSB:
			//case OPLBU:
			case OPSQ:
				break;

			case OPSH:
			//case OPLHU:
				iMaxWidth |= 0x1;
				break;

			case OPSW:
			//case OPLWU:
				iMaxWidth |= 0x3;
				break;

			case OPSD:
				iMaxWidth |= 0x7;
				break;

			// supported
			case OPSWC1:
				iMaxWidth |= 0x3;
				break;

			// not supported yet
			case OPSQC2:
			case OPSWL:
			case OPSWR:
			case OPSDL:
			case OPSDR:
				break;

			default:
				break;

		}	// end switch( i.Opcode )

	}	// end for ( iIdx = 0; iIdx < iLoadCount; iIdx++ )

	return iMaxWidth;
}


int32_t R5900::Recompiler::Generate_Combined_Store ( R5900::Instruction::Format i, u32 Address, u32 BitTest, void* StoreFunctionToCall, int iLoadCount, R5900::Instruction::Format* pLoadList )
{
	int32_t ret;
	R5900::Instruction::Format i2;
	
	char *pJumpTarget;
	
	u32 MaxAddress, InstCount, DependCount;
	R5900::Instruction::Format oCheckInst;
	
	bool bPerformInlineLoad = false;
	
	// set register as being recompiled into load/store
	// also needs to be reset when the runcount gets reset
	ullLSRegs |= ( 1ull << i.Rt );
	
	
#ifdef CHECK_EVENT_AFTER_START
	if ( RunCount )
	{
	// part 1: first check for event //
	
	// get updated CycleCount value for CPU
	e->MovRegMem64 ( RAX, (int64_t*) & r->CycleCount );
	e->AddReg64ImmX ( RAX, LocalCycleCount - ( MemCycles - 1 ) );
	//e->AddReg64ImmX ( RAX, LocalCycleCount - MemCycles );
	
	
	// want check that there are no events pending //
	
	// get the current cycle count and compare with next event cycle
	// note: actually need to either offset the next event cycle and correct when done or
	// or need to offset the next even cycle into another variable and check against that one
	e->CmpRegMem64 ( RAX, (int64_t*) & Playstation2::System::_SYSTEM->NextEvent_Cycle );
	
	// branch if current cycle is greater (or equal?) than next event cycle
	// changing this so that it branches if not returning
	// note: should probably be below or equal then jump, since the interpreter adds one to cycle
	//e->Jmp8_B ( 0, 0 );
	e->Jmp_AE ( 0, 2 );

	
	// ***todo*** math here is wrong since the cyclecount value changes for the next load/store
	// since we have not reached the next event cycle, should write back the current system cycle
	// so that the correct cycle# gets seen when the store is executed
	// no need to update the CPU cycle count until either a branch/jump is encountered or returning
	// this way, there is no need to reset the current cycle number tally unless a branch/jump is encountered
	e->MovMemReg64 ( (int64_t*) & Playstation2::System::_SYSTEM->CycleCount, RAX );
	
	// part 2: check for synchronous interrupt //
	
	// this is where the entry point should be if this is the first instruction in the run
	pCodeStart [ BlockIndex ] = (u8*) e->Get_CodeBlock_CurrentPtr ();
	}
#endif
	
	// get the load address
	//u32 StoreAddress = r->GPR [ i.Base ].s + i.sOffset;
	e->MovRegFromMem32 ( RCX, &r->GPR [ i.Base ].sw0 );

	// note: the offset is constant for this one
	// but still need to check the first load for a synchronous interrupt
	//e->AddReg32ImmX ( RCX, i.sOffset );

	// check for synchronous interrupt
	
	// if there is a synchronous interrupt possible, then check for it
	if ( BitTest )
	{
		// if ( StoreAddress & 0x1 )
		e->TestReg32ImmX ( RCX, BitTest );

		// branch if zero
		//e->Jmp8_E ( 0, 0 );
		e->Jmp_NE ( 0, 3 );
		
	}
	
	
	// part 3: execute the load //


#ifdef ENABLE_INLINE_LOAD

	// exclusions for testing
	switch ( i.Opcode )
	{
		case OPSB:
		case OPSH:
		case OPSW:
		//case OPLBU:
		//case OPLHU:
		//case OPLWU:
		case OPSWC1:
		case OPSD:
		case OPSWL:
		case OPSWR:
		case OPSDL:
		case OPSDR:
		case OPSQ:
		case OPSQC2:
			bPerformInlineLoad = true;
			break;
			
		default:
			bPerformInlineLoad = false;
			break;
	}
	
	if ( bPerformInlineLoad )
	{

	// RCX has the address
	// RDX has the value to store
	
	// get the index into the device pointer array
	e->MovRegReg32 ( RAX, RCX );
	e->ShrRegImm32 ( RAX, 22 );
	//e->AddRegReg32 ( RAX, RAX );
	e->ShlRegImm32 ( RAX, 2 );
	
	// get the pointer into the device pointer array
	//e->MovRegImm64 ( 9, (u64) & Playstation2::DataBus::LUT_DataBus_Read );
	e->LeaRegMem64 ( 9, & Playstation2::DataBus::LUT_DataBus_Write );
	
	// load the pointer into the device into RCX
	// save RCX into R9 first, though
	//e->MovRegReg32 ( 9, RCX );
	e->MovRegFromMem64 ( RDX, 9, RAX, SCALE_EIGHT, 0 );
	
	// jump if pointer into RAM device is zero
	//e->CmpReg64ImmX ( RDX, 0 );
	//e->Jmp_E ( 0, 0 );
	e->OrRegReg64 ( RDX, RDX );
	e->Jmp_E ( 0, 0 );

	

	// mask address with the mask for that RAM/ROM device
	e->AndRegMem32 ( RCX, 9, RAX, SCALE_EIGHT, 8 );



	// get pointer into invalidate array
	e->MovRegFromMem64 ( 11, 9, RAX, SCALE_EIGHT, 16 );

	
	// also need to invalidate recompiler cache
	//e->MovRegReg32 ( 10, RCX );
	//e->ShrRegImm32 ( 10, 2 + r->Bus->c_iInvalidate_Shift );
	//e->MovMemImm8 ( 1, 11, 10, SCALE_NONE, 0 );

	
	
	//pJumpTarget = e->Get_CodeBlock_CurrentPtr ();

	

	// loop and load multiple values //

	for ( int iIdx = 0; iIdx < iLoadCount; iIdx++ )
	{

		i2 = pLoadList [ iIdx ];

		// only need to load the value if lwc1 or Rt!=0
		//if ( ( i2.Opcode == OPLWC1 ) || ( i2.Rt != 0 ) )
		//{
	
	// load the value
	switch ( i2.Opcode )
	{
		case OPSB:
			e->MovRegMem32 ( RAX, &r->GPR [ i2.Rt ].sw0 );
			e->MovRegToMem8 ( RAX, RDX, RCX, SCALE_NONE, i2.sOffset );
			break;
		case OPSH:
			e->MovRegMem32 ( RAX, &r->GPR [ i2.Rt ].sw0 );
			e->MovRegToMem16 ( RAX, RDX, RCX, SCALE_NONE, i2.sOffset );
			break;
		case OPSW:
			e->MovRegMem32 ( RAX, &r->GPR [ i2.Rt ].sw0 );
			e->MovRegToMem32 ( RAX, RDX, RCX, SCALE_NONE, i2.sOffset );
			break;
		case OPSWC1:
			e->MovRegMem32 ( RAX, &r->CPR1 [ i2.Rt ].s );
			e->MovRegToMem32 ( RAX, RDX, RCX, SCALE_NONE, i2.sOffset );
			break;
		case OPSD:
			e->MovRegMem64 ( RAX, &r->GPR [ i2.Rt ].s );
			e->MovRegToMem64 ( RAX, RDX, RCX, SCALE_NONE, i2.sOffset );
			break;
		case OPSQ:
			e->movdqa_regmem ( RAX, (void*) &r->GPR [ i2.Rt ].s );
			e->LeaRegRegImm64 ( RAX, RCX, i2.sOffset );
			e->AndReg32ImmX ( RAX, ~0xf );
			// ***TODO*** movdqa below does not work with R10 as base
			//e->MovRegReg64 ( RAX, 10 );
			e->movdqa_to_mem128 ( RAX, RDX, RAX, SCALE_NONE, 0 );
			break;


		// note: unsure whether to include these now or later
		case OPSQC2:
			break;

		// note: LWL,LWR,LDL,LDR excluded from combined load for now
		case OPSWL:
		case OPSWR:
			break;
		case OPSDL:
		case OPSDR:
			break;

	}	// end switch ( i2.Opcode )


	switch ( i2.Opcode )
	{
		case OPSB:
		case OPSH:
		case OPSW:
		case OPSWC1:
		case OPSD:
			e->LeaRegRegImm32 ( RAX, RCX, i2.sOffset );
			e->ShrRegImm32 ( RAX, 2 + r->Bus->c_iInvalidate_Shift );
			e->MovMemImm8 ( 1, 11, RAX, SCALE_NONE, 0 );
			break;

		case OPSQ:
			e->ShrRegImm32 ( RAX, 2 + r->Bus->c_iInvalidate_Shift );
			e->MovMemImm8 ( 1, 11, RAX, SCALE_NONE, 0 );
			break;

	}

		//}	// end if ( ( i2.Opcode == OPLWC1 ) || ( i2.Rt != 0 ) )

	}	// end for ( int iIdx = 0; iIdx < iLoadCount; iIdx++ )



	// after loading the values, update cycles, update PC, and return //
	//***todo*** branch to the next address to execute if possible (if so, then don't update cycles or pc here)

#ifdef USE_FORWARD_BRANCH

	// use the forward branch to jump to the correct address after doing multiple instructions
	FJMP( Address, Address + ( iLoadCount << 2 ) );

#else

	// update NextPC
	e->MovMemImm32 ( (int32_t*) & r->NextPC, Address + ( iLoadCount << 2 ) );

	// update cycles (need to check math)
	e->AddMem64ImmX ( (int64_t*) & r->CycleCount, LocalCycleCount + ( MemCycles * iLoadCount ) - 1 );

	// done for now - return
	// ***todo*** in the future, skip updating pc and cycles and set forward jump to the correct code
	e->Ret ();
	//e->Jmp ( 0, 1 );

#endif
	
	
	} // end if ( bPerformInlineStore )
	else
	{
	e->Jmp8 ( 0, 0 );
	}
#else
	e->Jmp8 ( 0, 0 );
#endif

#ifdef CHECK_EVENT_AFTER_START

	// there is an event before first load, so need to return //

	if ( RunCount )
	{
	e->SetJmpTarget ( 2 );

	// update NextPC
	e->MovMemImm32 ( (int32_t*) & r->NextPC, Address );
	
	// update CPU CycleCount
	// ***TODO*** check math
	// did not actually execute this instruction, so before return do -MemCycles and -ExeCycles
	//e->MovMemReg64 ( (int64_t*) & r->CycleCount, RAX );
	e->AddMem64ImmX ( (int64_t*) & r->CycleCount, LocalCycleCount - MemCycles );
	//e->AddMem64ImmX ( (int64_t*) & r->CycleCount, LocalCycleCount - MemCycles - ExeCycles );
	
	// done for now - return
	e->Ret ();
	}
#endif

	if ( BitTest )
	{
		// continue processing store from here //
		e->SetJmpTarget ( 3 );
		
		// update CycleCount, set PC, then jump to synchronous interrupt
		// here executed the instruction but had a trap, so -MemCycles, NOT -ExeCycles, possibly +TrapCycles?
		//e->MovMemReg64 ( (int64_t*) & r->CycleCount, RAX );
		e->AddMem64ImmX ( (int64_t*) & r->CycleCount, LocalCycleCount );
		//e->AddMem64ImmX ( (int64_t*) & r->CycleCount, LocalCycleCount - MemCycles );
		
		// set pc
		e->MovMemImm32 ( (int32_t*) & r->PC, Address );
		
		//r->ProcessSynchronousInterrupt ( Cpu::EXC_ADES );
		e->JMP ( (void*) Cpu::ProcessSynchronousInterrupt_t<Cpu::EXC_ADES> );
		
	}


	// the address is for a register here, so it is more complicated //

	//if ( !e->SetJmpTarget8 ( 0 ) ) { cout << "\nProblem setting short jump target #0\n"; }
	if ( !e->SetJmpTarget ( 0 ) ) { cout << "\nProblem setting int32_t jump target #0\n"; }

	
	// *** perform non-optimized register read *** //

	// if not adding first offset for multi-load, then need to add it for single load
	e->AddReg32ImmX ( RCX, i.sOffset );

	switch ( i.Opcode )
	{
		case OPSQ:
			// get address of value to store
			e->LeaRegMem64 ( RDX, &r->GPR [ i.Rt ].s );
			
			break;

		case OPSQC2:
			// get address of value to store
			e->LeaRegMem64 ( RDX, & VU0::_VU0->vf [ i.Ft ].sq0 );
			
			break;
			
		case OPSWC1:
			// get the value to store from COP1 register
			e->MovRegMem32 ( RDX, &r->CPR1 [ i.Rt ].s );
			break;
			
		case OPSD:
			// get the value to store (64-bit)
			e->MovRegMem64 ( RDX, &r->GPR [ i.Rt ].s );
			break;
			
		case OPSWL:
			// temporarily save store address
			e->MovRegReg32 ( RDX, RCX );
			
			e->NotReg32 ( RCX );
			e->AndReg32ImmX ( RCX, 3 );
			//e->XorReg32ImmX ( RCX, 3 );
			e->ShlRegImm32 ( RCX, 3 );
			e->MovReg32ImmX ( RAX, -1 );
			e->ShrRegReg32 ( RAX );
			e->MovRegReg32 ( 8, RAX );
			e->MovRegMem32 ( RAX, &r->GPR [ i.Rt ].sw0 );
			e->ShrRegReg32 ( RAX );
			e->MovRegReg32 ( RCX, RDX );
			e->MovRegReg32 ( RDX, RAX );
		
			// clear bottom two bits of address
			e->AndReg32ImmX ( RCX, ~0x3 );
			
			break;
			
		case OPSWR:
			// temporarily save store address
			e->MovRegReg32 ( RDX, RCX );
			
			//e->NotReg32 ( RCX );
			e->AndReg32ImmX ( RCX, 3 );
			//e->XorReg32ImmX ( RCX, 3 );
			e->ShlRegImm32 ( RCX, 3 );
			e->MovReg32ImmX ( RAX, -1 );
			e->ShlRegReg32 ( RAX );
			e->MovRegReg32 ( 8, RAX );
			e->MovRegMem32 ( RAX, &r->GPR [ i.Rt ].sw0 );
			e->ShlRegReg32 ( RAX );
			e->MovRegReg32 ( RCX, RDX );
			e->MovRegReg32 ( RDX, RAX );
		
			// clear bottom two bits of address
			e->AndReg32ImmX ( RCX, ~0x3 );
			break;

		case OPSDL:
			// temporarily save store address
			e->MovRegReg32 ( RDX, RCX );
			
			e->NotReg32 ( RCX );
			e->AndReg32ImmX ( RCX, 7 );
			//e->XorReg32ImmX ( RCX, 3 );
			e->ShlRegImm32 ( RCX, 3 );
			e->MovReg64ImmX ( RAX, -1 );
			e->ShrRegReg64 ( RAX );
			e->MovRegReg64 ( 8, RAX );
			e->MovRegMem64 ( RAX, &r->GPR [ i.Rt ].sq0 );
			e->ShrRegReg64 ( RAX );
			e->MovRegReg32 ( RCX, RDX );
			e->MovRegReg64 ( RDX, RAX );
		
			// clear bottom three bits of address
			e->AndReg32ImmX ( RCX, ~0x7 );
			
			break;
			
		case OPSDR:
			// temporarily save store address
			e->MovRegReg32 ( RDX, RCX );
			
			//e->NotReg32 ( RCX );
			e->AndReg32ImmX ( RCX, 7 );
			//e->XorReg32ImmX ( RCX, 3 );
			e->ShlRegImm32 ( RCX, 3 );
			e->MovReg64ImmX ( RAX, -1 );
			e->ShlRegReg64 ( RAX );
			e->MovRegReg64 ( 8, RAX );
			e->MovRegMem64 ( RAX, &r->GPR [ i.Rt ].sq0 );
			e->ShlRegReg64 ( RAX );
			e->MovRegReg32 ( RCX, RDX );
			e->MovRegReg64 ( RDX, RAX );
		
			// clear bottom three bits of address
			e->AndReg32ImmX ( RCX, ~0x7 );
			break;

			
		default:
			// get the value to store (32-bit)
			e->MovRegMem32 ( RDX, &r->GPR [ i.Rt ].sw0 );
			
			break;
			
	}
	
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

	ret = e->Call ( StoreFunctionToCall );

#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif


	e->SetJmpTarget ( 1 );

	

	return ret;
}







int32_t R5900::Recompiler::Generate_Normal_Load_L2 ( Instruction::Format i, u32 Address, u32 BitTest, u32 BaseAddress )
{
	int32_t ret;
	bool bPerformInlineStore;
	
	u8* pMemoryDevice8;
	u32 ulMask;
	u32 ulLatency;
	u8* pInvalidateDevice8;
	u32 ulDeviceTestMask;
	u32 Dummy;
	
	u64 lConst;
	
	int Rt;
	
	u32 LoadAddress;




	// get the store address
	//u32 StoreAddress = r->GPR [ i.Base ].s + i.sOffset;
	//e->MovRegFromMem32 ( RDX, &r->GPR [ i.Base ].s );
	//e->AddReg32ImmX ( RDX, i.sOffset );
	BaseAddress += ( (s32) i.sOffset );


	pMemoryDevice8 = (u8*) Playstation2::DataBus::LUT_DataBus_Read [ BaseAddress >> 22 ].pMemoryDevice;
	pInvalidateDevice8 = Playstation2::DataBus::LUT_DataBus_Read [ BaseAddress >> 22 ].pInvalidateDevice;
	ulMask = Playstation2::DataBus::LUT_DataBus_Read [ BaseAddress >> 22 ].ulMask;
	//ulLatency = Playstation2::DataBus::LUT_DataBus_Write [ BaseAddress >> 22 ].ulLatency;
	//ulDeviceTestMask = Playstation2::DataBus::LUT_DataBus_Write [ BaseAddress >> 22 ].ulDeviceTest;
	
	
	// check for synchronous interrupt
	
	// if there is a synchronous interrupt possible, then check for it
	if ( BaseAddress & BitTest )
	{
		return 0;
	}

	if ( !pMemoryDevice8 )
	{
		return 0;
	}
	
	//if ( BaseAddress & ulDeviceTestMask )
	//{
	//	return 0;
	//}


	
	switch ( i.Opcode )
	{
		//case OPLWL:
		//case OPLWR:
		//case OPLDL:
		//case OPLDR:
		case OPLWC1:
		case OPLQ:
		case OPLQC2:
			return 0;
			break;
		default:
			break;
	}
	
	
	// part 1: first check for event //
	
#ifdef CHECK_EVENT_AFTER_START
	if ( RunCount2 )
	{
	// get updated CycleCount value for CPU (the value as it would be after instruction executed)
	e->MovRegMem64 ( RCX, (int64_t*) & r->CycleCount );
	e->AddReg64ImmX ( RCX, LocalCycleCount2 - ( MemCycles - 1 ) );
	//e->AddReg64ImmX ( RAX, LocalCycleCount - MemCycles );
	
	
	// want check that there are no events pending //
	
	// get the current cycle count and compare with next event cycle
	// note: actually need to either offset the next event cycle and correct when done or
	// or need to offset the next even cycle into another variable and check against that one
	e->CmpRegMem64 ( RCX, (int64_t*) & Playstation2::System::_SYSTEM->NextEvent_Cycle );
	
	// branch if current cycle is greater (or equal?) than next event cycle
	// changing this so that it branches if not returning
	// note: should probably be below or equal then jump, since the interpreter adds one to cycle
	e->Jmp_B ( 0, 0 );
	//e->Jmp8_AE ( 0, 0 );
	//e->Jmp_AE ( 0, 0 );
	

	// update NextPC
	e->MovMemImm32 ( (int32_t*) & r->NextPC, Address );
	
	// update CPU CycleCount
	//e->MovMemReg64 ( (int64_t*) & r->CycleCount, RAX );
	e->AddMem64ImmX ( (int64_t*) & r->CycleCount, LocalCycleCount2 - MemCycles );
	//e->AddMem64ImmX ( (int64_t*) & r->CycleCount, LocalCycleCount - MemCycles - ExeCycles );
	
	WriteBackModifiedRegs ();
	
	RestoreRegsFromStack ();
	
	// done for now - return
	e->Ret ();


	//if ( !e->SetJmpTarget8 ( 0 ) )
	if ( !e->SetJmpTarget ( 0 ) )
	{
		cout << "\nhps1x64: R3000A: Recompiler: short branch0 too far!";
	}

	
	// since we have not reached the next event cycle, should write back the current system cycle
	// so that the correct cycle# gets seen when the store is executed
	// no need to update the CPU cycle count until either a branch/jump is encountered or returning
	// this way, there is no need to reset the current cycle number tally unless a branch/jump is encountered
	//e->DecReg64 ( RAX );
	e->MovMemReg64 ( (int64_t*) & Playstation2::System::_SYSTEM->CycleCount, RCX );
	
	// part 2: check for synchronous interrupt //
	
	// this is where the entry point should be if this is the first instruction in the run
	//pCodeStart [ BlockIndex ] = e->Get_CodeBlock_CurrentPtr ();
	}
#endif
	

	
	// part 3: execute the store //
			

		
	// check isc
	//e->MovRegMem32 ( RAX, & r->CPR0.Status.Value );
	//e->BtRegImm32 ( RAX, 16 );
	//e->BtMemImm32 ( & r->CPR0.Status.Value, 16 );
	//e->Jmp8_AE ( 0, 6 );
	//e->Jmp8 ( 0, 6 );
	
	
	//e->MovMemImm32 ( & r->ICache.ICacheBlockSource [ ( BaseAddress >> 4 ) & 0xff ], -1 );


	//e->Jmp8 ( 0, 5 );


	//if ( !e->SetJmpTarget8 ( 7 ) )
	//{
	//	cout << "\nhps1x64: R3000A: Recompiler: short branch7 too far!";
	//}





	//if ( !e->SetJmpTarget ( 6 ) )
	//if ( !e->SetJmpTarget8 ( 6 ) )
	//{
	//	cout << "\nhps1x64: R3000A: Recompiler: short branch6 too far!";
	//}
	

	
	LoadAddress = BaseAddress & ulMask;

	
	
	switch ( i.Opcode )
	{

		default:
			Rt = Alloc_DstReg ( i.Rt );
			//e->MovRegMem32 ( RCX, &r->GPR [ i.Rt ].s );
			
			break;
			
	}

	
	// store the value
	switch ( i.Opcode )
	{
		case OPLB:
			//e->MovMemReg8 ( & pMemoryDevice8 [ StoreAddress ], Rt );
			e->MovsxReg64Mem8 ( Rt, (char*) & pMemoryDevice8 [ LoadAddress ] );
			break;
		case OPLBU:
			e->MovzxReg64Mem8 ( Rt, (char*) & pMemoryDevice8 [ LoadAddress ] );
			break;
		case OPLH:
			e->MovsxReg64Mem16 ( Rt, (short*) & pMemoryDevice8 [ LoadAddress ] );
			break;
		case OPLHU:
			e->MovzxReg64Mem16 ( Rt, (short*) & pMemoryDevice8 [ LoadAddress ] );
			break;
		case OPLWL:
			if ( ( LoadAddress & 3 ) == 3 )
			{
				e->MovsxdReg64Mem32 ( Rt, (int32_t*) & pMemoryDevice8 [ LoadAddress & ~3 ] );
			}
			else
			{
				e->MovRegMem32 ( RCX, & r->GPR [ i.Rt ].sw1 );
				e->MovRegMem32 ( Rt, (int32_t*) & pMemoryDevice8 [ LoadAddress & ~3 ] );
				e->MovMemReg32 ( (int32_t*) ( ( (u8*) & r->GPR [ i.Rt ].sw0 ) + ( ( ~LoadAddress ) & 3 ) ), Rt );
				e->MovMemReg32 ( & r->GPR [ i.Rt ].sw1, RCX );
				//e->MovRegMem64 ( Rt, & r->GPR [ i.Rt ].sw0 );
				e->MovsxdReg64Mem32 ( Rt, & r->GPR [ i.Rt ].sw0 );
			}
			break;
		case OPLWR:
			if ( ( LoadAddress & 3 ) == 0 )
			{
				e->MovsxdReg64Mem32 ( Rt, (int32_t*) & pMemoryDevice8 [ LoadAddress & ~3 ] );
			}
			else
			{
				e->MovRegMem32 ( RCX, & r->GPR [ i.Rt - 1 ].sw3 );
				e->MovRegMem32 ( Rt, (int32_t*) & pMemoryDevice8 [ LoadAddress & ~3 ] );
				e->MovMemReg32 ( (int32_t*) ( ( (u8*) & r->GPR [ i.Rt ].sw0 ) - ( ( LoadAddress ) & 3 ) ), Rt );
				e->MovMemReg32 ( & r->GPR [ i.Rt - 1 ].sw3, RCX );
				//e->MovRegMem64 ( Rt, & r->GPR [ i.Rt ].sw0 );
				e->MovRegMem64 ( Rt, & r->GPR [ i.Rt ].sq0 );
			}
			break;
		case OPLW:
			e->MovsxdReg64Mem32 ( Rt, (int32_t*) & pMemoryDevice8 [ LoadAddress ] );
			break;
		case OPLWU:
			e->MovRegMem32 ( Rt, (int32_t*) & pMemoryDevice8 [ LoadAddress ] );
			break;
		case OPLD:
			e->MovRegMem64 ( Rt, (int64_t*) & pMemoryDevice8 [ LoadAddress ] );
			break;
		case OPLDL:
			if ( ( LoadAddress & 7 ) == 7 )
			{
				e->MovRegMem64 ( Rt, (int64_t*) & pMemoryDevice8 [ LoadAddress & ~7 ] );
			}
			else
			{
				e->MovRegMem64 ( RCX, & r->GPR [ i.Rt ].sq1 );
				e->MovRegMem64 ( Rt, (int64_t*) & pMemoryDevice8 [ LoadAddress ] );
				e->MovMemReg64 ( (int64_t*) ( ( (u8*) & r->GPR [ i.Rt ].sq0 ) + ( ( ~LoadAddress ) & 7 ) ), Rt );
				e->MovMemReg64 ( & r->GPR [ i.Rt ].sq1, RCX );
				e->MovRegMem64 ( Rt, & r->GPR [ i.Rt ].sq0 );
			}
			break;
		case OPLDR:
			if ( ( LoadAddress & 7 ) == 0 )
			{
				e->MovRegMem64 ( Rt, (int64_t*) & pMemoryDevice8 [ LoadAddress & ~7 ] );
			}
			else
			{
				e->MovRegMem64 ( RCX, & r->GPR [ i.Rt - 1 ].sq1 );
				e->MovRegMem64 ( Rt, (int64_t*) & pMemoryDevice8 [ LoadAddress ] );
				e->MovMemReg64 ( (int64_t*) ( ( (u8*) & r->GPR [ i.Rt ].sq0 ) - ( LoadAddress & 7 ) ), Rt );
				e->MovMemReg64 ( & r->GPR [ i.Rt - 1 ].sq1, RCX );
				e->MovRegMem64 ( Rt, & r->GPR [ i.Rt ].sq0 );
			}
			break;
		case OPLWC1:
			break;
		case OPLQ:
			break;
		case OPLQC2:
			break;
	}
	
	
	// add additional latency
	//e->AddMem64ImmX ( (int64_t*) & r->CycleCount, ulLatency );

	





	//if ( !e->SetJmpTarget8 ( 2 ) )
	//{
	//	cout << "\nhps1x64: R3000A: Recompiler: short branch2 too far!";
	//}
	//if ( !e->SetJmpTarget8 ( 5 ) )
	//{
	//	cout << "\nhps1x64: R3000A: Recompiler: short branch5 too far!";
	//}
	
//cout << "\nRecompile L2 Store: ADDR=" << hex << Address << " BaseAddr=" << BaseAddress << " StoreAddr=" << StoreAddress << " Const=" << lConst << dec << " Rt=" << Rt << " i.Rt=" << i.Rt;
	
	return 1;
}



static void call_stub ( u64 CycleCount, u64 NextEvent, u32 Address, u32 TargetAddress )
{
	cout << "\ntesting: Address=" << hex << Address << " Target=" << TargetAddress << " Cycle#" << dec << CycleCount << " NextEvent=" << NextEvent;
	//Playstation2::System::debug << "\ntesting: Address=" << hex << Address << " Target=" << TargetAddress << " Cycle#" << dec << CycleCount << " NextEvent=" << NextEvent;
}

static void call_stub2 ( u64 CycleCount, u64 NextEvent, u32 Address, u32 TargetAddress )
{
	//cout << "\ntesting: Address=" << hex << Address << " Target=" << TargetAddress << " Cycle#" << dec << CycleCount << " NextEvent=" << NextEvent;
	Playstation2::System::debug << "\ntesting(before): Address=" << hex << Address << " Target=" << TargetAddress << " Cycle#" << dec << CycleCount << " NextEvent=" << NextEvent;
}

int32_t R5900::Recompiler::Generate_Normal_Branch(R5900::Instruction::Format i, u32 Address, void* BranchFunctionToCall)
{
	u32 TargetAddress;
	u32* pInst;
	bool bIdle;
	int32_t ret = 1;

	int32_t lBranchTaken_Cycles;

	// this is the number of Cycles to update CycleCount if this instruction does NOT execute successfully
	u64 ullCycles_Compare = LocalCycleCount - ullLoadCycles;
	u64 ullCycles_OnError = LocalCycleCount;

#ifdef VERBOSE_NORMAL_BRANCH
	cout << "\nStart";
#endif


	// get the target address
	switch (i.Opcode)
	{
	case OPJR:
		//case OPJALR:

			// don't know what the address is since it is variable
		//TargetAddress = 0;
		TargetAddress = -1;
		break;

	case OPJ:
	case OPJAL:
#ifdef VERBOSE_NORMAL_BRANCH
		cout << "\nAddress=" << hex << Address << " JumpAddress=" << i.JumpAddress;
#endif
		TargetAddress = (0xf0000000 & Address) | (i.JumpAddress << 2);

		break;

		// must be a branch
	default:
#ifdef VERBOSE_NORMAL_BRANCH
		cout << "\nAddress=" << hex << Address << " sOffset=" << i.sImmediate;
#endif
		TargetAddress = 4 + Address + (i.sImmediate << 2);
		break;
	}

	// set delay slot target address
	r->DelaySlot0_TargetAddr = TargetAddress;

	// set the cycles to update if branch is taken
#ifdef ENABLE_R5900_BRANCH_PREDICTION_RECOMPILER
	lBranchTaken_Cycles = (TargetAddress & 0x4) ? r->c_ullLatency_BranchMisPredict : 0;
#else
	lBranchTaken_Cycles = 0;
#endif

	r->DelaySlot0_BranchTakenCycles = lBranchTaken_Cycles;


#ifdef CHECK_EVENT_AFTER_START_BRANCH
	// part 1: first check for event //
	if (RunCount)
	{

		// get updated CycleCount value for CPU
		e->MovRegMem64(RAX, (int64_t*)&r->CycleCount);
		e->AddReg64ImmX(RAX, ullCycles_Compare);
		//e->AddReg64ImmX(RAX, LocalCycleCount - (MemCycles - 1));
		//e->AddReg64ImmX ( RAX, LocalCycleCount - MemCycles );

		// load params to exit recompilers
		e->MovReg32ImmX(RCX, Address);
		e->MovReg64ImmX(RDX, LocalCycleCount - MemCycles);

		// want check that there are no events pending //

		// get the current cycle count and compare with next event cycle
		// note: actually need to either offset the next event cycle and correct when done or
		// or need to offset the next even cycle into another variable and check against that one
		e->CmpRegMem64(RAX, (int64_t*)&Playstation2::System::_SYSTEM->NextEvent_Cycle);

		// branch if current cycle is greater (or equal?) than next event cycle
		// changing this so that it branches if not returning
		// note: should probably be below or equal then jump, since the interpreter adds one to cycle
		//e->Jmp8_B ( 0, 0 );
		//e->Jmp8_AE ( 0, 3 );
		//e->Jmp_AE(0, 3);
		e->JMP_AE(Exit_Recompiler);
	}


	// this is where the entry point should be if this is the first instruction in the run
	pCodeStart[BlockIndex] = (u8*)e->Get_CodeBlock_CurrentPtr();
#endif


#ifdef USE_NEW_BRANCH_CODE_R5900

	if (
		i.Opcode == OPBEQ
		||
		i.Opcode == OPBEQL
		||
		i.Opcode == OPBNE
		||
		i.Opcode == OPBNEL
		||
		i.Opcode == OPBLEZ
		||
		i.Opcode == OPBLEZL
		||
		i.Opcode == OPBGTZ
		||
		i.Opcode == OPBGTZL
		||
		(i.Opcode == OPCOP1
			&&
			(
				i.Rt == RTBC1T
				||
				i.Rt == RTBC1TL
				||
				i.Rt == RTBC1F
				||
				i.Rt == RTBC1FL
			)
		)
		||
		(	i.Opcode == OPREGIMM
			&&
			(
				i.Rt == RTBLTZ
				||
				i.Rt == RTBLTZL
				||
				i.Rt == RTBGEZ
				||
				i.Rt == RTBGEZL
				||
				i.Rt == RTBLTZAL
				||
				i.Rt == RTBLTZALL
				||
				i.Rt == RTBGEZAL
				||
				i.Rt == RTBGEZALL
			)
		)
		||
		i.Opcode == OPJ
		||
		i.Opcode == OPJAL
		||
		i.Opcode == OPSPECIAL
		)
	{

		if (i.Opcode == OPJR)
		{
			// get the address being jumped to
			e->MovRegMem32(RAX, &r->GPR[i.Rs].sw0);

#define ENABLE_SYNC_ADDRESS_EXCEPTION_JR
#ifdef ENABLE_SYNC_ADDRESS_EXCEPTION_JR
			// get pc for current address
			e->MovReg32ImmX(RCX, Address);

			// get cycle offset
			e->MovReg32ImmX(RDX, LocalCycleCount);

			// check for address exception
			//e->TestMem32ImmX(&r->GPR[i.Rs].sw0, 0x3);
			e->TestReg32ImmX(RAX, 0x3);

			// trigger synchronous interrupt on exception
			e->JMP_NE((void*)r->ProcessSynchronousInterrupt2_t<Cpu::EXC_ADEL>);
#else

			// if address exception not enabled, then need to mask the address
			e->AndReg32ImmX(RAX, ~0x3);

#endif

		}


		// set the instruction
		//r->DelaySlot0.Instruction = i;
		//e->MovMemImm32((int32_t*)&r->DelaySlot0.Instruction.Value, i.Value);


		switch (i.Opcode)
		{
		case OPCOP1:
			switch (i.Rt)
			{
			case RTBC1T:
			case RTBC1TL:
				if (!isNop(NextInst))
				{
					r->DelaySlot0_Recompiler = r->Recompiler_ProcessBranchDelaySlot_t<OPBC1T>;

					// set target address
					e->MovMemImm32((int32_t*)&r->DelaySlot0.Data, TargetAddress);

					// set callbacks
					//e->MovRegImm64(RAX, (int64_t)r->ProcessBranchDelaySlot_t<OPBC1T>);
					//e->MovMemReg64((int64_t*)&r->DelaySlot0.cb, RAX);
				}
				else
				{
					r->DelaySlot0_Recompiler = nullptr;
				}

				// todo - check for condition
				e->BtMemImm32(&r->CPC1[31], 23);

				if (!isNop(NextInst))
				{
					// todo: handle likely branch here
					if (i.Rt == RTBC1TL)
					{
						e->MovRegImm32(RCX, Address + 8);
						e->MovRegImm32(RDX, LocalCycleCount + lBranchTaken_Cycles);

						ret = e->JMP_AE(Exit_Recompiler);
					}

					e->Set_B(RAX);
					e->AddRegReg32(RAX, RAX);
					ret = e->MovMemReg8((char*)&r->Status.DelaySlot_Valid, RAX);
				}
				else
				{
					// delay slot is nop //

					e->MovRegImm32(RCX, TargetAddress);
					e->MovRegImm32(RDX, LocalCycleCount + lBranchTaken_Cycles);

					ret = e->JMP_B(Exit_Recompiler);
				}

				break;

			case RTBC1F:
			case RTBC1FL:
				if (!isNop(NextInst))
				{
					r->DelaySlot0_Recompiler = r->Recompiler_ProcessBranchDelaySlot_t<OPBC1F>;

					// set target address
					e->MovMemImm32((int32_t*)&r->DelaySlot0.Data, TargetAddress);

					// set callbacks
					//e->MovRegImm64(RAX, (int64_t)r->ProcessBranchDelaySlot_t<OPBC1F>);
					//e->MovMemReg64((int64_t*)&r->DelaySlot0.cb, RAX);
				}
				else
				{
					r->DelaySlot0_Recompiler = nullptr;
				}

				// todo - check for condition
				e->BtMemImm32(&r->CPC1[31], 23);

				if (!isNop(NextInst))
				{
					// todo: handle likely branch here
					if (i.Rt == RTBC1FL)
					{
						e->MovRegImm32(RCX, Address + 8);
						e->MovRegImm32(RDX, LocalCycleCount);

						ret = e->JMP_B(Exit_Recompiler);
					}

					e->Set_AE(RAX);
					e->AddRegReg32(RAX, RAX);
					ret = e->MovMemReg8((char*)&r->Status.DelaySlot_Valid, RAX);
				}
				else
				{
					// delay slot is nop //

					e->MovRegImm32(RCX, TargetAddress);
					e->MovRegImm32(RDX, LocalCycleCount + lBranchTaken_Cycles);

					ret = e->JMP_AE(Exit_Recompiler);
				}

				break;
			}

			break;

		case OPBEQ:
		case OPBEQL:
			// testing
			//bStopEncodingAfter = true;

			if (!isNop(NextInst))
			{
				r->DelaySlot0_Recompiler = r->Recompiler_ProcessBranchDelaySlot_t<OPBEQ>;

				// set target address
				e->MovMemImm32((int32_t*)&r->DelaySlot0.Data, TargetAddress);

				// set callbacks
				//e->MovRegImm64(RAX, (int64_t)r->ProcessBranchDelaySlot_t<OPBEQ>);
				//e->MovMemReg64((int64_t*)&r->DelaySlot0.cb, RAX);
			}
			else
			{
				r->DelaySlot0_Recompiler = nullptr;
			}

			if (i.Rs != i.Rt)
			{
				// conditional branch //

				if (!i.Rs || !i.Rt)
				{
					e->CmpMem64ImmX(&r->GPR[i.Rs + i.Rt].s, 0);
				}
				else
				{
					e->MovRegMem64(RCX, &r->GPR[i.Rs].s);
					e->CmpMemReg64(&r->GPR[i.Rt].s, RCX);
				}

				if (!isNop(NextInst))
				{
					// todo: handle likely branch here
					if (i.Opcode == OPBEQL)
					{
						e->MovRegImm32(RCX, Address + 8);
						e->MovRegImm32(RDX, LocalCycleCount);

						ret = e->JMP_NE(Exit_Recompiler);
					}

					e->Set_E(RAX);
					e->AddRegReg32(RAX, RAX);
					ret = e->MovMemReg8((char*)&r->Status.DelaySlot_Valid, RAX);
				}
				else
				{
					// delay slot is nop //

					e->MovRegImm32(RCX, TargetAddress);
					e->MovRegImm32(RDX, LocalCycleCount + lBranchTaken_Cycles);

					ret = e->JMP_E(Exit_Recompiler);
				}

			}
			else
			{
				// unconditional branch //

				if (!isNop(NextInst))
				{
					//ret = e->BtsMemImm32((int32_t*)&r->Status.isSomethingBusy, 9);
					ret = e->MovMemImm8((char*)&r->Status.DelaySlot_Valid, 2);
				}
				else
				{
					// delay slot is nop //

					e->MovMemImm32((int32_t*) & r->NextPC, TargetAddress);
					e->AddMem64ImmX((int64_t*)&r->CycleCount, LocalCycleCount + lBranchTaken_Cycles);
					ret = e->Ret();
				}
			}
			break;

		case OPBNE:
		case OPBNEL:

			if (!isNop(NextInst))
			{
				r->DelaySlot0_Recompiler = r->Recompiler_ProcessBranchDelaySlot_t<OPBNE>;

				// set target address
				e->MovMemImm32((int32_t*)&r->DelaySlot0.Data, TargetAddress);

				// set callbacks
				//e->MovRegImm64(RAX, (int64_t)r->ProcessBranchDelaySlot_t<OPBNE>);
				//e->MovMemReg64((int64_t*)&r->DelaySlot0.cb, RAX);
			}
			else
			{
				r->DelaySlot0_Recompiler = nullptr;
			}

			if (!i.Rs || !i.Rt)
			{
				e->CmpMem64ImmX(&r->GPR[i.Rs + i.Rt].s, 0);
			}
			else
			{
				e->MovRegMem64(RCX, &r->GPR[i.Rs].s);
				e->CmpMemReg64(&r->GPR[i.Rt].s, RCX);
			}

			if (!isNop(NextInst))
			{
				// todo: handle likely branch here
				if (i.Opcode == OPBNEL)
				{
					e->MovRegImm32(RCX, Address + 8);
					e->MovRegImm32(RDX, LocalCycleCount);

					ret = e->JMP_E(Exit_Recompiler);
				}

				e->Set_NE(RAX);
				e->AddRegReg32(RAX, RAX);
				ret = e->MovMemReg8((char*)&r->Status.DelaySlot_Valid, RAX);
			}
			else
			{
				// delay slot is nop //

				e->MovRegImm32(RCX, TargetAddress);
				e->MovRegImm32(RDX, LocalCycleCount + lBranchTaken_Cycles);

				ret = e->JMP_NE(Exit_Recompiler);
			}

			break;

		case OPBLEZ:
		case OPBLEZL:
			if (!isNop(NextInst))
			{
				r->DelaySlot0_Recompiler = r->Recompiler_ProcessBranchDelaySlot_t<OPBLEZ>;

				// set target address
				e->MovMemImm32((int32_t*)&r->DelaySlot0.Data, TargetAddress);

				// set callbacks
				//e->MovRegImm64(RAX, (int64_t)r->ProcessBranchDelaySlot_t<OPBLEZ>);
				//e->MovMemReg64((int64_t*)&r->DelaySlot0.cb, RAX);
			}
			else
			{
				r->DelaySlot0_Recompiler = nullptr;
			}

			if (i.Rs)
			{
				// conditional branch //

				e->CmpMem64ImmX(&r->GPR[i.Rs].s, 0);

				if (!isNop(NextInst))
				{
					// todo: handle likely branch here
					if (i.Opcode == OPBLEZL)
					{
						e->MovRegImm32(RCX, Address + 8);
						e->MovRegImm32(RDX, LocalCycleCount);

						ret = e->JMP_G(Exit_Recompiler);
					}

					e->Set_LE(RAX);
					e->AddRegReg32(RAX, RAX);
					ret = e->MovMemReg8((char*)&r->Status.DelaySlot_Valid, RAX);
				}
				else
				{
					// delay slot is nop //

					e->MovRegImm32(RCX, TargetAddress);
					e->MovRegImm32(RDX, LocalCycleCount + lBranchTaken_Cycles);

					ret = e->JMP_LE(Exit_Recompiler);
				}
			}
			else
			{
				// unconditional branch //

				if (!isNop(NextInst))
				{
					//ret = e->BtsMemImm32((int32_t*)&r->Status.isSomethingBusy, 9);
					ret = e->MovMemImm8((char*)&r->Status.DelaySlot_Valid, 2);
				}
				else
				{
					// delay slot is nop //

					e->MovMemImm32((int32_t*)&r->NextPC, TargetAddress);
					e->AddMem64ImmX((int64_t*)&r->CycleCount, LocalCycleCount + lBranchTaken_Cycles);
					ret = e->Ret();
				}
			}

			break;

		case OPBGTZ:
		case OPBGTZL:

			if (!isNop(NextInst))
			{
				r->DelaySlot0_Recompiler = r->Recompiler_ProcessBranchDelaySlot_t<OPBGTZ>;

				// set target address
				e->MovMemImm32((int32_t*)&r->DelaySlot0.Data, TargetAddress);

				// set callbacks
				//e->MovRegImm64(RAX, (int64_t)r->ProcessBranchDelaySlot_t<OPBGTZ>);
				//e->MovMemReg64((int64_t*)&r->DelaySlot0.cb, RAX);
			}
			else
			{
				r->DelaySlot0_Recompiler = nullptr;
			}

			e->CmpMem64ImmX(&r->GPR[i.Rs].s, 0);


			if (!isNop(NextInst))
			{
				// todo: handle likely branch here
				if (i.Opcode == OPBGTZL)
				{
					e->MovRegImm32(RCX, Address + 8);
					e->MovRegImm32(RDX, LocalCycleCount);

					ret = e->JMP_LE(Exit_Recompiler);
				}

				e->Set_G(RAX);
				e->AddRegReg32(RAX, RAX);
				ret = e->MovMemReg8((char*)&r->Status.DelaySlot_Valid, RAX);
			}
			else
			{
				// delay slot is nop //

				e->MovRegImm32(RCX, TargetAddress);
				e->MovRegImm32(RDX, LocalCycleCount + lBranchTaken_Cycles);

				ret = e->JMP_G(Exit_Recompiler);
			}

			break;

		case OPREGIMM:
			//case OPBGEZ:
			//case OPBLTZAL:
			//case OPBGEZAL:
			switch (i.Rt)
			{
			case RTBLTZ:
			case RTBLTZL:

				if (!isNop(NextInst))
				{
					r->DelaySlot0_Recompiler = r->Recompiler_ProcessBranchDelaySlot_t<OPREGIMM>;

					// set target address
					e->MovMemImm32((int32_t*)&r->DelaySlot0.Data, TargetAddress);

					// set callbacks
					//e->MovRegImm64(RAX, (int64_t)r->ProcessBranchDelaySlot_t<OPREGIMM>);
					//e->MovMemReg64((int64_t*)&r->DelaySlot0.cb, RAX);
				}
				else
				{
					r->DelaySlot0_Recompiler = nullptr;
				}

				e->CmpMem64ImmX(&r->GPR[i.Rs].s, 0);

				if (!isNop(NextInst))
				{
					// todo: handle likely branch here
					if (i.Rt == RTBLTZL)
					{
						e->MovRegImm32(RCX, Address + 8);
						e->MovRegImm32(RDX, LocalCycleCount);

						ret = e->JMP_GE(Exit_Recompiler);
					}

					e->Set_L(RAX);
					e->AddRegReg32(RAX, RAX);
					ret = e->MovMemReg8((char*)&r->Status.DelaySlot_Valid, RAX);
				}
				else
				{
					// delay slot is nop //

					e->MovRegImm32(RCX, TargetAddress);
					e->MovRegImm32(RDX, LocalCycleCount + lBranchTaken_Cycles);

					ret = e->JMP_L(Exit_Recompiler);
				}

				break;

			case RTBGEZ:
			case RTBGEZL:
				if (!isNop(NextInst))
				{
					r->DelaySlot0_Recompiler = r->Recompiler_ProcessBranchDelaySlot_t<OPREGIMM>;

					// set target address
					e->MovMemImm32((int32_t*)&r->DelaySlot0.Data, TargetAddress);

					// set callbacks
					//e->MovRegImm64(RAX, (int64_t)r->ProcessBranchDelaySlot_t<OPREGIMM>);
					//e->MovMemReg64((int64_t*)&r->DelaySlot0.cb, RAX);
				}
				else
				{
					r->DelaySlot0_Recompiler = nullptr;
				}

				if (i.Rs)
				{
					e->CmpMem64ImmX(&r->GPR[i.Rs].s, 0);

					if (!isNop(NextInst))
					{
						// todo: handle likely branch here
						if (i.Rt == RTBGEZL)
						{
							e->MovRegImm32(RCX, Address + 8);
							e->MovRegImm32(RDX, LocalCycleCount);

							ret = e->JMP_L(Exit_Recompiler);
						}

						e->Set_GE(RAX);
						e->AddRegReg32(RAX, RAX);
						ret = e->MovMemReg8((char*)&r->Status.DelaySlot_Valid, RAX);
					}
					else
					{
						// delay slot is nop //

						e->MovRegImm32(RCX, TargetAddress);
						e->MovRegImm32(RDX, LocalCycleCount + lBranchTaken_Cycles);

						ret = e->JMP_GE(Exit_Recompiler);
					}
				}
				else
				{
					// unconditional branch //

					if (!isNop(NextInst))
					{
						//ret = e->BtsMemImm32((int32_t*)&r->Status.isSomethingBusy, 9);
						ret = e->MovMemImm8((char*)&r->Status.DelaySlot_Valid, 2);
					}
					else
					{
						// delay slot is nop //

						e->MovMemImm32((int32_t*)&r->NextPC, TargetAddress);
						e->AddMem64ImmX((int64_t*)&r->CycleCount, LocalCycleCount + lBranchTaken_Cycles);
						ret = e->Ret();
					}
				}
				break;

			case RTBLTZAL:
			case RTBLTZALL:
				e->MovMemImm64(&r->GPR[31].s, Address + 8);

				if (!isNop(NextInst))
				{
					r->DelaySlot0_Recompiler = r->Recompiler_ProcessBranchDelaySlot_t<OPREGIMM>;

					// set target address
					e->MovMemImm32((int32_t*)&r->DelaySlot0.Data, TargetAddress);

					// set callbacks
					//e->MovRegImm64(RAX, (int64_t)r->ProcessBranchDelaySlot_t<OPREGIMM>);
					//e->MovMemReg64((int64_t*)&r->DelaySlot0.cb, RAX);
				}
				else
				{
					r->DelaySlot0_Recompiler = nullptr;
				}

				e->CmpMem64ImmX(&r->GPR[i.Rs].s, 0);

				if (!isNop(NextInst))
				{
					// todo: handle likely branch here
					if (i.Rt == RTBLTZALL)
					{
						e->MovRegImm32(RCX, Address + 8);
						e->MovRegImm32(RDX, LocalCycleCount);

						ret = e->JMP_GE(Exit_Recompiler);
					}

					e->Set_L(RAX);
					e->AddRegReg32(RAX, RAX);
					ret = e->MovMemReg8((char*)&r->Status.DelaySlot_Valid, RAX);
				}
				else
				{
					// delay slot is nop //

					e->MovRegImm32(RCX, TargetAddress);
					e->MovRegImm32(RDX, LocalCycleCount + lBranchTaken_Cycles);

					ret = e->JMP_L(Exit_Recompiler);
				}

				break;

			case RTBGEZAL:
			case RTBGEZALL:
				e->MovMemImm64(&r->GPR[31].s, Address + 8);

				if (!isNop(NextInst))
				{
					r->DelaySlot0_Recompiler = r->Recompiler_ProcessBranchDelaySlot_t<OPREGIMM>;

					// set target address
					e->MovMemImm32((int32_t*)&r->DelaySlot0.Data, TargetAddress);

					// set callbacks
					//e->MovRegImm64(RAX, (int64_t)r->ProcessBranchDelaySlot_t<OPREGIMM>);
					//e->MovMemReg64((int64_t*)&r->DelaySlot0.cb, RAX);
				}
				else
				{
					r->DelaySlot0_Recompiler = nullptr;
				}

				if (i.Rs)
				{
					e->CmpMem64ImmX(&r->GPR[i.Rs].s, 0);

					if (!isNop(NextInst))
					{
						// todo: handle likely branch here
						if (i.Rt == RTBGEZALL)
						{
							e->MovRegImm32(RCX, Address + 8);
							e->MovRegImm32(RDX, LocalCycleCount);

							ret = e->JMP_L(Exit_Recompiler);
						}

						e->Set_GE(RAX);
						e->AddRegReg32(RAX, RAX);
						ret = e->MovMemReg8((char*)&r->Status.DelaySlot_Valid, RAX);
					}
					else
					{
						// delay slot is nop //

						e->MovRegImm32(RCX, TargetAddress);
						e->MovRegImm32(RDX, LocalCycleCount + lBranchTaken_Cycles);

						ret = e->JMP_GE(Exit_Recompiler);
					}
				}
				else
				{
					// unconditional branch //

					if (!isNop(NextInst))
					{
						//ret = e->BtsMemImm32((int32_t*)&r->Status.isSomethingBusy, 9);
						ret = e->MovMemImm8((char*)&r->Status.DelaySlot_Valid, 2);
					}
					else
					{
						// delay slot is nop //

						e->MovMemImm32((int32_t*)&r->NextPC, TargetAddress);
						e->AddMem64ImmX((int64_t*)&r->CycleCount, LocalCycleCount);
						ret = e->Ret();
					}
				}

				break;
			}

			break;

			
		case OPJ:

			if (!isNop(NextInst))
			{
				r->DelaySlot0_Recompiler = r->Recompiler_ProcessBranchDelaySlot_t<OPJ>;

				// set target address
				e->MovMemImm32((int32_t*)&r->DelaySlot0.Data, TargetAddress);

				// set callbacks
				//e->MovRegImm64(RAX, (int64_t)r->ProcessBranchDelaySlot_t<OPJ>);
				//e->MovMemReg64((int64_t*)&r->DelaySlot0.cb, RAX);

				// unconditional branch //
				//ret = e->BtsMemImm32((int32_t*)&r->Status.isSomethingBusy, 9);
				ret = e->MovMemImm8((char*)&r->Status.DelaySlot_Valid, 2);
			}
			else
			{
				// delay slot is nop //

				r->DelaySlot0_Recompiler = nullptr;

				e->MovMemImm32((int32_t*)&r->NextPC, TargetAddress);
				e->AddMem64ImmX((int64_t*)&r->CycleCount, LocalCycleCount + lBranchTaken_Cycles);
				ret = e->Ret();
			}

			break;

		case OPJAL:

			// store return address to r31
			e->MovMemImm64(&r->GPR[31].s, Address + 8);

			if (!isNop(NextInst))
			{
				r->DelaySlot0_Recompiler = r->Recompiler_ProcessBranchDelaySlot_t<OPJAL>;

				// set target address
				e->MovMemImm32((int32_t*)&r->DelaySlot0.Data, TargetAddress);

				// set callbacks
				//e->MovRegImm64(RAX, (int64_t)r->ProcessBranchDelaySlot_t<OPJAL>);
				//e->MovMemReg64((int64_t*)&r->DelaySlot0.cb, RAX);


				// unconditional branch //
				//ret = e->BtsMemImm32((int32_t*)&r->Status.isSomethingBusy, 9);
				ret = e->MovMemImm8((char*)&r->Status.DelaySlot_Valid, 2);
			}
			else
			{
				// delay slot is nop //

				r->DelaySlot0_Recompiler = nullptr;

				e->MovMemImm32((int32_t*)&r->NextPC, TargetAddress);
				e->AddMem64ImmX((int64_t*)&r->CycleCount, LocalCycleCount + lBranchTaken_Cycles);
				ret = e->Ret();
			}

			break;

		case OPSPECIAL:
			// JR or JALR //

			// unconditional branch //

			if (i.Funct == 9)
			{
				// JALR //

				// make sure Rd is not r0
				if (i.Rd)
				{
					// save return address in Rd
					e->MovMemImm64(&r->GPR[i.Rd].s, Address + 8);
				}
			}

			if (!isNop(NextInst))
			{
				r->DelaySlot0_Recompiler = r->Recompiler_ProcessBranchDelaySlot_t<OPJALR>;

				// store the address (rax) to delay slot
				e->MovMemReg32((int32_t*)&r->DelaySlot0.Data, RAX);

				// set callbacks
				//e->MovRegImm64(RAX, (int64_t)r->ProcessBranchDelaySlot_t<OPJALR>);
				//e->MovMemReg64((int64_t*)&r->DelaySlot0.cb, RAX);

				//ret = e->BtsMemImm32((int32_t*)&r->Status.isSomethingBusy, 9);
				ret = e->MovMemImm8((char*)&r->Status.DelaySlot_Valid, 2);
			}
			else
			{
				// delay slot is nop //

				r->DelaySlot0_Recompiler = nullptr;

				e->MovMemReg32((int32_t*)&r->NextPC, RAX);
				e->AddMem64ImmX((int64_t*)&r->CycleCount, LocalCycleCount + lBranchTaken_Cycles);
				ret = e->Ret();
			}

			break;


		}	// end switch (i.Opcode)


		return ret;

	}	// end if (i.Opcode == OPBEQ)

#endif


	// check for sychronous interrupt if applicable
	if ( i.Opcode == OPJR )
	{
		// get the address being jumped to
		e->MovRegMem32 ( RDX, & r->GPR [ i.Rs ].sw0 );
		
		// if ( StoreAddress & 0x1 )
		//e->TestReg32ImmX ( RDX, BitTest );
		e->TestReg32ImmX ( RDX, 0x3 );

		// branch if zero
		//e->Jmp8_E ( 0, 0 );
		e->Jmp8_NE ( 0, 4 );
		
	}


	// check if branching or not
	switch ( i.Opcode )
	{
		case OPBEQ:
		case OPBEQL:
			if ( i.Rs != i.Rt )
			{
			if ( !i.Rs || !i.Rt )
			{
			e->CmpMem64ImmX ( & r->GPR [ i.Rs + i.Rt ].s, 0 );
			e->Jmp_NE ( 0, 0 );
			}
			else
			{
			e->MovRegMem64 ( RCX, & r->GPR [ i.Rs ].s );
			e->CmpMemReg64 ( & r->GPR [ i.Rt ].s, RCX );
			//e->Jmp8_NE ( 0, 0 );
			e->Jmp_NE ( 0, 0 );
			}
			}
			break;
			
		case OPBNE:
		case OPBNEL:
			if ( !i.Rs || !i.Rt )
			{
			e->CmpMem64ImmX ( & r->GPR [ i.Rs + i.Rt ].s, 0 );
			e->Jmp_E ( 0, 0 );
			}
			else
			{
			e->MovRegMem64 ( RCX, & r->GPR [ i.Rs ].s );
			e->CmpMemReg64 ( & r->GPR [ i.Rt ].s, RCX );
			//e->Jmp8_E ( 0, 0 );
			e->Jmp_E ( 0, 0 );
			}
			break;
			
		case OPBLEZ:
		case OPBLEZL:
			e->CmpMem64ImmX ( & r->GPR [ i.Rs ].s, 0 );
			//e->Jmp8_G ( 0, 0 );
			e->Jmp_G ( 0, 0 );
			break;
			
		case OPBGTZ:
		case OPBGTZL:
			e->CmpMem64ImmX ( & r->GPR [ i.Rs ].s, 0 );
			//e->Jmp8_LE ( 0, 0 );
			e->Jmp_LE ( 0, 0 );
			break;
			
		case OPBLTZ:
		//case OPBGEZ:
		//case OPBLTZAL:
		//case OPBGEZAL:
			switch ( i.Rt )
			{
				case RTBLTZ:
				case RTBLTZL:
					e->CmpMem64ImmX ( & r->GPR [ i.Rs ].s, 0 );
					//e->Jmp8_GE ( 0, 0 );
					e->Jmp_GE ( 0, 0 );
					break;
					
				case RTBGEZ:
				case RTBGEZL:
					e->CmpMem64ImmX ( & r->GPR [ i.Rs ].s, 0 );
					//e->Jmp8_L ( 0, 0 );
					e->Jmp_L ( 0, 0 );
					break;
			
				case RTBLTZAL:
				case RTBLTZALL:
					e->CmpMem64ImmX ( & r->GPR [ i.Rs ].s, 0 );
					e->MovMemImm64 ( & r->GPR [ 31 ].s, Address + 8 );
					//e->Jmp8_GE ( 0, 0 );
					e->Jmp_GE ( 0, 0 );
					break;
			
				case RTBGEZAL:
				case RTBGEZALL:
					e->CmpMem64ImmX ( & r->GPR [ i.Rs ].s, 0 );
					e->MovMemImm64 ( & r->GPR [ 31 ].s, Address + 8 );
					//e->Jmp8_L ( 0, 0 );
					e->Jmp_L ( 0, 0 );
					break;
			}
			
			break;
			
		case OPJAL:
			e->MovMemImm64 ( & r->GPR [ 31 ].s, Address + 8 );
			break;
			
		case OPJALR:
		
			if ( i.Funct == 9 )
			{
				// JALR //
				
				// make sure Rd is not r0
				if ( i.Rd )
				{
					// save return address in Rd
					e->MovMemImm64 ( & r->GPR [ i.Rd ].s, Address + 8 );
				}
			}
			
			break;
	}
	
	
	// branching //
	
	
	
#ifdef ALLOW_ENCODING_DELAYSLOT
	// check if target address is inside current block or not
	// for now, only check for only jumping backwards
	//if ( TargetAddress && TargetAddress >= CurrentBlock_StartAddress && TargetAddress < NextBlock_StartAddress && isBranchDelayOk ( NextInst.Value ) )
	if (
/*
#ifdef ENABLE_AUTO_BRANCH
		( TargetAddress && TargetAddress >= CurrentBlock_StartAddress && TargetAddress <= Address && isBranchDelayOk ( NextInst.Value, Address + 4 ) ) ||
#endif
*/
		// make sure the instruction in the branch delay slot is a simple one
		( isBranchDelayOk ( NextInst.Value, Address + 4 ) )
		
		// also need the branch delay slot to be in the same cache block
		&& ( ( ( Address + 4 ) >> 2 ) & 0xf )
		
		)
	{
		// target can be reached with jump in same block //
#ifdef VERBOSE_NORMAL_BRANCH
cout << "\nisBranchDelayOk";
#endif



#ifdef ENABLE_R5900_SKIP_IDLE_CYCLES

		// check for processor waiting
		if ( ! NextInst.Value )
		{
			// make sure not jr //
			if ( i.Opcode != OPJR )
			{
				u8* pBranchedTo;
				u8* pBranch;
				
				// get the pointer being branched to
				pBranchedTo = pCodeStart [ ( TargetAddress >> 2 ) & ulIndex_Mask ];
				
				// get the pointer to the branch
				pBranch = pCodeStart [ ( Address >> 2 ) & ulIndex_Mask ];

				// make sure we are jumping backwards
				if (TargetAddress <= Address)
				{
					// check if equal
					if (pBranchedTo == pBranch)
					{
						// update NextPC
						e->MovMemImm32((int32_t*)&r->NextPC, TargetAddress);

						// update CycleCount
						// ***todo*** should be the cycles plus one instruction since branch into delay slot has already been executed
						//e->AddMem64ImmX ( (int64_t*) & r->CycleCount, LocalCycleCount );
						e->MovRegMem64(RCX, (int64_t*)&r->CycleCount);

						// add number of cycles at branch, plus delay slot instruction, exclude branch instruction (gets added in at return)
						// *** todo *** calculate if can add in a branch pipeline refill
						e->AddReg64ImmX(RCX, LocalCycleCount + 1);

						// check against the next event cycle (next ps1 cycle is checked by the event cycle also)
						e->CmpRegMem64(RCX, (int64_t*)&Playstation2::System::_SYSTEM->NextEvent_Cycle);
						e->CmovBRegMem64(RCX, (int64_t*)&Playstation2::System::_SYSTEM->NextEvent_Cycle);

						// store as the new cycle count
						e->MovMemReg64((int64_t*)&r->CycleCount, RCX);

						// should be done
						e->Ret();

					}
				}
			}
		}

#endif


#ifdef VERBOSE_NORMAL_BRANCH
cout << "\nbRecompile";
#endif
		// no auto branch, but cache line is loaded, so execute delay slot //
		// execute the instruction in delay slot
		// if it is in the same cache block or its cache block is loaded
		// note: if this is a mult/div then need to update the CPU cycles both before and after ?
		ret = Recompile ( NextInst, Address + 4 );
		
		if ( ret <= 0 )
		{
			cout << "\nR5900: Recompiler: Error encoding branch in delay slot.";
		}


#ifdef ENABLE_AUTO_BRANCH
		if (
			// make sure not JR
			( i.Opcode != OPJR )
			
			// make sure target address is in same cache block for now
			// staying within same cache block means this can be done purely at re-compile time
			//&& ( ( TargetAddress >> 6 ) == ( Address >> 6 ) )
			
			// and also make sure we are jumping backwards
			&& ( TargetAddress <= Address )
			
			//&& ( ( ( Address - TargetAddress ) >> 2 ) <= RunCount )
			
		)
		{

			if (
			// make sure target address is in same cache block for now
			// staying within same cache block means this can be done purely at re-compile time
			( ( TargetAddress >> 6 ) == ( Address >> 6 ) )
			
			// and also make sure we are jumping backwards
			&& ( TargetAddress <= Address )
			)
			{
				// update the cycle count before jumping
				// +MemCycles for the delay slot memory access cycles and +1 for the delay slot execute cycles -> but +1 is already included in memcycles
				//e->AddMem64ImmX ( (int64_t*) & r->CycleCount, LocalCycleCount + MemCycles - CycleCount [ ( TargetAddress >> 2 ) & ulIndex_Mask ] + 1 );
				//e->AddMem64ImmX ( (int64_t*) & r->CycleCount, LocalCycleCount + ( MemCycles << 1 ) - CycleCount [ ( TargetAddress >> 2 ) & ulIndex_Mask ] );
				// so, have to add in the cycles for the branch and also the delay slot
				//e->AddMem64ImmX ( (int64_t*) & r->CycleCount, LocalCycleCount + ( MemCycles << 1 ) + ( ExeCycles << 1 ) - CycleCount [ ( TargetAddress >> 2 ) & ulIndex_Mask ] );

			// *** todo *** check cycle count against next event
		// get updated CycleCount value for CPU (the value as it would be after instruction executed)
		e->MovRegMem64 ( RAX, (int64_t*) & r->CycleCount );
		e->AddReg64ImmX ( RAX, LocalCycleCount + ( MemCycles << 1 ) );
		//e->AddReg64ImmX ( RAX, LocalCycleCount - MemCycles );
		
		
		// want check that there are no events pending //
		
		// get the current cycle count and compare with next event cycle
		// note: actually need to either offset the next event cycle and correct when done or
		// or need to offset the next even cycle into another variable and check against that one
		e->CmpRegMem64 ( RAX, (int64_t*) & Playstation2::System::_SYSTEM->NextEvent_Cycle );
	
		// branch if current cycle is greater (or equal?) than next event cycle
		// changing this so that it branches if not returning
		// note: should probably be below or equal then jump, since the interpreter adds one to cycle
		//e->Jmp8_B ( 0, 0 );
		e->Jmp8_AE ( 0, 9 );
		//e->Jmp_AE ( 0, 0 );
		
		
		// subtract cycle count for new address
		e->MovRegMem32 ( RCX, & CycleCount [ ( TargetAddress >> 2 ) & ulIndex_Mask ] );
		e->SubRegReg64 ( RAX, RCX );
		e->MovMemReg64 ( (int64_t*) & r->CycleCount, RAX );
				
			e->MovMemImm32 ( (int32_t*) & r->NextPC, TargetAddress );
			
				// make the jump backwards
				//ret = e->JMP ( pPrefix_CodeStart [ ( TargetAddress >> 2 ) & MaxStep_Mask ] );
				//ret = e->JMP ( pPrefix_CodeStart [ ( TargetAddress >> 2 ) & ulIndex_Mask ] );
				//ret = e->JMP ( pCodeStart [ ( TargetAddress >> 2 ) & ulIndex_Mask ] );
				e->JmpMem64 ( (int64_t*) & pCodeStart [ ( TargetAddress >> 2 ) & ulIndex_Mask ] );
				
				e->SetJmpTarget8 ( 9 );
			}
			else
			{
				// get the block to encode in
				u32 tBlock;
				tBlock = ( TargetAddress >> ( 2 + MaxStep_Shift ) ) & NumBlocks_Mask;
		
		
				// step 1: check if next block has been modified (if it is in main memory)
				if ( ( TargetAddress & 0x1fc00000 ) != 0x1fc00000 )
				{
					e->CmpMemImm8 ( & r->Bus->InvalidArray.b8 [ ( TargetAddress & Playstation2::DataBus::MainMemory_Mask ) >> ( 2 + r->Bus->c_iInvalidate_Shift ) ], 0 );
					e->Jmp8_NE( 0, 6 );
				}
				
				// step 2: check if next block has the correct source address
				e->CmpMem32ImmX ( & StartAddress [ ( tBlock ) & NumBlocks_Mask ], ( TargetAddress >> ( 2 + MaxStep_Shift ) ) << ( 2 + MaxStep_Shift ) );
				e->Jmp8_NE( 0, 7 );
				
				// step 3: if next block is cached, check that it is in i-cache
				if ( bIsBlockInICache )
				{
					// get the cache line that address should be at
					u32 ICacheBlockIndex = ( TargetAddress >> 6 ) & 0x7f;
					
					// make room for the way
					ICacheBlockIndex <<= 1;

					e->CmpMem32ImmX ( & r->ICache.PFN [ ICacheBlockIndex ], ( TargetAddress & 0x1fffffc0 ) );
					e->Jmp8_E ( 0, 8 );

					e->CmpMem32ImmX ( & r->ICache.PFN [ ICacheBlockIndex ^ 1 ], ( TargetAddress & 0x1fffffc0 ) );
					e->Jmp8_NE ( 0, 9 );
					
					// make sure the cache line is valid and that the address is actually cached there
					// for ps2, must check way0 and way1 both
					//if ( PFN [ ICacheBlockIndex ] == ( Address & 0x1fffffc0 ) )
					//{
					//	//return & Data [ ICacheBlockIndex << 4 ];
					//	return & Data [ ( ICacheBlockIndex << 4 ) ^ ( ( Address >> 2 ) & 0xf ) ];
					//}
					
					//if ( PFN [ ICacheBlockIndex ^ 1 ] == ( Address & 0x1fffffc0 ) )
					//{
					//	//return & Data [ ( ICacheBlockIndex ^ 1 ) << 4 ];
					//	return & Data [ ( ( ICacheBlockIndex ^ 1 ) << 4 ) ^ ( ( Address >> 2 ) & 0xf ) ];
					//}
			
					e->SetJmpTarget8 ( 8 );
				}
		
				e->MovRegMem64 ( RAX, (int64_t*) & r->CycleCount );
				
				// this isn't available at re-compile time
				e->MovRegMem32 ( RCX, & CycleCount [ ( TargetAddress >> 2 ) & ulIndex_Mask ] );


				// update cycle count
				//e->AddReg64ImmX ( RAX, LocalCycleCount + ( MemCycles << 1 ) + ( ExeCycles << 1 ) );
				e->AddReg64ImmX ( RAX, LocalCycleCount + ( MemCycles << 1 ) );
				
				
		e->CmpRegMem64 ( RAX, (int64_t*) & Playstation2::System::_SYSTEM->NextEvent_Cycle );
	
		// branch if current cycle is greater (or equal?) than next event cycle
		// changing this so that it branches if not returning
		// note: should probably be below or equal then jump, since the interpreter adds one to cycle
		//e->Jmp8_B ( 0, 0 );
		e->Jmp8_AE ( 0, 10 );
				
				
				
				e->SubRegReg64 ( RAX, RCX );
	
				e->MovMemReg64 ( (int64_t*) & r->CycleCount, RAX );

			e->MovMemImm32 ( (int32_t*) & r->NextPC, TargetAddress );
			
				// step 4a: if all checks out, then jump to start of next code
				e->JmpMem64 ( (int64_t*) & pCodeStart [ ( TargetAddress >> 2 ) & ulIndex_Mask ] );
				
				// step 4b: if doesn't check out, then return
				if ( ( TargetAddress & 0x1fc00000 ) != 0x1fc00000 )
				{
				e->SetJmpTarget8 ( 6 );
				}
				e->SetJmpTarget8 ( 7 );
				if ( bIsBlockInICache )
				{
				e->SetJmpTarget8 ( 9 );
				}
				e->SetJmpTarget8 ( 10 );
				
			}
		
			//cout << "\nhps2x64: R5900: recompiler: Address=" << hex << Address << " Target=" << TargetAddress;
			// return //
			// did not meet all criteria for open-auto-branch
	
			e->MovMemImm32 ( (int32_t*) & r->NextPC, TargetAddress );
			//e->AddMem64ImmX ( (int64_t*) & r->CycleCount, LocalCycleCount + ( MemCycles ) + ( ExeCycles ) );
			e->AddMem64ImmX ( (int64_t*) & r->CycleCount, LocalCycleCount + MemCycles );
			e->Ret();
		}
		else
		{
#endif
		
		// update CPU CycleCount
		// returning, so do -MemCycles, but NOT -ExeCycles since this instruction hasn't been counted, but +ExeCycles due to needing to count branch delay slot
		e->AddMem64ImmX ( (int64_t*) & r->CycleCount, LocalCycleCount + MemCycles );
		//e->AddMem64ImmX ( (int64_t*) & r->CycleCount, LocalCycleCount + ( MemCycles << 1 ) + ( ExeCycles << 1 ) - MemCycles - ExeCycles );
		
#ifdef VERBOSE_NORMAL_BRANCH
cout << "\nTargetAddress=" << hex << TargetAddress;
#endif
		
		if ( TargetAddress )
		{
			// update NextPC
			e->MovMemImm32 ( (int32_t*) & r->NextPC, TargetAddress );
			
#ifdef ENABLE_R5900_BRANCH_PREDICTION
			// if target address is odd, then need to reload pipeline after branch
			if ( ( TargetAddress & 4 ) /*|| ( TargetAddress & 0x60000000 )*/ )
			{
				e->AddMem64ImmX ( (int64_t*) & r->CycleCount, r->c_ullLatency_BranchMisPredict );
			}
#endif
		}
		else
		{
			if ( i.Opcode == OPJR )
			{
				//e->MovRegMem32 ( RAX, & r->GPR [ i.Rs ].s );
				e->MovMemReg32 ( (int32_t*) & r->NextPC, RDX );
				
#ifdef ENABLE_R5900_BRANCH_PREDICTION
				// jr,jalr instructions are excluded from branch prediction??
				e->AddMem64ImmX ( (int64_t*) & r->CycleCount, r->c_ullLatency_BranchMisPredict );
#endif
			}
			else
			{
				// ???
				//cout << "\nR5900: Recompiler: Potential problem setting NextPC for branch after delay slot.";
				//cout << "Address=" << hex << Address << " TargetAddress=" << hex << TargetAddress;
				
				// update NextPC
				e->MovMemImm32 ( (int32_t*) & r->NextPC, TargetAddress );
			}
		}
		
		// done - return
		ret = e->Ret ();
		
#ifdef ENABLE_AUTO_BRANCH
		}
#endif
		
//#endif

#ifdef CHECK_EVENT_AFTER_START_BRANCH
	if (RunCount)
	{
		//if ( !e->SetJmpTarget8 ( 3 ) )
		if (!e->SetJmpTarget(3))
		{
			cout << "\nR5900: Recompiler: Short branch3 too far.";
		}

		// update NextPC
		e->MovMemImm32((int32_t*)&r->NextPC, Address);

		// update CPU CycleCount
		// hasn't executed the instruction at all, so do -MemCycles, -ExeCycles
		//e->MovMemReg64 ( (int64_t*) & r->CycleCount, RAX );
		e->AddMem64ImmX((int64_t*)&r->CycleCount, LocalCycleCount - MemCycles);
		//e->AddMem64ImmX ( (int64_t*) & r->CycleCount, LocalCycleCount - MemCycles - ExeCycles );

		// done for now - return
		e->Ret();
	}
#endif

	
	if ( i.Opcode == OPJR )
	{
		if ( !e->SetJmpTarget8 ( 4 ) )
		{
			//cout << "\nR5900: Recompiler: Short branch4 too far.";
		}
		
		// update CycleCount, set PC, then jump to synchronous interrupt
		// executed the instruction but had a trap, so add in the instruction +MemCycles, +ExeCycles, possibly +TrapCycles?
		//e->MovMemReg64 ( (int64_t*) & r->CycleCount, RAX );
		e->AddMem64ImmX ( (int64_t*) & r->CycleCount, LocalCycleCount );
		//e->AddMem64ImmX ( (int64_t*) & r->CycleCount, LocalCycleCount - MemCycles - ExeCycles );
		
		// set pc
		e->MovMemImm32 ( (int32_t*) & r->PC, Address );
		
		//r->ProcessSynchronousInterrupt ( Cpu::EXC_ADEL );
		e->JMP ( (void*) Cpu::ProcessSynchronousInterrupt_t<Cpu::EXC_ADEL> );
	}
	
		
		// the cache-line is not loaded //
		
		// also jump here from above if needed
		if ( !e->SetJmpTarget8 ( 1 ) )
		{
			cout << "\nR5900: Recompiler: Short branch1 too far.";
		}
		
		
		// put branch into delay slot
		
		// first put in the target address
		switch ( i.Opcode )
		{
			case OPJR:
			//case OPJALR:
				//e->MovMemReg32 ( (int32_t*) & r->DelaySlots [ 1 ].Data, RDX );
				e->MovMemReg32((int32_t*)&r->DelaySlot0.Data, RDX);
				break;
				
			default:
				//e->MovMemImm32 ( (int32_t*) & r->DelaySlots [ 1 ].Data, TargetAddress );
				e->MovMemImm32((int32_t*)&r->DelaySlot0.Data, TargetAddress);
				break;
		}
		
		// put in the instruction
		//e->MovMemImm32 ( (int32_t*) & r->DelaySlots [ 1 ].Instruction.Value, i.Value );
		e->MovMemImm32((int32_t*)&r->DelaySlot0.Instruction.Value, i.Value);

		e->MovReg64ImmX ( RAX, (u64) BranchFunctionToCall );
		//e->MovMemReg64 ( (int64_t*) & r->DelaySlots [ 1 ].cb, RAX );
		e->MovMemReg64((int64_t*)&r->DelaySlot0.cb, RAX);

		//e->MovMemImm32 ( (int32_t*) & r->NextDelaySlotIndex, 0 );
		e->OrMem64ImmX ( (int64_t*) &r->Status.Value, 2 << 8 );
		
		// important? - must update LastPC? PC? when releasing to a branch delay slot?
		e->MovMemImm32 ( (int32_t*) & r->PC, Address );

		// update NextPC,CycleCount
#ifdef UPDATE_BEFORE_RETURN
		// update NextPC
		// it should have already returned if NextPC was modified through other means so this should be ok
		// NextPC is Address+4 here because the current instruction was already executed
		e->MovMemImm32 ( (int32_t*) & r->NextPC, Address + 4 );
				
		// update CycleCount
		// ***todo*** should be the cycles plus one instruction since branch into delay slot has already been executed
		// here it is returning but has executed the branch, so -MemCycles, but NOT -ExeCycles since it has not been counted yet
		e->AddMem64ImmX ( (int64_t*) & r->CycleCount, LocalCycleCount );
#endif
				
		// done - return
		ret = e->Ret ();

	}
	else
#endif
	{
		// not directly branching to target address right now //
#ifdef VERBOSE_NORMAL_BRANCH
cout << "\nIntoDelaySlot";
#endif
		
		// put branch into delay slot
		//e->MovMemImm32 ( & r->DelaySlots [ 1 ].Data, TargetAddress );
		//e->MovMemImm32 ( & r->DelaySlots [ 1 ].Instruction.Value, i.Value );

		// first put in the target address
		switch ( i.Opcode )
		{
			case OPJR:
			//case OPJALR:
				//e->MovMemReg32 ( (int32_t*) & r->DelaySlots [ 1 ].Data, RDX );
				e->MovMemReg32((int32_t*)&r->DelaySlot0.Data, RDX);
				break;
				
			default:
				//e->MovMemImm32 ( (int32_t*) & r->DelaySlots [ 1 ].Data, TargetAddress );
				e->MovMemImm32((int32_t*)&r->DelaySlot0.Data, TargetAddress);
				break;
		}
		
		// put in the instruction
		//e->MovMemImm32 ( (int32_t*) & r->DelaySlots [ 1 ].Instruction.Value, i.Value );
		e->MovMemImm32((int32_t*)&r->DelaySlot0.Instruction.Value, i.Value);

		
		e->MovReg64ImmX ( RAX, (u64) BranchFunctionToCall );
		//e->MovMemReg64 ( (int64_t*) & r->DelaySlots [ 1 ].cb, RAX );
		e->MovMemReg64((int64_t*)&r->DelaySlot0.cb, RAX);

		e->MovMemImm32 ( (int32_t*) & r->NextDelaySlotIndex, 0 );
		e->OrMem64ImmX ( (int64_t*) &r->Status.Value, 2 << 8 );
		
		// important? - must update LastPC? PC? when releasing to a branch delay slot?
		e->MovMemImm32 ( (int32_t*) & r->PC, Address );

		// update NextPC,CycleCount
#ifdef UPDATE_BEFORE_RETURN
		// update NextPC
		// it should have already returned if NextPC was modified through other means so this should be ok
		// NextPC is Address+4 here because the current instruction was already executed
		e->MovMemImm32 ( (int32_t*) & r->NextPC, Address + 4 );
				
		// update CycleCount
		// ***todo*** should be the cycles plus one instruction since branch into delay slot has already been executed
		// returning so -MemCycles, but NOT -ExeCycles because did not count the branch instruction yet even though it was executed
		e->AddMem64ImmX ( (int64_t*) & r->CycleCount, LocalCycleCount );
#endif
				
		// done - return
		ret = e->Ret ();
	}
	
	// if inside current block, then check if cache line is loaded
	// if cache line is loaded, then jump to it, otherwise put branch in delay slot and return
	
	// not branching //
	/*
	if ( !e->SetJmpTarget8 ( 0 ) )
	{
		cout << "\nR5900: Recompiler: Short branch0 too far.";
	}
	*/
	
	if ( !e->SetJmpTarget ( 0 ) )
	{
		cout << "\nR5900: Recompiler: Short branch0 too far.";
	}

	// check for likely branch
	if ( i.Opcode >= 0x14 || ( i.Opcode == 1 && ( i.Rt & 0x7 ) >= 2 ) )
	{
		// likely branch //
		
		// update NextPC,CycleCount
#ifdef UPDATE_BEFORE_RETURN
		// update NextPC
		// it should have already returned if NextPC was modified through other means so this should be ok
		// NextPC is Address+4 here because the current instruction was already executed
		//e->MovMemImm32 ( (int32_t*) & r->NextPC, Address + 4 );
		e->MovMemImm32 ( (int32_t*) & r->NextPC, Address + 8 );

		// update CycleCount
		// ***todo*** should be the cycles plus one instruction since branch into delay slot has already been executed
		// this is for a branch likely, so need to count the branch and also the skipped delay slot, but not the ExeCycles for the delay slot
		e->AddMem64ImmX ( (int64_t*) & r->CycleCount, LocalCycleCount );
		//e->AddMem64ImmX ( (int64_t*) & r->CycleCount, LocalCycleCount + ( MemCycles << 1 ) + ( ExeCycles ) - MemCycles );
#endif

		// done - return
		ret = e->Ret ();
	}


#ifdef VERBOSE_NORMAL_BRANCH
cout << "\nEND";
#endif

	// done
	return ret;
}


int32_t R5900::Recompiler::Generate_Normal_Trap ( R5900::Instruction::Format i, u32 Address )
{
	// step 1: check for trap condition //
	
	//e->MovMemImm32((int32_t*)&r->PC, Address);
	e->MovReg32ImmX(RCX, Address);

	// update CycleCount
	// ***todo*** should be the cycles plus one instruction since branch into delay slot has already been executed
#ifdef ENABLE_R5900_BRANCH_PREDICTION_TRAP
	//e->AddMem64ImmX((int64_t*)&r->CycleCount, LocalCycleCount + r->c_ullLatency_BranchMisPredict);
	e->MovReg32ImmX(RDX, LocalCycleCount + r->c_ullLatency_BranchMisPredict);
#else
	//e->AddMem64ImmX((int64_t*)&r->CycleCount, LocalCycleCount);
	e->MovReg32ImmX(RDX, LocalCycleCount);
#endif

	switch ( i.Opcode )
	{
		case OPSPECIAL:
		
			switch ( i.Funct )
			{
				case SPTGE:
					e->MovRegMem64 ( RAX, & r->GPR [ i.Rs ].s );
					e->CmpRegMem64 ( RAX, & r->GPR [ i.Rt ].s );
					//e->Jmp8_L ( 0, 0 );
					e->JMP_GE((void*)Cpu::ProcessSynchronousInterrupt2_t<Cpu::EXC_TRAP>);
					break;
					
				case SPTGEU:
					e->MovRegMem64 ( RAX, & r->GPR [ i.Rs ].s );
					e->CmpRegMem64 ( RAX, & r->GPR [ i.Rt ].s );
					//e->Jmp8_B ( 0, 0 );
					e->JMP_AE((void*)Cpu::ProcessSynchronousInterrupt2_t<Cpu::EXC_TRAP>);
					break;
					
				case SPTLT:
					e->MovRegMem64 ( RAX, & r->GPR [ i.Rs ].s );
					e->CmpRegMem64 ( RAX, & r->GPR [ i.Rt ].s );
					//e->Jmp8_GE ( 0, 0 );
					e->JMP_L((void*)Cpu::ProcessSynchronousInterrupt2_t<Cpu::EXC_TRAP>);
					break;
					
				case SPTLTU:
					e->MovRegMem64 ( RAX, & r->GPR [ i.Rs ].s );
					e->CmpRegMem64 ( RAX, & r->GPR [ i.Rt ].s );
					//e->Jmp8_AE ( 0, 0 );
					e->JMP_B((void*)Cpu::ProcessSynchronousInterrupt2_t<Cpu::EXC_TRAP>);
					break;
					
				case SPTEQ:
					e->MovRegMem64 ( RAX, & r->GPR [ i.Rs ].s );
					e->CmpRegMem64 ( RAX, & r->GPR [ i.Rt ].s );
					//e->Jmp8_NE ( 0, 0 );
					e->JMP_E((void*)Cpu::ProcessSynchronousInterrupt2_t<Cpu::EXC_TRAP>);
					break;
					
				case SPTNE:
					e->MovRegMem64 ( RAX, & r->GPR [ i.Rs ].s );
					e->CmpRegMem64 ( RAX, & r->GPR [ i.Rt ].s );
					//e->Jmp8_E ( 0, 0 );
					e->JMP_NE((void*)Cpu::ProcessSynchronousInterrupt2_t<Cpu::EXC_TRAP>);
					break;
			}
			
			break;
			
		case OPREGIMM:
			
			switch ( i.Rt )
			{
				case RTTGEI:
					e->CmpMem64ImmX ( & r->GPR [ i.Rs ].s, i.sImmediate );
					//e->Jmp8_L ( 0, 0 );
					e->JMP_GE((void*)Cpu::ProcessSynchronousInterrupt2_t<Cpu::EXC_TRAP>);
					break;
					
				case RTTGEIU:
					e->CmpMem64ImmX ( & r->GPR [ i.Rs ].s, i.sImmediate );
					//e->Jmp8_B ( 0, 0 );
					e->JMP_AE((void*)Cpu::ProcessSynchronousInterrupt2_t<Cpu::EXC_TRAP>);
					break;
					
				case RTTLTI:
					e->CmpMem64ImmX ( & r->GPR [ i.Rs ].s, i.sImmediate );
					//e->Jmp8_GE ( 0, 0 );
					e->JMP_L((void*)Cpu::ProcessSynchronousInterrupt2_t<Cpu::EXC_TRAP>);
					break;
					
				case RTTLTIU:
					e->CmpMem64ImmX ( & r->GPR [ i.Rs ].s, i.sImmediate );
					//e->Jmp8_AE ( 0, 0 );
					e->JMP_B((void*)Cpu::ProcessSynchronousInterrupt2_t<Cpu::EXC_TRAP>);
					break;
					
				case RTTEQI:
					e->CmpMem64ImmX ( & r->GPR [ i.Rs ].s, i.sImmediate );
					//e->Jmp8_NE ( 0, 0 );
					e->JMP_E((void*)Cpu::ProcessSynchronousInterrupt2_t<Cpu::EXC_TRAP>);
					break;
					
				case RTTNEI:
					e->CmpMem64ImmX ( & r->GPR [ i.Rs ].s, i.sImmediate );
					//e->Jmp8_E ( 0, 0 );
					e->JMP_NE((void*)Cpu::ProcessSynchronousInterrupt2_t<Cpu::EXC_TRAP>);
					break;
			}
			
			break;
	}
	
	// step 2: trap //

	/*
#ifdef UPDATE_BEFORE_RETURN
	// update NextPC
	// it should have already returned if NextPC was modified through other means so this should be ok
	// NextPC is Address+4 here because the current instruction was already executed
	//e->MovMemImm32 ( (int32_t*) & r->NextPC, Address + 4 );
	e->MovMemImm32 ( (int32_t*) & r->PC, Address );

	// update CycleCount
	// ***todo*** should be the cycles plus one instruction since branch into delay slot has already been executed
#ifdef ENABLE_R5900_BRANCH_PREDICTION_TRAP
		e->AddMem64ImmX ( (int64_t*) & r->CycleCount, LocalCycleCount + r->c_ullLatency_BranchMisPredict );
#else
		e->AddMem64ImmX ( (int64_t*) & r->CycleCount, LocalCycleCount );
#endif

#endif

	e->JMP ( (void*) Cpu::ProcessSynchronousInterrupt_t<Cpu::EXC_TRAP> );
	
	// no trap taken
	e->SetJmpTarget8 ( 0 );
	*/
	
	return true;
}



// regular arithemetic //

// *** todo *** no need to save LastModifiedRegister unless instruction is KNOWN to be in a delay slot on run
int32_t R5900::Recompiler::ADDU ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "ADDU";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::ADDU;
	
	//r->GPR [ i.Rd ].u = r->GPR [ i.Rs ].s + r->GPR [ i.Rt ].u;
	//CHECK_DELAYSLOT ( i.Rd );
	
	int Rd, Rs, Rt;
	int Reg1, Reg2;
	s64 lConst;
	
	int ret = 1;
	
	// *testing*
	//bStopEncodingBefore = true;
	//bStopEncodingAfter = true;
	
	switch ( OpLevel )
	{
		case -1:
			// source registers are Rs and Rt
			ullSrcRegBitmap |= ( 1ull << i.Rs ) | ( 1ull << i.Rt );
			
			// destination register is Rd
			ullDstRegBitmap |= ( 1ull << i.Rd );
			break;
			
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
				e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

				// load arguments
				e->LoadImm32 ( RCX, i.Value );
				ret = e->Call ( c_vFunction ); //ADDU );
				
#ifdef RESERVE_STACK_FRAME_FOR_CALL
				ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			
			break;
			
		case 1:

			/*
			* Optimal path:
				; addr1, addr2: addresses of the two 32-bit signed inputs
				; addr_res:     address for the 64-bit signed result

				mov     eax, dword ptr [addr1]    ; load first 32-bit value
				add     eax, dword ptr [addr2]    ; add second 32-bit value

				cdqe                               ; sign-extend EAX ? RAX (32?64)

				mov     qword ptr [addr_res], rax ; store full 64-bit result
			*/

#ifdef USE_NEW_R5900_ASSEMBLER_ADDU

			if (i.Rd)
			{
				if ((!i.Rs) && (!i.Rt))
				{
					//e->MovMemImm64(&r->GPR[i.Rd].s, 0);
					x->emit("mov qword ptr @ptr, 0", &r->GPR[i.Rd].s);
				}
				else if ((!i.Rs) || (!i.Rt))
				{
					//e->MovsxdReg64Mem32(RAX, &r->GPR[i.Rs | i.Rt].sw0);
					//ret = e->MovMemReg64(&r->GPR[i.Rd].s, RAX);
					x->emit("movsxd rax, @ptr", &r->GPR[i.Rs | i.Rt].sw0);
					x->emit("mov @ptr, rax", &r->GPR[i.Rd].s);
				}
				else if (i.Rs == i.Rt)
				{
					//e->MovRegFromMem32(RAX, &r->GPR[i.Rs].sw0);
					//e->AddRegReg32(RAX, RAX);
					//e->Cdqe();
					//ret = e->MovMemReg64(&r->GPR[i.Rd].s, RAX);
					x->emit("mov eax, @ptr", &r->GPR[i.Rs].sw0);
					x->emit("add eax, eax");
					x->emit("cdqe");
					x->emit("mov @ptr, rax", &r->GPR[i.Rd].s);
				}
				/*
				else if ( i.Rd == i.Rs )
				{
					e->MovsxdReg64Mem32 ( RAX, &r->GPR [ i.Rt ].s );
					ret = e->AddMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
				}
				else if ( i.Rd == i.Rt )
				{
					e->MovsxdReg64Mem32 ( RAX, &r->GPR [ i.Rs ].s );
					ret = e->AddMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
				}
				*/
				else
				{
					//e->MovRegFromMem32(RAX, &r->GPR[i.Rs].sw0);
					//e->AddRegMem32(RAX, &r->GPR[i.Rt].sw0);
					//e->Cdqe();
					//ret = e->MovMemReg64(&r->GPR[i.Rd].s, RAX);
					x->emit("mov eax, @ptr", &r->GPR[i.Rs].sw0);
					x->emit("add eax, @ptr", &r->GPR[i.Rt].sw0);
					x->emit("cdqe");
					x->emit("mov @ptr, rax", &r->GPR[i.Rd].s);
				}

			}

#else
			if ( i.Rd )
			{
				if ( ( !i.Rs ) && ( !i.Rt ) )
				{
					e->MovMemImm64 ( &r->GPR [ i.Rd ].s, 0 );
				}
				else if ( ( !i.Rs ) || ( !i.Rt ) )
				{
					e->MovsxdReg64Mem32 ( RAX, &r->GPR [ i.Rs | i.Rt ].sw0 );
					ret = e->MovMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
				}
				else if ( i.Rs == i.Rt )
				{
					e->MovRegFromMem32 ( RAX, &r->GPR [ i.Rs ].sw0 );
					e->AddRegReg32 ( RAX, RAX );
					e->Cdqe ();
					ret = e->MovMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
				}
				/*
				else if ( i.Rd == i.Rs )
				{
					e->MovsxdReg64Mem32 ( RAX, &r->GPR [ i.Rt ].s );
					ret = e->AddMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
				}
				else if ( i.Rd == i.Rt )
				{
					e->MovsxdReg64Mem32 ( RAX, &r->GPR [ i.Rs ].s );
					ret = e->AddMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
				}
				*/
				else
				{
					e->MovRegFromMem32 ( RAX, &r->GPR [ i.Rs ].sw0 );
					e->AddRegMem32 ( RAX, &r->GPR [ i.Rt ].sw0 );
					e->Cdqe ();
					ret = e->MovMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
				}
				
			}

#endif
			break;
			

		default:
			return -1;
			break;
	} // end switch ( OpLevel )
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //ADDU instruction.\n";
		return -1;
	}
	
	return 1;
}

int32_t R5900::Recompiler::SUBU ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "SUBU";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::SUBU;
	
	//r->GPR [ i.Rd ].u = r->GPR [ i.Rs ].s - r->GPR [ i.Rt ].u;
	//CHECK_DELAYSLOT ( i.Rd );
	
	int Rd, Rs, Rt;
	int Reg1, Reg2;
	s64 lConst;
	
	int ret = 1;
	
	// *testing*
	//bStopEncodingBefore = true;
	//bStopEncodingAfter = true;
	
	switch ( OpLevel )
	{
		case -1:
			// source registers are Rs and Rt
			ullSrcRegBitmap |= ( 1ull << i.Rs ) | ( 1ull << i.Rt );
			
			// destination register is Rd
			ullDstRegBitmap |= ( 1ull << i.Rd );
			break;
			
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
				e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

				// load arguments
				e->LoadImm32 ( RCX, i.Value );
				ret = e->Call ( c_vFunction ); //SUBU );
				
#ifdef RESERVE_STACK_FRAME_FOR_CALL
				ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
		case 1:

#ifdef USE_NEW_R5900_ASSEMBLER_SUBU

			if (i.Rd)
			{
				if (i.Rs == i.Rt)
				{
					//e->MovMemImm64(&r->GPR[i.Rd].s, 0);
					x->emit("mov qword ptr @ptr, 0", &r->GPR[i.Rd].s);
				}
				else if (!i.Rt)
				{
					//e->MovsxdReg64Mem32(RAX, &r->GPR[i.Rs].sw0);
					//ret = e->MovMemReg64(&r->GPR[i.Rd].s, RAX);
					x->emit("movsxd rax, @ptr", &r->GPR[i.Rs].sw0);
					x->emit("mov @ptr, rax", &r->GPR[i.Rd].s);
				}
				else if (!i.Rs)
				{
					//e->MovRegFromMem32(RAX, &r->GPR[i.Rt].sw0);
					//e->NegReg32(RAX);
					//e->Cdqe();
					//ret = e->MovMemReg64(&r->GPR[i.Rd].s, RAX);
					x->emit("mov eax, @ptr", &r->GPR[i.Rt].sw0);
					x->emit("neg eax");
					x->emit("cdqe");
					x->emit("mov @ptr, rax", &r->GPR[i.Rd].s);
				}
				/*
				else if ( i.Rd == i.Rs )
				{
					e->MovRegFromMem32 ( RAX, &r->GPR [ i.Rt ].s );
					ret = e->SubMemReg32 ( &r->GPR [ i.Rd ].s, RAX );
				}
				*/
				else
				{
					//e->MovRegFromMem32(RAX, &r->GPR[i.Rs].sw0);
					//e->SubRegMem32(RAX, &r->GPR[i.Rt].sw0);
					//e->Cdqe();
					//ret = e->MovMemReg64(&r->GPR[i.Rd].s, RAX);
					x->emit("mov eax, @ptr", &r->GPR[i.Rs].sw0);
					x->emit("sub eax, @ptr", &r->GPR[i.Rt].sw0);
					x->emit("cdqe");
					x->emit("mov @ptr, rax", &r->GPR[i.Rd].s);
				}
			}

#else
			if ( i.Rd )
			{
				if ( i.Rs == i.Rt )
				{
					e->MovMemImm64 ( &r->GPR [ i.Rd ].s, 0 );
				}
				else if ( !i.Rt )
				{
					//e->MovRegFromMem32 ( RAX, &r->GPR [ i.Rs ].s );
					e->MovsxdReg64Mem32 ( RAX, &r->GPR [ i.Rs ].sw0 );
					ret = e->MovMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
				}
				else if ( !i.Rs )
				{
					//e->MovsxdReg64Mem32 ( RAX, &r->GPR [ i.Rt ].sw0 );
					e->MovRegFromMem32 ( RAX, &r->GPR [ i.Rt ].sw0 );
					//e->NegReg64 ( RAX );
					e->NegReg32 ( RAX );
					e->Cdqe ();
					ret = e->MovMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
				}
				/*
				else if ( i.Rd == i.Rs )
				{
					e->MovRegFromMem32 ( RAX, &r->GPR [ i.Rt ].s );
					ret = e->SubMemReg32 ( &r->GPR [ i.Rd ].s, RAX );
				}
				*/
				else
				{
					e->MovRegFromMem32 ( RAX, &r->GPR [ i.Rs ].sw0 );
					e->SubRegMem32 ( RAX, &r->GPR [ i.Rt ].sw0 );
					e->Cdqe ();
					//ret = e->MovRegToMem32 ( &r->GPR [ i.Rd ].s, RAX );
					ret = e->MovMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
				}
				
			}
#endif

			break;
			

		default:
			return -1;
			break;
	} // end switch ( OpLevel )
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //ADDU instruction.\n";
		return -1;
	}
	
	return 1;
}

int32_t R5900::Recompiler::AND ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "AND";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::AND;
	
	int Rd, Rs, Rt;
	int Reg1, Reg2;
	s64 lConst;
	
	int ret = 1;
	
	// *testing*
	//bStopEncodingBefore = true;
	//bStopEncodingAfter = true;
	
	switch ( OpLevel )
	{
		case -1:
			// source registers are Rs and Rt
			ullSrcRegBitmap |= ( 1ull << i.Rs ) | ( 1ull << i.Rt );
			
			// destination register is Rd
			ullDstRegBitmap |= ( 1ull << i.Rd );
			break;
			
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
				e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

				// load arguments
				e->LoadImm32 ( RCX, i.Value );
				ret = e->Call ( c_vFunction ); //AND );
				
#ifdef RESERVE_STACK_FRAME_FOR_CALL
				ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
		case 1:

#ifdef USE_NEW_R5900_ASSEMBLER_AND

			if (i.Rd)
			{
				if ((!i.Rs) || (!i.Rt))
				{
					//ret = e->MovMemImm64(&r->GPR[i.Rd].s, 0);
					x->emit("mov qword ptr @ptr, 0", &r->GPR[i.Rd].s);
				}
				else if (i.Rs == i.Rt)
				{
					if (i.Rs != i.Rd)
					{
						//e->MovRegMem64(RAX, &r->GPR[i.Rs].s);
						//ret = e->MovMemReg64(&r->GPR[i.Rd].s, RAX);
						x->emit("mov rax, @ptr", &r->GPR[i.Rs].s);
						x->emit("mov @ptr, rax", &r->GPR[i.Rd].s);
					}
				}
				else if (i.Rd == i.Rs)
				{
					if (i.Rt != i.Rd)
					{
						//e->MovRegMem64(RAX, &r->GPR[i.Rt].s);
						//ret = e->AndMemReg64(&r->GPR[i.Rd].s, RAX);
						x->emit("mov rax, @ptr", &r->GPR[i.Rt].s);
						x->emit("and @ptr, rax", &r->GPR[i.Rd].s);
					}
				}
				else if (i.Rd == i.Rt)
				{
					if (i.Rs != i.Rd)
					{
						//e->MovRegMem64(RAX, &r->GPR[i.Rs].s);
						//ret = e->AndMemReg64(&r->GPR[i.Rd].s, RAX);
						x->emit("mov rax, @ptr", &r->GPR[i.Rs].s);
						x->emit("and @ptr, rax", &r->GPR[i.Rd].s);
					}
				}
				else
				{
					//e->MovRegMem64(RAX, &r->GPR[i.Rs].s);
					//e->AndRegMem64(RAX, &r->GPR[i.Rt].s);
					//ret = e->MovMemReg64(&r->GPR[i.Rd].s, RAX);
					x->emit("mov rax, @ptr", &r->GPR[i.Rs].s);
					x->emit("and rax, @ptr", &r->GPR[i.Rt].s);
					x->emit("mov @ptr, rax", &r->GPR[i.Rd].s);
				}

			}

#else
			if ( i.Rd )
			{
				if ( ( !i.Rs ) || ( !i.Rt ) )
				{
					//ret = e->MovMemImm32 ( &r->GPR [ i.Rd ].s, 0 );
					ret = e->MovMemImm64 ( &r->GPR [ i.Rd ].s, 0 );
				}
				else if ( i.Rs == i.Rt )
				{
					if ( i.Rs != i.Rd )
					{
						e->MovRegMem64 ( RAX, &r->GPR [ i.Rs ].s );
						ret = e->MovMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
					}
				}
				else if ( i.Rd == i.Rs )
				{
					if ( i.Rt != i.Rd )
					{
						//e->MovRegFromMem32 ( RAX, &r->GPR [ i.Rt ].s );
						e->MovRegMem64 ( RAX, &r->GPR [ i.Rt ].s );
						//ret = e->AndMemReg32 ( &r->GPR [ i.Rd ].s, RAX );
						ret = e->AndMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
					}
				}
				else if ( i.Rd == i.Rt )
				{
					if ( i.Rs != i.Rd )
					{
						//e->MovRegFromMem32 ( RAX, &r->GPR [ i.Rs ].s );
						e->MovRegMem64 ( RAX, &r->GPR [ i.Rs ].s );
						//ret = e->AndMemReg32 ( &r->GPR [ i.Rd ].s, RAX );
						ret = e->AndMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
					}
				}
				else
				{
					//e->MovRegFromMem32 ( RAX, &r->GPR [ i.Rs ].s );
					e->MovRegMem64 ( RAX, &r->GPR [ i.Rs ].s );
					//e->AndRegMem32 ( RAX, &r->GPR [ i.Rt ].s );
					e->AndRegMem64 ( RAX, &r->GPR [ i.Rt ].s );
					//ret = e->MovRegToMem32 ( &r->GPR [ i.Rd ].s, RAX );
					ret = e->MovMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
				}
				
			}
#endif
			break;
			

		default:
			return -1;
			break;
	} // end switch ( OpLevel )
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //ADDU instruction.\n";
		return -1;
	}
	
	return 1;
}

int32_t R5900::Recompiler::OR ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "OR";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::OR;
	
	int Rd, Rs, Rt;
	int Reg1, Reg2;
	s64 lConst;
	
	int ret = 1;
	
	// *testing*
	//bStopEncodingBefore = true;
	//bStopEncodingAfter = true;
	
	switch ( OpLevel )
	{
		case -1:
			// source registers are Rs and Rt
			ullSrcRegBitmap |= ( 1ull << i.Rs ) | ( 1ull << i.Rt );
			
			// destination register is Rd
			ullDstRegBitmap |= ( 1ull << i.Rd );
			break;
			
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
				e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

				// load arguments
				e->LoadImm32 ( RCX, i.Value );
				ret = e->Call ( c_vFunction ); //OR );
				
#ifdef RESERVE_STACK_FRAME_FOR_CALL
				ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
		case 1:
#ifdef USE_NEW_R5900_ASSEMBLER_OR

			if (i.Rd)
			{
				if ((!i.Rs) && (!i.Rt))
				{
					//e->MovMemImm64(&r->GPR[i.Rd].s, 0);
					x->emit("mov qword ptr @ptr, 0", &r->GPR[i.Rd].s);
				}
				else if ((!i.Rs) || (!i.Rt) || (i.Rs == i.Rt))
				{
					if (i.Rd != (i.Rs | i.Rt))
					{
						//e->MovRegMem64(RAX, &r->GPR[i.Rs | i.Rt].s);
						//ret = e->MovMemReg64(&r->GPR[i.Rd].s, RAX);
						x->emit("mov rax, @ptr", &r->GPR[i.Rs | i.Rt].s);
						x->emit("mov @ptr, rax", &r->GPR[i.Rd].s);
					}
				}
				else if (i.Rd == i.Rs)
				{
					if (i.Rd != i.Rt)
					{
						//e->MovRegMem64(RAX, &r->GPR[i.Rt].s);
						//ret = e->OrMemReg64(&r->GPR[i.Rd].s, RAX);
						x->emit("mov rax, @ptr", &r->GPR[i.Rt].s);
						x->emit("or @ptr, rax", &r->GPR[i.Rd].s);
					}
				}
				else if (i.Rd == i.Rt)
				{
					if (i.Rd != i.Rs)
					{
						//e->MovRegMem64(RAX, &r->GPR[i.Rs].s);
						//ret = e->OrMemReg64(&r->GPR[i.Rd].s, RAX);
						x->emit("mov rax, @ptr", &r->GPR[i.Rs].s);
						x->emit("or @ptr, rax", &r->GPR[i.Rd].s);
					}
				}
				else
				{
					//e->MovRegMem64(RAX, &r->GPR[i.Rs].s);
					//e->OrRegMem64(RAX, &r->GPR[i.Rt].s);
					//ret = e->MovMemReg64(&r->GPR[i.Rd].s, RAX);
					x->emit("mov rax, @ptr", &r->GPR[i.Rs].s);
					x->emit("or rax, @ptr", &r->GPR[i.Rt].s);
					x->emit("mov @ptr, rax", &r->GPR[i.Rd].s);
				}

			}

#else
			if ( i.Rd )
			{
				if ( ( !i.Rs ) && ( !i.Rt ) )
				{
					e->MovMemImm64 ( &r->GPR [ i.Rd ].s, 0 );
				}
				else if ( ( !i.Rs ) || ( !i.Rt ) || ( i.Rs == i.Rt ) )
				{
					if ( i.Rd != ( i.Rs | i.Rt ) )
					{
						//e->MovRegFromMem32 ( RAX, &r->GPR [ i.Rt ].s );
						e->MovRegMem64 ( RAX, &r->GPR [ i.Rs | i.Rt ].s );
						//ret = e->MovRegToMem32 ( &r->GPR [ i.Rd ].s, RAX );
						ret = e->MovMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
					}
				}
				else if ( i.Rd == i.Rs )
				{
					if ( i.Rd != i.Rt )
					{
						//e->MovRegFromMem32 ( RAX, &r->GPR [ i.Rt ].s );
						e->MovRegMem64 ( RAX, &r->GPR [ i.Rt ].s );
						//ret = e->OrMemReg32 ( &r->GPR [ i.Rd ].s, RAX );
						ret = e->OrMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
					}
				}
				else if ( i.Rd == i.Rt )
				{
					if ( i.Rd != i.Rs )
					{
						//e->MovRegFromMem32 ( RAX, &r->GPR [ i.Rs ].s );
						e->MovRegMem64 ( RAX, &r->GPR [ i.Rs ].s );
						//ret = e->OrMemReg32 ( &r->GPR [ i.Rd ].s, RAX );
						ret = e->OrMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
					}
				}
				else
				{
					//e->MovRegFromMem32 ( RAX, &r->GPR [ i.Rs ].s );
					e->MovRegMem64 ( RAX, &r->GPR [ i.Rs ].s );
					//e->OrRegMem32 ( RAX, &r->GPR [ i.Rt ].s );
					e->OrRegMem64 ( RAX, &r->GPR [ i.Rt ].s );
					//ret = e->MovRegToMem32 ( &r->GPR [ i.Rd ].s, RAX );
					ret = e->MovMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
				}
				
			}
#endif
			break;
			

		default:
			return -1;
			break;
	} // end switch ( OpLevel )
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //ADDU instruction.\n";
		return -1;
	}
	
	return 1;
}

int32_t R5900::Recompiler::XOR ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "XOR";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::XOR;
	
	int Rd, Rs, Rt;
	int Reg1, Reg2;
	s64 lConst;
	
	int ret = 1;
	
	// *testing*
	//bStopEncodingBefore = true;
	//bStopEncodingAfter = true;
	
	switch ( OpLevel )
	{
		case -1:
			// source registers are Rs and Rt
			ullSrcRegBitmap |= ( 1ull << i.Rs ) | ( 1ull << i.Rt );
			
			// destination register is Rd
			ullDstRegBitmap |= ( 1ull << i.Rd );
			break;
			
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
				e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

				// load arguments
				e->LoadImm32 ( RCX, i.Value );
				ret = e->Call ( c_vFunction ); //XOR );
				
#ifdef RESERVE_STACK_FRAME_FOR_CALL
				ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
		case 1:
#ifdef USE_NEW_R5900_ASSEMBLER_XOR

			if (i.Rd)
			{
				if (i.Rs == i.Rt)
				{
					//e->MovMemImm64(&r->GPR[i.Rd].s, 0);
					x->emit("mov qword ptr @ptr, 0", &r->GPR[i.Rd].s);
				}
				else if (!i.Rs)
				{
					//e->MovRegMem64(RAX, &r->GPR[i.Rt].s);
					//ret = e->MovMemReg64(&r->GPR[i.Rd].s, RAX);
					x->emit("mov rax, @ptr", &r->GPR[i.Rt].s);
					x->emit("mov @ptr, rax", &r->GPR[i.Rd].s);
				}
				else if (!i.Rt)
				{
					//e->MovRegMem64(RAX, &r->GPR[i.Rs].s);
					//ret = e->MovMemReg64(&r->GPR[i.Rd].s, RAX);
					x->emit("mov rax, @ptr", &r->GPR[i.Rs].s);
					x->emit("mov @ptr, rax", &r->GPR[i.Rd].s);
				}
				else if (i.Rd == i.Rs)
				{
					//e->MovRegMem64(RAX, &r->GPR[i.Rt].s);
					//ret = e->XorMemReg64(&r->GPR[i.Rd].s, RAX);
					x->emit("mov rax, @ptr", &r->GPR[i.Rt].s);
					x->emit("xor @ptr, rax", &r->GPR[i.Rd].s);
				}
				else if (i.Rd == i.Rt)
				{
					//e->MovRegMem64(RAX, &r->GPR[i.Rs].s);
					//ret = e->XorMemReg64(&r->GPR[i.Rd].s, RAX);
					x->emit("mov rax, @ptr", &r->GPR[i.Rs].s);
					x->emit("xor @ptr, rax", &r->GPR[i.Rd].s);
				}
				else
				{
					//e->MovRegMem64(RAX, &r->GPR[i.Rs].s);
					//e->XorRegMem64(RAX, &r->GPR[i.Rt].s);
					//ret = e->MovMemReg64(&r->GPR[i.Rd].s, RAX);
					x->emit("mov rax, @ptr", &r->GPR[i.Rs].s);
					x->emit("xor rax, @ptr", &r->GPR[i.Rt].s);
					x->emit("mov @ptr, rax", &r->GPR[i.Rd].s);
				}

			}

#else
			if ( i.Rd )
			{
				if ( i.Rs == i.Rt )
				{
					e->MovMemImm64 ( &r->GPR [ i.Rd ].s, 0 );
				}
				else if ( !i.Rs )
				{
					//e->MovRegFromMem32 ( RAX, &r->GPR [ i.Rt ].s );
					e->MovRegMem64 ( RAX, &r->GPR [ i.Rt ].s );
					//ret = e->MovRegToMem32 ( &r->GPR [ i.Rd ].s, RAX );
					ret = e->MovMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
				}
				else if ( !i.Rt )
				{
					//e->MovRegFromMem32 ( RAX, &r->GPR [ i.Rs ].s );
					e->MovRegMem64 ( RAX, &r->GPR [ i.Rs ].s );
					//ret = e->MovRegToMem32 ( &r->GPR [ i.Rd ].s, RAX );
					ret = e->MovMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
				}
				else if ( i.Rd == i.Rs )
				{
					//e->MovRegFromMem32 ( RAX, &r->GPR [ i.Rt ].s );
					e->MovRegMem64 ( RAX, &r->GPR [ i.Rt ].s );
					//ret = e->XorMemReg32 ( &r->GPR [ i.Rd ].s, RAX );
					ret = e->XorMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
				}
				else if ( i.Rd == i.Rt )
				{
					//e->MovRegFromMem32 ( RAX, &r->GPR [ i.Rs ].s );
					e->MovRegMem64 ( RAX, &r->GPR [ i.Rs ].s );
					//ret = e->XorMemReg32 ( &r->GPR [ i.Rd ].s, RAX );
					ret = e->XorMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
				}
				else
				{
					//e->MovRegFromMem32 ( RAX, &r->GPR [ i.Rs ].s );
					e->MovRegMem64 ( RAX, &r->GPR [ i.Rs ].s );
					//e->XorRegMem32 ( RAX, &r->GPR [ i.Rt ].s );
					e->XorRegMem64 ( RAX, &r->GPR [ i.Rt ].s );
					//ret = e->MovRegToMem32 ( &r->GPR [ i.Rd ].s, RAX );
					ret = e->MovMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
				}
				
			}
#endif
			break;
			

		default:
			return -1;
			break;
	} // end switch ( OpLevel )
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //ADDU instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::NOR ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "NOR";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::NOR;
	
	int Rd, Rs, Rt;
	int Reg1, Reg2;
	s64 lConst;
	
	int ret = 1;
	
	// *testing*
	//bStopEncodingBefore = true;
	//bStopEncodingAfter = true;
	
	switch ( OpLevel )
	{
		case -1:
			// source registers are Rs and Rt
			ullSrcRegBitmap |= ( 1ull << i.Rs ) | ( 1ull << i.Rt );
			
			// destination register is Rd
			ullDstRegBitmap |= ( 1ull << i.Rd );
			break;
			
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
				e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

				// load arguments
				e->LoadImm32 ( RCX, i.Value );
				ret = e->Call ( c_vFunction ); //NOR );
				
#ifdef RESERVE_STACK_FRAME_FOR_CALL
				ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
		case 1:
#ifdef USE_NEW_R5900_ASSEMBLER_NOR

			if (i.Rd)
			{
				if ((!i.Rs) && (!i.Rt))
				{
					//e->MovMemImm64(&r->GPR[i.Rd].s, -1);
					x->emit("mov qword ptr @ptr, -1", &r->GPR[i.Rd].s);
				}
				else if ((!i.Rs) || (!i.Rt) || (i.Rs == i.Rt))
				{
					if (i.Rd != i.Rs)
					{
						//e->MovRegMem64(RAX, &r->GPR[i.Rs | i.Rt].s);
						//e->NotReg64(RAX);
						//ret = e->MovMemReg64(&r->GPR[i.Rd].s, RAX);
						x->emit("mov rax, @ptr", &r->GPR[i.Rs | i.Rt].s);
						x->emit("not rax");
						x->emit("mov @ptr, rax", &r->GPR[i.Rd].s);
					}
					else
					{
						//e->NotMem64(&r->GPR[i.Rd].s);
						x->emit("not qword ptr @ptr", &r->GPR[i.Rd].s);
					}
				}
				else
				{
					//e->MovRegMem64(RAX, &r->GPR[i.Rs].s);
					//e->OrRegMem64(RAX, &r->GPR[i.Rt].s);
					//e->NotReg64(RAX);
					//ret = e->MovMemReg64(&r->GPR[i.Rd].s, RAX);
					x->emit("mov rax, @ptr", &r->GPR[i.Rs].s);
					x->emit("or rax, @ptr", &r->GPR[i.Rt].s);
					x->emit("not rax");
					x->emit("mov @ptr, rax", &r->GPR[i.Rd].s);
				}

			}

#else
			if ( i.Rd )
			{
				if ( ( !i.Rs ) && ( !i.Rt ) )
				{
					e->MovMemImm64 ( &r->GPR [ i.Rd ].s, -1 );
				}
				else if ( ( !i.Rs ) || ( !i.Rt ) || ( i.Rs == i.Rt ) )
				{
					if ( i.Rd != i.Rs )
					{
						//e->MovRegFromMem32 ( RAX, &r->GPR [ i.Rt ].s );
						e->MovRegMem64 ( RAX, &r->GPR [ i.Rs | i.Rt ].s );
						//e->NotReg32 ( RAX );
						e->NotReg64 ( RAX );
						//ret = e->MovRegToMem32 ( &r->GPR [ i.Rd ].s, RAX );
						ret = e->MovMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
					}
					else
					{
						e->NotMem64 ( &r->GPR [ i.Rd ].s );
					}
				}
				else
				{
					//e->MovRegFromMem32 ( RAX, &r->GPR [ i.Rs ].s );
					e->MovRegMem64 ( RAX, &r->GPR [ i.Rs ].s );
					//e->OrRegMem32 ( RAX, &r->GPR [ i.Rt ].s );
					e->OrRegMem64 ( RAX, &r->GPR [ i.Rt ].s );
					//e->NotReg32 ( RAX );
					e->NotReg64 ( RAX );
					//ret = e->MovRegToMem32 ( &r->GPR [ i.Rd ].s, RAX );
					ret = e->MovMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
				}
				
			}
#endif
			break;
			

		default:
			return -1;
			break;
	} // end switch ( OpLevel )
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //ADDU instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::SLT ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "SLT";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::SLT;
	
	//r->GPR [ i.Rd ].s = r->GPR [ i.Rs ].s < r->GPR [ i.Rt ].s ? 1 : 0;
	//CHECK_DELAYSLOT ( i.Rd );
	
	int Rd, Rs, Rt;
	int Reg1, Reg2;
	s64 lConst;
	
	int ret = 1;
	
	// *testing*
	//bStopEncodingBefore = true;
	//bStopEncodingAfter = true;
	
	switch ( OpLevel )
	{
		case -1:
			// source registers are Rs and Rt
			ullSrcRegBitmap |= ( 1ull << i.Rs ) | ( 1ull << i.Rt );
			
			// destination register is Rd
			ullDstRegBitmap |= ( 1ull << i.Rd );
			break;
			
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
				e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

				// load arguments
				e->LoadImm32 ( RCX, i.Value );
				ret = e->Call ( c_vFunction ); //SLT );
				
#ifdef RESERVE_STACK_FRAME_FOR_CALL
				ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
		case 1:
#ifdef USE_NEW_R5900_ASSEMBLER_SLT

			if (i.Rd)
			{
				if (i.Rs == i.Rt)
				{
					//ret = e->MovMemImm64(&r->GPR[i.Rd].s, 0);
					x->emit("mov qword ptr @ptr, 0", &r->GPR[i.Rd].s);
				}
				else if (!i.Rt)
				{
					// ***todo*** implement ShrMemImm64
					if ( i.Rd == i.Rs )
					{
						//e->ShrMemImm64 ( &r->GPR [ i.Rs ].s, 63 );
						x->emit("shr qword ptr @ptr, 63", &r->GPR[i.Rd].s);
					}
					else
					{
						//e->MovRegMem64(RAX, &r->GPR[i.Rs].s);
						//e->ShrRegImm64(RAX, 63);
						//ret = e->MovMemReg64(&r->GPR[i.Rd].s, RAX);
						x->emit("mov rax, @ptr", &r->GPR[i.Rs].s);
						x->emit("shr rax, 63");
						x->emit("mov @ptr, rax", &r->GPR[i.Rd].s);
					}
				}
				else
				{
					/*
						xor eax, eax
						mov rdx, [a]
						cmp rdx, [b]
						setl al             ; CPU handles overflow correctly for signed comparison
					*/

					// this should zero-extend to 64 bits
					//e->XorRegReg32(RCX, RCX);
					//e->MovRegMem64(RAX, &r->GPR[i.Rs].s);
					//e->CmpRegMem64(RAX, &r->GPR[i.Rt].s);
					//e->Set_L(RCX);
					//ret = e->MovMemReg64(&r->GPR[i.Rd].s, RCX);
					x->emit("xor eax, eax");
					x->emit("mov rdx, @ptr", &r->GPR[i.Rs].s);
					x->emit("cmp rdx, @ptr", &r->GPR[i.Rt].s);
					x->emit("setl al");
					x->emit("mov @ptr, rax", &r->GPR[i.Rd].s);
				}

			}

#else
			if ( i.Rd )
			{
				if ( i.Rs == i.Rt )
				{
					ret = e->MovMemImm64 ( &r->GPR [ i.Rd ].s, 0 );
				}
				else if ( !i.Rt )
				{
					// ***todo*** implement ShrMemImm64
					//if ( i.Rd == i.Rs )
					//{
					//	e->ShrMemImm64 ( &r->GPR [ i.Rs ].s, 63 );
					//}
					//else
					{
						e->MovRegMem64 ( RAX, &r->GPR [ i.Rs ].s );
						//e->Cqo ();
						//e->NegReg32 ( RDX );
						e->ShrRegImm64 ( RAX, 63 );
						ret = e->MovMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
					}
				}
				else
				{
					// this should zero-extend to 64 bits
					e->XorRegReg32 ( RCX, RCX );
					e->MovRegMem64 ( RAX, &r->GPR [ i.Rs ].s );
					e->CmpRegMem64 ( RAX, &r->GPR [ i.Rt ].s );
					e->Set_L ( RCX );
					ret = e->MovMemReg64 ( &r->GPR [ i.Rd ].s, RCX );
				}
				
			}
#endif
			break;
			

		default:
			return -1;
			break;
	} // end switch ( OpLevel )
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //ADDU instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::SLTU ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "SLTU";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::SLTU;
	
	//r->GPR [ i.Rd ].u = r->GPR [ i.Rs ].s < r->GPR [ i.Rt ].s ? 1 : 0;
	//CHECK_DELAYSLOT ( i.Rd );
	
	int Rd, Rs, Rt;
	int Reg1, Reg2;
	s64 lConst;
	
	int ret = 1;
	
	// *testing*
	//bStopEncodingBefore = true;
	//bStopEncodingAfter = true;
	
	switch ( OpLevel )
	{
		case -1:
			// source registers are Rs and Rt
			ullSrcRegBitmap |= ( 1ull << i.Rs ) | ( 1ull << i.Rt );
			
			// destination register is Rd
			ullDstRegBitmap |= ( 1ull << i.Rd );
			break;
			
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
				e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

				// load arguments
				e->LoadImm32 ( RCX, i.Value );
				ret = e->Call ( c_vFunction ); //SLTU );
				
#ifdef RESERVE_STACK_FRAME_FOR_CALL
				ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
		case 1:
#ifdef USE_NEW_R5900_ASSEMBLER_SLTU

			if (i.Rd)
			{
				if ((!i.Rt) || (i.Rs == i.Rt))
				{
					//e->MovMemImm64(&r->GPR[i.Rd].s, 0);
					x->emit("mov qword ptr @ptr, 0", &r->GPR[i.Rd].s);
				}
				else
				{
					/*
						mov rax, [a]
						cmp rax, [b]
						sbb eax, eax        ; eax = -1 if carry set (a < b), else 0
						neg eax             ; eax = 1 if it was -1, else 0
					*/

					// this should zero-extend to 64 bits
					//e->XorRegReg32(RCX, RCX);
					//e->MovRegMem64(RAX, &r->GPR[i.Rs].s);
					//e->CmpRegMem64(RAX, &r->GPR[i.Rt].s);
					//e->AdcRegReg32(RCX, RCX);
					//ret = e->MovMemReg64(&r->GPR[i.Rd].s, RCX);
					x->emit("mov rax, @ptr", &r->GPR[i.Rs].s);
					x->emit("cmp rax, @ptr", &r->GPR[i.Rt].s);
					x->emit("sbb eax, eax");
					x->emit("neg eax");
					x->emit("mov @ptr, rax", &r->GPR[i.Rd].s);
				}

			}

#else
			if ( i.Rd )
			{
				if ( ( !i.Rt ) || ( i.Rs == i.Rt ) )
				{
					e->MovMemImm64 ( &r->GPR [ i.Rd ].s, 0 );
				}
				else
				{
					/*
					mov     eax, [val1]; load val1 into EAX
					cmp     eax, [val2]; compare EAX with val2 in memory
					setb    al; AL ? 1 if val1 < val2(unsigned), else 0
					movzx   eax, al; zero - extend AL into EAX cleanly
					mov		[result], eax; store 32 - bit result(0 or 1)
					*/

					// this should zero-extend to 64 bits
					e->XorRegReg32 ( RCX, RCX );
					e->MovRegMem64 ( RAX, &r->GPR [ i.Rs ].s );
					e->CmpRegMem64 ( RAX, &r->GPR [ i.Rt ].s );
					//e->Set_B ( RCX );
					e->AdcRegReg32 ( RCX, RCX );
					ret = e->MovMemReg64 ( &r->GPR [ i.Rd ].s, RCX );
				}
				
			}
#endif
			break;
			

		default:
			return -1;
			break;
	} // end switch ( OpLevel )
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //ADDU instruction.\n";
		return -1;
	}
	return 1;
}


////////////////////////////////////////////
// I-Type Instructions (non-interrupt)



int32_t R5900::Recompiler::ADDIU ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "ADDIU";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::ADDIU;
	
	//r->GPR [ i.Rt ].s = r->GPR [ i.Rs ].s + i.sImmediate;
	//CHECK_DELAYSLOT ( i.Rt );
	
	int Rd, Rs, Rt;
	int Reg1, Reg2;
	s64 lConst;
	
	int ret = 1;
	
	// *testing*
	//bStopEncodingBefore = true;
	//bStopEncodingAfter = true;
	
	switch ( OpLevel )
	{
		case -1:
			// source registers are Rs
			ullSrcRegBitmap |= ( 1ull << i.Rs );
			
			// destination register is Rt
			ullDstRegBitmap |= ( 1ull << i.Rt );
			break;
			
		case 0:
			if ( i.Rt )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
				e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

				// load arguments
				e->LoadImm32 ( RCX, i.Value );
				ret = e->Call ( c_vFunction ); //ADDIU );
				
#ifdef RESERVE_STACK_FRAME_FOR_CALL
				ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
		case 1:
#ifdef USE_NEW_R5900_ASSEMBLER_ADDIU

			if (i.Rt)
			{
				if (!i.Rs)
				{
					//ret = e->MovMemImm64(&r->GPR[i.Rt].s, i.sImmediate);
					x->emit("mov qword ptr @ptr, @imm", &r->GPR[i.Rt].s, (s32)i.sImmediate);
				}
				else if (!i.sImmediate)
				{
					//e->MovsxdReg64Mem32(RAX, &r->GPR[i.Rs].sw0);
					//ret = e->MovMemReg64(&r->GPR[i.Rt].s, RAX);
					x->emit("movsxd rax, @ptr", &r->GPR[i.Rs].sw0);
					x->emit("mov @ptr, rax", &r->GPR[i.Rt].s);
				}
				/*
				else if ( i.Rt == i.Rs )
				{
					e->AddMem64ImmX ( &r->GPR [ i.Rt ].s, i.sImmediate );
				}
				*/
				else
				{
					//e->MovRegFromMem32(RAX, &r->GPR[i.Rs].sw0);
					//e->AddReg32ImmX(RAX, i.sImmediate);
					//e->Cdqe();
					//ret = e->MovMemReg64(&r->GPR[i.Rt].s, RAX);
					x->emit("mov eax, @ptr", &r->GPR[i.Rs].sw0);

					if (i.sImmediate == 1)
					{
						x->emit("inc eax");
					}
					else if (i.sImmediate == -1)
					{
						x->emit("dec eax");
					}
					else
					{
						x->emit("add eax, @imm", (s32)i.sImmediate);
					}

					x->emit("cdqe");
					x->emit("mov @ptr, rax", &r->GPR[i.Rt].s);
				}

			}

#else
			if ( i.Rt )
			{
				if ( !i.Rs )
				{
					//e->MovMemImm32 ( &r->GPR [ i.Rt ].s, i.sImmediate );
					ret = e->MovMemImm64 ( &r->GPR [ i.Rt ].s, i.sImmediate );
				}
				else if ( !i.sImmediate )
				{
					e->MovsxdReg64Mem32 ( RAX, &r->GPR [ i.Rs ].sw0 );
					ret = e->MovMemReg64 ( &r->GPR [ i.Rt ].s, RAX );
				}
				/*
				else if ( i.Rt == i.Rs )
				{
					e->AddMem64ImmX ( &r->GPR [ i.Rt ].s, i.sImmediate );
				}
				*/
				else
				{
					e->MovRegFromMem32 ( RAX, &r->GPR [ i.Rs ].sw0 );
					//e->MovsxdReg64Mem32 ( RAX, &r->GPR [ i.Rs ].sw0 );
					e->AddReg32ImmX ( RAX, i.sImmediate );
					//e->AddReg64ImmX ( RAX, i.sImmediate );
					//ret = e->MovRegToMem32 ( &r->GPR [ i.Rt ].s, RAX );
					e->Cdqe ();
					ret = e->MovMemReg64 ( &r->GPR [ i.Rt ].s, RAX );
				}
				
			}
#endif
			break;
			

		default:
			return -1;
			break;
	} // end switch ( OpLevel )
	
	if ( !ret )
	{
		cout << "\nError encoding ADDIU instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::ANDI ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "ANDI";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::ANDI;
	
	//r->GPR [ i.Rt ].s = r->GPR [ i.Rs ].s & i.uImmediate;
	//CHECK_DELAYSLOT ( i.Rt );
	
	int Rd, Rs, Rt;
	int Reg1, Reg2;
	s64 lConst;
	
	int ret = 1;
	
	// *testing*
	//bStopEncodingBefore = true;
	//bStopEncodingAfter = true;
	
	switch ( OpLevel )
	{
		case -1:
			// source registers are Rs
			ullSrcRegBitmap |= ( 1ull << i.Rs );
			
			// destination register is Rt
			ullDstRegBitmap |= ( 1ull << i.Rt );
			break;
			
		case 0:
			if ( i.Rt )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
				e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

				// load arguments
				e->LoadImm32 ( RCX, i.Value );
				ret = e->Call ( c_vFunction ); //ANDI );
				
#ifdef RESERVE_STACK_FRAME_FOR_CALL
				ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
		case 1:
#ifdef USE_NEW_R5900_ASSEMBLER_ANDI

			if (i.Rt)
			{
				if ((!i.Rs) || (!i.uImmediate))
				{
					//ret = e->MovMemImm64(&r->GPR[i.Rt].s, 0);
					x->emit("mov qword ptr @ptr, 0", &r->GPR[i.Rt].s);
				}
				else if (i.Rt == i.Rs)
				{
					//ret = e->AndMem64ImmX(&r->GPR[i.Rt].s, i.uImmediate);
					x->emit("and qword ptr @ptr, @imm", &r->GPR[i.Rt].s, i.uImmediate);
				}
				else
				{
					//e->MovRegMem64(RAX, &r->GPR[i.Rs].s);
					//e->AndReg64ImmX(RAX, i.uImmediate);
					//ret = e->MovMemReg64(&r->GPR[i.Rt].s, RAX);

					if (i.uImmediate == 0xff)
					{
						x->emit("movzx eax, byte ptr @ptr", &r->GPR[i.Rs].s);
					}
					else if (i.uImmediate == 0xffff)
					{
						x->emit("movzx eax, word ptr @ptr", &r->GPR[i.Rs].s);
					}
					else
					{
						x->emit("mov eax, @ptr", &r->GPR[i.Rs].sw0);
						x->emit("and eax, @imm", i.uImmediate);
					}

					x->emit("mov @ptr, rax", &r->GPR[i.Rt].s);
				}

			}

#else
			if ( i.Rt )
			{
				if ( ( !i.Rs ) || ( !i.uImmediate ) )
				{
					//e->MovMemImm32 ( &r->GPR [ i.Rt ].s, 0 );
					ret = e->MovMemImm64 ( &r->GPR [ i.Rt ].s, 0 );
				}
				else if ( i.Rt == i.Rs )
				{
					//e->AndMem32ImmX ( &r->GPR [ i.Rt ].s, i.uImmediate );
					ret = e->AndMem64ImmX ( &r->GPR [ i.Rt ].s, i.uImmediate );
				}
				else if ( i.uImmediate == 0xff )
				{
					e->MovzxReg32Mem8 ( RAX, (char*) &r->GPR [ i.Rs ].s );
					ret = e->MovMemReg64 ( &r->GPR [ i.Rt ].s, RAX );
				}
				else if ( i.uImmediate == 0xffff )
				{
					e->MovzxReg32Mem16 ( RAX, (short*) &r->GPR [ i.Rs ].s );
					ret = e->MovMemReg64 ( &r->GPR [ i.Rt ].s, RAX );
				}
				else
				{
					//e->MovRegFromMem32 ( RAX, &r->GPR [ i.Rs ].s );
					e->MovRegMem64 ( RAX, &r->GPR [ i.Rs ].s );
					//e->AndReg32ImmX ( RAX, i.uImmediate );
					e->AndReg64ImmX ( RAX, i.uImmediate );
					//ret = e->MovRegToMem32 ( &r->GPR [ i.Rt ].s, RAX );
					ret = e->MovMemReg64 ( &r->GPR [ i.Rt ].s, RAX );
				}
				
			}
#endif
			break;
			

		default:
			return -1;
			break;
	} // end switch ( OpLevel )
	
	if ( !ret )
	{
		cout << "\nError encoding ANDI instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::ORI ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "ORI";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::ORI;
	
	//r->GPR [ i.Rt ].s = r->GPR [ i.Rs ].s | i.uImmediate;
	//CHECK_DELAYSLOT ( i.Rt );
	
	int Rd, Rs, Rt;
	int Reg1, Reg2;
	s64 lConst;
	
	int ret = 1;
	
	// *testing*
	//bStopEncodingBefore = true;
	//bStopEncodingAfter = true;
	
	switch ( OpLevel )
	{
		case -1:
			// source registers are Rs
			ullSrcRegBitmap |= ( 1ull << i.Rs );
			
			// destination register is Rt
			ullDstRegBitmap |= ( 1ull << i.Rt );
			break;
			
		case 0:
			if ( i.Rt )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
				e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

				// load arguments
				e->LoadImm32 ( RCX, i.Value );
				ret = e->Call ( c_vFunction ); //ORI );
				
#ifdef RESERVE_STACK_FRAME_FOR_CALL
				ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
		case 1:
#ifdef USE_NEW_R5900_ASSEMBLER_ORI

			if (i.Rt)
			{
				if (!i.Rs)
				{
					//e->MovMemImm64(&r->GPR[i.Rt].s, i.uImmediate);
					x->emit("mov qword ptr @ptr, @imm", &r->GPR[i.Rt].s, i.uImmediate);
				}
				else if (i.Rt == i.Rs)
				{
					//e->OrMem64ImmX(&r->GPR[i.Rt].s, i.uImmediate);
					if (i.uImmediate)
					{
						x->emit("or qword ptr @ptr, @imm", &r->GPR[i.Rt].s, i.uImmediate);
					}
				}
				else
				{
					//e->MovRegMem64(RAX, &r->GPR[i.Rs].s);
					//e->OrReg64ImmX(RAX, i.uImmediate);
					//ret = e->MovMemReg64(&r->GPR[i.Rt].s, RAX);
					x->emit("mov rax, @ptr", &r->GPR[i.Rs].s);

					if (i.uImmediate)
					{
						x->emit("or rax, @imm", i.uImmediate);
					}

					x->emit("mov @ptr, rax", &r->GPR[i.Rt].s);
				}

			}

#else
			if ( i.Rt )
			{
				if ( !i.Rs )
				{
					//e->MovMemImm32 ( &r->GPR [ i.Rt ].s, i.uImmediate );
					e->MovMemImm64 ( &r->GPR [ i.Rt ].s, i.uImmediate );
				}
				else if ( i.Rt == i.Rs )
				{
					//e->OrMem32ImmX ( &r->GPR [ i.Rt ].s, i.uImmediate );
					e->OrMem64ImmX ( &r->GPR [ i.Rt ].s, i.uImmediate );
				}
				else if ( !i.uImmediate )
				{
					if ( i.Rt != i.Rs )
					{
						e->MovRegMem64 ( RAX, &r->GPR [ i.Rs ].s );
						ret = e->MovMemReg64 ( &r->GPR [ i.Rt ].s, RAX );
					}
				}
				else
				{
					//e->MovRegFromMem32 ( RAX, &r->GPR [ i.Rs ].s );
					e->MovRegMem64 ( RAX, &r->GPR [ i.Rs ].s );
					//e->OrReg32ImmX ( RAX, i.uImmediate );
					e->OrReg64ImmX ( RAX, i.uImmediate );
					//ret = e->MovRegToMem32 ( &r->GPR [ i.Rt ].s, RAX );
					ret = e->MovMemReg64 ( &r->GPR [ i.Rt ].s, RAX );
				}
				
			}
#endif
			break;
			

		default:
			return -1;
			break;
	} // end switch ( OpLevel )
	
	if ( !ret )
	{
		cout << "\nError encoding ORI instruction.\n";
		return -1;
	}
	
	return 1;
}

int32_t R5900::Recompiler::XORI ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "XORI";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::XORI;
	
	//r->GPR [ i.Rt ].s = r->GPR [ i.Rs ].s ^ i.uImmediate;
	//CHECK_DELAYSLOT ( i.Rt );
	
	int Rd, Rs, Rt;
	int Reg1, Reg2;
	s64 lConst;
	
	int ret = 1;
	
	// *testing*
	//bStopEncodingBefore = true;
	//bStopEncodingAfter = true;
	
	switch ( OpLevel )
	{
		case -1:
			// source registers are Rs
			ullSrcRegBitmap |= ( 1ull << i.Rs );
			
			// destination register is Rt
			ullDstRegBitmap |= ( 1ull << i.Rt );
			break;
			
		case 0:
			if ( i.Rt )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
				e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

				// load arguments
				e->LoadImm32 ( RCX, i.Value );
				ret = e->Call ( c_vFunction ); //XORI );
				
#ifdef RESERVE_STACK_FRAME_FOR_CALL
				ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
		case 1:
#ifdef USE_NEW_R5900_ASSEMBLER_XORI

			if (i.Rt)
			{
				if (!i.Rs)
				{
					//e->MovMemImm64(&r->GPR[i.Rt].s, i.uImmediate);
					x->emit("mov qword ptr @ptr, @imm", &r->GPR[i.Rt].s, i.uImmediate);
				}
				else if (i.Rt == i.Rs)
				{
					//e->XorMem64ImmX(&r->GPR[i.Rt].s, i.uImmediate);
					if (i.uImmediate)
					{
						x->emit("xor qword ptr @ptr, @imm", &r->GPR[i.Rt].s, i.uImmediate);
					}
				}
				else
				{
					//e->MovRegMem64(RAX, &r->GPR[i.Rs].s);
					//e->XorReg64ImmX(RAX, i.uImmediate);
					//ret = e->MovMemReg64(&r->GPR[i.Rt].s, RAX);
					x->emit("mov rax, @ptr", &r->GPR[i.Rs].s);

					if (i.uImmediate)
					{
						x->emit("xor rax, @imm", i.uImmediate);
					}

					x->emit("mov @ptr, rax", &r->GPR[i.Rt].s);
				}
			}

#else
			if ( i.Rt )
			{
				if ( !i.Rs )
				{
					//e->MovMemImm32 ( &r->GPR [ i.Rt ].s, i.uImmediate );
					e->MovMemImm64 ( &r->GPR [ i.Rt ].s, i.uImmediate );
				}
				else if ( i.Rt == i.Rs )
				{
					//e->XorMem32ImmX ( &r->GPR [ i.Rt ].s, i.uImmediate );
					e->XorMem64ImmX ( &r->GPR [ i.Rt ].s, i.uImmediate );
				}
				else if ( !i.uImmediate )
				{
					if ( i.Rt != i.Rs )
					{
						e->MovRegMem64 ( RAX, &r->GPR [ i.Rs ].s );
						ret = e->MovMemReg64 ( &r->GPR [ i.Rt ].s, RAX );
					}
				}
				else
				{
					//e->MovRegFromMem32 ( RAX, &r->GPR [ i.Rs ].s );
					e->MovRegMem64 ( RAX, &r->GPR [ i.Rs ].s );
					//e->XorReg32ImmX ( RAX, i.uImmediate );
					e->XorReg64ImmX ( RAX, i.uImmediate );
					//ret = e->MovRegToMem32 ( &r->GPR [ i.Rt ].s, RAX );
					ret = e->MovMemReg64 ( &r->GPR [ i.Rt ].s, RAX );
				}
				
			}
#endif
			break;
			

		default:
			return -1;
			break;
	} // end switch ( OpLevel )
	
	if ( !ret )
	{
		cout << "\nError encoding XORI instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::SLTI ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "SLTI";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::SLTI;
	
	//r->GPR [ i.Rt ].s = r->GPR [ i.Rs ].s < i.sImmediate ? 1 : 0;
	//CHECK_DELAYSLOT ( i.Rt );
	
	int Rd, Rs, Rt;
	int Reg1, Reg2;
	s64 lConst;
	
	int ret = 1;
	
	// *testing*
	//bStopEncodingBefore = true;
	//bStopEncodingAfter = true;
	
	switch ( OpLevel )
	{
		case -1:
			// source registers are Rs
			ullSrcRegBitmap |= ( 1ull << i.Rs );
			
			// destination register is Rt
			ullDstRegBitmap |= ( 1ull << i.Rt );
			break;
			
		case 0:
			if ( i.Rt )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
				e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

				// load arguments
				e->LoadImm32 ( RCX, i.Value );
				ret = e->Call ( c_vFunction ); //SLTI );
				
#ifdef RESERVE_STACK_FRAME_FOR_CALL
				ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
		case 1:
#ifdef USE_NEW_R5900_ASSEMBLER_SLTI

			if (i.Rt)
			{
				if (!i.sImmediate)
				{
					if ( i.Rt == i.Rs )
					{
						//e->ShrMemImm64 ( &r->GPR [ i.Rs ].s, 63 );
						x->emit("shr qword ptr @ptr, 63", &r->GPR[i.Rt].s);
					}
					else
					{
						//e->MovRegMem64(RAX, &r->GPR[i.Rs].s);
						//e->ShrRegImm64(RAX, 63);
						//ret = e->MovMemReg64(&r->GPR[i.Rt].s, RAX);
						x->emit("mov rax, @ptr", &r->GPR[i.Rs].s);
						x->emit("shr rax, 63");
						x->emit("mov @ptr, rax", &r->GPR[i.Rt].s);
					}
				}
				else
				{
					// this should zero-extend to 64-bits
					//e->XorRegReg32(RAX, RAX);
					//e->CmpMemImm64(&r->GPR[i.Rs].s, i.sImmediate);
					//e->Set_L(RAX);
					//ret = e->MovMemReg64(&r->GPR[i.Rt].s, RAX);
					x->emit("xor eax, eax");
					x->emit("cmp qword ptr @ptr, @imm", &r->GPR[i.Rs].s, (s32)i.sImmediate);
					x->emit("setl al");
					x->emit("mov @ptr, rax", &r->GPR[i.Rt].s);
				}
			}

#else
			if ( i.Rt )
			{
				if ( !i.sImmediate )
				{
					// ***todo*** implement ShrMemImm64
					//if ( i.Rt == i.Rs )
					//{
					//	e->ShrMemImm64 ( &r->GPR [ i.Rs ].s, 63 );
					//}
					//else
					{
						e->MovRegMem64 ( RAX, &r->GPR [ i.Rs ].s );
						//e->Cqo ();
						//e->NegReg32 ( RDX );
						e->ShrRegImm64 ( RAX, 63 );
						ret = e->MovMemReg64 ( &r->GPR [ i.Rt ].s, RAX );
					}
				}
				else
				{
					// this should zero-extend to 64-bits
					e->XorRegReg32 ( RAX, RAX );
					e->CmpMemImm64 ( &r->GPR [ i.Rs ].s, i.sImmediate );
					e->Set_L ( RAX );
					ret = e->MovMemReg64 ( &r->GPR [ i.Rt ].s, RAX );
				}
			}
#endif
			break;
			

		default:
			return -1;
			break;
	} // end switch ( OpLevel )
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //ADDU instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::SLTIU ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "SLTIU";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::SLTIU;
	
	//r->GPR [ i.Rt ].s = r->GPR [ i.Rs ].s < ((u32) ((s32) i.sImmediate)) ? 1 : 0;
	//CHECK_DELAYSLOT ( i.Rt );
	
	int Rd, Rs, Rt;
	int Reg1, Reg2;
	s64 lConst;
	
	int ret = 1;
	
	// *testing*
	//bStopEncodingBefore = true;
	//bStopEncodingAfter = true;
	
	switch ( OpLevel )
	{
		case -1:
			// source registers are Rs
			ullSrcRegBitmap |= ( 1ull << i.Rs );
			
			// destination register is Rt
			ullDstRegBitmap |= ( 1ull << i.Rt );
			break;
			
		case 0:
			if ( i.Rt )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
				e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

				// load arguments
				e->LoadImm32 ( RCX, i.Value );
				ret = e->Call ( c_vFunction ); //SLTIU );
				
#ifdef RESERVE_STACK_FRAME_FOR_CALL
				ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
		case 1:
#ifdef USE_NEW_R5900_ASSEMBLER_SLTIU

			if (i.Rt)
			{
				if (!i.sImmediate)
				{
					//ret = e->MovMemImm64(&r->GPR[i.Rt].s, 0);
					x->emit("mov qword ptr @ptr, 0", &r->GPR[i.Rt].s);
				}
				else
				{
					// this should zero-extend to 64-bits
					//e->XorRegReg32(RAX, RAX);
					//e->CmpMemImm64(&r->GPR[i.Rs].s, i.sImmediate);
					//e->AdcRegReg32(RAX, RAX);
					//ret = e->MovMemReg64(&r->GPR[i.Rt].s, RAX);
					x->emit("cmp qword ptr @ptr, @imm", &r->GPR[i.Rs].s, (s32)i.sImmediate);
					x->emit("sbb eax, eax");
					x->emit("neg eax");
					x->emit("mov @ptr, rax", &r->GPR[i.Rt].s);
				}
			}

#else
			if ( i.Rt )
			{
				if ( !i.sImmediate )
				{
					ret = e->MovMemImm64 ( &r->GPR [ i.Rt ].s, 0 );
				}
				else
				{
					// this should zero-extend to 64-bits
					e->XorRegReg32 ( RAX, RAX );
					e->CmpMemImm64 ( &r->GPR [ i.Rs ].s, i.sImmediate );
					//e->Set_B ( RAX );
					e->AdcRegReg32 ( RAX, RAX );
					ret = e->MovMemReg64 ( &r->GPR [ i.Rt ].s, RAX );
				}
			}
#endif
			break;
			

		default:
			return -1;
			break;
	} // end switch ( OpLevel )
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //ADDU instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::LUI ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "LUI";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::LUI;
	
	//r->GPR [ i.Rt ].s = ( i.uImmediate << 16 );
	//CHECK_DELAYSLOT ( i.Rt );
	
	int Rd, Rs, Rt;
	int Reg1, Reg2;
	s64 lConst;
	
	int ret = 1;
	
	// *testing*
	//bStopEncodingBefore = true;
	//bStopEncodingAfter = true;
	
	switch ( OpLevel )
	{
		case -1:
			// destination register is Rt
			ullDstRegBitmap |= ( 1ull << i.Rt );
			break;
			
		case 0:
			if ( i.Rt )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
				e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

				// load arguments
				e->LoadImm32 ( RCX, i.Value );
				ret = e->Call ( c_vFunction ); //LUI );
				
#ifdef RESERVE_STACK_FRAME_FOR_CALL
				ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
		case 1:
#ifdef USE_NEW_R5900_ASSEMBLER_LUI

			if (i.Rt)
			{
				//ret = e->MovMemImm64(&r->GPR[i.Rt].s, (i.uImmediate << 16));
				x->emit("mov qword ptr @ptr, @imm", &r->GPR[i.Rt].s, (i.uImmediate << 16));
			}

#else
			if ( i.Rt )
			{
				//ret = e->MovMemImm32 ( &r->GPR [ i.Rt ].s, ( i.uImmediate << 16 ) );
				ret = e->MovMemImm64 ( &r->GPR [ i.Rt ].s, ( i.uImmediate << 16 ) );
			}
#endif
			break;
			

		default:
			return -1;
			break;
	} // end switch ( OpLevel )
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //LUI instruction.\n";
		return -1;
	}
	return 1;
}







//////////////////////////////////////////////////////////
// Shift instructions



int32_t R5900::Recompiler::SLL ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "SLL";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::SLL;
	
	//r->GPR [ i.Rd ].u = ( r->GPR [ i.Rt ].s << i.Shift );
	//CHECK_DELAYSLOT ( i.Rd );
	
	int Rd, Rs, Rt;
	int Reg1, Reg2;
	s64 lConst;
	
	int ret = 1;
	
	// *testing*
	//bStopEncodingBefore = true;
	//bStopEncodingAfter = true;
	
	switch ( OpLevel )
	{
		case -1:
			// source registers are Rt
			ullSrcRegBitmap |= ( 1 << i.Rt );
			
			// destination register is Rd
			ullDstRegBitmap |= ( 1ull << i.Rd );
			break;
			
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
				e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

				// load arguments
				e->LoadImm32 ( RCX, i.Value );
				ret = e->Call ( c_vFunction ); //SLL );
				
#ifdef RESERVE_STACK_FRAME_FOR_CALL
				ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
		case 1:
#ifdef USE_NEW_R5900_ASSEMBLER_SLL

			if (i.Rd)
			{
				if (!i.Rt)
				{
					//ret = e->MovMemImm64(&r->GPR[i.Rd].s, 0);
					x->emit("mov qword ptr @ptr, 0", &r->GPR[i.Rd].s);
				}
				else if (!i.Shift)
				{
					//e->MovsxdReg64Mem32(RAX, &r->GPR[i.Rt].sw0);
					//ret = e->MovMemReg64(&r->GPR[i.Rd].s, RAX);
					x->emit("movsxd rax, dword ptr @ptr", &r->GPR[i.Rt].sw0);
					x->emit("mov @ptr, rax", &r->GPR[i.Rd].s);
				}
				else
				{
					//e->MovRegFromMem32(RAX, &r->GPR[i.Rt].sw0);
					//e->ShlRegImm32(RAX, (u32)i.Shift);
					//e->Cdqe();
					//ret = e->MovMemReg64(&r->GPR[i.Rd].s, RAX);
					x->emit("mov eax, @ptr", &r->GPR[i.Rt].s);
					x->emit("shl eax, @imm", i.Shift);
					x->emit("cdqe");
					x->emit("mov @ptr, rax", &r->GPR[i.Rd].s);
				}
			}

#else
			if ( i.Rd )
			{
				if ( !i.Rt )
				{
					ret = e->MovMemImm64 ( &r->GPR [ i.Rd ].s, 0 );
				}
				else if ( !i.Shift )
				{
					e->MovsxdReg64Mem32 ( RAX, &r->GPR [ i.Rt ].sw0 );
					ret = e->MovMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
				}
				else
				{
					e->MovRegFromMem32 ( RAX, &r->GPR [ i.Rt ].sw0 );
					
					e->ShlRegImm32 ( RAX, (u32) i.Shift );
					
					e->Cdqe ();
					//ret = e->MovRegToMem32 ( &r->GPR [ i.Rd ].s, RAX );
					ret = e->MovMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
				}
			}
#endif
			break;
			

		default:
			return -1;
			break;
	} // end switch ( OpLevel )
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //SLL instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::SRL ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "SRL";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::SRL;
	
	int Rd, Rs, Rt;
	int Reg1, Reg2;
	s64 lConst;
	
	int ret = 1;
	
	// *testing*
	//bStopEncodingBefore = true;
	//bStopEncodingAfter = true;
	
	switch ( OpLevel )
	{
		case -1:
			// source registers are Rt
			ullSrcRegBitmap |= ( 1 << i.Rt );
			
			// destination register is Rd
			ullDstRegBitmap |= ( 1ull << i.Rd );
			break;
			
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
				e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

				// load arguments
				e->LoadImm32 ( RCX, i.Value );
				ret = e->Call ( c_vFunction ); //SRL );
				
#ifdef RESERVE_STACK_FRAME_FOR_CALL
				ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
		case 1:
#ifdef USE_NEW_R5900_ASSEMBLER_SRL

			if (i.Rd)
			{
				if (!i.Rt)
				{
					//ret = e->MovMemImm64(&r->GPR[i.Rd].s, 0);
					x->emit("mov qword ptr @ptr, 0", &r->GPR[i.Rd].s);
				}
				else if (!i.Shift)
				{
					//e->MovsxdReg64Mem32(RAX, &r->GPR[i.Rt].sw0);
					//ret = e->MovMemReg64(&r->GPR[i.Rd].s, RAX);
					x->emit("movsxd rax, dword ptr @ptr", &r->GPR[i.Rt].sw0);
					x->emit("mov @ptr, rax", &r->GPR[i.Rd].s);
				}
				else
				{
					//e->MovRegFromMem32(RAX, &r->GPR[i.Rt].sw0);
					//e->ShrRegImm32(RAX, (u32)i.Shift);
					//ret = e->MovMemReg64(&r->GPR[i.Rd].s, RAX);
					x->emit("mov eax, @ptr", &r->GPR[i.Rt].s);
					x->emit("shr eax, @imm", i.Shift);
					x->emit("mov @ptr, rax", &r->GPR[i.Rd].s);
				}
			}

#else
			if ( i.Rd )
			{
				if ( !i.Rt )
				{
					ret = e->MovMemImm64 ( &r->GPR [ i.Rd ].s, 0 );
				}
				else if ( !i.Shift )
				{
					e->MovsxdReg64Mem32 ( RAX, &r->GPR [ i.Rt ].sw0 );
					ret = e->MovMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
				}
				else
				{
					e->MovRegFromMem32 ( RAX, &r->GPR [ i.Rt ].sw0 );
				
					e->ShrRegImm32 ( RAX, (u32) i.Shift );
					//e->Cdqe ();
				
					//ret = e->MovRegToMem32 ( &r->GPR [ i.Rd ].s, RAX );
					ret = e->MovMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
				}
			}
#endif
			break;
			

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //ADDU instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::SRA ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "SRA";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::SRA;
	
	int Rd, Rs, Rt;
	int Reg1, Reg2;
	s64 lConst;
	
	int ret = 1;
	
	// *testing*
	//bStopEncodingBefore = true;
	//bStopEncodingAfter = true;
	
	switch ( OpLevel )
	{
		case -1:
			// source registers are Rt
			ullSrcRegBitmap |= ( 1 << i.Rt );
			
			// destination register is Rd
			ullDstRegBitmap |= ( 1ull << i.Rd );
			break;
			
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
				e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

				// load arguments
				e->LoadImm32 ( RCX, i.Value );
				ret = e->Call ( c_vFunction ); //SRA );
				
#ifdef RESERVE_STACK_FRAME_FOR_CALL
				ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
		case 1:
#ifdef USE_NEW_R5900_ASSEMBLER_SRA

			if (i.Rd)
			{
				if (!i.Rt)
				{
					//ret = e->MovMemImm64(&r->GPR[i.Rd].s, 0);
					x->emit("mov qword ptr @ptr, 0", &r->GPR[i.Rd].s);
				}
				else
				{
					//e->MovsxdReg64Mem32(RAX, &r->GPR[i.Rt].sw0);
					//e->SarRegImm64(RAX, (u32)i.Shift);
					//ret = e->MovMemReg64(&r->GPR[i.Rd].s, RAX);
					x->emit("movsxd rax, dword ptr @ptr", &r->GPR[i.Rt].sw0);

					if (i.Shift)
					{
						x->emit("sar rax, @imm", i.Shift);
					}

					x->emit("mov @ptr, rax", &r->GPR[i.Rd].s);
				}
			}

#else
			if ( i.Rd )
			{
				if ( !i.Rt )
				{
					ret = e->MovMemImm64 ( &r->GPR [ i.Rd ].s, 0 );
				}
				else if ( !i.Shift )
				{
					e->MovsxdReg64Mem32 ( RAX, &r->GPR [ i.Rt ].sw0 );
					ret = e->MovMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
				}
				else
				{
					//e->MovRegFromMem32 ( RAX, &r->GPR [ i.Rt ].s );
					e->MovsxdReg64Mem32 ( RAX, &r->GPR [ i.Rt ].sw0 );
					//e->SarRegImm32 ( RAX, (u32) i.Shift );
					
					e->SarRegImm64 ( RAX, (u32) i.Shift );
					
					//ret = e->MovRegToMem32 ( &r->GPR [ i.Rd ].s, RAX );
					ret = e->MovMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
				}
			}
#endif
			break;
			

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //ADDU instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::SLLV ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "SLLV";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::SLLV;
	
	//r->GPR [ i.Rd ].u = ( r->GPR [ i.Rt ].s << ( r->GPR [ i.Rs ].s & 0x1f ) );
	//CHECK_DELAYSLOT ( i.Rd );
	
	int Rd, Rs, Rt;
	int Reg1, Reg2;
	s64 lConst;
	
	int ret = 1;
	
	// *testing*
	//bStopEncodingBefore = true;
	//bStopEncodingAfter = true;
	
	switch ( OpLevel )
	{
		case -1:
			// source registers are Rs and Rt
			ullSrcRegBitmap |= ( 1ull << i.Rs ) | ( 1ull << i.Rt );
			
			// destination register is Rd
			ullDstRegBitmap |= ( 1ull << i.Rd );
			break;
			
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
				e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

				// load arguments
				e->LoadImm32 ( RCX, i.Value );
				ret = e->Call ( c_vFunction ); //SLLV );
				
#ifdef RESERVE_STACK_FRAME_FOR_CALL
				ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
		case 1:
#ifdef USE_NEW_R5900_ASSEMBLER_SLLV

			if (i.Rd)
			{
				if (!i.Rt)
				{
					//ret = e->MovMemImm64(&r->GPR[i.Rd].s, 0);
					x->emit("mov qword ptr @ptr, 0", &r->GPR[i.Rd].s);
				}
				else if (!i.Rs)
				{
					//e->MovsxdReg64Mem32(RAX, &r->GPR[i.Rt].sw0);
					//ret = e->MovMemReg64(&r->GPR[i.Rd].s, RAX);
					x->emit("movsxd rax, dword ptr @ptr", &r->GPR[i.Rt].sw0);
					x->emit("mov @ptr, rax", &r->GPR[i.Rd].s);
				}
				else
				{
					//e->MovRegMem32(RAX, &r->GPR[i.Rt].sw0);
					//e->MovRegMem32(RCX, &r->GPR[i.Rs].sw0);
					//e->ShlRegReg32(RAX);
					//e->Cdqe();
					//ret = e->MovMemReg64(&r->GPR[i.Rd].s, RAX);
					x->emit("mov eax, @ptr", &r->GPR[i.Rt].s);
					x->emit("mov ecx, @ptr", &r->GPR[i.Rs].s);
					x->emit("shl eax, cl");
					x->emit("cdqe");
					x->emit("mov @ptr, rax", &r->GPR[i.Rd].s);
				}
			}

#else
			if ( i.Rd )
			{
				if ( !i.Rt )
				{
					ret = e->MovMemImm64 ( &r->GPR [ i.Rd ].s, 0 );
				}
				else if ( !i.Rs )
				{
					e->MovsxdReg64Mem32 ( RAX, &r->GPR [ i.Rt ].sw0 );
					ret = e->MovMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
				}
				else
				{
					//e->MovRegFromMem32 ( RAX, &r->GPR [ i.Rt ].s );
					e->MovRegMem32 ( RAX, &r->GPR [ i.Rt ].sw0 );
					//e->MovRegFromMem32 ( RCX, &r->GPR [ i.Rs ].s );
				
					e->MovRegMem32 ( RCX, &r->GPR [ i.Rs ].sw0 );
					e->ShlRegReg32 ( RAX );
				
					e->Cdqe ();
					//ret = e->MovRegToMem32 ( &r->GPR [ i.Rd ].s, RAX );
					ret = e->MovMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
				}
			}
#endif
			break;
			

		default:
			return -1;
			break;
	} // end switch ( OpLevel )
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //ADDU instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::SRLV ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "SRLV";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::SRLV;
	
	int Rd, Rs, Rt;
	int Reg1, Reg2;
	s64 lConst;
	
	int ret = 1;
	
	// *testing*
	//bStopEncodingBefore = true;
	//bStopEncodingAfter = true;
	
	switch ( OpLevel )
	{
		case -1:
			// source registers are Rs and Rt
			ullSrcRegBitmap |= ( 1ull << i.Rs ) | ( 1ull << i.Rt );
			
			// destination register is Rd
			ullDstRegBitmap |= ( 1ull << i.Rd );
			break;
			
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
				e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

				// load arguments
				e->LoadImm32 ( RCX, i.Value );
				ret = e->Call ( c_vFunction ); //SRLV );
				
#ifdef RESERVE_STACK_FRAME_FOR_CALL
				ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
		case 1:
#ifdef USE_NEW_R5900_ASSEMBLER_SRLV

			if (i.Rd)
			{
				if (!i.Rt)
				{
					//ret = e->MovMemImm64(&r->GPR[i.Rd].s, 0);
					x->emit("mov qword ptr @ptr, 0", &r->GPR[i.Rd].s);
				}
				else if (!i.Rs)
				{
					//e->MovsxdReg64Mem32(RAX, &r->GPR[i.Rt].sw0);
					//ret = e->MovMemReg64(&r->GPR[i.Rd].s, RAX);
					x->emit("movsxd rax, dword ptr @ptr", &r->GPR[i.Rt].sw0);
					x->emit("mov @ptr, rax", &r->GPR[i.Rd].s);
				}
				else
				{
					//e->MovRegFromMem32(RAX, &r->GPR[i.Rt].sw0);
					//e->MovRegFromMem32(RCX, &r->GPR[i.Rs].sw0);
					//e->ShrRegReg32(RAX);
					//e->Cdqe();
					//ret = e->MovMemReg64(&r->GPR[i.Rd].s, RAX);
					x->emit("mov eax, @ptr", &r->GPR[i.Rt].s);
					x->emit("mov ecx, @ptr", &r->GPR[i.Rs].s);
					x->emit("shr eax, cl");
					x->emit("cdqe");
					x->emit("mov @ptr, rax", &r->GPR[i.Rd].s);
				}
			}

#else
			if ( i.Rd )
			{
				if ( !i.Rt )
				{
					ret = e->MovMemImm64 ( &r->GPR [ i.Rd ].s, 0 );
				}
				else if ( !i.Rs )
				{
					e->MovsxdReg64Mem32 ( RAX, &r->GPR [ i.Rt ].sw0 );
					ret = e->MovMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
				}
				else
				{
					e->MovRegFromMem32 ( RAX, &r->GPR [ i.Rt ].sw0 );
					e->MovRegFromMem32 ( RCX, &r->GPR [ i.Rs ].sw0 );
					e->ShrRegReg32 ( RAX );
					e->Cdqe ();
					//ret = e->MovRegToMem32 ( &r->GPR [ i.Rd ].s, RAX );
					ret = e->MovMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
				}
			}
#endif
			break;
			

		default:
			return -1;
			break;
	} // end switch ( OpLevel )
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //ADDU instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::SRAV ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "SRAV";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::SRAV;
	
	int Rd, Rs, Rt;
	int Reg1, Reg2;
	s64 lConst;
	
	int ret = 1;
	
	// *testing*
	//bStopEncodingBefore = true;
	//bStopEncodingAfter = true;
	
	switch ( OpLevel )
	{
		case -1:
			// source registers are Rs and Rt
			ullSrcRegBitmap |= ( 1ull << i.Rs ) | ( 1ull << i.Rt );
			
			// destination register is Rd
			ullDstRegBitmap |= ( 1ull << i.Rd );
			break;
			
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
				e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

				// load arguments
				e->LoadImm32 ( RCX, i.Value );
				ret = e->Call ( c_vFunction ); //SRAV );
				
#ifdef RESERVE_STACK_FRAME_FOR_CALL
				ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
		case 1:
#ifdef USE_NEW_R5900_ASSEMBLER_SRAV

			if (i.Rd)
			{
				if (!i.Rt)
				{
					//ret = e->MovMemImm64(&r->GPR[i.Rd].s, 0);
					x->emit("mov qword ptr @ptr, 0", &r->GPR[i.Rd].s);
				}
				else
				{
					//e->MovRegFromMem32(RAX, &r->GPR[i.Rt].sw0);
					//e->MovRegFromMem32(RCX, &r->GPR[i.Rs].sw0);
					//e->SarRegReg32(RAX);
					//e->Cdqe();
					//e->MovMemReg64(&r->GPR[i.Rd].s, RAX);
					//x->emit("mov eax, @ptr", &r->GPR[i.Rt].s);
					x->emit("movsxd rax, dword ptr @ptr", &r->GPR[i.Rt].sw0);

					if (i.Rs)
					{
						x->emit("mov ecx, @ptr", &r->GPR[i.Rs].s);
						x->emit("sar rax, cl");
					}

					//x->emit("cdqe");
					x->emit("mov @ptr, rax", &r->GPR[i.Rd].s);
				}
			}

#else
			if ( i.Rd )
			{
				if ( !i.Rt )
				{
					ret = e->MovMemImm64 ( &r->GPR [ i.Rd ].s, 0 );
				}
				else if ( !i.Rs )
				{
					e->MovsxdReg64Mem32 ( RAX, &r->GPR [ i.Rt ].sw0 );
					ret = e->MovMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
				}
				else
				{
					e->MovRegFromMem32 ( RAX, &r->GPR [ i.Rt ].sw0 );
					//e->MovsxdReg64Mem32 ( RAX, &r->GPR [ i.Rt ].sw0 );
					e->MovRegFromMem32 ( RCX, &r->GPR [ i.Rs ].sw0 );
					
					// must shift right 32-bits here and do cdqe, otherwise need to mask the shift count to a 32-bit shift
					e->SarRegReg32 ( RAX );
					//e->SarRegReg64 ( RAX );
					e->Cdqe ();
					
					//e->MovRegToMem32 ( &r->GPR [ i.Rd ].s, RAX );
					e->MovMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
				}
			}
#endif
			break;
			

		default:
			return -1;
			break;
	} // end switch ( OpLevel )
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //ADDU instruction.\n";
		return -1;
	}
	return 1;
}


//----------------------------------------------------------------------------


////////////////////////////////////////////
// Jump/Branch Instructions



int32_t R5900::Recompiler::J ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "J";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::J;
	
	//r->DelaySlot0.Instruction = i;
	//r->DelaySlot0.cb = r->_cb_Jump;
	//r->Status.DelaySlot_Valid |= 0x1;
	int ret = 1;
	
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			//bStopEncodingBefore = true;

			// *MUST* update PC if branch will return to delay slot (at least for now)
			e->MovMemImm32 ( (int32_t*) & r->PC, Address );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			// load arguments
			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction ); //J );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
#ifdef USE_NEW_J_CODE
			ret = Generate_Normal_Branch ( i, Address, (void*) Cpu::ProcessBranchDelaySlot_t<OPJ> );
#else
			return -1;
#endif
			
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //J instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::JR ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "JR";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::JR;
	
	//r->DelaySlot0.Instruction = i;
	//r->DelaySlot0.cb = r->_cb_JumpRegister;
	//r->DelaySlot0.Data = r->GPR [ i.Rs ].s & ~3;
	//r->Status.DelaySlot_Valid |= 0x1;
	int ret = 1;
	
	
	switch ( OpLevel )
	{
		case 0:
			// has to stop encoding before AND after here due to the posible synchronous interrupt
			// so it has to have PC,LastPC updated (or could set it and move up the entry point)
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// could potentially encounter a synchronous interrupt
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction ); //JR );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
#ifdef USE_NEW_JR_CODE
			ret = Generate_Normal_Branch ( i, Address, (void*) Cpu::ProcessBranchDelaySlot_t<OPJR> );
#else
			return -1;
#endif

			//e->MovMemImm32 ( &r->DelaySlot0.Instruction.Value, i.Value );
			//e->MovRegFromMem32 ( 0, &r->GPR [ i.Rs ].s );
			//e->MovRegToMem32 ( &r->DelaySlot0.Data, 0 );
			//ret = e->OrMemImm64 ( &r->Status.Value, 1 );
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //JR instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::JAL ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "JAL";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::JAL;
	
	//r->DelaySlot0.Instruction = i;
	//r->DelaySlot0.cb = r->_cb_Jump;
	//r->Status.DelaySlot_Valid |= 0x1;
	//r->GPR [ 31 ].u = r->PC + 8;
	//CHECK_DELAYSLOT ( 31 );
	int ret = 1;
	
	
	switch ( OpLevel )
	{
		case 0:
			// there is no synchronous interrupt possible here, so only needs to stop encoding after
			bStopEncodingAfter = true;
			
			// also have to stop before because need an updated NextPC so you get the correct link value
			bStopEncodingBefore = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction ); //JAL );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			break;
			
		case 1:
#ifdef USE_NEW_JAL_CODE
			ret = Generate_Normal_Branch ( i, Address, (void*) Cpu::ProcessBranchDelaySlot_t<OPJAL> );
#else
			return -1;
#endif

			//e->MovMemImm32 ( &r->DelaySlot0.Instruction.Value, i.Value );
			//e->OrMemImm64 ( &r->Status.Value, 1 );
			//e->MovMemImm32 ( &r->GPR [ 31 ].u, Address + 8 );
			//ret = e->MovMemImm32 ( (s32*) &r->LastModifiedRegister, 31 );
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //JAL instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::JALR ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "JALR";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::JALR;
	
	//r->DelaySlot0.Instruction = i;
	//r->DelaySlot0.Data = r->GPR [ i.Rs ].s & ~3;
	//r->DelaySlot0.cb = r->_cb_JumpRegister;
	//r->Status.DelaySlot_Valid |= 0x1;
	//r->GPR [ i.Rd ].u = r->PC + 8;
	//CHECK_DELAYSLOT ( i.Rd );
	int ret = 1;
	
	
	switch ( OpLevel )
	{
		case 0:
			// has to stop encoding before AND after here due to the posible synchronous interrupt
			// so it has to have PC,LastPC updated (or could set it and move up the entry point)
			bStopEncodingBefore = true;
			bStopEncodingAfter = true;
			
			// could potentially encounter a synchronous interrupt
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction ); //JALR );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			// make sure Rd is not r0
			if ( !i.Rd )
			{
				// make sure r0 stays at zero
				e->MovMemImm64 ( &r->GPR [ 0 ].s, 0 );
			}
			break;
			
		case 1:
#ifdef USE_NEW_JALR_CODE
			ret = Generate_Normal_Branch ( i, Address, (void*) Cpu::ProcessBranchDelaySlot_t<OPJALR> );
#else
			return -1;
#endif
			
			//e->MovMemImm32 ( &r->DelaySlot0.Instruction.Value, i.Value );
			//e->MovRegFromMem32 ( 0, &r->GPR [ i.Rs ].s );
			//e->MovRegToMem32 ( &r->DelaySlot0.Data, 0 );
			//ret = e->OrMemImm64 ( &r->Status.Value, 1 );
			//if ( i.Rd )
			//{
			//	e->MovMemImm32 ( &r->GPR [ i.Rd ].s, Address + 8 );
			//	ret = e->MovMemImm32 ( (s32*) &r->LastModifiedRegister, i.Rd );
			//}
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //JALR instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::BEQ ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "BEQ";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::BEQ;
	
	//if ( r->GPR [ i.Rs ].s == r->GPR [ i.Rt ].s )
	//{
	//	r->DelaySlot0.Instruction = i;
	//	r->DelaySlot0.cb = r->_cb_Branch;
	//	r->Status.DelaySlot_Valid |= 0x1;
	//}
	int ret = 1;
	
	
	switch ( OpLevel )
	{
		case 0:
			bStopEncodingAfter = true;

			// *MUST* update PC if branch will return to delay slot (at least for now)
			e->MovMemImm32 ( (int32_t*) & r->PC, Address );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction ); //BEQ );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
#ifdef USE_NEW_BEQ_CODE
			ret = Generate_Normal_Branch ( i, Address, (void*) Cpu::ProcessBranchDelaySlot_t<OPBEQ> );
#else
			return -1;
#endif
			
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //BEQ instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::BNE ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "BNE";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::BNE;
	
	int ret = 1;
	
	switch ( OpLevel )
	{
		case 0:
			bStopEncodingAfter = true;
			
			// *MUST* update PC if branch will return to delay slot (at least for now)
			e->MovMemImm32 ( (int32_t*) & r->PC, Address );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction ); //BNE );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
#ifdef USE_NEW_BNE_CODE
			ret = Generate_Normal_Branch ( i, Address, (void*) Cpu::ProcessBranchDelaySlot_t<OPBNE> );
#else
			return -1;
#endif
			
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //BNE instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::BLEZ ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "BLEZ";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::BLEZ;
	
	//if ( r->GPR [ i.Rs ].s <= 0 )
	//{
	//	// next instruction is in the branch delay slot
	//	r->DelaySlot0.Instruction = i;
	//	r->DelaySlot0.cb = r->_cb_Branch;
	//	r->Status.DelaySlot_Valid |= 0x1;
	//}
	int ret = 1;
	
	
	switch ( OpLevel )
	{
		case 0:
			bStopEncodingAfter = true;
			
			// *MUST* update PC if branch will return to delay slot (at least for now)
			e->MovMemImm32 ( (int32_t*) & r->PC, Address );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction ); //BLEZ );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
#ifdef USE_NEW_BLEZ_CODE
			ret = Generate_Normal_Branch ( i, Address, (void*) Cpu::ProcessBranchDelaySlot_t<OPBLEZ> );
#else
			return -1;
#endif
			
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //BLEZ instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::BGTZ ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "BGTZ";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::BGTZ;
	
	int ret = 1;
	
	switch ( OpLevel )
	{
		case 0:
			bStopEncodingAfter = true;
			
			// *MUST* update PC if branch will return to delay slot (at least for now)
			e->MovMemImm32 ( (int32_t*) & r->PC, Address );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction ); //BGTZ );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
#ifdef USE_NEW_BGTZ_CODE
			ret = Generate_Normal_Branch ( i, Address, (void*) Cpu::ProcessBranchDelaySlot_t<OPBGTZ> );
#else
			return -1;
#endif
			
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //BGTZ instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::BLTZ ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "BLTZ";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::BLTZ;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	
	// *testing*
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			bStopEncodingAfter = true;
			
			// *MUST* update PC if branch will return to delay slot (at least for now)
			e->MovMemImm32 ( (int32_t*) & r->PC, Address );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction ); //BLTZ );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
#ifdef USE_NEW_BLTZ_CODE
			ret = Generate_Normal_Branch ( i, Address, (void*) Cpu::ProcessBranchDelaySlot_t<OPBLTZ> );
#else
			return -1;
#endif
			
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //BLTZ instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::BGEZ ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "BGEZ";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::BGEZ;
	
	int ret = 1;
	
	switch ( OpLevel )
	{
		case 0:
			bStopEncodingAfter = true;
			
			// *MUST* update PC if branch will return to delay slot (at least for now)
			e->MovMemImm32 ( (int32_t*) & r->PC, Address );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction ); //BGEZ );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
#ifdef USE_NEW_BGEZ_CODE
			ret = Generate_Normal_Branch ( i, Address, (void*) Cpu::ProcessBranchDelaySlot_t<OPBGEZ> );
#else
			return -1;
#endif
			
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //BGEZ instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::BLTZAL ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "BLTZAL";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::BLTZAL;
	
	//if ( r->GPR [ i.Rs ].s < 0 )
	//{
	//	r->DelaySlot0.Instruction = i;
	//	r->DelaySlot0.cb = r->_cb_Branch;
	//	r->Status.DelaySlot_Valid |= 0x1;
	//}
	//r->GPR [ 31 ].u = r->PC + 8;
	//CHECK_DELAYSLOT ( 31 );
	int ret = 1;
	
	
	switch ( OpLevel )
	{
		case 0:
			// needs to also stop encoding before at level 0, because it requires an updated PC to link
			bStopEncodingBefore = true;
			bStopEncodingAfter = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction ); //BLTZAL );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
#ifdef USE_NEW_BLTZAL_CODE
			ret = Generate_Normal_Branch ( i, Address, (void*) Cpu::ProcessBranchDelaySlot_t<OPBLTZAL> );
#else
			return -1;
#endif
			
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //BLTZAL instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::BGEZAL ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "BGEZAL";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::BGEZAL;
	
	int ret = 1;
	
	switch ( OpLevel )
	{
		case 0:
			// needs to also stop encoding before at level 0, because it requires an updated PC to link
			bStopEncodingBefore = true;
			bStopEncodingAfter = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction ); //BGEZAL );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
#ifdef USE_NEW_BGEZAL_CODE
			ret = Generate_Normal_Branch ( i, Address, (void*) Cpu::ProcessBranchDelaySlot_t<OPBGEZAL> );
#else
			return -1;
#endif
			
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //BGEZAL instruction.\n";
		return -1;
	}
	return 1;
}


/////////////////////////////////////////////////////////////
// Multiply/Divide Instructions

int32_t R5900::Recompiler::MULT ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "MULT";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::MULT;
	
	
	// constant multiply cycles for PS2
	static constexpr int MULTIPLY_CYCLE_TIME = 4 / 2;
	
	
	int ret = 1;
	
	
	switch ( OpLevel )
	{
		case 0:
			// need to stop encoding before at level 0 to get an updated CycleCount
			// need to stop encoding after at level 0 because it updates CycleCount
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction ); //MULT );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
#ifdef USE_NEW_MULT_CODE
			
			// check if mul/div unit is in use
			//if ( r->MulDiv_BusyUntil_Cycle > r->CycleCount )
			//{
			//	// for now, just add onto memory latency
			//	r->CycleCount = r->MulDiv_BusyUntil_Cycle;
			//}

			e->MovRegMem64(RAX, (int64_t*)&r->CycleCount);
			e->MovRegReg64(RCX, RAX);
			e->AddReg64ImmX(RAX, LocalCycleCount);
			
			e->SubRegMem64(RAX, (int64_t*)&r->MulDiv_BusyUntil_Cycle);
			e->Cqo();
			e->AndRegReg64(RDX, RAX);
			
			// store cycle count minus one to the current cycle (because it adds one on return from recompiler for now)
			// or, no need to subtract one if we don't count the cycle for the instruction (can subtract one when resetting the cycle count)

			// note: copilot ai says to actually add to the register and store the value, due to a hidden load otherwise
			// add the REAL CycleCount (CPU) to the cycles for the multiply and store to the BusyUntil Cycle for Mul/Div unit
			e->SubRegReg64(RCX, RDX);
			//e->SubMemReg64 ( (int64_t*) & r->CycleCount, RDX );
			e->MovMemReg64((int64_t*)&r->CycleCount, RCX);
			
			// add in the latency for multiply
			//e->AddReg64ImmX(RCX, MULTIPLY_CYCLE_TIME);
			e->AddReg64ImmX(RCX, MULTIPLY_CYCLE_TIME + LocalCycleCount);

			// write back the new busy until cycle
			e->MovMemReg64((int64_t*)&r->MulDiv_BusyUntil_Cycle, RCX);
			

			/*
			* Optimal path:
				; num1         dd ?      ; 32-bit signed operand1
				; num2         dd ?      ; 32-bit signed operand2
				; low64_a      dq ?      ; first destination for sign-extended low half
				; low64_b      dq ?      ; second destination for sign-extended low half
				; high64       dq ?      ; destination for sign-extended high half

				mov     eax, dword ptr [num1]    ; EAX ? operand1 (low 32 bits)
				imul    dword ptr [num2]         ; signed multiply ? 64-bit in RDX:RAX

				; sign-extend low 32 bits ? 64, store to two QWORDs
				movsxd  rax, eax                 ; RAX ? sign-extended low 32-bit product
				mov     qword ptr [low64_a], rax ; store to first address
				mov     qword ptr [low64_b], rax ; store to second address

				; sign-extend high 32 bits ? 64, store once
				movsxd  rdx, edx                 ; RDX ? sign-extended high 32-bit product
				mov     qword ptr [high64], rdx  ; store high half
			*/


			// do the multiply
			e->MovRegMem32 ( RAX, & r->GPR [ i.Rs ].sw0 );
			e->ImulRegMem32 ( & r->GPR [ i.Rt ].sw0 );
			e->Cdqe ();
			e->MovMemReg64 ( & r->LO.s, RAX );
			e->MovsxdReg64Reg32 ( RDX, RDX );
			ret = e->MovMemReg64 ( & r->HI.s, RDX );
			
			// *note*: the R5900 additionally writes to a destination register
			if ( i.Rd )
			{
				e->MovMemReg64 ( & r->GPR [ i.Rd ].s, RAX );
			}
#else
			return -1;
#endif
			
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //MULT instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::MULTU ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "MULTU";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::MULTU;
	
	
	// constant multiply cycles for PS2
	static constexpr int MULTIPLY_CYCLE_TIME = 4 / 2;
	
	int ret = 1;
	
	
	switch ( OpLevel )
	{
		case 0:
			// need to stop encoding before at level 0 to get an updated CycleCount
			// need to stop encoding after at level 0 because it updates CycleCount
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction ); //MULTU );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
#ifdef USE_NEW_MULTU_CODE
			
			// check if mul/div unit is in use
			//if ( r->MulDiv_BusyUntil_Cycle > r->CycleCount )
			//{
			//	// for now, just add onto memory latency
			//	r->CycleCount = r->MulDiv_BusyUntil_Cycle;
			//}

			e->MovRegMem64(RAX, (int64_t*)&r->CycleCount);
			e->MovRegReg64(RCX, RAX);
			e->AddReg64ImmX(RAX, LocalCycleCount);

			e->SubRegMem64(RAX, (int64_t*)&r->MulDiv_BusyUntil_Cycle);
			e->Cqo();
			e->AndRegReg64(RDX, RAX);

			// store cycle count minus one to the current cycle (because it adds one on return from recompiler for now)
			// or, no need to subtract one if we don't count the cycle for the instruction (can subtract one when resetting the cycle count)

			// note: copilot ai says to actually add to the register and store the value, due to a hidden load otherwise
			// add the REAL CycleCount (CPU) to the cycles for the multiply and store to the BusyUntil Cycle for Mul/Div unit
			e->SubRegReg64(RCX, RDX);
			//e->SubMemReg64 ( (int64_t*) & r->CycleCount, RDX );
			e->MovMemReg64((int64_t*)&r->CycleCount, RCX);

			// add in the latency for multiply
			//e->AddReg64ImmX(RCX, MULTIPLY_CYCLE_TIME);
			e->AddReg64ImmX(RCX, MULTIPLY_CYCLE_TIME + LocalCycleCount);

			// write back the new busy until cycle
			e->MovMemReg64((int64_t*)&r->MulDiv_BusyUntil_Cycle, RCX);

			// do the multiply
			e->MovRegMem32 ( RAX, & r->GPR [ i.Rs ].sw0 );
			e->MulRegMem32 ( & r->GPR [ i.Rt ].sw0 );
			// *** todo for ps2 *** //
			//e->MovMemReg32 ( & r->HiLo.sLo, RAX );
			e->Cdqe ();
			e->MovMemReg64 ( & r->LO.s, RAX );
			//e->MovMemReg32 ( & r->HiLo.sHi, RDX );
			e->MovsxdReg64Reg32 ( RDX, RDX );
			e->MovMemReg64 ( & r->HI.s, RDX );
			
			// *note*: the R5900 additionally writes to a destination register
			if ( i.Rd )
			{
				e->MovMemReg64 ( & r->GPR [ i.Rd ].s, RAX );
			}
#else
			return -1;
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //MULTU instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::DIV ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "DIV";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::DIV;
	
	static constexpr int DIVIDE_CYCLE_TIME = 36 / 2;
	
	int ret = 1;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction ); //DIV );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
			
		case 1:
#ifdef USE_NEW_DIV_CODE
			
			// check if mul/div unit is in use
			//if ( r->MulDiv_BusyUntil_Cycle > r->CycleCount )
			//{
			//	// for now, just add onto memory latency
			//	r->CycleCount = r->MulDiv_BusyUntil_Cycle;
			//}

			e->MovRegMem64(RAX, (int64_t*)&r->CycleCount);
			e->MovRegReg64(RCX, RAX);
			e->AddReg64ImmX(RAX, LocalCycleCount);

			e->SubRegMem64(RAX, (int64_t*)&r->MulDiv_BusyUntil_Cycle);
			e->Cqo();
			e->AndRegReg64(RDX, RAX);

			// store cycle count minus one to the current cycle (because it adds one on return from recompiler for now)
			// or, no need to subtract one if we don't count the cycle for the instruction (can subtract one when resetting the cycle count)

			// note: copilot ai says to actually add to the register and store the value, due to a hidden load otherwise
			// add the REAL CycleCount (CPU) to the cycles for the multiply and store to the BusyUntil Cycle for Mul/Div unit
			e->SubRegReg64(RCX, RDX);
			//e->SubMemReg64 ( (int64_t*) & r->CycleCount, RDX );
			e->MovMemReg64((int64_t*)&r->CycleCount, RCX);

			// add in the latency for multiply
			//e->AddReg64ImmX(RCX, DIVIDE_CYCLE_TIME);
			e->AddReg64ImmX(RCX, DIVIDE_CYCLE_TIME + LocalCycleCount);

			// write back the new busy until cycle
			e->MovMemReg64((int64_t*)&r->MulDiv_BusyUntil_Cycle, RCX);

			
			// mult/div unit is busy now
			//r->MulDiv_BusyUntil_Cycle = r->CycleCount + c_iDivideCycles;
			// add the REAL CycleCount (CPU) to the cycles for the multiply and store to the BusyUntil Cycle for Mul/Div unit
			//e->AddReg64ImmX ( RAX, c_iDivideCycles );
			//e->MovMemReg64 ( (int64_t*) & r->MulDiv_BusyUntil_Cycle, RAX );
#ifdef USE_EXCEPTIONS_R5900_DIV

			e->MovRegMem32(RAX, (int32_t*)&r->GPR[i.Rs].s);
			e->MovRegMem32(RCX, (int32_t*)&r->GPR[i.Rt].s);
			e->Cdq();

			e->IdivRegReg32(RCX);

			e->Cdqe();
			e->MovsxdReg64Reg32(RDX, RDX);

			e->MovMemReg64(&r->LO.s, RAX);
			e->MovMemReg64(&r->HI.s, RDX);

#else


			// divide signed: Lo = rs / rt; Hi = rs % rt
			//if ( r->GPR [ i.Rt ].s != 0 )
			//{
			//	// if rs = 0x80000000 and rt = -1 then hi = 0 and lo = 0x80000000
			//	if ( r->GPR [ i.Rs ].s == 0x80000000 && r->GPR [ i.Rt ].s == -1 )
			//	{
			//		r->HiLo.uHi = 0;
			//		r->HiLo.uLo = 0x80000000;
			//	}
			//	else
			//	{
			//		r->HiLo.sLo = r->GPR [ i.Rs ].s / r->GPR [ i.Rt ].s;
			//		r->HiLo.sHi = r->GPR [ i.Rs ].s % r->GPR [ i.Rt ].s;
			//	}
			//}
			//else
			//{
			//	if ( r->GPR [ i.Rs ].s < 0 )
			//	{
			//		r->HiLo.sLo = 1;
			//	}
			//	else
			//	{
			//		r->HiLo.sLo = -1;
			//	}
			//	r->HiLo.uHi = r->GPR [ i.Rs ].u;
			//}
			//e->MovRegMem32 ( RCX, & r->GPR [ i.Rt ].s );
			//e->MovRegMem32 ( RAX, & r->GPR [ i.Rs ].s );
			e->MovsxdReg64Mem32 ( RAX, & r->GPR [ i.Rs ].sw0 );
			e->MovsxdReg64Mem32 ( RCX, & r->GPR [ i.Rt ].sw0 );


			e->Cqo ();
			e->NotReg64 ( RDX );
			e->OrReg64ImmX ( RDX, 1 );
			
			e->Jmp8_ECXZ ( 0, 0 );
			
			e->Cdq ();
			//e->IdivRegReg64 ( RCX );
			e->IdivRegReg32 ( RCX );

			e->Cdqe ();
			e->XchgRegReg64 ( RAX, RDX );
			e->Cdqe();

			e->SetJmpTarget8 ( 0 );
			
			
			e->MovMemReg64 ( & r->HI.s, RAX );
			e->MovMemReg64 ( & r->LO.s, RDX );

#endif
			
			// done //
#else
			return -1;
#endif
			
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //DIV instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::DIVU ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "DIVU";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::DIVU;
	
	static constexpr int DIVIDE_CYCLE_TIME = 36 / 2;
	
	int ret = 1;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			// actually needs to stop encoding before for now, because the correct current cycle count is needed
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction ); //DIVU );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
#ifdef USE_NEW_DIVU_CODE
			
			// check if mul/div unit is in use
			//if ( r->MulDiv_BusyUntil_Cycle > r->CycleCount )
			//{
			//	// for now, just add onto memory latency
			//	r->CycleCount = r->MulDiv_BusyUntil_Cycle;
			//}

			e->MovRegMem64(RAX, (int64_t*)&r->CycleCount);
			e->MovRegReg64(RCX, RAX);
			e->AddReg64ImmX(RAX, LocalCycleCount);

			e->SubRegMem64(RAX, (int64_t*)&r->MulDiv_BusyUntil_Cycle);
			e->Cqo();
			e->AndRegReg64(RDX, RAX);

			// store cycle count minus one to the current cycle (because it adds one on return from recompiler for now)
			// or, no need to subtract one if we don't count the cycle for the instruction (can subtract one when resetting the cycle count)

			// note: copilot ai says to actually add to the register and store the value, due to a hidden load otherwise
			// add the REAL CycleCount (CPU) to the cycles for the multiply and store to the BusyUntil Cycle for Mul/Div unit
			e->SubRegReg64(RCX, RDX);
			//e->SubMemReg64 ( (int64_t*) & r->CycleCount, RDX );
			e->MovMemReg64((int64_t*)&r->CycleCount, RCX);

			// add in the latency for multiply
			//e->AddReg64ImmX(RCX, DIVIDE_CYCLE_TIME);
			e->AddReg64ImmX(RCX, DIVIDE_CYCLE_TIME + LocalCycleCount);

			// write back the new busy until cycle
			e->MovMemReg64((int64_t*)&r->MulDiv_BusyUntil_Cycle, RCX);

#ifdef USE_EXCEPTIONS_R5900_DIV

			e->MovRegMem32(RAX, (int32_t*)&r->GPR[i.Rs].s);
			e->MovRegMem32(RCX, (int32_t*)&r->GPR[i.Rt].s);
			//e->Cdq();
			e->XorRegReg32(RDX, RDX);

			e->DivRegReg32(RCX);

			e->Cdqe();
			e->MovsxdReg64Reg32(RDX, RDX);

			e->MovMemReg64(&r->LO.s, RAX);
			e->MovMemReg64(&r->HI.s, RDX);

#else

			// mult/div unit is busy now
			//r->MulDiv_BusyUntil_Cycle = r->CycleCount + c_iDivideCycles;
			// add the REAL CycleCount (CPU) to the cycles for the multiply and store to the BusyUntil Cycle for Mul/Div unit
			//e->AddReg64ImmX ( RAX, c_iDivideCycles );
			//e->MovMemReg64 ( (int64_t*) & r->MulDiv_BusyUntil_Cycle, RAX );
			
			// divide unsigned: Lo = rs / rt; Hi = rs % rt
			//if ( r->GPR [ i.Rt ].s != 0 )
			//{
			//	r->HiLo.uLo = r->GPR [ i.Rs ].s / r->GPR [ i.Rt ].u;
			//	r->HiLo.uHi = r->GPR [ i.Rs ].s % r->GPR [ i.Rt ].u;
			//}
			//else
			//{
			//	r->HiLo.sLo = -1;
			//	r->HiLo.uHi = r->GPR [ i.Rs ].u;
			//}
			e->MovRegMem32 ( RCX, & r->GPR [ i.Rt ].sw0 );
			e->MovRegMem32 ( RAX, & r->GPR [ i.Rs ].sw0 );
			
			e->MovReg64ImmX ( RDX, -1 );
			
			e->Jmp8_ECXZ ( 0, 0 );
			
			e->XorRegReg32 ( RDX, RDX );
			e->DivRegReg32 ( RCX );

			e->Cdqe ();
			e->XchgRegReg64 ( RAX, RDX );
			e->Cdqe();

			e->SetJmpTarget8 ( 0 );
			
			e->MovMemReg64 ( & r->LO.s, RDX );
			e->MovMemReg64 ( & r->HI.s, RAX );

#endif
			
			// done //
#else
			return -1;
#endif
			
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //DIVU instruction.\n";
		return -1;
	}
	return 1;
}



int32_t R5900::Recompiler::MFHI ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "MFHI";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::MFHI;
	
	//if ( r->MulDiv_BusyUntil_Cycle > r->CycleCount )
	//{
	//	r->CycleCount = r->MulDiv_BusyUntil_Cycle;
	//}
	//r->GPR [ i.Rd ].u = r->HiLo.uHi;
	//CHECK_DELAYSLOT ( i.Rd );
	
	int ret = 1;
	
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction (can update CycleCount)
			bStopEncodingAfter = true;
			
			// for now, stop encoding before, because an updated CycleCount is needed to determine if Mul/Div is done
			bStopEncodingBefore = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction ); //MFHI );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			// make sure Rd is not r0
			if ( !i.Rd )
			{
				// make sure r0 stays at zero
				ret = e->MovMemImm64 ( &r->GPR [ 0 ].s, 0 );
			}
			break;
			
		case 1:
#ifdef USE_NEW_MFHI_CODE
			/*
			e->MovRegFromMem64 ( RAX, (int64_t*) & r->CycleCount );
			e->CmpRegMem64 ( RAX, &r->MulDiv_BusyUntil_Cycle );
			e->CmovBRegMem64 ( RAX, &r->MulDiv_BusyUntil_Cycle );
			ret = e->MovRegToMem64 ( (int64_t*) & r->CycleCount, RAX );
			if ( i.Rd )
			{
				e->MovRegFromMem32 ( RAX, &r->HiLo.uHi );
				ret = e->MovRegToMem32 ( &r->GPR [ i.Rd ].s, RAX );
			}
			Local_LastModifiedReg = i.Rd;
			*/
			
			// this instruction interlocks if multiply/divide unit is busy
			//if ( r->MulDiv_BusyUntil_Cycle > r->CycleCount )
			//{
			//	// for now, just add onto memory latency
			//	r->CycleCount = r->MulDiv_BusyUntil_Cycle;
			//}
			e->MovRegMem64 ( RAX, (int64_t*) & r->CycleCount );
			//e->MovRegMem64 ( RCX, (int64_t*) & r->MulDiv_BusyUntil_Cycle );
			e->AddReg64ImmX ( RAX, LocalCycleCount );
			
			//e->XorRegReg64 ( RDX, RDX );
			e->SubRegMem64 ( RAX, (int64_t*) & r->MulDiv_BusyUntil_Cycle );
			//e->CmovBRegReg64 ( RDX, RAX );
			e->Cqo ();
			e->AndRegReg64 ( RDX, RAX );
			
			// store cycle count minus one to the current cycle (because it adds one on return from recompiler for now)
			//e->MovMemReg64 ( (int64_t*) & r->CycleCount, RAX );
			e->SubMemReg64 ( (int64_t*) & r->CycleCount, RDX );
			
			// move from Hi register
			//r->GPR [ i.Rd ].u = r->HiLo.uHi;
			//CHECK_DELAYSLOT ( i.Rd );
			if ( i.Rd )
			{
				//e->MovRegMem32 ( RAX, & r->HiLo.uHi );
				e->MovRegMem64 ( RAX, & r->HI.s );
				//e->MovMemReg32 ( & r->GPR [ i.Rd ].s, RAX );
				e->MovMemReg64 ( & r->GPR [ i.Rd ].s, RAX );
			}
#else
			return -1;
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //MFHI instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::MFLO ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "MFLO";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::MFLO;
	
	int ret = 1;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction (can update CycleCount)
			bStopEncodingAfter = true;
			
			// for now, stop encoding before, because an updated CycleCount is needed to determine if Mul/Div is done
			bStopEncodingBefore = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction ); //MFLO );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			// make sure Rd is not r0
			if ( !i.Rd )
			{
				// make sure r0 stays at zero
				ret = e->MovMemImm64 ( &r->GPR [ 0 ].s, 0 );
			}
			break;
			
		case 1:
#ifdef USE_NEW_MFLO_CODE
			/*
			e->MovRegFromMem64 ( RAX, (int64_t*) & r->CycleCount );
			e->CmpRegMem64 ( RAX, &r->MulDiv_BusyUntil_Cycle );
			e->CmovBRegMem64 ( RAX, &r->MulDiv_BusyUntil_Cycle );
			ret = e->MovRegToMem64 ( (int64_t*) & r->CycleCount, RAX );
			if ( i.Rd )
			{
				e->MovRegFromMem32 ( RAX, &r->HiLo.uLo );
				ret = e->MovRegToMem32 ( &r->GPR [ i.Rd ].s, RAX );
			}
			Local_LastModifiedReg = i.Rd;
			*/
			
			// this instruction interlocks if multiply/divide unit is busy
			//if ( r->MulDiv_BusyUntil_Cycle > r->CycleCount )
			//{
			//	// for now, just add onto memory latency
			//	r->CycleCount = r->MulDiv_BusyUntil_Cycle;
			//}
			e->MovRegMem64 ( RAX, (int64_t*) & r->CycleCount );
			//e->MovRegMem64 ( RCX, (int64_t*) & r->MulDiv_BusyUntil_Cycle );
			e->AddReg64ImmX ( RAX, LocalCycleCount );
			
			//e->XorRegReg64 ( RDX, RDX );
			e->SubRegMem64 ( RAX, (int64_t*) & r->MulDiv_BusyUntil_Cycle );
			//e->CmovBRegReg64 ( RDX, RAX );
			e->Cqo ();
			e->AndRegReg64 ( RDX, RAX );
			
			// store cycle count minus one to the current cycle (because it adds one on return from recompiler for now)
			//e->MovMemReg64 ( (int64_t*) & r->CycleCount, RAX );
			e->SubMemReg64 ( (int64_t*) & r->CycleCount, RDX );
			
			// move from Lo register
			//r->GPR [ i.Rd ].u = r->HiLo.uLo;
			//CHECK_DELAYSLOT ( i.Rd );
			if ( i.Rd )
			{
				//e->MovRegMem32 ( RAX, & r->HiLo.uLo );
				e->MovRegMem64 ( RAX, & r->LO.s );
				//e->MovMemReg32 ( & r->GPR [ i.Rd ].s, RAX );
				e->MovMemReg64 ( & r->GPR [ i.Rd ].s, RAX );
			}
#else
			return -1;
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //MFLO instruction.\n";
		return -1;
	}
	return 1;
}




int32_t R5900::Recompiler::MTHI ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "MTHI";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::MTHI;
	
	//r->HiLo.uHi = r->GPR [ i.Rs ].u;
	
	// ***TODO*** should this sync with mul/div unit??
	
	int ret = 1;
	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction ); //MTHI );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
			//e->MovRegFromMem32 ( RAX, &r->GPR [ i.Rs ].sw0 );
			e->MovRegMem64 ( RAX, &r->GPR [ i.Rs ].s );
			//ret = e->MovRegToMem32 ( &r->HiLo.uHi, RAX );
			ret = e->MovMemReg64 ( &r->HI.s, RAX );
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //MTHI instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::MTLO ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "MTLO";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::MTLO;
	
	//r->HiLo.uLo = r->GPR [ i.Rs ].u;
	
	// ***TODO*** should this sync with mul/div unit??
	
	int ret = 1;
	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction ); //MTLO );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
			//e->MovRegFromMem32 ( RAX, &r->GPR [ i.Rs ].sw0 );
			e->MovRegMem64 ( RAX, &r->GPR [ i.Rs ].s );
			//ret = e->MovRegToMem32 ( &r->HiLo.uLo, RAX );
			ret = e->MovMemReg64 ( &r->LO.s, RAX );
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //MTLO instruction.\n";
		return -1;
	}
	return 1;
}








////////////////////////////////////////////////////////
// Instructions that can cause Synchronous Interrupts //
////////////////////////////////////////////////////////


int32_t R5900::Recompiler::ADD ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "ADD";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::ADD;
	
	int ret = 1;
	
	switch ( OpLevel )
	{
		case 0:
			// go ahead and say that it modifies NextPC since it might, even if it does not this time around
			// but only if instruction is actually encoded
			Local_NextPCModified = true;
			
			// need to stop encoding before, because if it sync ints, that requires PC to be updated
			bStopEncodingBefore = true;
			
			// need to stop encoding after because if it sync ints, then it needs to "jump"
			bStopEncodingAfter = true;
			
			// update NextPC before executing instruction at level 0 since it may do a sync int
			e->MovMemImm32 ( (int32_t*) & r->NextPC, Address + 4 );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction ); //ADD );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			if ( !i.Rd )
			{
				// make sure r0 stays at zero
				ret = e->MovMemImm64 ( &r->GPR [ 0 ].s, 0 );
			}
			
			break;
			
		case 1:
#ifdef USE_NEW_ADD_CODE
			e->MovRegFromMem32 ( RAX, &r->GPR [ i.Rs ].sw0 );
			e->AddRegMem32 ( RAX, &r->GPR [ i.Rt ].sw0 );
			
			if ( i.Rs && i.Rt )
			{
#ifdef USE_NEW_ADD_SEQUENCE_R5900

				e->MovRegImm32(RCX, Address);
				e->MovRegImm32(RDX, LocalCycleCount);
				e->JMP_O((void*)Cpu::ProcessSynchronousInterrupt2_t<Cpu::EXC_OV>);

#else
				// branch if not signed overflow
				e->Jmp8_NO ( 0, 0 );
				
				// update CycleCount, set PC, then jump to synchronous interrupt
				//e->MovMemReg64 ( (int64_t*) & r->CycleCount, RAX );
				e->AddMem64ImmX ( (int64_t*) & r->CycleCount, LocalCycleCount + MemCycles );
				//e->AddMem64ImmX ( (int64_t*) & r->CycleCount, LocalCycleCount );
				
				// set pc
				e->MovMemImm32 ( (int32_t*) & r->PC, Address );
				
				//r->ProcessSynchronousInterrupt ( Cpu::EXC_OV );
				e->JMP ( (void*) Cpu::ProcessSynchronousInterrupt_t<Cpu::EXC_OV> );
				
				// continue processing store from here //
				e->SetJmpTarget8 ( 0 );
#endif
			}
			
			// check if destination is r0
			if ( i.Rd )
			{
				// store result if not signed overflow
				e->Cdqe ();
				ret = e->MovMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
			}
#else
			return -1;
#endif
			
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //ADD instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::ADDI ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "ADDI";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::ADDI;
	
	int ret = 1;
	
	switch ( OpLevel )
	{
		case 0:
			// go ahead and say that it modifies NextPC since it might, even if it does not this time around
			// but only if instruction is actually encoded
			Local_NextPCModified = true;
			
			// need to stop encoding before, because if it sync ints, that requires PC to be updated
			bStopEncodingBefore = true;
			
			// need to stop encoding after because if it sync ints, then it needs to "jump"
			bStopEncodingAfter = true;
			
			// update NextPC before executing instruction at level 0 since it may do a sync int
			e->MovMemImm32 ( (int32_t*) & r->NextPC, Address + 4 );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction ); //ADDI );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			if ( !i.Rt )
			{
				// make sure r0 stays at zero
				ret = e->MovMemImm64 ( &r->GPR [ 0 ].s, 0 );
			}
			
			break;
			
		case 1:
#ifdef USE_NEW_ADDI_CODE
			e->MovRegFromMem32 ( RAX, &r->GPR [ i.Rs ].sw0 );
			//e->AddRegMem32 ( RAX, &r->GPR [ i.Rt ].s );
			e->AddReg32ImmX ( RAX, i.sImmediate );
			
			if ( i.Rs && i.sImmediate )
			{
#ifdef USE_NEW_ADDI_SEQUENCE_R5900

				e->MovRegImm32(RCX, Address);
				e->MovRegImm32(RDX, LocalCycleCount);
				e->JMP_O((void*)Cpu::ProcessSynchronousInterrupt2_t<Cpu::EXC_OV>);

#else
				// branch if not signed overflow
				e->Jmp8_NO ( 0, 0 );
				
				// update CycleCount, set PC, then jump to synchronous interrupt
				//e->MovMemReg64 ( (int64_t*) & r->CycleCount, RAX );
				e->AddMem64ImmX ( (int64_t*) & r->CycleCount, LocalCycleCount + MemCycles );
				//e->AddMem64ImmX ( (int64_t*) & r->CycleCount, LocalCycleCount );
				
				// set pc
				e->MovMemImm32 ( (int32_t*) & r->PC, Address );
				
				//r->ProcessSynchronousInterrupt ( Cpu::EXC_OV );
				e->JMP ( (void*) Cpu::ProcessSynchronousInterrupt_t<Cpu::EXC_OV> );
				
				// continue processing store from here //
				e->SetJmpTarget8 ( 0 );
#endif
			}
			
			// check if destination is r0
			if ( i.Rt )
			{
				// store result if not signed overflow
				e->Cdqe ();
				ret = e->MovMemReg64 ( &r->GPR [ i.Rt ].s, RAX );
			}
#else
			return -1;
#endif
			
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //ADDI instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::SUB ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "SUB";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::SUB;
	
	int ret = 1;
	
	switch ( OpLevel )
	{
		case 0:
			// go ahead and say that it modifies NextPC since it might, even if it does not this time around
			// but only if instruction is actually encoded
			Local_NextPCModified = true;
			
			// need to stop encoding before, because if it sync ints, that requires PC to be updated
			bStopEncodingBefore = true;
			
			// need to stop encoding after because if it sync ints, then it needs to "jump"
			bStopEncodingAfter = true;
			
			// update NextPC before executing instruction at level 0 since it may do a sync int
			e->MovMemImm32 ( (int32_t*) & r->NextPC, Address + 4 );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction ); //SUB );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			if ( !i.Rd )
			{
				// make sure r0 stays at zero
				ret = e->MovMemImm64 ( &r->GPR [ 0 ].s, 0 );
			}
			break;
			
		case 1:
#ifdef USE_NEW_SUB_CODE
			e->MovRegFromMem32 ( RAX, &r->GPR [ i.Rs ].sw0 );
			e->SubRegMem32 ( RAX, &r->GPR [ i.Rt ].sw0 );
			
			if ( i.Rt )
			{
				// branch if not signed overflow
				e->Jmp8_NO ( 0, 0 );
				
				// update CycleCount, set PC, then jump to synchronous interrupt
				e->AddMem64ImmX((int64_t*)&r->CycleCount, LocalCycleCount);
				
				// set pc
				e->MovMemImm32 ( (int32_t*) & r->PC, Address );
				
				//r->ProcessSynchronousInterrupt ( Cpu::EXC_OV );
				e->JMP ( (void*) Cpu::ProcessSynchronousInterrupt_t<Cpu::EXC_OV> );
				
				// continue processing store from here //
				e->SetJmpTarget8 ( 0 );
			}
			
			// check if destination is r0
			if ( i.Rd )
			{
				// store result if not signed overflow
				e->Cdqe ();
				ret = e->MovMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
			}
#else
			return -1;
#endif
			
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //SUB instruction.\n";
		return -1;
	}
	return 1;
}




int32_t R5900::Recompiler::SYSCALL ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "SYSCALL";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::SYSCALL;
	
	int ret = 1;
	
	// stop encoding after since it is an unconditional synchronous interrupt
	bStopEncodingAfter = true;
	
	// this instruction always has a synchronous interrupt
	Local_NextPCModified = true;
	
	
	switch ( OpLevel )
	{
		case 0:
			
			// stop encoding before due to synchronous interrupt (needs updated PC,LastPC)
			bStopEncodingBefore = true;
			
			// update NextPC before executing instruction at level 0 since it may do a sync int
			// note: no need for this since it is an unconditional sync int and stopped encoding before
			//e->MovMemImm32 ( (int32_t*) & r->NextPC, Address + 4 );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction ); //SYSCALL );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
			
#ifdef USE_NEW_SYSCALL_CODE
			// update CycleCount, set PC, then jump to synchronous interrupt
#ifdef ENABLE_R5900_BRANCH_PREDICTION_SYSCALL
			e->AddMem64ImmX ( (int64_t*) & r->CycleCount, LocalCycleCount + r->c_ullLatency_BranchMisPredict );
#else
			e->AddMem64ImmX ( (int64_t*) & r->CycleCount, LocalCycleCount );
#endif
			
			// set pc
			e->MovMemImm32 ( (int32_t*) & r->PC, Address );
			
			//r->ProcessSynchronousInterrupt ( Cpu::EXC_SYSCALL );
			e->JMP ( (void*) Cpu::ProcessSynchronousInterrupt_t<Cpu::EXC_SYSCALL> );
#else
			return -1;
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //SYSCALL instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::BREAK ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "BREAK";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::BREAK;
	
	int ret = 1;
	
	// stop encoding after since it is an unconditional synchronous interrupt
	bStopEncodingAfter = true;
	
	// this instruction always has a synchronous interrupt
	Local_NextPCModified = true;
	
	switch ( OpLevel )
	{
		case 0:
			// also need to stop encoding before, because it needs both PC and LastPC updated first
			bStopEncodingBefore = true;
			
			// update NextPC before executing instruction at level 0 since it may do a sync int
			// note: no need for this since it is an unconditional sync int
			//e->MovMemImm32 ( (int32_t*) & r->NextPC, Address + 4 );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction ); //BREAK );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //BREAK instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::Invalid ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "Invalid";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::Invalid;
	
	int ret = 1;
	
	// stop encoding after since it is an unconditional synchronous interrupt
	bStopEncodingAfter = true;
	
	// this instruction always has a synchronous interrupt
	Local_NextPCModified = true;
	
	switch ( OpLevel )
	{
		case 0:
			// also need to stop encoding before, because it needs both PC and LastPC updated first
			bStopEncodingBefore = true;
			
			// update NextPC before executing instruction at level 0 since it may do a sync int
			// note: no need for this since it is an unconditional sync int
			//e->MovMemImm32 ( (int32_t*) & r->NextPC, Address + 4 );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction ); //Invalid );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //Invalid instruction.\n";
		return -1;
	}
	return 1;
}





int32_t R5900::Recompiler::MFC0 ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "MFC0";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::MFC0;
	
	int ret = 1;
	
	// *testing*
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// should put something in delay slot, so return after this instruction at level 0
			bStopEncodingAfter = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction ); //MFC0 );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
			e->MovRegImm32 ( RCX, i.Rd );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->Call ( (void*) R5900::Cpu::Read_MFC0 );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->Cdqe ();
			e->MovMemReg64 ( & r->GPR [ i.Rt ].s, RAX );
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //MFC0 instruction.\n";
		return -1;
	}
	return 1;
}




int32_t R5900::Recompiler::MTC0 ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "MTC0";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::MTC0;
	
	int ret = 1;
	
	// *testing*
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// should put something in delay slot, so return after this instruction at level 0
			bStopEncodingAfter = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction ); //MTC0 );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			break;
			
		case 1:
			e->MovRegImm32 ( RCX, i.Rd );
			e->MovRegMem32 ( RDX, & r->GPR [ i.Rt ].sw0 );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->Call ( (void*) R5900::Cpu::Write_MTC0 );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //MTC0 instruction.\n";
		return -1;
	}
	return 1;
}








int32_t R5900::Recompiler::CFC2_I ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "CFC2_I";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::CFC2_I;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	
	// probably needs an updated CycleCount, so need to stop encoding before too for now
	//bStopEncodingBefore = true;
	
	// to keep accurate cycle count, update minus 1 after the instruction
	//bResetCycleCount = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			
			// probably needs an updated CycleCount, so need to stop encoding before too for now
			bStopEncodingBefore = true;
			
			// should assume NextPC might get modified
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction ); //CFC2 );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //CFC2 instruction.\n";
		return -1;
	}
	return 1;
}



int32_t R5900::Recompiler::CTC2_I ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "CTC2_I";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::CTC2_I;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	
	// probably needs an updated CycleCount, so need to stop encoding before too for now
	//bStopEncodingBefore = true;
	
	// to keep accurate cycle count, update minus 1 after the instruction
	//bResetCycleCount = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			
			// probably needs an updated CycleCount, so need to stop encoding before too for now
			bStopEncodingBefore = true;
			
			// should assume NextPC might get modified
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction ); //CTC2 );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //CTC2 instruction.\n";
		return -1;
	}
	return 1;
}



int32_t R5900::Recompiler::CFC2_NI ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "CFC2_NI";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::CFC2_NI;
	
	int ret = 1;
	
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			
			// probably needs an updated CycleCount, so need to stop encoding before too for now
			bStopEncodingBefore = true;
			
			// to keep accurate cycle count, update minus 1 after the instruction
			bResetCycleCount = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction ); //CFC2 );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
#ifdef USE_NEW_CFC2_NI_CODE
		case 1:
			if ( i.Rt )
			{
				switch ( i.Rd )
				{
					case 0:
						e->MovMemImm64 ( &r->GPR [ i.Rt ].sq0, 0 );
						break;
						
					case 28:
						e->MovRegMem32 ( RAX, &VU0::_VU0->vi [ i.Rd ].s );
						e->AndReg32ImmX ( RAX, 0xc0c );
						e->MovMemReg64 ( &r->GPR [ i.Rt ].sq0, RAX );
						break;
						
					default:
						e->MovsxdReg64Mem32 ( RAX, &VU0::_VU0->vi [ i.Rd ].s );
						e->MovMemReg64 ( &r->GPR [ i.Rt ].sq0, RAX );
						break;
				}
			}
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //CFC2 instruction.\n";
		return -1;
	}
	return 1;
}



int32_t R5900::Recompiler::CTC2_NI ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "CTC2_NI";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::CTC2_NI;
	
	int ret = 1;
	
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			
			// probably needs an updated CycleCount, so need to stop encoding before too for now
			bStopEncodingBefore = true;
			
			// to keep accurate cycle count, update minus 1 after the instruction
			bResetCycleCount = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction ); //CTC2 );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_CTC2_NI_CODE
		case 1:
			if ( i.Rd )
			{
				if ( i.Rd == 28 )
				{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
					e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

					e->LoadImm32 ( RCX, i.Value );
					ret = e->Call ( c_vFunction ); //CTC2 );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
					ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
				}
				else if ( i.Rd == 16 )
				{
					e->MovRegMem32 ( RAX, &r->GPR [ i.Rt ].sw0 );
					e->MovRegMem32 ( RCX, &VU0::_VU0->vi [ i.Rd ].s );
					e->AndReg32ImmX ( RAX, 0xfc0 );
					e->AndReg32ImmX ( RCX, 0x3f );
					e->OrRegReg32 ( RAX, RCX );
					e->MovMemReg32 ( &VU0::_VU0->vi [ i.Rd ].s, RAX );
				}
				else
				{
					if ( !i.Rt )
					{
						e->MovMemImm32 ( &VU0::_VU0->vi [ i.Rd ].s, 0 );
					}
					else
					{
						e->MovRegMem32 ( RAX, &r->GPR [ i.Rt ].sw0 );
						e->MovMemReg32 ( &VU0::_VU0->vi [ i.Rd ].s, RAX );
					}
				}
			}
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //CTC2 instruction.\n";
		return -1;
	}
	return 1;
}




// Load/Store - will need to use address translation to get physical addresses when needed

//////////////////////////////////////////////////////////////////////////
// store instructions

// store instructions
int32_t R5900::Recompiler::SB ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "SB";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::SB;
	
	int ret = 1;
	
/*
	// for now, stop encoding after this instruction
	// should be able to stop before, but continue after
#ifndef ENABLE_STORE_PREFIX
	bStopEncodingBefore = true;
#endif
#ifndef ENABLE_STORE_SUFFIX
	bStopEncodingAfter = true;
#endif
*/
	
	switch ( OpLevel )
	{
#ifdef USE_NEW_SB_CODE2
		case -1:
			// source registers are Rs and Rt
			ullSrcRegBitmap |= ( 1ull << i.Rs ) | ( 1ull << i.Rt );
			
			break;
#endif
			
		case 0:
			// can just stop encoding before and ignore the prefix requirement at level 0 for testing
			bStopEncodingBefore = true;
			//bStopEncodingAfter = true;
		
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

#ifdef ENABLE_R5900_DCACHE
			e->AddMemImm64 ( (int64_t*) & r->CycleCount, LocalCycleCount - MemCycles );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction ); //SB );

#ifdef ENABLE_R5900_DCACHE
			e->SubMemImm64 ( (int64_t*) & r->CycleCount, LocalCycleCount - MemCycles );
#endif
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
#ifdef USE_NEW_STORE_CODE

#ifdef ENABLE_PS2_VIRTUAL_MACHINE_SB
			if (!bitget_hwrw_bitmap(Address))
			{
				ret = Generate_Virtual_Store(i, Address, 0x0, (void*)Playstation2::DataBus::Write_t<0xffULL>);
			}
			else
#endif
			{
				ret = Generate_Normal_Store(i, Address, 0x0, (void*)Playstation2::DataBus::Write_t<0xffULL>);
			}

#else
			return -1;
#endif	// end #ifdef USE_NEW_STORE_CODE

			break;
			
#ifdef USE_NEW_SB_CODE2
		case 2:
			if ( isConst ( i.Rs ) )
			{
				ret = Generate_Normal_Store_L2 ( i, Address, 0x0, GetConst( i.Rs ) );
				if ( !ret ) return -1;
			}
			else
			{
				return -1;
			}
			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //SB instruction.\n";
		return -1;
	}
	return 1;
}





int32_t R5900::Recompiler::SH ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "SH";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::SH;
	
	int ret = 1;
	
/*
	// for now, stop encoding after this instruction
#ifndef ENABLE_STORE_PREFIX
	bStopEncodingBefore = true;
#endif
#ifndef ENABLE_STORE_SUFFIX
	bStopEncodingAfter = true;
#endif
*/
	
	switch ( OpLevel )
	{
#ifdef USE_NEW_SH_CODE2
		case -1:
			// source registers are Rs and Rt
			ullSrcRegBitmap |= ( 1ull << i.Rs ) | ( 1ull << i.Rt );
			
			break;
#endif
			
		case 0:
			// can just stop encoding before and ignore the prefix requirement at level 0 for testing
			bStopEncodingBefore = true;
			//bStopEncodingAfter = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

#ifdef ENABLE_R5900_DCACHE
			e->AddMemImm64 ( (int64_t*) & r->CycleCount, LocalCycleCount - MemCycles );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction ); //SH );

#ifdef ENABLE_R5900_DCACHE
			e->SubMemImm64 ( (int64_t*) & r->CycleCount, LocalCycleCount - MemCycles );
#endif
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

			
		case 1:
#ifdef USE_NEW_STORE_CODE

#ifdef ENABLE_PS2_VIRTUAL_MACHINE_SH
			if (!bitget_hwrw_bitmap(Address))
			{
				ret = Generate_Virtual_Store(i, Address, 0x1, (void*)Playstation2::DataBus::Write_t<0xffffULL>);
			}
			else
#endif
			{
				ret = Generate_Normal_Store(i, Address, 0x1, (void*)Playstation2::DataBus::Write_t<0xffffULL>);
			}

#else

			return -1;

#endif	// end #ifdef USE_NEW_STORE_CODE

			break;
			
#ifdef USE_NEW_SH_CODE2
		case 2:
			if ( isConst ( i.Rs ) )
			{
				ret = Generate_Normal_Store_L2 ( i, Address, 0x1, GetConst( i.Rs ) );
				if ( !ret ) return -1;
			}
			else
			{
				return -1;
			}
			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //SH instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::SW ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "SW";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::SW;
	
	int ret = 1;
	
/*
	// for now, stop encoding after this instruction
#ifndef ENABLE_STORE_PREFIX
	bStopEncodingBefore = true;
#endif
#ifndef ENABLE_STORE_SUFFIX
	bStopEncodingAfter = true;
#endif
*/
	
	switch ( OpLevel )
	{
#ifdef USE_NEW_SW_CODE2
		case -1:
			// source registers are Rs and Rt
			ullSrcRegBitmap |= ( 1ull << i.Rs ) | ( 1ull << i.Rt );
			
			break;
#endif
			
		case 0:
			// can just stop encoding before and ignore the prefix requirement at level 0 for testing
			bStopEncodingBefore = true;
			//bStopEncodingAfter = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

#ifdef ENABLE_R5900_DCACHE
			e->AddMemImm64 ( (int64_t*) & r->CycleCount, LocalCycleCount - MemCycles );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction ); //SW );

#ifdef ENABLE_R5900_DCACHE
			e->SubMemImm64 ( (int64_t*) & r->CycleCount, LocalCycleCount - MemCycles );
#endif
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		
		case 1:
#ifdef USE_NEW_STORE_CODE

#ifdef ENABLE_PS2_VIRTUAL_MACHINE_SW
			if (!bitget_hwrw_bitmap(Address))
			{
				ret = Generate_Virtual_Store(i, Address, 0x3, (void*)Playstation2::DataBus::Write_t<0xffffffffULL>);
			}
			else
#endif
			{
				ret = Generate_Normal_Store(i, Address, 0x3, (void*)Playstation2::DataBus::Write_t<0xffffffffULL>);
			}

#else

			return -1;

#endif	// end #ifdef USE_NEW_STORE_CODE

			break;
			
#ifdef USE_NEW_SW_CODE2
		case 2:
			if ( isConst ( i.Rs ) )
			{
				ret = Generate_Normal_Store_L2 ( i, Address, 0x3, GetConst( i.Rs ) );
				if ( !ret ) return -1;
			}
			else
			{
				return -1;
			}
			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //SW instruction.\n";
		return -1;
	}
	return 1;
}





int32_t R5900::Recompiler::SWL ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "SWL";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::SWL;
	
	int ret = 1;
	
/*
	// for now, stop encoding after this instruction
#ifndef ENABLE_STORE_PREFIX
	bStopEncodingBefore = true;
#endif
#ifndef ENABLE_STORE_SUFFIX
	bStopEncodingAfter = true;
#endif
*/
	
	switch ( OpLevel )
	{
#ifdef USE_NEW_SWL_CODE2
		case -1:
			// source registers are Rs and Rt
			ullSrcRegBitmap |= ( 1ull << i.Rs ) | ( 1ull << i.Rt );
			
			break;
#endif
			
		case 0:
			// can just stop encoding before and ignore the prefix requirement at level 0 for testing
			bStopEncodingBefore = true;
			//bStopEncodingAfter = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

#ifdef ENABLE_R5900_DCACHE
			e->AddMemImm64 ( (int64_t*) & r->CycleCount, LocalCycleCount - MemCycles );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction ); //SWL );

#ifdef ENABLE_R5900_DCACHE
			e->SubMemImm64 ( (int64_t*) & r->CycleCount, LocalCycleCount - MemCycles );
#endif
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		
#ifdef USE_NEW_STORE_CODE_SWL
		case 1:
#ifdef ENABLE_PS2_VIRTUAL_MACHINE_SWL
			if (!bitget_hwrw_bitmap(Address))
			{
				ret = Generate_Virtual_Store(i, Address, 0x0, (void*)Playstation2::DataBus::Write);
			}
			else
#endif
			{
				ret = Generate_Normal_Store(i, Address, 0x0, (void*)Playstation2::DataBus::Write);
			}

			break;
#endif
			
#ifdef USE_NEW_SWL_CODE2
		case 2:
			if ( isConst ( i.Rs ) )
			{
				ret = Generate_Normal_Store_L2 ( i, Address, 0x0, GetConst( i.Rs ) );
				if ( !ret ) return -1;
			}
			else
			{
				return -1;
			}
			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //SWL instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::SWR ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "SWR";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::SWR;
	
	int ret = 1;
	
/*
	// for now, stop encoding after this instruction
#ifndef ENABLE_STORE_PREFIX
	bStopEncodingBefore = true;
#endif
#ifndef ENABLE_STORE_SUFFIX
	bStopEncodingAfter = true;
#endif
*/
	
	switch ( OpLevel )
	{
#ifdef USE_NEW_SWR_CODE2
		case -1:
			// source registers are Rs and Rt
			ullSrcRegBitmap |= ( 1ull << i.Rs ) | ( 1ull << i.Rt );
			
			break;
#endif
			
		case 0:
			// can just stop encoding before and ignore the prefix requirement at level 0 for testing
			bStopEncodingBefore = true;
			//bStopEncodingAfter = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

#ifdef ENABLE_R5900_DCACHE
			e->AddMemImm64 ( (int64_t*) & r->CycleCount, LocalCycleCount - MemCycles );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction ); //SWR );

#ifdef ENABLE_R5900_DCACHE
			e->SubMemImm64 ( (int64_t*) & r->CycleCount, LocalCycleCount - MemCycles );
#endif
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
			
#ifdef USE_NEW_STORE_CODE_SWR
		case 1:
#ifdef ENABLE_PS2_VIRTUAL_MACHINE_SWR
			if (!bitget_hwrw_bitmap(Address))
			{
				ret = Generate_Virtual_Store(i, Address, 0x0, (void*)Playstation2::DataBus::Write);
			}
			else
#endif
			{
				ret = Generate_Normal_Store(i, Address, 0x0, (void*)Playstation2::DataBus::Write);
			}

			break;
#endif

#ifdef USE_NEW_SWR_CODE2
		case 2:
			if ( isConst ( i.Rs ) )
			{
				ret = Generate_Normal_Store_L2 ( i, Address, 0x0, GetConst( i.Rs ) );
				if ( !ret ) return -1;
			}
			else
			{
				return -1;
			}
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //SWR instruction.\n";
		return -1;
	}
	return 1;
}



/////////////////////////////////////////////////
// load instructions

// load instructions with delay slot
// *** todo *** it is also possible to this and just process load after load delay slot has executed - would still need previous load address before delay slot
// *** todo *** could also skip delay slot zero and put straight into delay slot 1 after next instruction, or just process load delay slot after next instruction
int32_t R5900::Recompiler::LB ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "LB";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::LB;
	
	//LoadAddress = r->GPR [ i.Base ].s + i.sOffset;
	//r->DelaySlot0.Instruction = i;
	//r->DelaySlot0.Data = LoadAddress;
	//r->DelaySlot0.cb = LB_DelaySlot_Callback_Bus;
	//r->Status.DelaySlot_Valid |= 0x1;
	//r->LastModifiedRegister = 255;
	int ret = 1;

/*
#ifndef ENABLE_LOAD_SUFFIX
	// for now, stop encoding after this instruction
	bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
#endif
*/
	
	switch ( OpLevel )
	{
#ifdef USE_NEW_LB_CODE2
		case -1:
			// source registers are Rt
			ullSrcRegBitmap |= ( 1ull << i.Rs );
			
			// destination register is Rd
			ullDstRegBitmap |= ( 1ull << i.Rt );
			break;
#endif
			
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			//bStopEncodingBefore = true;

			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			// need to do a before/after adjust on the CycleCount when calling from recompiler?
#ifdef ENABLE_R5900_DCACHE
			e->AddMemImm64 ( (int64_t*) & r->CycleCount, LocalCycleCount - MemCycles );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction ); //LB );

#ifdef ENABLE_R5900_DCACHE
			e->SubMemImm64 ( (int64_t*) & r->CycleCount, LocalCycleCount - MemCycles );
#endif
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
#ifdef USE_NEW_LOAD_CODE

#ifdef ENABLE_PS2_VIRTUAL_MACHINE_LB

			if (!bitget_hwrw_bitmap(Address))
			{
				ret = Generate_Virtual_Load(i, Address, 0x0, (void*)Playstation2::DataBus::Read_t<0xff>);
			}
			else
			{
				ret = Generate_Basic_Load(i, Address, 0x0, (void*)Playstation2::DataBus::Read_t<0xff>);
			}
#else

			ret = Generate_Normal_Load(i, Address, 0x0, (void*)Playstation2::DataBus::Read_t<0xff>);
#endif

			// store result //
			
			if ( i.Rt )
			{
				// store
				ret = e->MovMemReg64 ( & r->GPR [ i.Rt ].sq0, RAX );
			}
#else
			return -1;
#endif
			
			break;
			
#ifdef USE_NEW_LB_CODE2
		case 2:
			if ( isConst ( i.Rs ) )
			{
				ret = Generate_Normal_Load_L2 ( i, Address, 0x0, GetConst( i.Rs ) );
				if ( !ret ) return -1;
			}
			else
			{
				return -1;
			}
			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //LB instruction.\n";
		return -1;
	}
	return 1;
}






int32_t R5900::Recompiler::LH ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "LH";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::LH;
	
	int ret = 1;

/*
#ifndef ENABLE_LOAD_SUFFIX
	// for now, stop encoding after this instruction
	bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
#endif
*/
	
	switch ( OpLevel )
	{
#ifdef USE_NEW_LH_CODE2
		case -1:
			// source registers are Rt
			ullSrcRegBitmap |= ( 1ull << i.Rs );
			
			// destination register is Rd
			ullDstRegBitmap |= ( 1ull << i.Rt );
			break;
#endif
			
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			//bStopEncodingBefore = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

#ifdef ENABLE_R5900_DCACHE
			e->AddMemImm64 ( (int64_t*) & r->CycleCount, LocalCycleCount - MemCycles );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction ); //LH );
			
#ifdef ENABLE_R5900_DCACHE
			e->SubMemImm64 ( (int64_t*) & r->CycleCount, LocalCycleCount - MemCycles );
#endif

#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
#ifdef USE_NEW_LOAD_CODE

#ifdef ENABLE_PS2_VIRTUAL_MACHINE_LH

			if (!bitget_hwrw_bitmap(Address))
			{
				ret = Generate_Virtual_Load(i, Address, 0x1, (void*)Playstation2::DataBus::Read_t<0xffff>);
			}
			else
			{
				ret = Generate_Basic_Load(i, Address, 0x1, (void*)Playstation2::DataBus::Read_t<0xffff>);
			}
#else

			ret = Generate_Normal_Load(i, Address, 0x1, (void*)Playstation2::DataBus::Read_t<0xffff>);
#endif

			
			// store result //
			
			if ( i.Rt )
			{
				// store
				ret = e->MovMemReg64 ( & r->GPR [ i.Rt ].sq0, RAX );
			}
#else
			return -1;
#endif
			
			break;
			
#ifdef USE_NEW_LH_CODE2
		case 2:
			if ( isConst ( i.Rs ) )
			{
				ret = Generate_Normal_Load_L2 ( i, Address, 0x1, GetConst( i.Rs ) );
				if ( !ret ) return -1;
			}
			else
			{
				return -1;
			}
			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //LB instruction.\n";
		return -1;
	}
	return 1;
}








int32_t R5900::Recompiler::LW ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "LW";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::LW;
	
	int ret = 1;
	
/*
#ifndef ENABLE_LOAD_SUFFIX
	// for now, stop encoding after this instruction
	bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
#endif
*/
	
	switch ( OpLevel )
	{
#ifdef USE_NEW_LW_CODE2
		case -1:
			// source registers are Rt
			ullSrcRegBitmap |= ( 1ull << i.Rs );
			
			// destination register is Rd
			ullDstRegBitmap |= ( 1ull << i.Rt );
			break;
#endif
			
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			//bStopEncodingBefore = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

#ifdef ENABLE_R5900_DCACHE
			e->AddMemImm64 ( (int64_t*) & r->CycleCount, LocalCycleCount - MemCycles );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction ); //LW );
			
#ifdef ENABLE_R5900_DCACHE
			e->SubMemImm64 ( (int64_t*) & r->CycleCount, LocalCycleCount - MemCycles );
#endif

#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
#ifdef USE_NEW_LOAD_CODE

#ifdef ENABLE_PS2_VIRTUAL_MACHINE_LW

			if (!bitget_hwrw_bitmap(Address))
			{
				ret = Generate_Virtual_Load(i, Address, 0x3, (void*)Playstation2::DataBus::Read_t<0xffffffffULL>);
			}
			else
			{
				ret = Generate_Basic_Load(i, Address, 0x3, (void*)Playstation2::DataBus::Read_t<0xffffffffULL>);
			}
#else

			ret = Generate_Normal_Load(i, Address, 0x3, (void*)Playstation2::DataBus::Read_t<0xffffffffULL>);
#endif

			
			// store result //
			
			if ( i.Rt )
			{
				// sign-extend from byte to 64-bits ??
				//e->Cdqe ();
				
				// store
				ret = e->MovMemReg64 ( & r->GPR [ i.Rt ].sq0, RAX );
			}

#else

			return -1;
#endif
			
			break;
			
#ifdef USE_NEW_LW_CODE2
		case 2:
			if ( isConst ( i.Rs ) )
			{
				ret = Generate_Normal_Load_L2 ( i, Address, 0x3, GetConst( i.Rs ) );
				if ( !ret ) return -1;
			}
			else
			{
				return -1;
			}
			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //LB instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::LBU ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "LBU";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::LBU;
	
	int ret = 1;
	
/*
#ifndef ENABLE_LOAD_SUFFIX
	// for now, stop encoding after this instruction
	bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
#endif
*/
	
	switch ( OpLevel )
	{
#ifdef USE_NEW_LBU_CODE2
		case -1:
			// source registers are Rt
			ullSrcRegBitmap |= ( 1ull << i.Rs );
			
			// destination register is Rd
			ullDstRegBitmap |= ( 1ull << i.Rt );
			break;
#endif
			
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			//bStopEncodingBefore = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

#ifdef ENABLE_R5900_DCACHE
			e->AddMemImm64 ( (int64_t*) & r->CycleCount, LocalCycleCount - MemCycles );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction ); //LBU );
			
#ifdef ENABLE_R5900_DCACHE
			e->SubMemImm64 ( (int64_t*) & r->CycleCount, LocalCycleCount - MemCycles );
#endif

#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
#ifdef USE_NEW_LOAD_CODE

#ifdef ENABLE_PS2_VIRTUAL_MACHINE_LBU

			if (!bitget_hwrw_bitmap(Address))
			{
				ret = Generate_Virtual_Load(i, Address, 0x0, (void*)Playstation2::DataBus::Read_t<0xff>);
			}
			else
			{
				ret = Generate_Basic_Load(i, Address, 0x0, (void*)Playstation2::DataBus::Read_t<0xff>);
			}
#else

			ret = Generate_Normal_Load(i, Address, 0x0, (void*)Playstation2::DataBus::Read_t<0xff>);
#endif

			
			// store result //
			
			if ( i.Rt )
			{
				// zero-extend 16-bit value to 64-bits
				//e->AndReg32ImmX ( RAX, 0xff );
				
				// store
				ret = e->MovMemReg64 ( & r->GPR [ i.Rt ].sq0, RAX );
			}
#else
			return -1;
#endif
			
			break;
			
#ifdef USE_NEW_LBU_CODE2
		case 2:
			if ( isConst ( i.Rs ) )
			{
				ret = Generate_Normal_Load_L2 ( i, Address, 0x0, GetConst( i.Rs ) );
				if ( !ret ) return -1;
			}
			else
			{
				return -1;
			}
			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //LBU instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::LHU ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "LHU";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::LHU;
	
	int ret = 1;
	
/*
#ifndef ENABLE_LOAD_SUFFIX
	// for now, stop encoding after this instruction
	bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
#endif
*/
	
	switch ( OpLevel )
	{
#ifdef USE_NEW_LHU_CODE2
		case -1:
			// source registers are Rt
			ullSrcRegBitmap |= ( 1ull << i.Rs );
			
			// destination register is Rd
			ullDstRegBitmap |= ( 1ull << i.Rt );
			break;
#endif
			
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			//bStopEncodingBefore = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

#ifdef ENABLE_R5900_DCACHE
			e->AddMemImm64 ( (int64_t*) & r->CycleCount, LocalCycleCount - MemCycles );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction ); //LHU );
			
#ifdef ENABLE_R5900_DCACHE
			e->SubMemImm64 ( (int64_t*) & r->CycleCount, LocalCycleCount - MemCycles );
#endif

#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
#ifdef USE_NEW_LOAD_CODE

#ifdef ENABLE_PS2_VIRTUAL_MACHINE_LHU

			if (!bitget_hwrw_bitmap(Address))
			{
				ret = Generate_Virtual_Load(i, Address, 0x1, (void*)Playstation2::DataBus::Read_t<0xffff>);
			}
			else
			{
				ret = Generate_Basic_Load(i, Address, 0x1, (void*)Playstation2::DataBus::Read_t<0xffff>);
			}
#else

			ret = Generate_Normal_Load(i, Address, 0x1, (void*)Playstation2::DataBus::Read_t<0xffff>);
#endif

			
			// store result //
			
			if ( i.Rt )
			{
				// store
				ret = e->MovMemReg64 ( & r->GPR [ i.Rt ].sq0, RAX );
			}
#else
			return -1;
#endif
			
			break;
			
#ifdef USE_NEW_LHU_CODE2
		case 2:
			if ( isConst ( i.Rs ) )
			{
				ret = Generate_Normal_Load_L2 ( i, Address, 0x1, GetConst( i.Rs ) );
				if ( !ret ) return -1;
			}
			else
			{
				return -1;
			}
			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //LB instruction.\n";
		return -1;
	}
	return 1;
}





// load instructions without load-delay slot
int32_t R5900::Recompiler::LWL ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "LWL";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::LWL;
	
	int ret = 1;
	
/*
#ifndef ENABLE_LOAD_SUFFIX
	// for now, stop encoding after this instruction
	bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
#endif
*/
	
	switch ( OpLevel )
	{
#ifdef USE_NEW_LWL_CODE2
		case -1:
			// source registers are Rt
			ullSrcRegBitmap |= ( 1ull << i.Rs );
			
			// destination register is Rd
			ullDstRegBitmap |= ( 1ull << i.Rt );
			break;
#endif
			
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			//bStopEncodingBefore = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

#ifdef ENABLE_R5900_DCACHE
			e->AddMemImm64 ( (int64_t*) & r->CycleCount, LocalCycleCount - MemCycles );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction ); //LWL );
			
#ifdef ENABLE_R5900_DCACHE
			e->SubMemImm64 ( (int64_t*) & r->CycleCount, LocalCycleCount - MemCycles );
#endif

#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
#ifdef USE_NEW_LOAD_CODE_LWL
		case 1:
#ifdef ENABLE_PS2_VIRTUAL_MACHINE_LWL

			if (!bitget_hwrw_bitmap(Address))
			{
				ret = Generate_Virtual_Load(i, Address, 0x0, (void*)Playstation2::DataBus::Read_t<0xffffffffULL>);
			}
			else
			{
				ret = Generate_Basic_Load(i, Address, 0x0, (void*)Playstation2::DataBus::Read_t<0xffffffffULL>);
			}
#else

			ret = Generate_Normal_Load(i, Address, 0x0, (void*)Playstation2::DataBus::Read_t<0xffffffffULL>);
#endif

			if ( i.Rt )
			{
#ifdef USE_SHORT_LWL_CODE
				e->LeaRegMem64 ( RDX, & r->GPR [ i.Rt ].s );
				//e->MovRegFromMem32 ( 8, RDX, NO_INDEX, SCALE_NONE, 4 );
				e->NotReg32 ( RCX );
				e->AndReg32ImmX ( RCX, 3 );
				e->MovRegToMem32 ( RAX, RDX, RCX, SCALE_NONE, 0 );
				//e->MovRegToMem32 ( 8, RDX, NO_INDEX, SCALE_NONE, 4 );
				e->MovsxdReg64Mem32 ( RAX, RDX, NO_INDEX, SCALE_NONE, 0 );
				e->MovRegToMem64 ( RAX, RDX, NO_INDEX, SCALE_NONE, 0 );
#else
				//e->MovRegFromMem32 ( RCX, &r->GPR [ i.Base ].sw0 );
				//e->AddReg32ImmX ( RCX, i.sOffset );
				
				//e->XorReg32ImmX ( RCX, 3 );
				e->NotReg32 ( RCX );
				e->AndReg32ImmX ( RCX, 3 );
				e->ShlRegImm32 ( RCX, 3 );
				e->ShlRegReg32 ( RAX );
				e->MovRegReg32 ( RDX, RAX );
				e->MovReg32ImmX ( RAX, -1 );
				//e->SubReg32ImmX ( RCX, 32 );
				//e->NegReg32 ( RCX );
				e->ShlRegReg32 ( RAX );
				e->NotReg32 ( RAX );
				e->AndRegMem32 ( RAX, &r->GPR [ i.Rt ].sw0 );
				e->OrRegReg32 ( RAX, RDX );
				e->Cdqe ();
				ret = e->MovMemReg64 ( &r->GPR [ i.Rt ].sq0, RAX );
#endif
			}

			break;
#endif
			
#ifdef USE_NEW_LWL_CODE2
		case 2:
			if ( isConst ( i.Rs ) )
			{
				ret = Generate_Normal_Load_L2 ( i, Address, 0x0, GetConst( i.Rs ) );
				if ( !ret ) return -1;
			}
			else
			{
				return -1;
			}
			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //LB instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::LWR ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "LWR";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::LWR;
	
	int ret = 1;
	
/*
#ifndef ENABLE_LOAD_SUFFIX
	// for now, stop encoding after this instruction
	bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
#endif
*/
	
	switch ( OpLevel )
	{
#ifdef USE_NEW_LWR_CODE2
		case -1:
			// source registers are Rt
			ullSrcRegBitmap |= ( 1ull << i.Rs );
			
			// destination register is Rd
			ullDstRegBitmap |= ( 1ull << i.Rt );
			break;
#endif
			
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			//bStopEncodingBefore = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

#ifdef ENABLE_R5900_DCACHE
			e->AddMemImm64 ( (int64_t*) & r->CycleCount, LocalCycleCount - MemCycles );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction ); //LWR );
			
#ifdef ENABLE_R5900_DCACHE
			e->SubMemImm64 ( (int64_t*) & r->CycleCount, LocalCycleCount - MemCycles );
#endif

#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
#ifdef USE_NEW_LOAD_CODE_LWR
		case 1:

#ifdef ENABLE_PS2_VIRTUAL_MACHINE_LWR

			if (!bitget_hwrw_bitmap(Address))
			{
				ret = Generate_Virtual_Load(i, Address, 0x0, (void*)Playstation2::DataBus::Read_t<0xffffffffULL>);
			}
			else
			{
				ret = Generate_Basic_Load(i, Address, 0x0, (void*)Playstation2::DataBus::Read_t<0xffffffffULL>);
			}
#else

			ret = Generate_Normal_Load(i, Address, 0x0, (void*)Playstation2::DataBus::Read_t<0xffffffffULL>);
#endif

			if ( i.Rt )
			{
#ifdef USE_SHORT_LWR_CODE
				e->LeaRegMem64 ( RDX, & r->GPR [ i.Rt ].s );
				e->MovRegFromMem32 ( 8, RDX, NO_INDEX, SCALE_NONE, -4 );
				e->AndReg32ImmX ( RCX, 3 );
				e->NegReg64 ( RCX );
				e->MovRegToMem32 ( RAX, RDX, RCX, SCALE_NONE, 0 );
				e->MovRegToMem32 ( 8, RDX, NO_INDEX, SCALE_NONE, -4 );
				e->SarRegImm32 ( RAX, 31 );
				e->CmovERegMem32 ( RAX, RDX, NO_INDEX, SCALE_NONE, 4 );
				e->MovRegToMem32 ( RAX, RDX, NO_INDEX, SCALE_NONE, 4 );
#else
				//e->MovRegFromMem32 ( RCX, &r->GPR [ i.Base ].sw0 );
				//e->AddReg32ImmX ( RCX, i.sOffset );
				
				//e->XorReg32ImmX ( RCX, 3 );
				e->AndReg32ImmX ( RCX, 3 );
				e->ShlRegImm32 ( RCX, 3 );
				e->ShrRegReg32 ( RAX );
				e->Cdqe ();
				e->MovRegReg64 ( RDX, RAX );
				e->MovReg32ImmX ( RAX, -1 );
				//e->SubReg32ImmX ( RCX, 32 );
				//e->NegReg32 ( RCX );
				e->ShrRegReg32 ( RAX );
				e->Cdqe ();
				e->NotReg64 ( RAX );
				e->AndRegMem64 ( RAX, &r->GPR [ i.Rt ].s );
				e->OrRegReg64 ( RAX, RDX );
				//e->Cdqe ();
				ret = e->MovMemReg64 ( &r->GPR [ i.Rt ].s, RAX );
#endif
			}

			break;
#endif
			
#ifdef USE_NEW_LWR_CODE2
		case 2:
			if ( isConst ( i.Rs ) )
			{
				ret = Generate_Normal_Load_L2 ( i, Address, 0x0, GetConst( i.Rs ) );
				if ( !ret ) return -1;
			}
			else
			{
				return -1;
			}
			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //LWR instruction.\n";
		return -1;
	}
	return 1;
}






int32_t R5900::Recompiler::COP2 ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "COP2";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::COP2;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	bStopEncodingAfter = true;
	bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}



//// ***** R5900 INSTRUCTIONS ***** ////

// arithemetic instructions //

int32_t R5900::Recompiler::DADD ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "DADD";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::DADD;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// go ahead and say that it modifies NextPC since it might, even if it does not this time around
			// but only if instruction is actually encoded
			Local_NextPCModified = true;
			
			// need to stop encoding before, because if it sync ints, that requires PC to be updated
			bStopEncodingBefore = true;
			
			// need to stop encoding after because if it sync ints, then it needs to "jump"
			bStopEncodingAfter = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
#ifdef USE_NEW_DADD_CODE
			e->MovRegMem64 ( RAX, &r->GPR [ i.Rs ].s );
			e->AddRegMem64 ( RAX, &r->GPR [ i.Rt ].s );
			
			if ( i.Rs && i.Rt )
			{
#ifdef USE_NEW_DADD_SEQUENCE_R5900

				e->MovRegImm32(RCX, Address);
				e->MovRegImm32(RDX, LocalCycleCount);
				e->JMP_O((void*)Cpu::ProcessSynchronousInterrupt2_t<Cpu::EXC_OV>);

#else
				// branch if not signed overflow
				e->Jmp8_NO ( 0, 0 );
				
				// update CycleCount, set PC, then jump to synchronous interrupt
				e->AddMem64ImmX ( (int64_t*) & r->CycleCount, LocalCycleCount );
				
				// set pc
				e->MovMemImm32 ( (int32_t*) & r->PC, Address );
				
				//r->ProcessSynchronousInterrupt ( Cpu::EXC_OV );
				e->JMP ( (void*) Cpu::ProcessSynchronousInterrupt_t<Cpu::EXC_OV> );
				
				// continue processing store from here //
				e->SetJmpTarget8 ( 0 );
#endif
			}
			
			// check if destination is r0
			if ( i.Rd )
			{
				// store result if not signed overflow
				ret = e->MovMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
			}
#else
			return -1;
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //" << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::DADDI ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "DADDI";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::DADDI;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// go ahead and say that it modifies NextPC since it might, even if it does not this time around
			// but only if instruction is actually encoded
			Local_NextPCModified = true;
			
			// need to stop encoding before, because if it sync ints, that requires PC to be updated
			bStopEncodingBefore = true;
			
			// need to stop encoding after because if it sync ints, then it needs to "jump"
			bStopEncodingAfter = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
#ifdef USE_NEW_DADDI_CODE
			e->MovRegMem64 ( RAX, &r->GPR [ i.Rs ].s );
			e->AddReg64ImmX ( RAX, i.sImmediate );
			
			if ( i.Rs && i.sImmediate )
			{
#ifdef USE_NEW_DADDI_SEQUENCE_R5900

				e->MovRegImm32(RCX, Address);
				e->MovRegImm32(RDX, LocalCycleCount);
				e->JMP_O((void*)Cpu::ProcessSynchronousInterrupt2_t<Cpu::EXC_OV>);

#else
				// branch if not signed overflow
				e->Jmp8_NO ( 0, 0 );
				
				// update CycleCount, set PC, then jump to synchronous interrupt
				e->AddMem64ImmX ( (int64_t*) & r->CycleCount, LocalCycleCount );
				
				// set pc
				e->MovMemImm32 ( (int32_t*) & r->PC, Address );
				
				//r->ProcessSynchronousInterrupt ( Cpu::EXC_OV );
				e->JMP ( (void*) Cpu::ProcessSynchronousInterrupt_t<Cpu::EXC_OV> );
				
				// continue processing store from here //
				e->SetJmpTarget8 ( 0 );
#endif
			}
			
			// check if destination is r0
			if ( i.Rt )
			{
				// store result if not signed overflow
				ret = e->MovMemReg64 ( &r->GPR [ i.Rt ].s, RAX );
			}
#else
			return -1;
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::DADDU ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "DADDU";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::DADDU;
	
	int Rd, Rs, Rt;
	int Reg1, Reg2;
	s64 lConst;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case -1:
			// source registers are Rs and Rt
			ullSrcRegBitmap |= ( 1ull << i.Rs ) | ( 1ull << i.Rt );
			
			// destination register is Rd
			ullDstRegBitmap |= ( 1ull << i.Rd );
			break;
			
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
#ifdef USE_NEW_DADDU_CODE

#ifdef USE_NEW_R5900_ASSEMBLER_DADDU

			if (i.Rd)
			{
				if ((!i.Rs) && (!i.Rt))
				{
					//ret = e->MovMemImm32(&r->GPR[i.Rd].s, 0);
					x->emit("mov qword ptr @ptr, 0", &r->GPR[i.Rd].s);
				}
				else if ((!i.Rs) || (!i.Rt))
				{
					if (i.Rd != (i.Rs | i.Rt))
					{
						//e->MovRegFromMem32(RAX, &r->GPR[i.Rs | i.Rt].s);
						//ret = e->MovRegToMem32(&r->GPR[i.Rd].s, RAX);
						x->emit("mov rax, @ptr", &r->GPR[i.Rs | i.Rt].s);
						x->emit("mov @ptr, rax", &r->GPR[i.Rd].s);
					}
				}
				else if (i.Rd == i.Rs)
				{
					//e->MovRegFromMem32(RAX, &r->GPR[i.Rt].s);
					//ret = e->AddMemReg32(&r->GPR[i.Rd].s, RAX);
					x->emit("mov rax, @ptr", &r->GPR[i.Rt].s);
					x->emit("add @ptr, rax", &r->GPR[i.Rd].s);
				}
				else if (i.Rd == i.Rt)
				{
					//e->MovRegFromMem32(RAX, &r->GPR[i.Rs].s);
					//ret = e->AddMemReg32(&r->GPR[i.Rd].s, RAX);
					x->emit("mov rax, @ptr", &r->GPR[i.Rs].s);
					x->emit("add @ptr, rax", &r->GPR[i.Rd].s);
				}
				else if (i.Rs == i.Rt)
				{
					//e->MovRegFromMem32(RAX, &r->GPR[i.Rs].s);
					//e->AddRegReg32(RAX, RAX);
					//ret = e->MovRegToMem32(&r->GPR[i.Rd].s, RAX);
					x->emit("mov rax, @ptr", &r->GPR[i.Rs].s);
					x->emit("add rax, rax");
					x->emit("mov @ptr, rax", &r->GPR[i.Rd].s);
				}
				else
				{
					//e->MovRegFromMem32(RAX, &r->GPR[i.Rs].s);
					//e->AddRegMem32(RAX, &r->GPR[i.Rt].s);
					//ret = e->MovRegToMem32(&r->GPR[i.Rd].s, RAX);
					x->emit("mov rax, @ptr", &r->GPR[i.Rs].s);
					x->emit("add rax, @ptr", &r->GPR[i.Rt].s);
					x->emit("mov @ptr, rax", &r->GPR[i.Rd].s);
				}

			}

#else
			if ( i.Rd )
			{
				if ( ( !i.Rs ) && ( !i.Rt ) )
				{
					ret = e->MovMemImm64 ( &r->GPR [ i.Rd ].s, 0 );
				}
				else if ( ( !i.Rs ) || ( !i.Rt ) )
				{
					if ( i.Rd != ( i.Rs | i.Rt ) )
					{
						e->MovRegMem64 ( RAX, &r->GPR [ i.Rs | i.Rt ].s );
						ret = e->MovMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
					}
				}
				else if ( i.Rd == i.Rs )
				{
					e->MovRegMem64 ( RAX, &r->GPR [ i.Rt ].s );
					ret = e->AddMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
				}
				else if ( i.Rd == i.Rt )
				{
					e->MovRegMem64 ( RAX, &r->GPR [ i.Rs ].s );
					ret = e->AddMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
				}
				else if ( i.Rs == i.Rt )
				{
					e->MovRegMem64 ( RAX, &r->GPR [ i.Rs ].s );
					e->AddRegReg64 ( RAX, RAX );
					ret = e->MovMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
				}
				else
				{
					e->MovRegMem64 ( RAX, &r->GPR [ i.Rs ].s );
					e->AddRegMem64 ( RAX, &r->GPR [ i.Rt ].s );
					ret = e->MovMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
				}
			}
#endif

#else
			return -1;
#endif
			break;
			

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	
	return 1;
}

int32_t R5900::Recompiler::DADDIU ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "DADDIU";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::DADDIU;
	
	int Rd, Rs, Rt;
	int Reg1, Reg2;
	s64 lConst;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
#ifdef USE_NEW_DADDIU_CODE

#ifdef USE_NEW_R5900_ASSEMBLER_DADDIU

			if (i.Rt)
			{
				if (!i.Rs)
				{
					//ret = e->MovMemImm32(&r->GPR[i.Rt].s, i.sImmediate);
					x->emit("mov qword ptr @ptr, @imm", &r->GPR[i.Rt].s, (s32)i.sImmediate);
				}
				else if (i.Rt == i.Rs)
				{
					if (i.sImmediate == 1)
					{
						x->emit("inc qword ptr @ptr", &r->GPR[i.Rt].s);
					}
					else if (i.sImmediate == -1)
					{
						x->emit("dec qword ptr @ptr", &r->GPR[i.Rt].s);
					}
					else if (i.sImmediate)
					{
						//ret = e->AddMem32ImmX(&r->GPR[i.Rt].s, i.sImmediate);
						x->emit("add qword ptr @ptr, @imm", &r->GPR[i.Rt].s, (s32)i.sImmediate);
					}
				}
				else
				{
					//e->MovRegFromMem32(RAX, &r->GPR[i.Rs].s);
					//e->AddReg32ImmX(RAX, i.sImmediate);
					//ret = e->MovRegToMem32(&r->GPR[i.Rt].s, RAX);
					x->emit("mov rax, @ptr", &r->GPR[i.Rs].s);

					if (i.sImmediate == 1)
					{
						x->emit("inc rax");
					}
					else if (i.sImmediate == -1)
					{
						x->emit("dec rax");
					}
					else if (i.sImmediate)
					{
						x->emit("add rax, @imm", (s32)i.sImmediate);
					}

					x->emit("mov @ptr, rax", &r->GPR[i.Rt].s);
				}
			}


#else
			if ( i.Rt )
			{
				if ( !i.Rs )
				{
					ret = e->MovMemImm64 ( &r->GPR [ i.Rt ].s, i.sImmediate );
				}
				else if ( i.Rt == i.Rs )
				{
					if ( i.sImmediate )
					{
						ret = e->AddMem64ImmX ( &r->GPR [ i.Rt ].s, i.sImmediate );
					}
				}
				else if ( !i.sImmediate )
				{
					if ( i.Rt != i.Rs )
					{
						e->MovRegMem64 ( RAX, &r->GPR [ i.Rs ].s );
						ret = e->MovMemReg64 ( &r->GPR [ i.Rt ].s, RAX );
					}
				}
				else
				{
					e->MovRegMem64 ( RAX, &r->GPR [ i.Rs ].s );
					e->AddReg64ImmX ( RAX, i.sImmediate );
					ret = e->MovMemReg64 ( &r->GPR [ i.Rt ].s, RAX );
				}
			}
#endif

#else
			return -1;
#endif
			break;
			

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::DSUB ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "DSUB";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::DSUB;
	
	int ret = 1;
	
	switch ( OpLevel )
	{
		case 0:
			// go ahead and say that it modifies NextPC since it might, even if it does not this time around
			// but only if instruction is actually encoded
			Local_NextPCModified = true;
			
			// need to stop encoding before, because if it sync ints, that requires PC to be updated
			bStopEncodingBefore = true;
			
			// need to stop encoding after because if it sync ints, then it needs to "jump"
			bStopEncodingAfter = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
#ifdef USE_NEW_DSUB_CODE
			e->MovRegMem64 ( RAX, &r->GPR [ i.Rs ].s );
			e->SubRegMem64 ( RAX, &r->GPR [ i.Rt ].s );
			
			if ( i.Rt )
			{
				// branch if not signed overflow
				e->Jmp8_NO ( 0, 0 );
				
				// update CycleCount, set PC, then jump to synchronous interrupt
				e->AddMem64ImmX ( (int64_t*) & r->CycleCount, LocalCycleCount );
				
				// set pc
				e->MovMemImm32 ( (int32_t*) & r->PC, Address );
				
				//r->ProcessSynchronousInterrupt ( Cpu::EXC_OV );
				e->JMP ( (void*) Cpu::ProcessSynchronousInterrupt_t<Cpu::EXC_OV> );
				
				// continue processing store from here //
				e->SetJmpTarget8 ( 0 );
			}
			
			// check if destination is r0
			if ( i.Rd )
			{
				// store result if not signed overflow
				ret = e->MovMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
			}
#else
			return -1;
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::DSUBU ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "DSUBU";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::DSUBU;
	
	int Rd, Rs, Rt;
	int Reg1, Reg2;
	s64 lConst;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case -1:
			// source registers are Rs and Rt
			ullSrcRegBitmap |= ( 1ull << i.Rs ) | ( 1ull << i.Rt );
			
			// destination register is Rd
			ullDstRegBitmap |= ( 1ull << i.Rd );
			break;
			
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
#ifdef USE_NEW_DSUBU_CODE

#ifdef USE_NEW_R5900_ASSEMBLER_DSUBU

			if (i.Rd)
			{
				if (i.Rs == i.Rt)
				{
					//ret = e->MovMemImm32(&r->GPR[i.Rd].s, 0);
					x->emit("mov qword ptr @ptr, 0", &r->GPR[i.Rd].s);
				}
				else if (!i.Rt)
				{
					if (i.Rd != i.Rs)
					{
						//e->MovRegFromMem32(RAX, &r->GPR[i.Rs].s);
						//ret = e->MovRegToMem32(&r->GPR[i.Rd].s, RAX);
						x->emit("mov rax, @ptr", &r->GPR[i.Rs].s);
						x->emit("mov @ptr, rax", &r->GPR[i.Rd].s);
					}
				}
				else if (i.Rd == i.Rs)
				{
					//e->MovRegFromMem32(RAX, &r->GPR[i.Rt].s);
					//ret = e->SubMemReg32(&r->GPR[i.Rd].s, RAX);
					x->emit("mov rax, @ptr", &r->GPR[i.Rt].s);
					x->emit("sub @ptr, rax", &r->GPR[i.Rd].s);
				}
				else if (!i.Rs)
				{
					if (i.Rd != i.Rt)
					{
						//e->MovRegFromMem32(RAX, &r->GPR[i.Rt].s);
						//e->NegReg32(RAX);
						//ret = e->MovRegToMem32(&r->GPR[i.Rd].s, RAX);
						x->emit("mov rax, @ptr", &r->GPR[i.Rt].s);
						x->emit("neg rax");
						x->emit("mov @ptr, rax", &r->GPR[i.Rd].s);
					}
					else
					{
						//ret = e->NegMem32(&r->GPR[i.Rd].s);
						x->emit("neg qword ptr @ptr", &r->GPR[i.Rd].s);
					}
				}
				else
				{
					//e->MovRegFromMem32(RAX, &r->GPR[i.Rs].s);
					//e->SubRegMem32(RAX, &r->GPR[i.Rt].s);
					//ret = e->MovRegToMem32(&r->GPR[i.Rd].s, RAX);
					x->emit("mov rax, @ptr", &r->GPR[i.Rs].s);
					x->emit("sub rax, @ptr", &r->GPR[i.Rt].s);
					x->emit("mov @ptr, rax", &r->GPR[i.Rd].s);
				}
			}

#else
			if ( i.Rd )
			{
				if ( i.Rs == i.Rt )
				{
					ret = e->MovMemImm64 ( &r->GPR [ i.Rd ].s, 0 );
				}
				else if ( !i.Rs )
				{
					if ( i.Rd == i.Rt )
					{
						ret = e->NegMem64 ( &r->GPR [ i.Rd ].s );
					}
					else
					{
						e->MovRegMem64 ( RAX, &r->GPR [ i.Rt ].s );
						e->NegReg64 ( RAX );
						ret = e->MovMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
					}
				}
				else if ( !i.Rt )
				{
					if ( i.Rd != i.Rs )
					{
						e->MovRegMem64 ( RAX, &r->GPR [ i.Rs ].s );
						ret = e->MovMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
					}
				}
				else if ( i.Rd == i.Rs )
				{
					e->MovRegMem64 ( RAX, &r->GPR [ i.Rt ].s );
					ret = e->SubMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
				}
				/*
				else if ( i.Rd == i.Rt )
				{
					e->MovRegMem64 ( RAX, &r->GPR [ i.Rs ].s );
					ret = e->AddMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
				}
				*/
				else
				{
					e->MovRegMem64 ( RAX, &r->GPR [ i.Rs ].s );
					e->SubRegMem64 ( RAX, &r->GPR [ i.Rt ].s );
					ret = e->MovMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
				}
			}
#endif

#else
			return -1;
#endif
			break;
			

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::DSLL ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "DSLL";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::DSLL;
	
	int Rd, Rs, Rt;
	int Reg1, Reg2;
	s64 lConst;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case -1:
			// source registers are Rt
			ullSrcRegBitmap |= ( 1 << i.Rt );
			
			// destination register is Rd
			ullDstRegBitmap |= ( 1ull << i.Rd );
			break;
			
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
#ifdef USE_NEW_R5900_ASSEMBLER_DSLL

			if (i.Rd)
			{
				if (!i.Rt)
				{
					//ret = e->MovMemImm32(&r->GPR[i.Rd].s, 0);
					x->emit("mov qword ptr @ptr, 0", &r->GPR[i.Rd].s);
				}
				else if (i.Rd == i.Rt)
				{
					if (i.Shift)
					{
						x->emit("shl qword ptr @ptr, @imm", &r->GPR[i.Rd].s, i.Shift);
					}
				}
				else
				{
					//e->MovRegFromMem32(RAX, &r->GPR[i.Rt].s);
					//e->ShlRegImm32(RAX, (u32)i.Shift);
					//ret = e->MovRegToMem32(&r->GPR[i.Rd].s, RAX);
					x->emit("mov rax, @ptr", &r->GPR[i.Rt].s);

					if (i.Shift)
					{
						x->emit("shl rax, @imm", i.Shift);
					}

					x->emit("mov @ptr, rax", &r->GPR[i.Rd].s);
				}
			}

#else
			if ( i.Rd )
			{
				if ( !i.Rt )
				{
					ret = e->MovMemImm64 ( &r->GPR [ i.Rd ].s, 0 );
				}
				else if ( !i.Shift )
				{
					if ( i.Rd != i.Rt )
					{
						e->MovRegMem64 ( RAX, &r->GPR [ i.Rt ].s );
						ret = e->MovMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
					}
				}
				else
				{
					e->MovRegMem64 ( RAX, &r->GPR [ i.Rt ].s );
					
					e->ShlRegImm64 ( RAX, (u32) i.Shift );
					
					ret = e->MovMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
				}
			}
#endif
			break;
			

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::DSLL32 ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "DSLL32";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::DSLL32;
	
	int Rd, Rs, Rt;
	int Reg1, Reg2;
	s64 lConst;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case -1:
			// source registers are Rt
			ullSrcRegBitmap |= ( 1 << i.Rt );
			
			// destination register is Rd
			ullDstRegBitmap |= ( 1ull << i.Rd );
			break;
			
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
#ifdef USE_NEW_R5900_ASSEMBLER_DSLL32

			if (i.Rd)
			{
				if (!i.Rt)
				{
					//ret = e->MovMemImm32(&r->GPR[i.Rd].s, 0);
					x->emit("mov qword ptr @ptr, 0", &r->GPR[i.Rd].s);
				}
				else if (i.Rd == i.Rt)
				{
					x->emit("shl qword ptr @ptr, @imm", &r->GPR[i.Rd].s, i.Shift + 32);
				}
				else
				{
					//e->MovRegFromMem32(RAX, &r->GPR[i.Rt].s);
					//e->ShlRegImm32(RAX, (u32)i.Shift);
					//ret = e->MovRegToMem32(&r->GPR[i.Rd].s, RAX);
					x->emit("mov rax, @ptr", &r->GPR[i.Rt].s);
					x->emit("shl rax, @imm", i.Shift + 32);
					x->emit("mov @ptr, rax", &r->GPR[i.Rd].s);
				}
			}

#else
			if ( i.Rd )
			{
				if ( !i.Rt )
				{
					e->MovMemImm64 ( &r->GPR [ i.Rd ].s, 0 );
				}
				else
				{
					e->MovRegMem64 ( RAX, &r->GPR [ i.Rt ].s );
					e->ShlRegImm64 ( RAX, (u32) i.Shift + 32 );
					ret = e->MovMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
				}
			}
#endif
			break;
			

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::DSLLV ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "DSLLV";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::DSLLV;
	
	int Rd, Rs, Rt;
	int Reg1, Reg2;
	s64 lConst;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case -1:
			// source registers are Rs and Rt
			ullSrcRegBitmap |= ( 1ull << i.Rs ) | ( 1ull << i.Rt );
			
			// destination register is Rd
			ullDstRegBitmap |= ( 1ull << i.Rd );
			break;
			
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
#ifdef USE_NEW_R5900_ASSEMBLER_DSLLV

			if (i.Rd)
			{
				if (!i.Rt)
				{
					//ret = e->MovMemImm32(&r->GPR[i.Rd].s, 0);
					x->emit("mov qword ptr @ptr, 0", &r->GPR[i.Rd].s);
				}
				else if (i.Rd == i.Rt)
				{
					if (i.Rs)
					{
						x->emit("mov ecx, @ptr", &r->GPR[i.Rs].s);
						x->emit("shl qword ptr @ptr, cl", &r->GPR[i.Rd].s);
					}
				}
				else
				{
					//e->MovRegFromMem32(RAX, &r->GPR[i.Rt].s);
					//e->MovRegFromMem32(RCX, &r->GPR[i.Rs].s);
					//e->ShlRegReg32(RAX);
					//ret = e->MovRegToMem32(&r->GPR[i.Rd].s, RAX);
					x->emit("mov rax, @ptr", &r->GPR[i.Rt].s);

					if (i.Rs)
					{
						x->emit("mov ecx, @ptr", &r->GPR[i.Rs].s);
						x->emit("shl rax, cl");
					}

					x->emit("mov @ptr, rax", &r->GPR[i.Rd].s);
				}
			}

#else
			if ( i.Rd )
			{
				if ( !i.Rt )
				{
					e->MovMemImm64 ( &r->GPR [ i.Rd ].s, 0 );
				}
				else if ( !i.Rs )
				{
					e->MovRegMem64 ( RAX, &r->GPR [ i.Rt ].s );
					ret = e->MovMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
				}
				else
				{
					e->MovRegMem64 ( RAX, &r->GPR [ i.Rt ].s );
					e->MovRegMem32 ( RCX, &r->GPR [ i.Rs ].sw0 );
					e->ShlRegReg64 ( RAX );
					ret = e->MovMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
				}
			}
#endif
			break;
			

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::DSRA ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "DSRA";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::DSRA;
	
	int Rd, Rs, Rt;
	int Reg1, Reg2;
	s64 lConst;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case -1:
			// source registers are Rt
			ullSrcRegBitmap |= ( 1 << i.Rt );
			
			// destination register is Rd
			ullDstRegBitmap |= ( 1ull << i.Rd );
			break;
			
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:

#ifdef USE_NEW_R5900_ASSEMBLER_DSRA

			if (i.Rd)
			{
				if (!i.Rt)
				{
					//ret = e->MovMemImm32(&r->GPR[i.Rd].s, 0);
					x->emit("mov qword ptr @ptr, 0", &r->GPR[i.Rd].s);
				}
				else if (i.Rd == i.Rt)
				{
					if (i.Shift)
					{
						x->emit("sar qword ptr @ptr, @imm", &r->GPR[i.Rd].s, i.Shift);
					}
				}
				else
				{
					//e->MovRegFromMem32(RAX, &r->GPR[i.Rt].s);
					//e->ShlRegImm32(RAX, (u32)i.Shift);
					//ret = e->MovRegToMem32(&r->GPR[i.Rd].s, RAX);
					x->emit("mov rax, @ptr", &r->GPR[i.Rt].s);

					if (i.Shift)
					{
						x->emit("sar rax, @imm", i.Shift);
					}

					x->emit("mov @ptr, rax", &r->GPR[i.Rd].s);
				}
			}

#else

			if ( i.Rd )
			{
				if ( !i.Rt )
				{
					e->MovMemImm64 ( &r->GPR [ i.Rd ].s, 0 );
				}
				else
				{
					e->MovRegMem64 ( RAX, &r->GPR [ i.Rt ].s );
					
					if ( i.Shift )
					{
						e->SarRegImm64 ( RAX, (u32) i.Shift );
					}
					
					ret = e->MovMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
				}
			}
#endif
			break;
			

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::DSRA32 ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "DSRA32";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::DSRA32;
	
	int Rd, Rs, Rt;
	int Reg1, Reg2;
	s64 lConst;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case -1:
			// source registers are Rt
			ullSrcRegBitmap |= ( 1 << i.Rt );
			
			// destination register is Rd
			ullDstRegBitmap |= ( 1ull << i.Rd );
			break;
			
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
#ifdef USE_NEW_R5900_ASSEMBLER_DSRA32

			if (i.Rd)
			{
				if (!i.Rt)
				{
					//ret = e->MovMemImm32(&r->GPR[i.Rd].s, 0);
					x->emit("mov qword ptr @ptr, 0", &r->GPR[i.Rd].s);
				}
				else if (i.Rd == i.Rt)
				{
					x->emit("sar qword ptr @ptr, @imm", &r->GPR[i.Rd].s, i.Shift + 32);
				}
				else
				{
					//e->MovRegFromMem32(0, &r->GPR[i.Rt].s);
					//e->SarRegImm32(0, (u32)i.Shift);
					//ret = e->MovRegToMem32(&r->GPR[i.Rd].s, 0);
					x->emit("mov rax, @ptr", &r->GPR[i.Rt].s);
					x->emit("sar rax, @imm", i.Shift + 32);
					x->emit("mov @ptr, rax", &r->GPR[i.Rd].s);
				}
			}

#else
			if ( i.Rd )
			{
				if ( !i.Rt )
				{
					e->MovMemImm64 ( &r->GPR [ i.Rd ].s, 0 );
				}
				else
				{
					e->MovRegMem64 ( RAX, &r->GPR [ i.Rt ].s );
					e->SarRegImm64 ( RAX, (u32) i.Shift + 32 );
					ret = e->MovMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
				}
			}
#endif
			break;
			

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::DSRAV ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "DSRAV";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::DSRAV;
	
	int Rd, Rs, Rt;
	int Reg1, Reg2;
	s64 lConst;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case -1:
			// source registers are Rs and Rt
			ullSrcRegBitmap |= ( 1ull << i.Rs ) | ( 1ull << i.Rt );
			
			// destination register is Rd
			ullDstRegBitmap |= ( 1ull << i.Rd );
			break;
			
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
#ifdef USE_NEW_R5900_ASSEMBLER_DSRAV

			if (i.Rd)
			{
				if (!i.Rt)
				{
					//ret = e->MovMemImm32(&r->GPR[i.Rd].s, 0);
					x->emit("mov qword ptr @ptr, 0", &r->GPR[i.Rd].s);
				}
				else if (i.Rd == i.Rt)
				{
					if (i.Rs)
					{
						x->emit("mov ecx, @ptr", &r->GPR[i.Rs].s);
						x->emit("sar qword ptr @ptr, cl", &r->GPR[i.Rd].s);
					}
				}
				else
				{
					//e->MovRegFromMem32(RAX, &r->GPR[i.Rt].s);
					//e->MovRegFromMem32(RCX, &r->GPR[i.Rs].s);
					//e->SarRegReg32(RAX);
					//e->MovRegToMem32(&r->GPR[i.Rd].s, RAX);
					x->emit("mov rax, @ptr", &r->GPR[i.Rt].s);

					if (i.Rs)
					{
						x->emit("mov ecx, @ptr", &r->GPR[i.Rs].s);
						x->emit("sar rax, cl");
					}

					x->emit("mov @ptr, rax", &r->GPR[i.Rd].s);
				}
			}

#else
			if ( i.Rd )
			{
				if ( !i.Rt )
				{
					e->MovMemImm64 ( &r->GPR [ i.Rd ].s, 0 );
				}
				else if ( !i.Rs )
				{
					e->MovRegMem64 ( RAX, &r->GPR [ i.Rt ].s );
					ret = e->MovMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
				}
				else
				{
					e->MovRegMem64 ( RAX, &r->GPR [ i.Rt ].s );
					e->MovRegMem32 ( RCX, &r->GPR [ i.Rs ].sw0 );
					e->SarRegReg64 ( RAX );
					ret = e->MovMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
				}
			}
#endif
			break;
			

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::DSRL ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "DSRL";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::DSRL;
	
	int Rd, Rs, Rt;
	int Reg1, Reg2;
	s64 lConst;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case -1:
			// source registers are Rt
			ullSrcRegBitmap |= ( 1 << i.Rt );
			
			// destination register is Rd
			ullDstRegBitmap |= ( 1ull << i.Rd );
			break;
			
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
#ifdef USE_NEW_R5900_ASSEMBLER_DSRL

			if (i.Rd)
			{
				if (!i.Rt)
				{
					//ret = e->MovMemImm32(&r->GPR[i.Rd].s, 0);
					x->emit("mov qword ptr @ptr, 0", &r->GPR[i.Rd].s);
				}
				else if (i.Rd == i.Rt)
				{
					if (i.Shift)
					{
						x->emit("shr qword ptr @ptr, @imm", &r->GPR[i.Rd].s, i.Shift);
					}
				}
				else
				{
					//e->MovRegFromMem32(RAX, &r->GPR[i.Rt].s);
					//e->ShrRegImm32(RAX, (u32)i.Shift);
					//ret = e->MovRegToMem32(&r->GPR[i.Rd].s, RAX);
					x->emit("mov rax, @ptr", &r->GPR[i.Rt].s);

					if (i.Shift)
					{
						x->emit("shr rax, @imm", i.Shift);
					}

					x->emit("mov @ptr, rax", &r->GPR[i.Rd].s);
				}
			}

#else

			if ( i.Rd )
			{
				if ( !i.Rt )
				{
					e->MovMemImm64 ( &r->GPR [ i.Rd ].s, 0 );
				}
				else
				{
					e->MovRegMem64 ( RAX, &r->GPR [ i.Rt ].s );
					
					if ( i.Shift )
					{
						e->ShrRegImm64 ( RAX, (u32) i.Shift );
					}
					
					ret = e->MovMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
				}
			}
#endif
			break;
			

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::DSRL32 ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "DSRL32";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::DSRL32;
	
	int Rd, Rs, Rt;
	int Reg1, Reg2;
	s64 lConst;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case -1:
			// source registers are Rt
			ullSrcRegBitmap |= ( 1 << i.Rt );
			
			// destination register is Rd
			ullDstRegBitmap |= ( 1ull << i.Rd );
			break;
			
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
#ifdef USE_NEW_R5900_ASSEMBLER_DSRL32

			if (i.Rd)
			{
				if (!i.Rt)
				{
					//ret = e->MovMemImm32(&r->GPR[i.Rd].s, 0);
					x->emit("mov qword ptr @ptr, 0", &r->GPR[i.Rd].s);
				}
				else if (i.Rd == i.Rt)
				{
					x->emit("shr qword ptr @ptr, @imm", &r->GPR[i.Rd].s, i.Shift + 32);
				}
				else
				{
					//e->MovRegFromMem32(RAX, &r->GPR[i.Rt].s);
					//e->ShrRegImm32(RAX, (u32)i.Shift);
					//ret = e->MovRegToMem32(&r->GPR[i.Rd].s, RAX);
					x->emit("mov rax, @ptr", &r->GPR[i.Rt].s);
					x->emit("shr rax, @imm", i.Shift + 32);
					x->emit("mov @ptr, rax", &r->GPR[i.Rd].s);
				}
			}

#else

			if ( i.Rd )
			{
				if ( !i.Rt )
				{
					e->MovMemImm64 ( &r->GPR [ i.Rd ].s, 0 );
				}
				else
				{
					e->MovRegMem64 ( RAX, &r->GPR [ i.Rt ].s );
					e->ShrRegImm64 ( RAX, (u32) i.Shift + 32 );
					ret = e->MovMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
				}
			}
#endif
			break;
			

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::DSRLV ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "DSRLV";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::DSRLV;
	
	int Rd, Rs, Rt;
	int Reg1, Reg2;
	s64 lConst;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case -1:
			// source registers are Rs and Rt
			ullSrcRegBitmap |= ( 1ull << i.Rs ) | ( 1ull << i.Rt );
			
			// destination register is Rd
			ullDstRegBitmap |= ( 1ull << i.Rd );
			break;
			
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
#ifdef USE_NEW_R5900_ASSEMBLER_DSRLV

			if (i.Rd)
			{
				if (!i.Rt)
				{
					//ret = e->MovMemImm32(&r->GPR[i.Rd].s, 0);
					x->emit("mov qword ptr @ptr, 0", &r->GPR[i.Rd].s);
				}
				else if (i.Rd == i.Rt)
				{
					if (i.Rs)
					{
						x->emit("mov ecx, @ptr", &r->GPR[i.Rs].s);
						x->emit("shr qword ptr @ptr, cl", &r->GPR[i.Rd].s);
					}
				}
				else
				{
					//e->MovRegFromMem32(RAX, &r->GPR[i.Rt].s);
					//e->MovRegFromMem32(RCX, &r->GPR[i.Rs].s);
					//e->ShrRegReg32(RAX);
					//ret = e->MovRegToMem32(&r->GPR[i.Rd].s, RAX);
					x->emit("mov rax, @ptr", &r->GPR[i.Rt].s);

					if (i.Rs)
					{
						x->emit("mov ecx, @ptr", &r->GPR[i.Rs].s);
						x->emit("shr rax, cl");
					}

					x->emit("mov @ptr, rax", &r->GPR[i.Rd].s);
				}
			}

#else

			if ( i.Rd )
			{
				if ( !i.Rt )
				{
					e->MovMemImm64 ( &r->GPR [ i.Rd ].s, 0 );
				}
				else if ( !i.Rs )
				{
					e->MovRegMem64 ( RAX, &r->GPR [ i.Rt ].s );
					ret = e->MovMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
				}
				else
				{
					e->MovRegMem64 ( RAX, &r->GPR [ i.Rt ].s );
					e->MovRegMem32 ( RCX, &r->GPR [ i.Rs ].sw0 );
					e->ShrRegReg64 ( RAX );
					ret = e->MovMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
				}
			}
#endif
			break;
			

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}


int32_t R5900::Recompiler::MULT1 ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "MULT1";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::MULT1;
	
	
	// constant multiply cycles for PS2
	static constexpr int MULTIPLY_CYCLE_TIME = 4 / 2;
	
	int ret = 1;
	
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
#ifdef USE_NEW_MULT1_CODE
			
			// check if mul/div unit is in use
			//if ( r->MulDiv_BusyUntil_Cycle > r->CycleCount )
			//{
			//	// for now, just add onto memory latency
			//	r->CycleCount = r->MulDiv_BusyUntil_Cycle;
			//}

			e->MovRegMem64(RAX, (int64_t*)&r->CycleCount);
			e->MovRegReg64(RCX, RAX);
			e->AddReg64ImmX(RAX, LocalCycleCount);

			e->SubRegMem64(RAX, (int64_t*)&r->MulDiv_BusyUntil_Cycle1);
			e->Cqo();
			e->AndRegReg64(RDX, RAX);

			// store cycle count minus one to the current cycle (because it adds one on return from recompiler for now)
			// or, no need to subtract one if we don't count the cycle for the instruction (can subtract one when resetting the cycle count)

			// note: copilot ai says to actually add to the register and store the value, due to a hidden load otherwise
			// add the REAL CycleCount (CPU) to the cycles for the multiply and store to the BusyUntil Cycle for Mul/Div unit
			e->SubRegReg64(RCX, RDX);
			//e->SubMemReg64 ( (int64_t*) & r->CycleCount, RDX );
			e->MovMemReg64((int64_t*)&r->CycleCount, RCX);

			// add in the latency for multiply
			//e->AddReg64ImmX(RCX, MULTIPLY_CYCLE_TIME);
			e->AddReg64ImmX(RCX, MULTIPLY_CYCLE_TIME + LocalCycleCount);

			// write back the new busy until cycle
			e->MovMemReg64((int64_t*)&r->MulDiv_BusyUntil_Cycle1, RCX);


			// do the multiply
			e->MovRegMem32 ( RAX, & r->GPR [ i.Rs ].sw0 );
			e->ImulRegMem32 ( & r->GPR [ i.Rt ].sw0 );
			// *** TODO FOR PS2 *** //
			//e->MovMemReg32 ( & r->HiLo.sLo, RAX );
			e->Cdqe ();
			e->MovMemReg64 ( & r->LO.sq1, RAX );
			//ret = e->MovMemReg32 ( & r->HiLo.sHi, RDX );
			e->MovsxdReg64Reg32 ( RDX, RDX );
			ret = e->MovMemReg64 ( & r->HI.sq1, RDX );
			
			// *note*: the R5900 additionally writes to a destination register
			if ( i.Rd )
			{
				e->MovMemReg64 ( & r->GPR [ i.Rd ].s, RAX );
			}
#else
			return -1;
#endif
			
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::MULTU1 ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "MULTU1";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::MULTU1;
	
	
	// constant multiply cycles for PS2
	static constexpr int MULTIPLY_CYCLE_TIME = 4 / 2;
	
	int ret = 1;
	
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
#ifdef USE_NEW_MULTU1_CODE
			
			// check if mul/div unit is in use
			//if ( r->MulDiv_BusyUntil_Cycle > r->CycleCount )
			//{
			//	// for now, just add onto memory latency
			//	r->CycleCount = r->MulDiv_BusyUntil_Cycle;
			//}

			e->MovRegMem64(RAX, (int64_t*)&r->CycleCount);
			e->MovRegReg64(RCX, RAX);
			e->AddReg64ImmX(RAX, LocalCycleCount);

			e->SubRegMem64(RAX, (int64_t*)&r->MulDiv_BusyUntil_Cycle1);
			e->Cqo();
			e->AndRegReg64(RDX, RAX);

			// store cycle count minus one to the current cycle (because it adds one on return from recompiler for now)
			// or, no need to subtract one if we don't count the cycle for the instruction (can subtract one when resetting the cycle count)

			// note: copilot ai says to actually add to the register and store the value, due to a hidden load otherwise
			// add the REAL CycleCount (CPU) to the cycles for the multiply and store to the BusyUntil Cycle for Mul/Div unit
			e->SubRegReg64(RCX, RDX);
			//e->SubMemReg64 ( (int64_t*) & r->CycleCount, RDX );
			e->MovMemReg64((int64_t*)&r->CycleCount, RCX);

			// add in the latency for multiply
			//e->AddReg64ImmX(RCX, MULTIPLY_CYCLE_TIME);
			e->AddReg64ImmX(RCX, MULTIPLY_CYCLE_TIME + LocalCycleCount);

			// write back the new busy until cycle
			e->MovMemReg64((int64_t*)&r->MulDiv_BusyUntil_Cycle1, RCX);


			// do the multiply
			e->MovRegMem32 ( RAX, & r->GPR [ i.Rs ].sw0 );
			e->MulRegMem32 ( & r->GPR [ i.Rt ].sw0 );
			e->Cdqe ();
			e->MovMemReg64 ( & r->LO.sq1, RAX );
			e->MovsxdReg64Reg32 ( RDX, RDX );
			e->MovMemReg64 ( & r->HI.sq1, RDX );
			
			// *note*: the R5900 additionally writes to a destination register
			if ( i.Rd )
			{
				e->MovMemReg64 ( & r->GPR [ i.Rd ].s, RAX );
			}
#else
			return -1;
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::DIV1 ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "DIV1";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::DIV1;
	
	static constexpr int DIVIDE_CYCLE_TIME = 36 / 2;
	
	int ret = 1;
	
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
#ifdef USE_NEW_DIV1_CODE
			
			// check if mul/div unit is in use
			//if ( r->MulDiv_BusyUntil_Cycle > r->CycleCount )
			//{
			//	// for now, just add onto memory latency
			//	r->CycleCount = r->MulDiv_BusyUntil_Cycle;
			//}

			e->MovRegMem64(RAX, (int64_t*)&r->CycleCount);
			e->MovRegReg64(RCX, RAX);
			e->AddReg64ImmX(RAX, LocalCycleCount);

			e->SubRegMem64(RAX, (int64_t*)&r->MulDiv_BusyUntil_Cycle1);
			e->Cqo();
			e->AndRegReg64(RDX, RAX);

			// store cycle count minus one to the current cycle (because it adds one on return from recompiler for now)
			// or, no need to subtract one if we don't count the cycle for the instruction (can subtract one when resetting the cycle count)

			// note: copilot ai says to actually add to the register and store the value, due to a hidden load otherwise
			// add the REAL CycleCount (CPU) to the cycles for the multiply and store to the BusyUntil Cycle for Mul/Div unit
			e->SubRegReg64(RCX, RDX);
			//e->SubMemReg64 ( (int64_t*) & r->CycleCount, RDX );
			e->MovMemReg64((int64_t*)&r->CycleCount, RCX);

			// add in the latency for multiply
			//e->AddReg64ImmX(RCX, DIVIDE_CYCLE_TIME);
			e->AddReg64ImmX(RCX, DIVIDE_CYCLE_TIME + LocalCycleCount);

			// write back the new busy until cycle
			e->MovMemReg64((int64_t*)&r->MulDiv_BusyUntil_Cycle1, RCX);


			// mult/div unit is busy now
			//r->MulDiv_BusyUntil_Cycle = r->CycleCount + c_iDivideCycles;
			// add the REAL CycleCount (CPU) to the cycles for the multiply and store to the BusyUntil Cycle for Mul/Div unit
			//e->AddReg64ImmX ( RAX, c_iDivideCycles );
			//e->MovMemReg64 ( (int64_t*) & r->MulDiv_BusyUntil_Cycle, RAX );
			
#ifdef USE_EXCEPTIONS_R5900_DIV

			e->MovRegMem32(RAX, (int32_t*)&r->GPR[i.Rs].s);
			e->MovRegMem32(RCX, (int32_t*)&r->GPR[i.Rt].s);
			e->Cdq();

			e->IdivRegReg32(RCX);

			e->Cdqe();
			e->MovsxdReg64Reg32(RDX, RDX);

			e->MovMemReg64(&r->LO.sq1, RAX);
			e->MovMemReg64(&r->HI.sq1, RDX);

#else


			// divide signed: Lo = rs / rt; Hi = rs % rt
			//if ( r->GPR [ i.Rt ].s != 0 )
			//{
			//	// if rs = 0x80000000 and rt = -1 then hi = 0 and lo = 0x80000000
			//	if ( r->GPR [ i.Rs ].s == 0x80000000 && r->GPR [ i.Rt ].s == -1 )
			//	{
			//		r->HiLo.uHi = 0;
			//		r->HiLo.uLo = 0x80000000;
			//	}
			//	else
			//	{
			//		r->HiLo.sLo = r->GPR [ i.Rs ].s / r->GPR [ i.Rt ].s;
			//		r->HiLo.sHi = r->GPR [ i.Rs ].s % r->GPR [ i.Rt ].s;
			//	}
			//}
			//else
			//{
			//	if ( r->GPR [ i.Rs ].s < 0 )
			//	{
			//		r->HiLo.sLo = 1;
			//	}
			//	else
			//	{
			//		r->HiLo.sLo = -1;
			//	}
			//	r->HiLo.uHi = r->GPR [ i.Rs ].u;
			//}
			//e->MovRegMem32 ( RCX, & r->GPR [ i.Rt ].s );
			//e->MovRegMem32 ( RAX, & r->GPR [ i.Rs ].s );
			e->MovsxdReg64Mem32 ( RCX, & r->GPR [ i.Rt ].sw0 );
			e->MovsxdReg64Mem32 ( RAX, & r->GPR [ i.Rs ].sw0 );
			
			e->Cqo ();
			e->NotReg64 ( RDX );
			e->OrReg64ImmX ( RDX, 1 );
			
			e->Jmp8_ECXZ ( 0, 0 );
			
			e->Cdq ();
			//e->IdivRegReg64 ( RCX );
			e->IdivRegReg32 ( RCX );

			// *** todo for ps2 *** //
			//e->MovMemReg32 ( & r->HiLo.sLo, RAX );
			e->Cdqe ();
			e->MovsxdReg64Reg32 ( RDX, RDX );
			e->XchgRegReg64 ( RAX, RDX );
			
			e->SetJmpTarget8 ( 0 );
			
			
			// *** todo for ps2 *** //
			//e->MovMemReg32 ( & r->HiLo.uHi, RAX );
			e->MovMemReg64 ( & r->HI.sq1, RAX );
			//e->MovMemReg32 ( & r->HiLo.uLo, RCX );
			e->MovMemReg64 ( & r->LO.sq1, RDX );

#endif

			// done //
#else
			return -1;
#endif
			
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::DIVU1 ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "DIVU1";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::DIVU1;
	
	static constexpr int DIVIDE_CYCLE_TIME = 36 / 2;
	
	int ret = 1;
	
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
#ifdef USE_NEW_DIVU1_CODE
			
			// check if mul/div unit is in use
			//if ( r->MulDiv_BusyUntil_Cycle > r->CycleCount )
			//{
			//	// for now, just add onto memory latency
			//	r->CycleCount = r->MulDiv_BusyUntil_Cycle;
			//}

			e->MovRegMem64(RAX, (int64_t*)&r->CycleCount);
			e->MovRegReg64(RCX, RAX);
			e->AddReg64ImmX(RAX, LocalCycleCount);

			e->SubRegMem64(RAX, (int64_t*)&r->MulDiv_BusyUntil_Cycle1);
			e->Cqo();
			e->AndRegReg64(RDX, RAX);

			// store cycle count minus one to the current cycle (because it adds one on return from recompiler for now)
			// or, no need to subtract one if we don't count the cycle for the instruction (can subtract one when resetting the cycle count)

			// note: copilot ai says to actually add to the register and store the value, due to a hidden load otherwise
			// add the REAL CycleCount (CPU) to the cycles for the multiply and store to the BusyUntil Cycle for Mul/Div unit
			e->SubRegReg64(RCX, RDX);
			//e->SubMemReg64 ( (int64_t*) & r->CycleCount, RDX );
			e->MovMemReg64((int64_t*)&r->CycleCount, RCX);

			// add in the latency for multiply
			//e->AddReg64ImmX(RCX, DIVIDE_CYCLE_TIME);
			e->AddReg64ImmX(RCX, DIVIDE_CYCLE_TIME + LocalCycleCount);

			// write back the new busy until cycle
			e->MovMemReg64((int64_t*)&r->MulDiv_BusyUntil_Cycle1, RCX);

#ifdef USE_EXCEPTIONS_R5900_DIV

			e->MovRegMem32(RAX, (int32_t*)&r->GPR[i.Rs].s);
			e->MovRegMem32(RCX, (int32_t*)&r->GPR[i.Rt].s);
			//e->Cdq();
			e->XorRegReg32(RDX, RDX);

			e->DivRegReg32(RCX);

			e->Cdqe();
			e->MovsxdReg64Reg32(RDX, RDX);

			e->MovMemReg64(&r->LO.sq1, RAX);
			e->MovMemReg64(&r->HI.sq1, RDX);

#else

			// mult/div unit is busy now
			//r->MulDiv_BusyUntil_Cycle = r->CycleCount + c_iDivideCycles;
			// add the REAL CycleCount (CPU) to the cycles for the multiply and store to the BusyUntil Cycle for Mul/Div unit
			//e->AddReg64ImmX ( RAX, c_iDivideCycles );
			//e->MovMemReg64 ( (int64_t*) & r->MulDiv_BusyUntil_Cycle, RAX );
			
			// divide unsigned: Lo = rs / rt; Hi = rs % rt
			//if ( r->GPR [ i.Rt ].s != 0 )
			//{
			//	r->HiLo.uLo = r->GPR [ i.Rs ].s / r->GPR [ i.Rt ].u;
			//	r->HiLo.uHi = r->GPR [ i.Rs ].s % r->GPR [ i.Rt ].u;
			//}
			//else
			//{
			//	r->HiLo.sLo = -1;
			//	r->HiLo.uHi = r->GPR [ i.Rs ].u;
			//}
			e->MovRegMem32 ( RCX, & r->GPR [ i.Rt ].sw0 );
			e->MovRegMem32 ( RAX, & r->GPR [ i.Rs ].sw0 );
			
			e->MovReg64ImmX ( RDX, -1 );
			
			//e->OrRegReg64 ( RCX, RCX );
			//e->Jmp8_E ( 0, 0 );
			e->Jmp8_ECXZ ( 0, 0 );
			
			e->XorRegReg32 ( RDX, RDX );
			e->DivRegReg32 ( RCX );
			//e->MovMemReg32 ( & r->HiLo.sLo, RAX );
			e->Cdqe ();
			//e->MovMemReg64 ( & r->LO.sq1, RAX );
			//e->MovMemReg32 ( & r->HiLo.sHi, RDX );
			e->MovsxdReg64Reg32 ( RDX, RDX );
			//e->MovMemReg64 ( & r->HI.sq1, RDX );
			//e->Jmp8 ( 0, 1 );
			e->XchgRegReg64 ( RAX, RDX );
			
			e->SetJmpTarget8 ( 0 );
			
			//e->MovMemImm32 ( & r->HiLo.sLo, -1 );
			//e->MovMemReg32 ( & r->HiLo.uHi, RAX );
			//e->MovMemImm64 ( & r->LO.sq1, -1 );
			e->MovMemReg64 ( & r->LO.sq1, RDX );
			e->MovMemReg64 ( & r->HI.sq1, RAX );
#endif
			
			// done //
#else
			return -1;
#endif
			
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::MADD ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "MADD";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::MADD;
	
	// if rs is between -0x800 and 0x7ff, then multiply takes 6 cycles
	static const int c_iMultiplyCycles_Fast = 6;
	
	// if rs is between 0x800 and 0xfffff or between -0x7ff and -0x100000, then multiply takes 9 cycles
	static const int c_iMultiplyCycles_Med = 9;
	
	// otherwise, multiply takes 13 cycles
	static const int c_iMultiplyCycles_Slow = 13;

	// constant multiply cycles for PS2
	static const int c_iMultiplyCycles = 4 / 2;
	
	int ret = 1;
	
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
#ifdef USE_NEW_MADD_CODE
			//bResetCycleCount = true;
			
			// calculate cycles mul/div unit will be busy for
			//r->MulDiv_BusyUntil_Cycle = r->CycleCount + c_iMultiplyCycles_Slow;
			//if ( r->GPR [ i.Rs ].s < 0x800 && r->GPR [ i.Rs ].s >= -0x800 )
			//{
			//	r->MulDiv_BusyUntil_Cycle = r->CycleCount + c_iMultiplyCycles_Fast;
			//}
			//else if ( r->GPR [ i.Rs ].s < 0x100000 && r->GPR [ i.Rs ].s >= -0x100000 )
			//{
			//	r->MulDiv_BusyUntil_Cycle = r->CycleCount + c_iMultiplyCycles_Med;
			//}
			/*
			e->MovRegMem32 ( RCX, & r->GPR [ i.Rs ].sw0 );
			e->MovRegReg32 ( RAX, RCX );
			e->XorReg32ImmX ( RAX, -1 );
			e->CmovSRegReg32 ( RAX, RCX );
			e->MovReg32ImmX ( RDX, c_iMultiplyCycles_Slow );
			e->MovReg32ImmX ( RCX, c_iMultiplyCycles_Med );
			e->CmpReg32ImmX ( RAX, 0x100000 );
			e->CmovBRegReg32 ( RDX, RCX );
			e->MovReg32ImmX ( RCX, c_iMultiplyCycles_Fast );
			e->CmpReg32ImmX ( RAX, 0x800 );
			e->CmovBRegReg32 ( RDX, RCX );
			*/
			
			// check if mul/div unit is in use
			//if ( r->MulDiv_BusyUntil_Cycle > r->CycleCount )
			//{
			//	// for now, just add onto memory latency
			//	r->CycleCount = r->MulDiv_BusyUntil_Cycle;
			//}
			e->MovRegMem64 ( RAX, (int64_t*) & r->CycleCount );
			//e->MovRegMem64 ( RDX, (int64_t*) & r->MulDiv_BusyUntil_Cycle );
			e->AddReg64ImmX ( RAX, LocalCycleCount );
			
			e->MovRegReg64 ( RCX, RAX );
			e->SubRegMem64 ( RAX, (int64_t*) & r->MulDiv_BusyUntil_Cycle );
			e->Cqo ();
			e->AndRegReg64 ( RDX, RAX );
			
			//e->XorRegReg64 ( RDX, RDX );
			//e->SubRegReg64 ( RAX, RCX );
			//e->CmovBRegReg64 ( RDX, RAX );
			
			
			// store cycle count minus one to the current cycle (because it adds one on return from recompiler for now)
			// or, no need to subtract one if we don't count the cycle for the instruction (can subtract one when resetting the cycle count)
			//e->MovMemReg64 ( (int64_t*) & r->CycleCount, RAX );
			e->SubMemReg64 ( (int64_t*) & r->CycleCount, RDX );
			
			
			// add the REAL CycleCount (CPU) to the cycles for the multiply and store to the BusyUntil Cycle for Mul/Div unit
			//e->AddRegReg64 ( RDX, RAX );
			e->SubRegReg64 ( RCX, RDX );
			
#ifdef ENABLE_MULTIPLY_LATENCY
			// add in the latency for multiply
			e->AddReg64ImmX ( RCX, c_iMultiplyCycles );
#endif

			// write back the new busy until cycle
			e->MovMemReg64 ( (int64_t*) & r->MulDiv_BusyUntil_Cycle, RCX );
			
			// do the multiply
			e->MovRegMem32 ( RAX, & r->GPR [ i.Rs ].sw0 );
			e->ImulRegMem32 ( & r->GPR [ i.Rt ].sw0 );
			
			// for MADD, add to LO,HI
			e->AddRegMem32 ( RAX, & r->LO.sw0 );
			e->AdcRegMem32 ( RDX, & r->HI.sw0 );
			
			// *** TODO FOR PS2 *** //
			//e->MovMemReg32 ( & r->HiLo.sLo, RAX );
			e->Cdqe ();
			e->MovMemReg64 ( & r->LO.sq0, RAX );
			//ret = e->MovMemReg32 ( & r->HiLo.sHi, RDX );
			e->MovsxdReg64Reg32 ( RDX, RDX );
			ret = e->MovMemReg64 ( & r->HI.sq0, RDX );
			
			// *note*: the R5900 additionally writes to a destination register
			if ( i.Rd )
			{
				ret = e->MovMemReg64 ( & r->GPR [ i.Rd ].s, RAX );
			}
#else
			return -1;
#endif
			
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::MADD1 ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "MADD1";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::MADD1;
	
	// if rs is between -0x800 and 0x7ff, then multiply takes 6 cycles
	static const int c_iMultiplyCycles_Fast = 6;
	
	// if rs is between 0x800 and 0xfffff or between -0x7ff and -0x100000, then multiply takes 9 cycles
	static const int c_iMultiplyCycles_Med = 9;
	
	// otherwise, multiply takes 13 cycles
	static const int c_iMultiplyCycles_Slow = 13;

	// constant multiply cycles for PS2
	static const int c_iMultiplyCycles = 4 / 2;
	
	int ret = 1;
	
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
#ifdef USE_NEW_MADD1_CODE
			//bResetCycleCount = true;
			
			// calculate cycles mul/div unit will be busy for
			//r->MulDiv_BusyUntil_Cycle = r->CycleCount + c_iMultiplyCycles_Slow;
			//if ( r->GPR [ i.Rs ].s < 0x800 && r->GPR [ i.Rs ].s >= -0x800 )
			//{
			//	r->MulDiv_BusyUntil_Cycle = r->CycleCount + c_iMultiplyCycles_Fast;
			//}
			//else if ( r->GPR [ i.Rs ].s < 0x100000 && r->GPR [ i.Rs ].s >= -0x100000 )
			//{
			//	r->MulDiv_BusyUntil_Cycle = r->CycleCount + c_iMultiplyCycles_Med;
			//}
			/*
			e->MovRegMem32 ( RCX, & r->GPR [ i.Rs ].sw0 );
			e->MovRegReg32 ( RAX, RCX );
			e->XorReg32ImmX ( RAX, -1 );
			e->CmovSRegReg32 ( RAX, RCX );
			e->MovReg32ImmX ( RDX, c_iMultiplyCycles_Slow );
			e->MovReg32ImmX ( RCX, c_iMultiplyCycles_Med );
			e->CmpReg32ImmX ( RAX, 0x100000 );
			e->CmovBRegReg32 ( RDX, RCX );
			e->MovReg32ImmX ( RCX, c_iMultiplyCycles_Fast );
			e->CmpReg32ImmX ( RAX, 0x800 );
			e->CmovBRegReg32 ( RDX, RCX );
			*/
			
			// check if mul/div unit is in use
			//if ( r->MulDiv_BusyUntil_Cycle > r->CycleCount )
			//{
			//	// for now, just add onto memory latency
			//	r->CycleCount = r->MulDiv_BusyUntil_Cycle;
			//}
			e->MovRegMem64 ( RAX, (int64_t*) & r->CycleCount );
			//e->MovRegMem64 ( RDX, (int64_t*) & r->MulDiv_BusyUntil_Cycle1 );
			e->AddReg64ImmX ( RAX, LocalCycleCount );
			
			e->MovRegReg64 ( RCX, RAX );
			e->SubRegMem64 ( RAX, (int64_t*) & r->MulDiv_BusyUntil_Cycle1 );
			e->Cqo ();
			e->AndRegReg64 ( RDX, RAX );
			
			//e->XorRegReg64 ( RDX, RDX );
			//e->SubRegReg64 ( RAX, RCX );
			//e->CmovBRegReg64 ( RDX, RAX );
			
			
			// store cycle count minus one to the current cycle (because it adds one on return from recompiler for now)
			// or, no need to subtract one if we don't count the cycle for the instruction (can subtract one when resetting the cycle count)
			//e->MovMemReg64 ( (int64_t*) & r->CycleCount, RAX );
			e->SubMemReg64 ( (int64_t*) & r->CycleCount, RDX );
			
			
			// add the REAL CycleCount (CPU) to the cycles for the multiply and store to the BusyUntil Cycle for Mul/Div unit
			//e->AddRegReg64 ( RDX, RAX );
			e->SubRegReg64 ( RCX, RDX );
			
#ifdef ENABLE_MULTIPLY_LATENCY
			// add in the latency for multiply
			e->AddReg64ImmX ( RCX, c_iMultiplyCycles );
#endif

			// write back the new busy until cycle
			e->MovMemReg64 ( (int64_t*) & r->MulDiv_BusyUntil_Cycle1, RCX );
			
			// do the multiply
			e->MovRegMem32 ( RAX, & r->GPR [ i.Rs ].sw0 );
			e->ImulRegMem32 ( & r->GPR [ i.Rt ].sw0 );
			
			// for MADD, add to LO,HI
			e->AddRegMem32 ( RAX, & r->LO.sw2 );
			e->AdcRegMem32 ( RDX, & r->HI.sw2 );
			
			// *** TODO FOR PS2 *** //
			//e->MovMemReg32 ( & r->HiLo.sLo, RAX );
			e->Cdqe ();
			e->MovMemReg64 ( & r->LO.sq1, RAX );
			//ret = e->MovMemReg32 ( & r->HiLo.sHi, RDX );
			e->MovsxdReg64Reg32 ( RDX, RDX );
			ret = e->MovMemReg64 ( & r->HI.sq1, RDX );
			
			// *note*: the R5900 additionally writes to a destination register
			if ( i.Rd )
			{
				ret = e->MovMemReg64 ( & r->GPR [ i.Rd ].s, RAX );
			}
#else
			return -1;
#endif
			
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::MADDU ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "MADDU";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::MADDU;
	
	// if rs is between -0x800 and 0x7ff, then multiply takes 6 cycles
	static const int c_iMultiplyCycles_Fast = 6;
	
	// if rs is between 0x800 and 0xfffff or between -0x7ff and -0x100000, then multiply takes 9 cycles
	static const int c_iMultiplyCycles_Med = 9;
	
	// otherwise, multiply takes 13 cycles
	static const int c_iMultiplyCycles_Slow = 13;

	// constant multiply cycles for PS2
	static const int c_iMultiplyCycles = 4 / 2;
	
	int ret = 1;
	
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
#ifdef USE_NEW_MADDU_CODE
			//bResetCycleCount = true;
			
			//r->MulDiv_BusyUntil_Cycle = r->CycleCount + c_iMultiplyCycles_Slow;
			//if ( r->GPR [ i.Rs ].s < 0x800 )
			//{
			//	r->MulDiv_BusyUntil_Cycle = r->CycleCount + c_iMultiplyCycles_Fast;
			//}
			//else if ( r->GPR [ i.Rs ].s < 0x100000 )
			//{
			//	r->MulDiv_BusyUntil_Cycle = r->CycleCount + c_iMultiplyCycles_Med;
			//}
			/*
			e->MovRegMem32 ( RAX, & r->GPR [ i.Rs ].sw0 );
			e->MovReg32ImmX ( RDX, c_iMultiplyCycles_Slow );
			e->MovReg32ImmX ( RCX, c_iMultiplyCycles_Med );
			e->CmpReg32ImmX ( RAX, 0x100000 );
			e->CmovBRegReg32 ( RDX, RCX );
			e->MovReg32ImmX ( RCX, c_iMultiplyCycles_Fast );
			e->CmpReg32ImmX ( RAX, 0x800 );
			e->CmovBRegReg32 ( RDX, RCX );
			*/
			
			// check if mul/div unit is in use
			//if ( r->MulDiv_BusyUntil_Cycle > r->CycleCount )
			//{
			//	// for now, just add onto memory latency
			//	r->CycleCount = r->MulDiv_BusyUntil_Cycle;
			//}
			e->MovRegMem64 ( RAX, (int64_t*) & r->CycleCount );
			//e->MovRegMem64 ( RDX, (int64_t*) & r->MulDiv_BusyUntil_Cycle );
			e->AddReg64ImmX ( RAX, LocalCycleCount );
			
			e->MovRegReg64 ( RCX, RAX );
			e->SubRegMem64 ( RAX, (int64_t*) & r->MulDiv_BusyUntil_Cycle );
			e->Cqo ();
			e->AndRegReg64 ( RDX, RAX );
			
			//e->XorRegReg64 ( RDX, RDX );
			//e->SubRegReg64 ( RAX, RCX );
			//e->CmovBRegReg64 ( RDX, RAX );
			
			
			// store cycle count minus one to the current cycle (because it adds one on return from recompiler for now)
			// or, no need to subtract one if we don't count the cycle for the instruction (can subtract one when resetting the cycle count)
			//e->MovMemReg64 ( (int64_t*) & r->CycleCount, RAX );
			e->SubMemReg64 ( (int64_t*) & r->CycleCount, RDX );
			
			
			// add the REAL CycleCount (CPU) to the cycles for the multiply and store to the BusyUntil Cycle for Mul/Div unit
			//e->AddRegReg64 ( RDX, RAX );
			e->SubRegReg64 ( RCX, RDX );
			
#ifdef ENABLE_MULTIPLY_LATENCY
			// add in the latency for multiply
			e->AddReg64ImmX ( RCX, c_iMultiplyCycles );
#endif

			// write back the new busy until cycle
			e->MovMemReg64 ( (int64_t*) & r->MulDiv_BusyUntil_Cycle, RCX );
			
			// do the multiply
			e->MovRegMem32 ( RAX, & r->GPR [ i.Rs ].sw0 );
			e->MulRegMem32 ( & r->GPR [ i.Rt ].sw0 );
			
			// for MADD, add to LO,HI
			e->AddRegMem32 ( RAX, & r->LO.sw0 );
			e->AdcRegMem32 ( RDX, & r->HI.sw0 );
			
			// *** todo for ps2 *** //
			//e->MovMemReg32 ( & r->HiLo.sLo, RAX );
			e->Cdqe ();
			e->MovMemReg64 ( & r->LO.sq0, RAX );
			//e->MovMemReg32 ( & r->HiLo.sHi, RDX );
			e->MovsxdReg64Reg32 ( RDX, RDX );
			ret = e->MovMemReg64 ( & r->HI.sq0, RDX );
			
			// *note*: the R5900 additionally writes to a destination register
			if ( i.Rd )
			{
				ret = e->MovMemReg64 ( & r->GPR [ i.Rd ].s, RAX );
			}
#else
			return -1;
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::MADDU1 ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "MADDU1";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::MADDU1;
	
	// if rs is between -0x800 and 0x7ff, then multiply takes 6 cycles
	static const int c_iMultiplyCycles_Fast = 6;
	
	// if rs is between 0x800 and 0xfffff or between -0x7ff and -0x100000, then multiply takes 9 cycles
	static const int c_iMultiplyCycles_Med = 9;
	
	// otherwise, multiply takes 13 cycles
	static const int c_iMultiplyCycles_Slow = 13;

	// constant multiply cycles for PS2
	static const int c_iMultiplyCycles = 4 / 2;
	
	int ret = 1;
	
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
#ifdef USE_NEW_MADDU1_CODE
			//bResetCycleCount = true;
			
			//r->MulDiv_BusyUntil_Cycle = r->CycleCount + c_iMultiplyCycles_Slow;
			//if ( r->GPR [ i.Rs ].s < 0x800 )
			//{
			//	r->MulDiv_BusyUntil_Cycle = r->CycleCount + c_iMultiplyCycles_Fast;
			//}
			//else if ( r->GPR [ i.Rs ].s < 0x100000 )
			//{
			//	r->MulDiv_BusyUntil_Cycle = r->CycleCount + c_iMultiplyCycles_Med;
			//}
			/*
			e->MovRegMem32 ( RAX, & r->GPR [ i.Rs ].sw0 );
			e->MovReg32ImmX ( RDX, c_iMultiplyCycles_Slow );
			e->MovReg32ImmX ( RCX, c_iMultiplyCycles_Med );
			e->CmpReg32ImmX ( RAX, 0x100000 );
			e->CmovBRegReg32 ( RDX, RCX );
			e->MovReg32ImmX ( RCX, c_iMultiplyCycles_Fast );
			e->CmpReg32ImmX ( RAX, 0x800 );
			e->CmovBRegReg32 ( RDX, RCX );
			*/
			
			// check if mul/div unit is in use
			//if ( r->MulDiv_BusyUntil_Cycle > r->CycleCount )
			//{
			//	// for now, just add onto memory latency
			//	r->CycleCount = r->MulDiv_BusyUntil_Cycle;
			//}
			e->MovRegMem64 ( RAX, (int64_t*) & r->CycleCount );
			//e->MovRegMem64 ( RDX, (int64_t*) & r->MulDiv_BusyUntil_Cycle1 );
			e->AddReg64ImmX ( RAX, LocalCycleCount );
			
			e->MovRegReg64 ( RCX, RAX );
			e->SubRegMem64 ( RAX, (int64_t*) & r->MulDiv_BusyUntil_Cycle1 );
			e->Cqo ();
			e->AndRegReg64 ( RDX, RAX );
			
			//e->XorRegReg64 ( RDX, RDX );
			//e->SubRegReg64 ( RAX, RCX );
			//e->CmovBRegReg64 ( RDX, RAX );
			
			
			// store cycle count minus one to the current cycle (because it adds one on return from recompiler for now)
			// or, no need to subtract one if we don't count the cycle for the instruction (can subtract one when resetting the cycle count)
			//e->MovMemReg64 ( (int64_t*) & r->CycleCount, RAX );
			e->SubMemReg64 ( (int64_t*) & r->CycleCount, RDX );
			
			
			// add the REAL CycleCount (CPU) to the cycles for the multiply and store to the BusyUntil Cycle for Mul/Div unit
			//e->AddRegReg64 ( RDX, RAX );
			e->SubRegReg64 ( RCX, RDX );
			
#ifdef ENABLE_MULTIPLY_LATENCY
			// add in the latency for multiply
			e->AddReg64ImmX ( RCX, c_iMultiplyCycles );
#endif

			// write back the new busy until cycle
			e->MovMemReg64 ( (int64_t*) & r->MulDiv_BusyUntil_Cycle1, RCX );
			
			// do the multiply
			e->MovRegMem32 ( RAX, & r->GPR [ i.Rs ].sw0 );
			e->MulRegMem32 ( & r->GPR [ i.Rt ].sw0 );
			
			// for MADD, add to LO,HI
			e->AddRegMem32 ( RAX, & r->LO.sw2 );
			e->AdcRegMem32 ( RDX, & r->HI.sw2 );
			
			// *** todo for ps2 *** //
			//e->MovMemReg32 ( & r->HiLo.sLo, RAX );
			e->Cdqe ();
			e->MovMemReg64 ( & r->LO.sq1, RAX );
			//e->MovMemReg32 ( & r->HiLo.sHi, RDX );
			e->MovsxdReg64Reg32 ( RDX, RDX );
			ret = e->MovMemReg64 ( & r->HI.sq1, RDX );
			
			// *note*: the R5900 additionally writes to a destination register
			if ( i.Rd )
			{
				ret = e->MovMemReg64 ( & r->GPR [ i.Rd ].s, RAX );
			}
#else
			return -1;
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}



// Load/Store instructions //

int32_t R5900::Recompiler::SD ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "SD";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::SD;
	
	int ret = 1;
	
	
	switch ( OpLevel )
	{
#ifdef USE_NEW_SD_CODE2
		case -1:
			// source registers are Rs and Rt
			ullSrcRegBitmap |= ( 1ull << i.Rs ) | ( 1ull << i.Rt );
			
			break;
#endif
			
		case 0:
			// for now, stop encoding after this instruction
			//bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

#ifdef ENABLE_R5900_DCACHE
			e->AddMemImm64 ( (int64_t*) & r->CycleCount, LocalCycleCount - MemCycles );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );

#ifdef ENABLE_R5900_DCACHE
			e->SubMemImm64 ( (int64_t*) & r->CycleCount, LocalCycleCount - MemCycles );
#endif
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
#ifdef USE_NEW_STORE_CODE

#ifdef ENABLE_PS2_VIRTUAL_MACHINE_SD
			if (!bitget_hwrw_bitmap(Address))
			{
				ret = Generate_Virtual_Store(i, Address, 0x7, (void*)Playstation2::DataBus::Write_t<0xffffffffffffffffULL>);
			}
			else
#endif
			{
				ret = Generate_Normal_Store(i, Address, 0x7, (void*)Playstation2::DataBus::Write_t<0xffffffffffffffffULL>);
			}

#else
			return -1;
#endif
			break;
			
#ifdef USE_NEW_SD_CODE2
		case 2:
			if ( isConst ( i.Rs ) )
			{
				ret = Generate_Normal_Store_L2 ( i, Address, 0x7, GetConst( i.Rs ) );
				if ( !ret ) return -1;
			}
			else
			{
				return -1;
			}
			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::LD ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "LD";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::LD;
	
	int ret = 1;
	
	
	switch ( OpLevel )
	{
#ifdef USE_NEW_LD_CODE2
		case -1:
			// source registers are Rt
			ullSrcRegBitmap |= ( 1ull << i.Rs );
			
			// destination register is Rd
			ullDstRegBitmap |= ( 1ull << i.Rt );
			break;
#endif
			
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			//bStopEncodingBefore = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

#ifdef ENABLE_R5900_DCACHE
			e->AddMemImm64 ( (int64_t*) & r->CycleCount, LocalCycleCount - MemCycles );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );

#ifdef ENABLE_R5900_DCACHE
			e->SubMemImm64 ( (int64_t*) & r->CycleCount, LocalCycleCount - MemCycles );
#endif
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
#ifdef USE_NEW_LOAD_CODE

#ifdef ENABLE_PS2_VIRTUAL_MACHINE_LD

			if (!bitget_hwrw_bitmap(Address))
			{
				ret = Generate_Virtual_Load(i, Address, 0x7, (void*)Playstation2::DataBus::Read_t<0xffffffffffffffffULL>);
			}
			else
			{
				ret = Generate_Basic_Load(i, Address, 0x7, (void*)Playstation2::DataBus::Read_t<0xffffffffffffffffULL>);
			}
#else

			ret = Generate_Normal_Load(i, Address, 0x7, (void*)Playstation2::DataBus::Read_t<0xffffffffffffffffULL>);
#endif

			
			// store result //
			
			if ( i.Rt )
			{
				// store
				ret = e->MovMemReg64 ( & r->GPR [ i.Rt ].sq0, RAX );
			}
#else
			return -1;
#endif
			break;
			
#ifdef USE_NEW_LD_CODE2
		case 2:
			if ( isConst ( i.Rs ) )
			{
				ret = Generate_Normal_Load_L2 ( i, Address, 0x7, GetConst( i.Rs ) );
				if ( !ret ) return -1;
			}
			else
			{
				return -1;
			}
			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::LWU ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "LWU";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::LWU;
	
	int ret = 1;
	
	
	switch ( OpLevel )
	{
		case -1:
			// source registers are Rt
			ullSrcRegBitmap |= ( 1ull << i.Rs );
			
			// destination register is Rd
			ullDstRegBitmap |= ( 1ull << i.Rt );
			break;
			
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			//bStopEncodingBefore = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
#ifdef USE_NEW_LOAD_CODE

#ifdef ENABLE_PS2_VIRTUAL_MACHINE_LWU

			if (!bitget_hwrw_bitmap(Address))
			{
				ret = Generate_Virtual_Load(i, Address, 0x3, (void*)Playstation2::DataBus::Read_t<0xffffffffULL>);
			}
			else
			{
				ret = Generate_Basic_Load(i, Address, 0x3, (void*)Playstation2::DataBus::Read_t<0xffffffffULL>);
			}
#else

			ret = Generate_Normal_Load(i, Address, 0x3, (void*)Playstation2::DataBus::Read_t<0xffffffffULL>);
#endif

			// store result //
			
			if ( i.Rt )
			{
				// store
				ret = e->MovMemReg64 ( & r->GPR [ i.Rt ].sq0, RAX );
			}
#else
			return -1;
#endif
			break;
			
#ifdef USE_NEW_LWU_CODE2
		case 2:
			if ( isConst ( i.Rs ) )
			{
				ret = Generate_Normal_Load_L2 ( i, Address, 0x3, GetConst( i.Rs ) );
				if ( !ret ) return -1;
			}
			else
			{
				return -1;
			}
			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::SDL ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "SDL";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::SDL;
	
	int ret = 1;
	
	
	switch ( OpLevel )
	{
#ifdef USE_NEW_SDL_CODE2
		case -1:
			// source registers are Rs and Rt
			ullSrcRegBitmap |= ( 1ull << i.Rs ) | ( 1ull << i.Rt );
			
			break;
#endif
			
		case 0:
			// for now, stop encoding after this instruction
			//bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

#ifdef ENABLE_R5900_DCACHE
			e->AddMemImm64 ( (int64_t*) & r->CycleCount, LocalCycleCount - MemCycles );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );

#ifdef ENABLE_R5900_DCACHE
			e->SubMemImm64 ( (int64_t*) & r->CycleCount, LocalCycleCount - MemCycles );
#endif
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;


#ifdef USE_NEW_STORE_CODE_SDL
		case 1:
#ifdef ENABLE_PS2_VIRTUAL_MACHINE_SDL
			if (!bitget_hwrw_bitmap(Address))
			{
				ret = Generate_Virtual_Store(i, Address, 0x0, (void*)Playstation2::DataBus::Write);
			}
			else
#endif
			{
				ret = Generate_Normal_Store(i, Address, 0x0, (void*)Playstation2::DataBus::Write);
			}

			break;
#endif

#ifdef USE_NEW_SDL_CODE2
		case 2:
			if ( isConst ( i.Rs ) )
			{
				ret = Generate_Normal_Store_L2 ( i, Address, 0x0, GetConst( i.Rs ) );
				if ( !ret ) return -1;
			}
			else
			{
				return -1;
			}
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::SDR ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "SDR";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::SDR;
	
	int ret = 1;
	
	
	switch ( OpLevel )
	{
#ifdef USE_NEW_SDR_CODE2
		case -1:
			// source registers are Rs and Rt
			ullSrcRegBitmap |= ( 1ull << i.Rs ) | ( 1ull << i.Rt );
			
			break;
#endif
			
		case 0:
			// for now, stop encoding after this instruction
			//bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

#ifdef ENABLE_R5900_DCACHE
			e->AddMemImm64 ( (int64_t*) & r->CycleCount, LocalCycleCount - MemCycles );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );

#ifdef ENABLE_R5900_DCACHE
			e->SubMemImm64 ( (int64_t*) & r->CycleCount, LocalCycleCount - MemCycles );
#endif
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;


#ifdef USE_NEW_STORE_CODE_SDR
		case 1:
#ifdef ENABLE_PS2_VIRTUAL_MACHINE_SDR
			if (!bitget_hwrw_bitmap(Address))
			{
				ret = Generate_Virtual_Store(i, Address, 0x0, (void*)Playstation2::DataBus::Write);
			}
			else
#endif
			{
				ret = Generate_Normal_Store(i, Address, 0x0, (void*)Playstation2::DataBus::Write);
			}

			break;
#endif

#ifdef USE_NEW_SDR_CODE2
		case 2:
			if ( isConst ( i.Rs ) )
			{
				ret = Generate_Normal_Store_L2 ( i, Address, 0x0, GetConst( i.Rs ) );
				if ( !ret ) return -1;
			}
			else
			{
				return -1;
			}
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::LDL ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "LDL";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::LDL;
	
	int ret = 1;
	
	
	switch ( OpLevel )
	{
#ifdef USE_NEW_LDL_CODE2
		case -1:
			// source registers are Rt
			ullSrcRegBitmap |= ( 1ull << i.Rs );
			
			// destination register is Rd
			ullDstRegBitmap |= ( 1ull << i.Rt );
			break;
#endif
			
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			//bStopEncodingBefore = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

#ifdef ENABLE_R5900_DCACHE
			e->AddMemImm64 ( (int64_t*) & r->CycleCount, LocalCycleCount - MemCycles );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );

#ifdef ENABLE_R5900_DCACHE
			e->SubMemImm64 ( (int64_t*) & r->CycleCount, LocalCycleCount - MemCycles );
#endif
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;


#ifdef USE_NEW_LOAD_CODE_LDL
		case 1:

#ifdef ENABLE_PS2_VIRTUAL_MACHINE_LDL

			if (!bitget_hwrw_bitmap(Address))
			{
				ret = Generate_Virtual_Load(i, Address, 0x0, (void*)Playstation2::DataBus::Read_t<0xffffffffffffffffULL>);
			}
			else
			{
				ret = Generate_Basic_Load(i, Address, 0x0, (void*)Playstation2::DataBus::Read_t<0xffffffffffffffffULL>);
			}
#else

			ret = Generate_Normal_Load(i, Address, 0x0, (void*)Playstation2::DataBus::Read_t<0xffffffffffffffffULL>);
#endif

			if ( i.Rt )
			{
#ifdef USE_SHORT_LDL_CODE
				e->LeaRegMem64 ( RDX, & r->GPR [ i.Rt ].sw0 );
				e->NotReg32( RCX );
				e->AndReg32ImmX ( RCX, 7 );
				
				e->MovRegFromMem64 ( 8, RDX, NO_INDEX, SCALE_NONE, 8 );
				
				e->MovRegToMem64 ( RAX, RDX, RCX, SCALE_NONE, 0 );
				
				e->MovRegToMem64 ( 8, RDX, NO_INDEX, SCALE_NONE, 8 );
#else
				//e->MovRegFromMem32 ( RCX, &r->GPR [ i.Base ].sw0 );
				//e->AddReg32ImmX ( RCX, i.sOffset );
				
				//e->XorReg32ImmX ( RCX, 7 );
				e->NotReg32 ( RCX );
				e->AndReg32ImmX ( RCX, 7 );
				e->ShlRegImm32 ( RCX, 3 );
				e->ShlRegReg64 ( RAX );
				e->MovRegReg64 ( RDX, RAX );
				e->MovReg64ImmX ( RAX, -1 );
				//e->SubReg32ImmX ( RCX, 32 );
				//e->NegReg32 ( RCX );
				e->ShlRegReg64 ( RAX );
				e->NotReg64 ( RAX );
				e->AndRegMem64 ( RAX, &r->GPR [ i.Rt ].sq0 );
				e->OrRegReg64 ( RAX, RDX );
				//e->Cdqe ();
				ret = e->MovMemReg64 ( &r->GPR [ i.Rt ].sq0, RAX );
#endif
			}

			break;
#endif

#ifdef USE_NEW_LDL_CODE2
		case 2:
			if ( isConst ( i.Rs ) )
			{
				ret = Generate_Normal_Load_L2 ( i, Address, 0x0, GetConst( i.Rs ) );
				if ( !ret ) return -1;
			}
			else
			{
				return -1;
			}
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::LDR ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "LDR";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::LDR;
	
	int ret = 1;
	
	
	switch ( OpLevel )
	{
#ifdef USE_NEW_LDR_CODE2
		case -1:
			// source registers are Rt
			ullSrcRegBitmap |= ( 1ull << i.Rs );
			
			// destination register is Rd
			ullDstRegBitmap |= ( 1ull << i.Rt );
			break;
#endif
			
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			//bStopEncodingBefore = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

#ifdef ENABLE_R5900_DCACHE
			e->AddMemImm64 ( (int64_t*) & r->CycleCount, LocalCycleCount - MemCycles );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );

#ifdef ENABLE_R5900_DCACHE
			e->SubMemImm64 ( (int64_t*) & r->CycleCount, LocalCycleCount - MemCycles );
#endif
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;


#ifdef USE_NEW_LOAD_CODE_LDR
		case 1:

#ifdef ENABLE_PS2_VIRTUAL_MACHINE_LDR

			if (!bitget_hwrw_bitmap(Address))
			{
				ret = Generate_Virtual_Load(i, Address, 0x0, (void*)Playstation2::DataBus::Read_t<0xffffffffffffffffULL>);
			}
			else
			{
				ret = Generate_Basic_Load(i, Address, 0x0, (void*)Playstation2::DataBus::Read_t<0xffffffffffffffffULL>);
			}
#else

			ret = Generate_Normal_Load(i, Address, 0x0, (void*)Playstation2::DataBus::Read_t<0xffffffffffffffffULL>);
#endif

			if ( i.Rt )
			{
#ifdef USE_SHORT_LDR_CODE
				e->LeaRegMem64 ( RDX, & r->GPR [ i.Rt ].sw0 );
				e->AndReg32ImmX ( RCX, 7 );
				e->NegReg64( RCX );
				
				e->MovRegFromMem64 ( 8, RDX, NO_INDEX, SCALE_NONE, -8 );
				
				e->MovRegToMem64 ( RAX, RDX, RCX, SCALE_NONE, 0 );
				
				e->MovRegToMem64 ( 8, RDX, NO_INDEX, SCALE_NONE, -8 );
#else
				//e->MovRegFromMem32 ( RCX, &r->GPR [ i.Base ].sw0 );
				//e->AddReg32ImmX ( RCX, i.sOffset );
				
				//e->XorReg32ImmX ( RCX, 3 );
				e->AndReg32ImmX ( RCX, 7 );
				e->ShlRegImm32 ( RCX, 3 );
				e->ShrRegReg64 ( RAX );
				//e->Cdqe ();
				e->MovRegReg64 ( RDX, RAX );
				e->MovReg64ImmX ( RAX, -1 );
				//e->SubReg32ImmX ( RCX, 32 );
				//e->NegReg32 ( RCX );
				e->ShrRegReg64 ( RAX );
				//e->Cdqe ();
				e->NotReg64 ( RAX );
				e->AndRegMem64 ( RAX, &r->GPR [ i.Rt ].sq0 );
				e->OrRegReg64 ( RAX, RDX );
				//e->Cdqe ();
				ret = e->MovMemReg64 ( &r->GPR [ i.Rt ].sq0, RAX );
#endif
			}

			break;
#endif

#ifdef USE_NEW_LDR_CODE2
		case 2:
			if ( isConst ( i.Rs ) )
			{
				ret = Generate_Normal_Load_L2 ( i, Address, 0x0, GetConst( i.Rs ) );
				if ( !ret ) return -1;
			}
			else
			{
				return -1;
			}
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::LQ ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "LQ";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::LQ;
	
	int ret = 1;
	
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			//bStopEncodingBefore = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

#ifdef ENABLE_R5900_DCACHE
			e->AddMemImm64 ( (int64_t*) & r->CycleCount, LocalCycleCount - MemCycles );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );

#ifdef ENABLE_R5900_DCACHE
			e->SubMemImm64 ( (int64_t*) & r->CycleCount, LocalCycleCount - MemCycles );
#endif
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
			
		case 1:
#ifdef USE_NEW_LOAD_CODE

#ifdef ENABLE_PS2_VIRTUAL_MACHINE_LQ

			if (!bitget_hwrw_bitmap(Address))
			{
				ret = Generate_Virtual_Load(i, Address, 0, (void*)Playstation2::DataBus::Read_t<0>);
			}
			else
			{
				ret = Generate_Basic_Load(i, Address, 0, (void*)Playstation2::DataBus::Read_t<0>);
			}
#else

			ret = Generate_Normal_Load(i, Address, 0, (void*)Playstation2::DataBus::Read_t<0>);
#endif

			// store result //
			
			if ( i.Rt )
			{
				// store
				ret = e->movdqa_memreg ( & r->GPR [ i.Rt ].s, RAX );
			}
#else
			return -1;
#endif
			break;
			
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::SQ ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "SQ";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::SQ;
	
	int ret = 1;
	
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			//bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

#ifdef ENABLE_R5900_DCACHE
			e->AddMemImm64 ( (int64_t*) & r->CycleCount, LocalCycleCount - MemCycles );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );

#ifdef ENABLE_R5900_DCACHE
			e->SubMemImm64 ( (int64_t*) & r->CycleCount, LocalCycleCount - MemCycles );
#endif
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
#ifdef USE_NEW_STORE_CODE

#ifdef ENABLE_PS2_VIRTUAL_MACHINE_SQ
			if (!bitget_hwrw_bitmap(Address))
			{
				ret = Generate_Virtual_Store(i, Address, 0, (void*)Playstation2::DataBus::Write_t<0>);
			}
			else
#endif
			{
				ret = Generate_Normal_Store(i, Address, 0, (void*)Playstation2::DataBus::Write_t<0>);
			}

#else
			return -1;
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}


int32_t R5900::Recompiler::MOVZ ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "MOVZ";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::MOVZ;
	
	int Rd, Rs, Rt;
	int Reg1, Reg2;
	s64 lConst;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case -1:
			// source registers are Rs and Rt
			ullSrcRegBitmap |= ( 1ull << i.Rs ) | ( 1ull << i.Rt ) | ( 1ull << i.Rd );
			
			// destination register is Rd
			ullDstRegBitmap |= ( 1ull << i.Rd );
			break;
			
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
#ifdef USE_NEW_R5900_ASSEMBLER_MOVZ

			if (i.Rd)
			{
				if (i.Rd != i.Rs)
				{
					if (i.Rd == i.Rt)
					{
						x->emit("mov rax, @ptr", &r->GPR[i.Rd].s);
						x->emit("or rax, rax");
						x->emit("cmove rax, @ptr", &r->GPR[i.Rs].s);
						x->emit("mov @ptr, rax", &r->GPR[i.Rd].s);
					}
					else if (i.Rs == i.Rt)
					{
						x->emit("mov rax, @ptr", &r->GPR[i.Rt].s);
						x->emit("or rax, rax");
						x->emit("cmovne rax, @ptr", &r->GPR[i.Rd].s);
						x->emit("mov @ptr, rax", &r->GPR[i.Rd].s);
					}
					else
					{
						//e->CmpMem64ImmX(&r->GPR[i.Rt].s, 0);
						//e->MovRegMem64(RCX, &r->GPR[i.Rd].s);
						//e->CmovERegMem64(RCX, &r->GPR[i.Rs].s);
						//e->MovMemReg64(&r->GPR[i.Rd].s, RCX);
						x->emit("cmp qword ptr @ptr, 0", &r->GPR[i.Rt].s);
						x->emit("mov rax, @ptr", &r->GPR[i.Rd].s);
						x->emit("cmove rax, @ptr", &r->GPR[i.Rs].s);
						x->emit("mov @ptr, rax", &r->GPR[i.Rd].s);
					}
				}
			}

#else
			if ( i.Rd )
			{
				if ( i.Rd != i.Rs )
				{
					if ( i.Rd == i.Rt )
					{
						//e->MovRegMem64 ( RAX, & r->GPR [ i.Rt ].s );
						e->MovRegMem64 ( RCX, & r->GPR [ i.Rd ].s );
						e->OrRegReg64 ( RCX, RCX );
						e->CmovERegMem64 ( RCX, & r->GPR [ i.Rs ].s );
						e->MovMemReg64 ( & r->GPR [ i.Rd ].s, RCX );
					}
					else if ( i.Rs == i.Rt )
					{
						e->MovRegMem64 ( RAX, & r->GPR [ i.Rt ].s );
						e->MovRegMem64 ( RCX, & r->GPR [ i.Rd ].s );
						e->OrRegReg64 ( RAX, RAX );
						e->CmovERegReg64 ( RCX, RAX );
						e->MovMemReg64 ( & r->GPR [ i.Rd ].s, RCX );
					}
					else
					{
						e->CmpMem64ImmX ( & r->GPR [ i.Rt ].s, 0 );
						//e->MovRegMem64 ( RAX, & r->GPR [ i.Rt ].s );
						e->MovRegMem64 ( RCX, & r->GPR [ i.Rd ].s );
						//e->OrRegReg64 ( RAX, RAX );
						e->CmovERegMem64 ( RCX, & r->GPR [ i.Rs ].s );
						e->MovMemReg64 ( & r->GPR [ i.Rd ].s, RCX );
					}
				}
			}
#endif
			break;
			
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::MOVN ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "MOVN";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::MOVN;
	
	int Rd, Rs, Rt;
	int Reg1, Reg2;
	s64 lConst;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case -1:
			// source registers are Rs and Rt
			ullSrcRegBitmap |= ( 1ull << i.Rs ) | ( 1ull << i.Rt ) | ( 1ull << i.Rd );
			
			// destination register is Rd
			ullDstRegBitmap |= ( 1ull << i.Rd );
			break;
			
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
#ifdef USE_NEW_R5900_ASSEMBLER_MOVN

			if (i.Rd)
			{
				if (i.Rd != i.Rs)
				{
					if (i.Rd == i.Rt)
					{
						x->emit("mov rax, @ptr", &r->GPR[i.Rd].s);
						x->emit("or rax, rax");
						x->emit("cmovne rax, @ptr", &r->GPR[i.Rs].s);
						x->emit("mov @ptr, rax", &r->GPR[i.Rd].s);
					}
					else if (i.Rs == i.Rt)
					{
						x->emit("mov rax, @ptr", &r->GPR[i.Rt].s);
						x->emit("or rax, rax");
						x->emit("cmove rax, @ptr", &r->GPR[i.Rd].s);
						x->emit("mov @ptr, rax", &r->GPR[i.Rd].s);
					}
					else
					{
						//e->CmpMem64ImmX(&r->GPR[i.Rt].s, 0);
						//e->MovRegMem64(RCX, &r->GPR[i.Rd].s);
						//e->CmovERegMem64(RCX, &r->GPR[i.Rs].s);
						//e->MovMemReg64(&r->GPR[i.Rd].s, RCX);
						x->emit("cmp qword ptr @ptr, 0", &r->GPR[i.Rt].s);
						x->emit("mov rax, @ptr", &r->GPR[i.Rd].s);
						x->emit("cmovne rax, @ptr", &r->GPR[i.Rs].s);
						x->emit("mov @ptr, rax", &r->GPR[i.Rd].s);
					}
				}
			}

#else

			if ( i.Rd )
			{
				if ( i.Rd != i.Rs )
				{
					if ( i.Rd == i.Rt )
					{
						//e->MovRegMem64 ( RAX, & r->GPR [ i.Rt ].s );
						e->MovRegMem64 ( RCX, & r->GPR [ i.Rd ].s );
						e->OrRegReg64 ( RCX, RCX );
						e->CmovNERegMem64 ( RCX, & r->GPR [ i.Rs ].s );
						e->MovMemReg64 ( & r->GPR [ i.Rd ].s, RCX );
					}
					else if ( i.Rs == i.Rt )
					{
						e->MovRegMem64 ( RAX, & r->GPR [ i.Rt ].s );
						e->MovRegMem64 ( RCX, & r->GPR [ i.Rd ].s );
						e->OrRegReg64 ( RAX, RAX );
						e->CmovNERegReg64 ( RCX, RAX );
						e->MovMemReg64 ( & r->GPR [ i.Rd ].s, RCX );
					}
					else
					{
						e->CmpMem64ImmX ( & r->GPR [ i.Rt ].s, 0 );
						//e->MovRegMem64 ( RAX, & r->GPR [ i.Rt ].s );
						e->MovRegMem64 ( RCX, & r->GPR [ i.Rd ].s );
						//e->OrRegReg64 ( RAX, RAX );
						e->CmovNERegMem64 ( RCX, & r->GPR [ i.Rs ].s );
						e->MovMemReg64 ( & r->GPR [ i.Rd ].s, RCX );
					}
				}
			}
#endif
			break;
			
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}


int32_t R5900::Recompiler::MFHI1 ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "MFHI1";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::MFHI1;
	
	int ret = 1;
	
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
#ifdef USE_NEW_MFHI1_CODE
			/*
			e->MovRegFromMem64 ( RAX, (int64_t*) & r->CycleCount );
			e->CmpRegMem64 ( RAX, &r->MulDiv_BusyUntil_Cycle );
			e->CmovBRegMem64 ( RAX, &r->MulDiv_BusyUntil_Cycle );
			ret = e->MovRegToMem64 ( (int64_t*) & r->CycleCount, RAX );
			if ( i.Rd )
			{
				e->MovRegFromMem32 ( RAX, &r->HiLo.uHi );
				ret = e->MovRegToMem32 ( &r->GPR [ i.Rd ].s, RAX );
			}
			Local_LastModifiedReg = i.Rd;
			*/
			
			// this instruction interlocks if multiply/divide unit is busy
			//if ( r->MulDiv_BusyUntil_Cycle > r->CycleCount )
			//{
			//	// for now, just add onto memory latency
			//	r->CycleCount = r->MulDiv_BusyUntil_Cycle;
			//}
			e->MovRegMem64 ( RAX, (int64_t*) & r->CycleCount );
			//e->MovRegMem64 ( RCX, (int64_t*) & r->MulDiv_BusyUntil_Cycle1 );
			e->AddReg64ImmX ( RAX, LocalCycleCount );
			
			//e->XorRegReg64 ( RDX, RDX );
			e->SubRegMem64 ( RAX, (int64_t*) & r->MulDiv_BusyUntil_Cycle1 );
			//e->CmovBRegReg64 ( RDX, RAX );
			e->Cqo ();
			e->AndRegReg64 ( RDX, RAX );
			
			// store cycle count minus one to the current cycle (because it adds one on return from recompiler for now)
			//e->MovMemReg64 ( (int64_t*) & r->CycleCount, RAX );
			e->SubMemReg64 ( (int64_t*) & r->CycleCount, RDX );
			
			// move from Hi register
			//r->GPR [ i.Rd ].u = r->HiLo.uHi;
			//CHECK_DELAYSLOT ( i.Rd );
			if ( i.Rd )
			{
				//e->MovRegMem32 ( RAX, & r->HiLo.uHi );
				e->MovRegMem64 ( RAX, & r->HI.sq1 );
				//e->MovMemReg32 ( & r->GPR [ i.Rd ].s, RAX );
				e->MovMemReg64 ( & r->GPR [ i.Rd ].s, RAX );
			}
#else
			return -1;
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::MTHI1 ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "MTHI1";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::MTHI1;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
			//e->MovRegFromMem32 ( RAX, &r->GPR [ i.Rs ].sw0 );
			e->MovRegMem64 ( RAX, &r->GPR [ i.Rs ].s );
			//ret = e->MovRegToMem32 ( &r->HiLo.uHi, RAX );
			ret = e->MovMemReg64 ( &r->HI.sq1, RAX );
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::MFLO1 ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "MFLO1";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::MFLO1;
	
	int ret = 1;
	
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
#ifdef USE_NEW_MFLO1_CODE
			/*
			e->MovRegFromMem64 ( RAX, (int64_t*) & r->CycleCount );
			e->CmpRegMem64 ( RAX, &r->MulDiv_BusyUntil_Cycle );
			e->CmovBRegMem64 ( RAX, &r->MulDiv_BusyUntil_Cycle );
			ret = e->MovRegToMem64 ( (int64_t*) & r->CycleCount, RAX );
			if ( i.Rd )
			{
				e->MovRegFromMem32 ( RAX, &r->HiLo.uLo );
				ret = e->MovRegToMem32 ( &r->GPR [ i.Rd ].s, RAX );
			}
			Local_LastModifiedReg = i.Rd;
			*/
			
			// this instruction interlocks if multiply/divide unit is busy
			//if ( r->MulDiv_BusyUntil_Cycle > r->CycleCount )
			//{
			//	// for now, just add onto memory latency
			//	r->CycleCount = r->MulDiv_BusyUntil_Cycle;
			//}
			e->MovRegMem64 ( RAX, (int64_t*) & r->CycleCount );
			//e->MovRegMem64 ( RCX, (int64_t*) & r->MulDiv_BusyUntil_Cycle1 );
			e->AddReg64ImmX ( RAX, LocalCycleCount );
			
			//e->XorRegReg64 ( RDX, RDX );
			e->SubRegMem64 ( RAX, (int64_t*) & r->MulDiv_BusyUntil_Cycle1 );
			//e->CmovBRegReg64 ( RDX, RAX );
			e->Cqo ();
			e->AndRegReg64 ( RDX, RAX );
			
			// store cycle count minus one to the current cycle (because it adds one on return from recompiler for now)
			//e->MovMemReg64 ( (int64_t*) & r->CycleCount, RAX );
			e->SubMemReg64 ( (int64_t*) & r->CycleCount, RDX );
			
			// move from Lo register
			//r->GPR [ i.Rd ].u = r->HiLo.uLo;
			//CHECK_DELAYSLOT ( i.Rd );
			if ( i.Rd )
			{
				//e->MovRegMem32 ( RAX, & r->HiLo.uLo );
				e->MovRegMem64 ( RAX, & r->LO.sq1 );
				//e->MovMemReg32 ( & r->GPR [ i.Rd ].s, RAX );
				e->MovMemReg64 ( & r->GPR [ i.Rd ].s, RAX );
			}
#else
			return -1;
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::MTLO1 ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "MTLO1";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::MTLO1;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
			//e->MovRegFromMem32 ( RAX, &r->GPR [ i.Rs ].sw0 );
			e->MovRegMem64 ( RAX, &r->GPR [ i.Rs ].s );
			//ret = e->MovRegToMem32 ( &r->HiLo.uLo, RAX );
			ret = e->MovMemReg64 ( &r->LO.sq1, RAX );
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}



int32_t R5900::Recompiler::MFSA ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "MFSA";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::MFSA;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
			e->MovRegMem32 ( RAX, (int32_t*) & r->SA );
			e->MovMemReg64 ( & r->GPR [ i.Rd ].sq0, RAX );
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::MTSA ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "MTSA";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::MTSA;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
			e->MovRegMem32 ( RAX, & r->GPR [ i.Rs ].sw0 );
			e->AndReg32ImmX ( RAX, 0xf );
			e->MovMemReg32 ( (int32_t*) & r->SA, RAX );
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::MTSAB ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "MTSAB";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::MTSAB;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
			e->MovRegMem32 ( RAX, & r->GPR [ i.Rs ].sw0 );
			e->XorReg32ImmX ( RAX, i.uImmediate );
			e->AndReg32ImmX ( RAX, 0xf );
			e->MovMemReg32 ( (int32_t*) & r->SA, RAX );
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::MTSAH ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "MTSAH";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::MTSAH;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
			e->MovRegMem32 ( RAX, & r->GPR [ i.Rs ].sw0 );
			e->XorReg32ImmX ( RAX, i.uImmediate );
			e->AndReg32ImmX ( RAX, 0x7 );
			e->AddRegReg32 ( RAX, RAX );
			e->MovMemReg32 ( (int32_t*) & r->SA, RAX );
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}




// Branch instructions //

int32_t R5900::Recompiler::BEQL ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "BEQL";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::BEQL;
	
	int ret = 1;
	
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;

			// this instruction always has a synchronous interrupt
			Local_NextPCModified = true;

#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
#ifdef USE_NEW_BEQL_CODE
			ret = Generate_Normal_Branch ( i, Address, (void*) Cpu::ProcessBranchDelaySlot_t<OPBEQL> );
#else
			return -1;
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::BNEL ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "BNEL";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::BNEL;
	
	int ret = 1;
		
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;

			// this instruction always has a synchronous interrupt
			Local_NextPCModified = true;

#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
#ifdef USE_NEW_BNEL_CODE
			ret = Generate_Normal_Branch ( i, Address, (void*) Cpu::ProcessBranchDelaySlot_t<OPBNEL> );
#else
			return -1;
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::BGEZL ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "BGEZL";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::BGEZL;
	
	int ret = 1;
	
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;

			// this instruction always has a synchronous interrupt
			Local_NextPCModified = true;

#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
#ifdef USE_NEW_BGEZL_CODE
			ret = Generate_Normal_Branch ( i, Address, (void*) Cpu::ProcessBranchDelaySlot_t<OPBGEZL> );
#else
			return -1;
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::BLEZL ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "BLEZL";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::BLEZL;
	
	int ret = 1;
	
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;

			// this instruction always has a synchronous interrupt
			Local_NextPCModified = true;

#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
#ifdef USE_NEW_BLEZL_CODE
			ret = Generate_Normal_Branch ( i, Address, (void*) Cpu::ProcessBranchDelaySlot_t<OPBLEZL> );
#else
			return -1;
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::BGTZL ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "BGTZL";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::BGTZL;
	
	int ret = 1;
	
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;

			// this instruction always has a synchronous interrupt
			Local_NextPCModified = true;

#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
#ifdef USE_NEW_BGTZL_CODE
			ret = Generate_Normal_Branch ( i, Address, (void*) Cpu::ProcessBranchDelaySlot_t<OPBGTZL> );
#else
			return -1;
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::BLTZL ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "BLTZL";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::BLTZL;
	
	int ret = 1;
	
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;

			// this instruction always has a synchronous interrupt
			Local_NextPCModified = true;

#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
#ifdef USE_NEW_BLTZL_CODE
			ret = Generate_Normal_Branch ( i, Address, (void*) Cpu::ProcessBranchDelaySlot_t<OPBLTZL> );
#else
			return -1;
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}



int32_t R5900::Recompiler::BLTZALL ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "BLTZALL";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::BLTZALL;
	
	int ret = 1;
	
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;

			// this instruction always has a synchronous interrupt
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
#ifdef USE_NEW_BLTZALL_CODE
			ret = Generate_Normal_Branch ( i, Address, (void*) Cpu::ProcessBranchDelaySlot_t<OPBLTZALL> );
#else
			return -1;
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::BGEZALL ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "BGEZALL";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::BGEZALL;
	
	int ret = 1;
	
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;

			// this instruction always has a synchronous interrupt
			Local_NextPCModified = true;

#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
#ifdef USE_NEW_BGEZALL_CODE
			ret = Generate_Normal_Branch ( i, Address, (void*) Cpu::ProcessBranchDelaySlot_t<OPBGEZALL> );
#else
			return -1;
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}




int32_t R5900::Recompiler::BC0T ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "BC0T";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::BC0T;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	bStopEncodingAfter = true;
	bStopEncodingBefore = true;

	switch ( OpLevel )
	{
		case 0:
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::BC0TL ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "BC0TL";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::BC0TL;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	bStopEncodingAfter = true;
	bStopEncodingBefore = true;

	// this instruction always has a synchronous interrupt
	Local_NextPCModified = true;

	switch ( OpLevel )
	{
		case 0:

#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::BC0F ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "BC0F";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::BC0F;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	bStopEncodingAfter = true;
	bStopEncodingBefore = true;

	switch ( OpLevel )
	{
		case 0:
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::BC0FL ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "BC0FL";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::BC0FL;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	bStopEncodingAfter = true;
	bStopEncodingBefore = true;
	
	// this instruction always has a synchronous interrupt
	Local_NextPCModified = true;
	
	switch ( OpLevel )
	{
		case 0:
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::BC1T ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "BC1T";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::BC1T;
	
	int ret = 1;
	
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
#ifdef USE_NEW_BC1T_CODE
			ret = Generate_Normal_Branch(i, Address, (void*)Cpu::ProcessBranchDelaySlot_t<OPBEQ>);
#else
			return -1;
#endif

			break;

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::BC1TL ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "BC1TL";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::BC1TL;
	
	int ret = 1;
	
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;

			// this instruction always has a synchronous interrupt
			Local_NextPCModified = true;

#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
#ifdef USE_NEW_BC1TL_CODE
			ret = Generate_Normal_Branch(i, Address, (void*)Cpu::ProcessBranchDelaySlot_t<OPBEQ>);
#else
			return -1;
#endif

			break;

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::BC1F ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "BC1F";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::BC1F;
	
	int ret = 1;
	
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
#ifdef USE_NEW_BC1F_CODE
			ret = Generate_Normal_Branch(i, Address, (void*)Cpu::ProcessBranchDelaySlot_t<OPBEQ>);
#else
			return -1;
#endif

			break;

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::BC1FL ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "BC1FL";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::BC1FL;
	
	int ret = 1;
	
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;

			// this instruction always has a synchronous interrupt
			Local_NextPCModified = true;

#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
#ifdef USE_NEW_BC1FL_CODE
			ret = Generate_Normal_Branch(i, Address, (void*)Cpu::ProcessBranchDelaySlot_t<OPBEQ>);
#else
			return -1;
#endif

			break;

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::BC2T ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "BC2T";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::BC2T;
	
	int ret = 1;
	
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::BC2TL ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "BC2TL";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::BC2TL;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	bStopEncodingAfter = true;
	bStopEncodingBefore = true;
	
	// this instruction always has a synchronous interrupt
	Local_NextPCModified = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::BC2F ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "BC2F";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::BC2F;
	
	int ret = 1;
	
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::BC2FL ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "BC2FL";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::BC2FL;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	bStopEncodingAfter = true;
	bStopEncodingBefore = true;
	
	// this instruction always has a synchronous interrupt
	Local_NextPCModified = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}






int32_t R5900::Recompiler::TGEI ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "TGEI";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::TGEI;
	
	int ret = 1;
	
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// this instruction might have a synchronous interrupt
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
			ret = Generate_Normal_Trap ( i, Address );
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::TGEIU ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "TGEIU";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::TGEIU;
	
	int ret = 1;
	
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// this instruction might have a synchronous interrupt
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
			ret = Generate_Normal_Trap ( i, Address );
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::TLTI ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "TLTI";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::TLTI;
	
	int ret = 1;
	
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// this instruction might have a synchronous interrupt
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
			ret = Generate_Normal_Trap ( i, Address );
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::TLTIU ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "TLTIU";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::TLTIU;
	
	int ret = 1;
	
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// this instruction might have a synchronous interrupt
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
			ret = Generate_Normal_Trap ( i, Address );
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::TEQI ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "TEQI";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::TEQI;
	
	int ret = 1;
	
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// this instruction might have a synchronous interrupt
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
			ret = Generate_Normal_Trap ( i, Address );
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::TNEI ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "TNEI";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::TNEI;
	
	int ret = 1;
	
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// this instruction might have a synchronous interrupt
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
			ret = Generate_Normal_Trap ( i, Address );
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}


int32_t R5900::Recompiler::TGE ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "TGE";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::TGE;
	
	int ret = 1;
	
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// this instruction might have a synchronous interrupt
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
			ret = Generate_Normal_Trap ( i, Address );
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::TGEU ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "TGEU";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::TGEU;
	
	int ret = 1;
	
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// this instruction might have a synchronous interrupt
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
			ret = Generate_Normal_Trap ( i, Address );
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::TLT ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "TLT";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::TLT;
	
	int ret = 1;
	
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// this instruction might have a synchronous interrupt
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
			ret = Generate_Normal_Trap ( i, Address );
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::TLTU ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "TLTU";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::TLTU;
	
	int ret = 1;
	
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// this instruction might have a synchronous interrupt
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
			ret = Generate_Normal_Trap ( i, Address );
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::TEQ ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "TEQ";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::TEQ;
	
	int ret = 1;
	
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// this instruction might have a synchronous interrupt
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
			ret = Generate_Normal_Trap ( i, Address );
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::TNE ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "TNE";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::TNE;
	
	int ret = 1;
	
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// this instruction might have a synchronous interrupt
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
			ret = Generate_Normal_Trap ( i, Address );
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}


















// * R5900 Parallel (SIMD) instructions * //


int32_t R5900::Recompiler::PADSBH ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "PADSBH";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PADSBH;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
#ifdef USE_NEW_PADSBH_CODE
		case 1:

#ifdef ALLOW_AVX2_PADSBH
			if (iVectorType == VECTOR_TYPE_SSE)
#endif
			{
				if (i.Rd)
				{
					if (!i.Rt)
					{
						if (i.Rd != i.Rs)
						{
							e->movdqa_regmem(RAX, &r->GPR[i.Rs].s);
							ret = e->movdqa_memreg(&r->GPR[i.Rd].s, RAX);
						}
					}
					else
					{
						e->movdqa_regmem(RAX, &r->GPR[i.Rs].s);
						e->movdqa_regmem(RDX, &r->GPR[i.Rt].s);
						e->movdqa_regreg(RCX, RAX);

						e->paddwregreg(RAX, RDX);
						e->psubwregreg(RCX, RDX);
						e->pblendwregregimm(RAX, RCX, 0xf);

						ret = e->movdqa_memreg(&r->GPR[i.Rd].s, RAX);
					}
				}
			}
#ifdef ALLOW_AVX2_PADSBH
			else
			{
#ifdef USE_NEW_R5900_ASSEMBLER_PADSBH
				if (i.Rd)
				{
					if (!i.Rt)
					{
						if (i.Rd != i.Rs)
						{
							//e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
							//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
							x->emit("vmovdqa xmm0, @ptr", &r->GPR[i.Rs].s);
							x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
						}
					}
					else
					{
						//e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
						//e->movdqa1_regmem(RDX, &r->GPR[i.Rt].s);
						x->emit("vmovdqa xmm0, @ptr", &r->GPR[i.Rs].s);
						x->emit("vmovdqa xmm1, @ptr", &r->GPR[i.Rt].s);

						//e->psubw1regreg(RCX, RAX, RDX);
						//e->paddw1regreg(RAX, RAX, RDX);
						//e->pblendw1regregimm(RAX, RAX, RCX, 0xf);
						x->emit("vpsubw xmm2, xmm0, xmm1");
						x->emit("vpaddw xmm0, xmm0, xmm1");
						x->emit("vpblendw xmm0, xmm0, xmm2, 0xf");

						//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
						x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
					}
				}
#else
				if (i.Rd)
				{
					if (!i.Rt)
					{
						if (i.Rd != i.Rs)
						{
							e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
							ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
						}
					}
					else
					{
						e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
						e->movdqa1_regmem(RDX, &r->GPR[i.Rt].s);
						//e->movdqa_regreg(RCX, RAX);

						e->psubw1regreg(RCX, RAX, RDX);
						e->paddw1regreg(RAX, RAX, RDX);
						e->pblendw1regregimm(RAX, RAX, RCX, 0xf);

						ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					}
				}
#endif

			}
#endif

			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::PABSH ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "PABSH";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PABSH;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch (OpLevel)
	{
	case 0:
		if (i.Rd)
		{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX(RSP, c_lSEH_StackSize);
#endif

			e->LoadImm32(RCX, i.Value);
			ret = e->Call(c_vFunction);

#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX(RSP, c_lSEH_StackSize);
#endif
		}
		break;

#ifdef USE_NEW_PABSH_CODE
	case 1:

#ifdef USE_NEW_R5900_ASSEMBLER_PABSH
		if (i.Rd)
		{
			if (!i.Rt)
			{
				//e->pxor1regreg(RAX, RAX, RAX);
				//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
				x->emit("vpxor xmm0, xmm0, xmm0");
				x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
			}
			else
			{
				//e->pabsw1regmem(RAX, &r->GPR[i.Rt].s);
				//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
				x->emit("vpabsw xmm0, @ptr", &r->GPR[i.Rt].s);
				x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
			}
		}
#else
		if (i.Rd)
		{
			if (!i.Rt)
			{
				e->pxor1regreg(RAX, RAX, RAX);
				ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
			}
			else
			{
				e->pabsw1regmem(RAX, &r->GPR[i.Rt].s);
				ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
			}
		}
#endif

		break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::PABSW ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "PABSW";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PABSW;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch (OpLevel)
	{
	case 0:
		if (i.Rd)
		{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX(RSP, c_lSEH_StackSize);
#endif

			e->LoadImm32(RCX, i.Value);
			ret = e->Call(c_vFunction);

#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX(RSP, c_lSEH_StackSize);
#endif
		}
		break;

#ifdef USE_NEW_PABSW_CODE
	case 1:

#ifdef USE_NEW_R5900_ASSEMBLER_PABSW
		if (i.Rd)
		{
			if (!i.Rt)
			{
				//e->pxor1regreg(RAX, RAX, RAX);
				//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
				x->emit("vpxor xmm0, xmm0, xmm0");
				x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
			}
			else
			{
				//e->pabsd1regmem(RAX, &r->GPR[i.Rt].s);
				//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
				x->emit("vpabsd xmm0, @ptr", &r->GPR[i.Rt].s);
				x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
			}
		}
#else
		if (i.Rd)
		{
			if (!i.Rt)
			{
				e->pxor1regreg(RAX, RAX, RAX);
				ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
			}
			else
			{
				e->pabsd1regmem(RAX, &r->GPR[i.Rt].s);
				ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
			}
		}
#endif

		break;
#endif

	default:
		return -1;
		break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::PAND ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "PAND";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PAND;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if (i.Rd)
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
				e->SubReg64ImmX(RSP, c_lSEH_StackSize);
#endif

				e->LoadImm32(RCX, i.Value);
				ret = e->Call(c_vFunction);

#ifdef RESERVE_STACK_FRAME_FOR_CALL
				ret = e->AddReg64ImmX(RSP, c_lSEH_StackSize);
#endif
			}
			break;
			
#ifdef USE_NEW_PAND_CODE
		case 1:

#ifdef USE_NEW_R5900_ASSEMBLER_PAND
			if (i.Rd)
			{
				if ((!i.Rs) || (!i.Rt))
				{
					//e->pxor1regreg(RAX, RAX, RAX);
					//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					x->emit("vpxor xmm0, xmm0, xmm0");
					x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
				}
				else if (i.Rs == i.Rt)
				{
					if (i.Rd != i.Rs)
					{
						//e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
						//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
						x->emit("vmovdqa xmm0, @ptr", &r->GPR[i.Rs].s);
						x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
					}
				}
				else
				{
					//e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
					//e->pand1regmem(RAX, RAX, &r->GPR[i.Rt].s);
					//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					x->emit("vmovdqa xmm0, @ptr", &r->GPR[i.Rs].s);
					x->emit("vpand xmm0, xmm0, @ptr", &r->GPR[i.Rt].s);
					x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
				}
			}

#else
			if (i.Rd)
			{
				if (!i.Rs)
				{
					e->pxor1regreg(RAX, RAX, RAX);
					ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
				}
				else if (!i.Rt)
				{
					e->pxor1regreg(RAX, RAX, RAX);
					ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
				}
				else if (i.Rs == i.Rt)
				{
					if (i.Rd != i.Rs)
					{
						e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
						ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					}
				}
				else
				{
					e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
					e->pand1regmem(RAX, RAX, &r->GPR[i.Rt].s);
					ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
				}
			}

#endif

			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::PXOR ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "PXOR";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PXOR;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
#ifdef USE_NEW_PXOR_CODE
		case 1:

#ifdef USE_NEW_R5900_ASSEMBLER_PXOR
			if (i.Rd)
			{
				if (i.Rs == i.Rt)
				{
					//e->pxor1regreg(RAX, RAX, RAX);
					//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					x->emit("vpxor xmm0, xmm0, xmm0");
					x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
				}
				else if ((!i.Rs) || (!i.Rt))
				{
					x->emit("vmovdqa xmm0, @ptr", &r->GPR[i.Rs | i.Rt].s);
					x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
				}
				else
				{
					//e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
					//e->pxor1regmem(RAX, RAX, &r->GPR[i.Rt].s);
					//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					x->emit("vmovdqa xmm0, @ptr", &r->GPR[i.Rs].s);
					x->emit("vpxor xmm0, xmm0, @ptr", &r->GPR[i.Rt].s);
					x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
				}
			}
#else
			if (i.Rd)
			{
				if (i.Rs == i.Rt)
				{
					e->pxor1regreg(RAX, RAX, RAX);
					ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
				}
				else if (!i.Rs)
				{
					e->movdqa1_regmem(RAX, &r->GPR[i.Rt].s);
					ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
				}
				else if (!i.Rt)
				{
					e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
					ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
				}
				else
				{
					e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
					e->pxor1regmem(RAX, RAX, &r->GPR[i.Rt].s);
					ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
				}
			}
#endif


			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::POR ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "POR";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::POR;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
#ifdef USE_NEW_POR_CODE
		case 1:

#ifdef USE_NEW_R5900_ASSEMBLER_POR
			if (i.Rd)
			{
				if ((!i.Rs) && (!i.Rt))
				{
					//e->pxor1regreg(RAX, RAX, RAX);
					//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					x->emit("vpxor xmm0, xmm0, xmm0");
					x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
				}
				else if ((!i.Rs) || (!i.Rt) || (i.Rs == i.Rt))
				{
					if (i.Rd != (i.Rs | i.Rt))
					{
						//e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
						//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
						x->emit("vmovdqa xmm0, @ptr", &r->GPR[i.Rs | i.Rt].s);
						x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
					}
				}
				else
				{
					//e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
					//e->por1regmem(RAX, RAX, &r->GPR[i.Rt].s);
					//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					x->emit("vmovdqa xmm0, @ptr", &r->GPR[i.Rs].s);
					x->emit("vpor xmm0, xmm0, @ptr", &r->GPR[i.Rt].s);
					x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
				}
			}
#else
			if (i.Rd)
			{
				if (!i.Rs)
				{
					if (!i.Rt)
					{
						e->pxor1regreg(RAX, RAX, RAX);
						ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					}
					else if (i.Rd != i.Rt)
					{
						e->movdqa1_regmem(RAX, &r->GPR[i.Rt].s);
						ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					}
				}
				else if (!i.Rt)
				{
					if (i.Rd != i.Rs)
					{
						e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
						ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					}
				}
				else if (i.Rs == i.Rt)
				{
					if (i.Rd != i.Rs)
					{
						e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
						ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					}
				}
				else
				{
					e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
					e->por1regmem(RAX, RAX, &r->GPR[i.Rt].s);
					ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
				}
			}
#endif

			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::PNOR ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "PNOR";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PNOR;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
#ifdef USE_NEW_PNOR_CODE
		case 1:

#ifdef USE_NEW_R5900_ASSEMBLER_PNOR
			if (i.Rd)
			{
				if (!i.Rs)
				{
					if (!i.Rt)
					{
						//e->pcmpeqd1regreg(RAX, RAX, RAX);
						//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
						x->emit("vpcmpeqd xmm0, xmm0, xmm0");
						x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
					}
					else
					{
						//e->pcmpeqd1regreg(RAX, RAX, RAX);
						//e->pxor1regmem(RAX, RAX, &r->GPR[i.Rt].s);
						//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
						x->emit("vpcmpeqd xmm0, xmm0, xmm0");
						x->emit("vpxor xmm0, xmm0, @ptr", &r->GPR[i.Rt].s);
						x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
					}
				}
				else if (!i.Rt)
				{
					//e->pcmpeqd1regreg(RAX, RAX, RAX);
					//e->pxor1regmem(RAX, RAX, &r->GPR[i.Rs].s);
					//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					x->emit("vpcmpeqd xmm0, xmm0, xmm0");
					x->emit("vpxor xmm0, xmm0, @ptr", &r->GPR[i.Rs].s);
					x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
				}
				else if (i.Rs == i.Rt)
				{
					//e->pcmpeqd1regreg(RAX, RAX, RAX);
					//e->pxor1regmem(RAX, RAX, &r->GPR[i.Rs].s);
					//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					x->emit("vpcmpeqd xmm0, xmm0, xmm0");
					x->emit("vpxor xmm0, xmm0, @ptr", &r->GPR[i.Rs].s);
					x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
				}
				else
				{
					//e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
					//e->pcmpeqd1regreg(RCX, RCX, RCX);
					//e->por1regmem(RAX, RAX, &r->GPR[i.Rt].s);
					//e->pxor1regreg(RAX, RAX, RCX);
					//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					x->emit("vmovdqa xmm0, @ptr", &r->GPR[i.Rs].s);
					x->emit("vpcmpeqd xmm1, xmm1, xmm1");
					x->emit("vpor xmm0, xmm0, @ptr", &r->GPR[i.Rt].s);
					x->emit("vpxor xmm0, xmm0, xmm1");
					x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
				}
			}

#else
			if (i.Rd)
			{
				if (!i.Rs)
				{
					if (!i.Rt)
					{
						e->pcmpeqd1regreg(RAX, RAX, RAX);
						ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					}
					else
					{
						//e->movdqa_regmem ( RAX, & r->GPR [ i.Rt ].s );
						e->pcmpeqd1regreg(RAX, RAX, RAX);
						e->pxor1regmem(RAX, RAX, &r->GPR[i.Rt].s);
						ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					}
				}
				else if (!i.Rt)
				{
					//e->movdqa_regmem ( RAX, & r->GPR [ i.Rs ].s );
					e->pcmpeqd1regreg(RAX, RAX, RAX);
					e->pxor1regmem(RAX, RAX, &r->GPR[i.Rs].s);
					ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
				}
				else if (i.Rs == i.Rt)
				{
					//e->movdqa_regmem ( RAX, & r->GPR [ i.Rs ].s );
					e->pcmpeqd1regreg(RAX, RAX, RAX);
					e->pxor1regmem(RAX, RAX, &r->GPR[i.Rs].s);
					ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
				}
				else
				{
					e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
					e->pcmpeqd1regreg(RCX, RCX, RCX);
					e->por1regmem(RAX, RAX, &r->GPR[i.Rt].s);
					e->pxor1regreg(RAX, RAX, RCX);
					ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
				}
			}
#endif

			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}


int32_t R5900::Recompiler::PLZCW ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "PLZCW";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PLZCW;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
#ifdef USE_NEW_PLZCW_CODE
		case 1:
#ifdef USE_NEW_R5900_ASSEMBLER_PLZCW
			if (i.Rd)
			{
				//e->MovRegMem32(RAX, &r->GPR[i.Rs].sw0);
				//e->MovReg32ImmX(RCX, -1);
				//e->Cdq();
				//e->XorRegReg32(RAX, RDX);
				//e->BsrRegReg32(RAX, RAX);
				//e->CmovERegReg32(RAX, RCX);
				//e->NegReg32(RAX);
				//e->AddReg32ImmX(RAX, 30);
				//e->MovMemReg32(&r->GPR[i.Rd].sw0, RAX);
				x->emit("mov eax, @ptr", &r->GPR[i.Rs].sw0);
				x->emit("mov ecx, -1");
				x->emit("cdq");
				x->emit("xor eax, edx");
				x->emit("bsr eax, eax");
				x->emit("cmove eax, ecx");
				x->emit("neg eax");
				x->emit("add eax, 30");
				x->emit("mov  @ptr, eax", &r->GPR[i.Rd].sw0);

				//e->MovRegMem32(RAX, &r->GPR[i.Rs].sw1);
				//e->Cdq();
				//e->XorRegReg32(RAX, RDX);
				//e->BsrRegReg32(RAX, RAX);
				//e->CmovERegReg32(RAX, RCX);
				//e->NegReg32(RAX);
				//e->AddReg32ImmX(RAX, 30);
				//e->MovMemReg32(&r->GPR[i.Rd].sw1, RAX);
				x->emit("mov eax, @ptr", &r->GPR[i.Rs].sw1);
				x->emit("mov ecx, -1");
				x->emit("cdq");
				x->emit("xor eax, edx");
				x->emit("bsr eax, eax");
				x->emit("cmove eax, ecx");
				x->emit("neg eax");
				x->emit("add eax, 30");
				x->emit("mov  @ptr, eax", &r->GPR[i.Rd].sw1);
			}
#else
			if ( i.Rd )
			{
				e->MovRegMem32 ( RAX, & r->GPR [ i.Rs ].sw0 );
				e->MovReg32ImmX ( RCX, -1 );
				e->Cdq ();
				e->XorRegReg32 ( RAX, RDX );
				e->BsrRegReg32 ( RAX, RAX );
				e->CmovERegReg32 ( RAX, RCX );
				e->NegReg32 ( RAX );
				e->AddReg32ImmX ( RAX, 30 );
				e->MovMemReg32 ( & r->GPR [ i.Rd ].sw0, RAX );
				
				e->MovRegMem32 ( RAX, & r->GPR [ i.Rs ].sw1 );
				e->Cdq ();
				e->XorRegReg32 ( RAX, RDX );
				e->BsrRegReg32 ( RAX, RAX );
				e->CmovERegReg32 ( RAX, RCX );
				e->NegReg32 ( RAX );
				e->AddReg32ImmX ( RAX, 30 );
				e->MovMemReg32 ( & r->GPR [ i.Rd ].sw1, RAX );
			}
#endif

			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}


int32_t R5900::Recompiler::PMFHL_LH ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "PMFHL_LH";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PMFHL_LH;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch (OpLevel)
	{
	case 0:
		if (i.Rd)
		{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX(RSP, c_lSEH_StackSize);
#endif

			e->LoadImm32(RCX, i.Value);
			ret = e->Call(c_vFunction);

#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX(RSP, c_lSEH_StackSize);
#endif
		}
		break;

#ifdef USE_NEW_PMFHL_LH_CODE
	case 1:

		// get maximum of busy until cycle in RDX (to be used as the cycle# Mul/Div unit is busy until)
		e->MovRegMem64(RCX, (int64_t*)&r->MulDiv_BusyUntil_Cycle);
		e->MovRegMem64(RDX, (int64_t*)&r->MulDiv_BusyUntil_Cycle1);
		e->CmpRegReg64(RDX, RCX);
		e->CmovBRegReg64(RDX, RCX);

		// get current cyclecount in RAX
		e->MovRegMem64(RAX, (int64_t*)&r->CycleCount);
		e->AddReg64ImmX(RAX, LocalCycleCount);

		// get any cycles between current cyclecount and when Mul/Div unit is available
		e->SubRegReg64(RAX, RDX);
		e->Cqo();
		e->AndRegReg64(RAX, RDX);

		// store cycle count minus one to the current cycle (because it adds one on return from recompiler for now)
		// offset current cyclecount with the number of cycles until mul/div unit is available
		e->SubMemReg64((int64_t*)&r->CycleCount, RAX);

		if (i.Rd)
		{
#ifdef ALLOW_AVX2_PMFHL_LH
			if (iVectorType == VECTOR_TYPE_SSE)
#endif
			{
				e->movdqa_regmem(RAX, &r->LO.s);
				e->movdqa_regmem(RBX, &r->HI.s);

				e->pshuflwregregimm(RCX, RAX, (2 << 2) + (0 << 0));
				e->pshufhwregregimm(RCX, RCX, (2 << 2) + (0 << 0));
				e->pshuflwregregimm(RDX, RBX, (3 << 6) + (1 << 4));
				e->pshufhwregregimm(RDX, RDX, (3 << 6) + (1 << 4));
				e->pblendwregregimm(RCX, RDX, 0xcc);

				ret = e->movdqa_memreg(&r->GPR[i.Rd].s, RCX);
			}
#ifdef ALLOW_AVX2_PMFHL_LH
			else
			{
				e->pshuflw1regmemimm(RAX, &r->LO.s, (2 << 2) | (0 << 0));
				e->pshuflw1regmemimm(RCX, &r->HI.s, (3 << 6) | (1 << 4));
				e->pshufhw1regregimm(RAX, RAX, (2 << 2) | (0 << 0));
				e->pshufhw1regregimm(RCX, RCX, (3 << 6) | (1 << 4));
				e->pblendw1regregimm(RAX, RAX, RCX, 0xcc);
				ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
			}
#endif
		}


		break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::PMFHL_LW ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "PMFHL_LW";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PMFHL_LW;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
#ifdef USE_NEW_PMFHL_LW_CODE
		case 1:
			// get maximum of busy until cycle in RDX (to be used as the cycle# Mul/Div unit is busy until)
			e->MovRegMem64 ( RCX, (int64_t*) & r->MulDiv_BusyUntil_Cycle );
			e->MovRegMem64 ( RDX, (int64_t*) & r->MulDiv_BusyUntil_Cycle1 );
			e->CmpRegReg64 ( RDX, RCX );
			e->CmovBRegReg64 ( RDX, RCX );
			
			// get current cyclecount in RAX
			e->MovRegMem64 ( RAX, (int64_t*) & r->CycleCount );
			e->AddReg64ImmX ( RAX, LocalCycleCount );
			
			// get any cycles between current cyclecount and when Mul/Div unit is available
			e->SubRegReg64 ( RAX, RDX );
			e->Cqo ();
			e->AndRegReg64 ( RAX, RDX );
			
			// store cycle count minus one to the current cycle (because it adds one on return from recompiler for now)
			// offset current cyclecount with the number of cycles until mul/div unit is available
			e->SubMemReg64 ( (int64_t*) & r->CycleCount, RAX );
			
			if (i.Rd)
			{
#ifdef ALLOW_AVX2_PMFHL_LW
				if (iVectorType == VECTOR_TYPE_SSE)
#endif
				{
					//e->movdqa_regmem ( RBX, & r->HI.s );
					e->movdqa_regmem(RAX, &r->LO.s);

					//e->pshufdregregimm ( RCX, RBX, ( 2 << 6 ) + ( 0 << 2 ) );
					e->pshufdregmemimm(RCX, &r->HI.s, (2 << 6) + (0 << 2));
					e->pblendwregregimm(RAX, RCX, 0xcc);

					ret = e->movdqa_memreg(&r->GPR[i.Rd].s, RAX);
				}
#ifdef ALLOW_AVX2_PMFHL_LW
				else
				{
					//e->movdqa1_regmem(RAX, &r->LO.s);

					e->pshufd1regmemimm(RCX, &r->HI.s, (2 << 6) + (0 << 2));
					//e->pblendw1regregimm(RAX, RAX, RCX, 0xcc);
					e->pblendw1regmemimm(RAX, RCX, &r->LO.s, 0x33);

					ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
				}
#endif
			}

			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::PMFHL_UW ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "PMFHL_UW";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PMFHL_UW;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
#ifdef USE_NEW_PMFHL_UW_CODE
		case 1:
			// get maximum of busy until cycle in RDX (to be used as the cycle# Mul/Div unit is busy until)
			e->MovRegMem64 ( RCX, (int64_t*) & r->MulDiv_BusyUntil_Cycle );
			e->MovRegMem64 ( RDX, (int64_t*) & r->MulDiv_BusyUntil_Cycle1 );
			e->CmpRegReg64 ( RDX, RCX );
			e->CmovBRegReg64 ( RDX, RCX );
			
			// get current cyclecount in RAX
			e->MovRegMem64 ( RAX, (int64_t*) & r->CycleCount );
			e->AddReg64ImmX ( RAX, LocalCycleCount );
			
			
			// get any cycles between current cyclecount and when Mul/Div unit is available
			e->SubRegReg64 ( RAX, RDX );
			e->Cqo ();
			e->AndRegReg64 ( RAX, RDX );
			
			
			// store cycle count minus one to the current cycle (because it adds one on return from recompiler for now)
			// offset current cyclecount with the number of cycles until mul/div unit is available
			e->SubMemReg64 ( (int64_t*) & r->CycleCount, RAX );
			
			if ( i.Rd )
			{
#ifdef ALLOW_AVX2_PMFHL_UW
				if (iVectorType == VECTOR_TYPE_SSE)
#endif
				{

					e->movdqa_regmem(RBX, &r->HI.s);
					//e->movdqa_regmem ( RAX, & r->LO.s );

					//e->pshufdregregimm ( RCX, RAX, ( 3 << 4 ) + ( 1 << 0 ) );
					e->pshufdregmemimm(RCX, &r->LO.s, (3 << 4) + (1 << 0));
					e->pblendwregregimm(RBX, RCX, 0x33);

					ret = e->movdqa_memreg(&r->GPR[i.Rd].s, RBX);
				}
#ifdef ALLOW_AVX2_PMFHL_UW
				else
				{
					//e->movdqa_regmem(RBX, &r->HI.s);

					e->pshufd1regmemimm(RCX, &r->LO.s, (3 << 4) | (1 << 0));
					//e->pblendwregregimm(RBX, RCX, 0x33);
					e->pblendw1regmemimm(RAX, RCX, &r->HI.s, 0xcc);

					ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
				}
#endif

			}

			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::PMTHL_LW ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "PMTHL_LW";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PMTHL_LW;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
#ifdef USE_NEW_PMTHL_LW_CODE
		case 1:

#ifdef ALLOW_AVX2_PMTHL_LW
			if (iVectorType == VECTOR_TYPE_SSE)
#endif
			{
				e->MovRegMem32(RAX, &r->GPR[i.Rs].sw0);
				e->MovRegMem32(RCX, &r->GPR[i.Rs].sw1);
				e->MovRegMem32(RDX, &r->GPR[i.Rs].sw2);

				e->MovMemReg32(&r->LO.sw0, RAX);

				e->MovRegMem32(RAX, &r->GPR[i.Rs].sw3);

				e->MovMemReg32(&r->HI.sw0, RCX);
				e->MovMemReg32(&r->LO.sw2, RDX);
				e->MovMemReg32(&r->HI.sw2, RAX);
			}
#ifdef ALLOW_AVX2_PMTHL_LW
			else
			{
				e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
				e->pshufd1regregimm(RBX, RAX, (3 << 4) | (1 << 0));
				e->pblendw1regmemimm(RAX, RAX, &r->LO.s, 0xcc);
				e->pblendw1regmemimm(RBX, RBX, &r->HI.s, 0xcc);
				e->movdqa1_memreg(&r->LO.s, RAX);
				e->movdqa1_memreg(&r->HI.s, RBX);
			}
#endif

			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}


int32_t R5900::Recompiler::PMFHL_SH ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "PMFHL_SH";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PMFHL_SH;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
#ifdef USE_NEW_PMFHL_SH_CODE
		case 1:

			// get maximum of busy until cycle in RDX (to be used as the cycle# Mul/Div unit is busy until)
			e->MovRegMem64 ( RCX, (int64_t*) & r->MulDiv_BusyUntil_Cycle );
			e->MovRegMem64 ( RDX, (int64_t*) & r->MulDiv_BusyUntil_Cycle1 );
			e->CmpRegReg64 ( RDX, RCX );
			e->CmovBRegReg64 ( RDX, RCX );
			
			// get current cyclecount in RAX
			e->MovRegMem64 ( RAX, (int64_t*) & r->CycleCount );
			e->AddReg64ImmX ( RAX, LocalCycleCount );
			
			
			// get any cycles between current cyclecount and when Mul/Div unit is available
			e->SubRegReg64 ( RAX, RDX );
			e->Cqo ();
			e->AndRegReg64 ( RAX, RDX );
			
			
			// store cycle count minus one to the current cycle (because it adds one on return from recompiler for now)
			// offset current cyclecount with the number of cycles until mul/div unit is available
			e->SubMemReg64 ( (int64_t*) & r->CycleCount, RAX );
			
			if ( i.Rd )
			{
#ifdef ALLOW_AVX2_PMFHL_SH
				if (iVectorType == VECTOR_TYPE_SSE)
#endif
				{

					e->movdqa_regmem(RBX, &r->HI.s);
					e->movdqa_regmem(RAX, &r->LO.s);

					e->pshufdregregimm(RCX, RBX, (1 << 6) + (0 << 4));
					e->pblendwregregimm(RCX, RAX, 0x0f);

					e->pshufdregregimm(RDX, RAX, (3 << 2) + (2 << 0));
					e->pblendwregregimm(RDX, RBX, 0xf0);

					e->packssdwregreg(RCX, RDX);

					ret = e->movdqa_memreg(&r->GPR[i.Rd].s, RCX);
				}
#ifdef ALLOW_AVX2_PMFHL_SH
				else
				{
					e->movdqa1_regmem(RAX, &r->LO.s);
					e->packssdw1regmem(RAX, RAX, &r->HI.s);
					e->pshufd1regregimm(RAX, RAX, 0xd8);
					ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
				}
#endif

			}

			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}


int32_t R5900::Recompiler::PMFHL_SLW ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "PMFHL_SLW";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PMFHL_SLW;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
#ifdef USE_NEW_PMFHL_SLW_CODE
		case 1:
			// get maximum of busy until cycle in RDX (to be used as the cycle# Mul/Div unit is busy until)
			e->MovRegMem64 ( RCX, (int64_t*) & r->MulDiv_BusyUntil_Cycle );
			e->MovRegMem64 ( RDX, (int64_t*) & r->MulDiv_BusyUntil_Cycle1 );
			e->CmpRegReg64 ( RDX, RCX );
			e->CmovBRegReg64 ( RDX, RCX );
			
			// get current cyclecount in RAX
			e->MovRegMem64 ( RAX, (int64_t*) & r->CycleCount );
			e->AddReg64ImmX ( RAX, LocalCycleCount );
			
			
			// get any cycles between current cyclecount and when Mul/Div unit is available
			e->SubRegReg64 ( RAX, RDX );
			e->Cqo ();
			e->AndRegReg64 ( RAX, RDX );
			
			
			// store cycle count minus one to the current cycle (because it adds one on return from recompiler for now)
			// offset current cyclecount with the number of cycles until mul/div unit is available
			e->SubMemReg64 ( (int64_t*) & r->CycleCount, RAX );
			
			if ( i.Rd )
			{
#ifdef ALLOW_AVX2_PMFHL_SLW
				if (iVectorType == VECTOR_TYPE_SSE)
#endif
				{

					e->MovRegMem32(RAX, &r->HI.sw0);
					e->Cdq();
					e->MovRegImm32(RCX, 0x7fffffff);
					e->XorRegReg32(RCX, RDX);
					e->CmpRegReg32(RAX, RDX);
					e->CmovERegMem32(RCX, &r->LO.sw0);
					e->MovsxdReg64Reg32(RCX, RCX);
					e->MovMemReg64(&r->GPR[i.Rd].sq0, RCX);

					e->MovRegMem32(RAX, &r->HI.sw2);
					e->Cdq();
					e->MovRegImm32(RCX, 0x7fffffff);
					e->XorRegReg32(RCX, RDX);
					e->CmpRegReg32(RAX, RDX);
					e->CmovERegMem32(RCX, &r->LO.sw2);
					e->MovsxdReg64Reg32(RCX, RCX);
					e->MovMemReg64(&r->GPR[i.Rd].sq1, RCX);

					/*
					e->movdqa_regmem ( RBX, & r->HI.s );
					e->movdqa_regmem ( RAX, & r->LO.s );

					pshufdregregimm ( RCX, RBX, ( 1 << 6 ) + ( 0 << 4 ) );
					pblendwregregimm ( RCX, RAX, 0x0f );

					pshufdregregimm ( RDX, RAX, ( 3 << 2 ) + ( 2 << 0 ) );
					pblendwregregimm ( RDX, RBX, 0xf0 );

					e->packssdwregreg ( RCX, RDX );

					ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RCX );
					*/
				}
#ifdef ALLOW_AVX2_PMFHL_SLW
				else
				{
					e->pshufd1regmemimm(RAX, &r->HI.s, 0x80);
					e->pblendw1regmemimm(RAX, RAX, &r->LO.s, 0x33);
					e->pcmpeqb1regreg(RBX, RBX, RBX);
					e->psrlq1regimm(RCX, RBX, 33);
					e->psllq1regimm(RBX, RBX, 31);
					e->pcmpgtq1regreg(RDX, RAX, RCX);
					e->pblendvb1regreg(RAX, RAX, RCX, RDX);
					e->pcmpgtq1regreg(4, RBX, RAX);
					e->pblendvb1regreg(RAX, RAX, RBX, 4);
					e->pshufd1regregimm(RAX, RAX, 0x04);
					e->pmovsxdqregreg(RAX, RAX);
					ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
				}
#endif
			}

			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}



int32_t R5900::Recompiler::PSLLH ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "PSLLH";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PSLLH;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
#ifdef USE_NEW_PSLLH_CODE
		case 1:

#ifdef USE_NEW_R5900_ASSEMBLER_PSLLH
				if (i.Rd)
				{
					if (!i.Rt)
					{
						//e->pxor1regreg(RAX, RAX, RAX);
						//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
						x->emit("vpxor xmm0, xmm0, xmm0");
						x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
					}
					else if (!(i.Shift & 0xf))
					{
						if (i.Rd != i.Rt)
						{
							//e->movdqa1_regmem(RAX, &r->GPR[i.Rt].s);
							//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
							x->emit("vmovdqa xmm0, @ptr", &r->GPR[i.Rt].s);
							x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
						}
					}
					else
					{
						//e->movdqa1_regmem(RAX, &r->GPR[i.Rt].s);
						//e->psllw1regimm(RAX, RAX, i.Shift & 0xf);
						//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
						x->emit("vmovdqa xmm0, @ptr", &r->GPR[i.Rt].s);
						x->emit("vpsllw xmm0, xmm0, @imm", i.Shift & 0xf);
						x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
					}
				}

#else
				if (i.Rd)
				{
					if (!i.Rt)
					{
						e->pxor1regreg(RAX, RAX, RAX);
						ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					}
					else if (!(i.Shift & 0xf))
					{
						if (i.Rd != i.Rt)
						{
							e->movdqa1_regmem(RAX, &r->GPR[i.Rt].s);
							ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
						}
					}
					else
					{
						e->movdqa1_regmem(RAX, &r->GPR[i.Rt].s);
						e->psllw1regimm(RAX, RAX, i.Shift & 0xf);
						ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					}
				}
#endif

			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::PSLLW ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "PSLLW";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PSLLW;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
#ifdef USE_NEW_PSLLW_CODE
		case 1:

#ifdef USE_NEW_R5900_ASSEMBLER_PSLLW
				if (i.Rd)
				{
					if (!i.Rt)
					{
						//e->pxor1regreg(RAX, RAX, RAX);
						//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
						x->emit("vpxor xmm0, xmm0, xmm0");
						x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
					}
					else if (!(i.Shift))
					{
						if (i.Rd != i.Rt)
						{
							//e->movdqa1_regmem(RAX, &r->GPR[i.Rt].s);
							//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
							x->emit("vmovdqa xmm0, @ptr", &r->GPR[i.Rt].s);
							x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
						}
					}
					else
					{
						//e->movdqa1_regmem(RAX, &r->GPR[i.Rt].s);
						//e->pslld1regimm(RAX, RAX, i.Shift);
						//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
						x->emit("vmovdqa xmm0, @ptr", &r->GPR[i.Rt].s);
						x->emit("vpslld xmm0, xmm0, @imm", i.Shift);
						x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
					}
				}

#else
				if (i.Rd)
				{
					if (!i.Rt)
					{
						e->pxor1regreg(RAX, RAX, RAX);
						ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					}
					else if (!(i.Shift))
					{
						if (i.Rd != i.Rt)
						{
							e->movdqa1_regmem(RAX, &r->GPR[i.Rt].s);
							ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
						}
					}
					else
					{
						e->movdqa1_regmem(RAX, &r->GPR[i.Rt].s);
						e->pslld1regimm(RAX, RAX, i.Shift);
						ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					}
				}
#endif

			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::PSRLH ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "PSRLH";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PSRLH;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
#ifdef USE_NEW_PSRLH_CODE
		case 1:

#ifdef USE_NEW_R5900_ASSEMBLER_PSRLH
				if (i.Rd)
				{
					if (!i.Rt)
					{
						//e->pxor1regreg(RAX, RAX, RAX);
						//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
						x->emit("vpxor xmm0, xmm0, xmm0");
						x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
					}
					else if (!(i.Shift & 0xf))
					{
						if (i.Rd != i.Rt)
						{
							//e->movdqa1_regmem(RAX, &r->GPR[i.Rt].s);
							//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
							x->emit("vmovdqa xmm0, @ptr", &r->GPR[i.Rt].s);
							x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
						}
					}
					else
					{
						//e->movdqa1_regmem(RAX, &r->GPR[i.Rt].s);
						//e->psrlw1regimm(RAX, RAX, i.Shift & 0xf);
						//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
						x->emit("vmovdqa xmm0, @ptr", &r->GPR[i.Rt].s);
						x->emit("vpsrlw xmm0, xmm0, @imm", i.Shift & 0xf);
						x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
					}
				}

#else
				if (i.Rd)
				{
					if (!i.Rt)
					{
						e->pxor1regreg(RAX, RAX, RAX);
						ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					}
					else if (!(i.Shift & 0xf))
					{
						if (i.Rd != i.Rt)
						{
							e->movdqa1_regmem(RAX, &r->GPR[i.Rt].s);
							ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
						}
					}
					else
					{
						e->movdqa1_regmem(RAX, &r->GPR[i.Rt].s);
						e->psrlw1regimm(RAX, RAX, i.Shift & 0xf);
						ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					}
				}

#endif

			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::PSRLW ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "PSRLW";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PSRLW;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch (OpLevel)
	{
	case 0:
		if (i.Rd)
		{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX(RSP, c_lSEH_StackSize);
#endif

			e->LoadImm32(RCX, i.Value);
			ret = e->Call(c_vFunction);

#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX(RSP, c_lSEH_StackSize);
#endif
		}
		break;

#ifdef USE_NEW_PSRLW_CODE
	case 1:

#ifdef USE_NEW_R5900_ASSEMBLER_PSRLW
			if (i.Rd)
			{
				if (!i.Rt)
				{
					//e->pxor1regreg(RAX, RAX, RAX);
					//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					x->emit("vpxor xmm0, xmm0, xmm0");
					x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
				}
				else if (!(i.Shift))
				{
					if (i.Rd != i.Rt)
					{
						//e->movdqa1_regmem(RAX, &r->GPR[i.Rt].s);
						//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
						x->emit("vmovdqa xmm0, @ptr", &r->GPR[i.Rt].s);
						x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
					}
				}
				else
				{
					//e->movdqa1_regmem(RAX, &r->GPR[i.Rt].s);
					//e->psrld1regimm(RAX, RAX, i.Shift);
					//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					x->emit("vmovdqa xmm0, @ptr", &r->GPR[i.Rt].s);
					x->emit("vpsrld xmm0, xmm0, @imm", i.Shift);
					x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
				}
			}

#else
			if (i.Rd)
			{
				if (!i.Rt)
				{
					e->pxor1regreg(RAX, RAX, RAX);
					ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
				}
				else if (!(i.Shift))
				{
					if (i.Rd != i.Rt)
					{
						e->movdqa1_regmem(RAX, &r->GPR[i.Rt].s);
						ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					}
				}
				else
				{
					e->movdqa1_regmem(RAX, &r->GPR[i.Rt].s);
					e->psrld1regimm(RAX, RAX, i.Shift);
					ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
				}
			}
#endif

		break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}


int32_t R5900::Recompiler::PSRAH ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "PSRAH";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PSRAH;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
#ifdef USE_NEW_PSRAH_CODE
		case 1:

#ifdef USE_NEW_R5900_ASSEMBLER_PSRAH
				if (i.Rd)
				{
					if (!i.Rt)
					{
						//e->pxor1regreg(RAX, RAX, RAX);
						//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
						x->emit("vpxor xmm0, xmm0, xmm0");
						x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
					}
					else if (!(i.Shift & 0xf))
					{
						if (i.Rd != i.Rt)
						{
							//e->movdqa1_regmem(RAX, &r->GPR[i.Rt].s);
							//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
							x->emit("vmovdqa xmm0, @ptr", &r->GPR[i.Rt].s);
							x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
						}
					}
					else
					{
						//e->movdqa1_regmem(RAX, &r->GPR[i.Rt].s);
						//e->psraw1regimm(RAX, RAX, i.Shift & 0xf);
						//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
						x->emit("vmovdqa xmm0, @ptr", &r->GPR[i.Rt].s);
						x->emit("vpsraw xmm0, xmm0, @imm", i.Shift & 0xf);
						x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
					}
				}

#else
				if (i.Rd)
				{
					if (!i.Rt)
					{
						e->pxor1regreg(RAX, RAX, RAX);
						ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					}
					else if (!(i.Shift & 0xf))
					{
						if (i.Rd != i.Rt)
						{
							e->movdqa1_regmem(RAX, &r->GPR[i.Rt].s);
							ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
						}
					}
					else
					{
						e->movdqa1_regmem(RAX, &r->GPR[i.Rt].s);
						e->psraw1regimm(RAX, RAX, i.Shift & 0xf);
						ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					}
				}
#endif

			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::PSRAW ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "PSRAW";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PSRAW;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
#ifdef USE_NEW_PSRAW_CODE
		case 1:

#ifdef USE_NEW_R5900_ASSEMBLER_PSRAW
				if (i.Rd)
				{
					if (!i.Rt)
					{
						//e->pxor1regreg(RAX, RAX, RAX);
						//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
						x->emit("vpxor xmm0, xmm0, xmm0");
						x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
					}
					else if (!(i.Shift))
					{
						if (i.Rd != i.Rt)
						{
							//e->movdqa1_regmem(RAX, &r->GPR[i.Rt].s);
							//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
							x->emit("vmovdqa xmm0, @ptr", &r->GPR[i.Rt].s);
							x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
						}
					}
					else
					{
						//e->movdqa1_regmem(RAX, &r->GPR[i.Rt].s);
						//e->psrad1regimm(RAX, RAX, i.Shift);
						//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
						x->emit("vmovdqa xmm0, @ptr", &r->GPR[i.Rt].s);
						x->emit("vpsrad xmm0, xmm0, @imm", i.Shift);
						x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
					}
				}

#else
				if (i.Rd)
				{
					if (!i.Rt)
					{
						e->pxor1regreg(RAX, RAX, RAX);
						ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					}
					else if (!(i.Shift))
					{
						if (i.Rd != i.Rt)
						{
							e->movdqa1_regmem(RAX, &r->GPR[i.Rt].s);
							ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
						}
					}
					else
					{
						e->movdqa1_regmem(RAX, &r->GPR[i.Rt].s);
						e->psrad1regimm(RAX, RAX, i.Shift);
						ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					}
				}
#endif

			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::PSLLVW ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "PSLLVW";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PSLLVW;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch (OpLevel)
	{
	case 0:
		if (i.Rd)
		{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX(RSP, c_lSEH_StackSize);
#endif

			e->LoadImm32(RCX, i.Value);
			ret = e->Call(c_vFunction);

#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX(RSP, c_lSEH_StackSize);
#endif
		}
		break;

#ifdef USE_NEW_PSLLVW_CODE
	case 1:

#ifdef USE_NEW_R5900_ASSEMBLER_PSLLVW
			if (i.Rd)
			{
				//e->pshufd1regmemimm(RBX, &r->GPR[i.Rs].s, 0x08);
				//e->pshufd1regmemimm(RAX, &r->GPR[i.Rt].s, 0x08);
				//e->pslld1regimm(RBX, RBX, 27);
				//e->psrld1regimm(RBX, RBX, 27);
				//e->vpsllvd1regreg(RAX, RAX, RBX);
				//e->pmovsxdq1regreg(RAX, RAX);
				//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
				x->emit("vpshufd xmm1, @ptr, @imm", &r->GPR[i.Rs].s, 0x08);
				x->emit("vpshufd xmm0, @ptr, @imm", &r->GPR[i.Rt].s, 0x08);
				x->emit("vpslld xmm1, xmm1, 27");
				x->emit("vpsrld xmm1, xmm1, 27");
				x->emit("vpsllvd xmm0, xmm0, xmm1");
				x->emit("vpmovsxdq xmm0, xmm0");
				x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
			}
#else
			if (i.Rd)
			{
				//e->movdqa1_regmem(RBX, &r->GPR[i.Rs].s);
				//e->movdqa1_regmem(RAX, &r->GPR[i.Rt].s);
				e->pshufd1regmemimm(RBX, &r->GPR[i.Rs].s, 0x08);
				e->pshufd1regmemimm(RAX, &r->GPR[i.Rt].s, 0x08);

				e->pslld1regimm(RBX, RBX, 27);
				e->psrld1regimm(RBX, RBX, 27);
				e->vpsllvd1regreg(RAX, RAX, RBX);
				//e->pshufd1regregimm(RAX, RAX, 0x08);
				e->pmovsxdq1regreg(RAX, RAX);

				ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
			}
#endif

		break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::PSRLVW ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "PSRLVW";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PSRLVW;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
#ifdef USE_NEW_PSRLVW_CODE
		case 1:

#ifdef USE_NEW_R5900_ASSEMBLER_PSRLVW
				if (i.Rd)
				{
					//e->pshufd1regmemimm(RBX, &r->GPR[i.Rs].s, 0x08);
					//e->pshufd1regmemimm(RAX, &r->GPR[i.Rt].s, 0x08);
					//e->pslld1regimm(RBX, RBX, 27);
					//e->psrld1regimm(RBX, RBX, 27);
					//e->vpsrlvd1regreg(RAX, RAX, RBX);
					//e->pmovsxdq1regreg(RAX, RAX);
					//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					x->emit("vpshufd xmm1, @ptr, @imm", &r->GPR[i.Rs].s, 0x08);
					x->emit("vpshufd xmm0, @ptr, @imm", &r->GPR[i.Rt].s, 0x08);
					x->emit("vpslld xmm1, xmm1, 27");
					x->emit("vpsrld xmm1, xmm1, 27");
					x->emit("vpsrlvd xmm0, xmm0, xmm1");
					x->emit("vpmovsxdq xmm0, xmm0");
					x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
				}
#else
				if (i.Rd)
				{
					//e->movdqa1_regmem(RBX, &r->GPR[i.Rs].s);
					//e->movdqa1_regmem(RAX, &r->GPR[i.Rt].s);
					e->pshufd1regmemimm(RBX, &r->GPR[i.Rs].s, 0x08);
					e->pshufd1regmemimm(RAX, &r->GPR[i.Rt].s, 0x08);

					e->pslld1regimm(RBX, RBX, 27);
					e->psrld1regimm(RBX, RBX, 27);
					e->vpsrlvd1regreg(RAX, RAX, RBX);
					//e->pshufd1regregimm(RAX, RAX, 0x08);
					e->pmovsxdq1regreg(RAX, RAX);

					ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
				}
#endif

			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::PSRAVW ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "PSRAVW";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PSRAVW;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch (OpLevel)
	{
	case 0:
		if (i.Rd)
		{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX(RSP, c_lSEH_StackSize);
#endif

			e->LoadImm32(RCX, i.Value);
			ret = e->Call(c_vFunction);

#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX(RSP, c_lSEH_StackSize);
#endif
		}
		break;

#ifdef USE_NEW_PSRAVW_CODE
	case 1:

#ifdef USE_NEW_R5900_ASSEMBLER_PSRAVW
			if (i.Rd)
			{
				//e->pshufd1regmemimm(RBX, &r->GPR[i.Rs].s, 0x08);
				//e->pshufd1regmemimm(RAX, &r->GPR[i.Rt].s, 0x08);
				//e->pslld1regimm(RBX, RBX, 27);
				//e->psrld1regimm(RBX, RBX, 27);
				//e->vpsravd1regreg(RAX, RAX, RBX);
				//e->pmovsxdq1regreg(RAX, RAX);
				//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
				x->emit("vpshufd xmm1, @ptr, @imm", &r->GPR[i.Rs].s, 0x08);
				x->emit("vpshufd xmm0, @ptr, @imm", &r->GPR[i.Rt].s, 0x08);
				x->emit("vpslld xmm1, xmm1, 27");
				x->emit("vpsrld xmm1, xmm1, 27");
				x->emit("vpsravd xmm0, xmm0, xmm1");
				x->emit("vpmovsxdq xmm0, xmm0");
				x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
			}
#else
			if (i.Rd)
			{
				//e->movdqa1_regmem(RBX, &r->GPR[i.Rs].s);
				//e->movdqa1_regmem(RAX, &r->GPR[i.Rt].s);
				e->pshufd1regmemimm(RBX, &r->GPR[i.Rs].s, 0x08);
				e->pshufd1regmemimm(RAX, &r->GPR[i.Rt].s, 0x08);

				e->pslld1regimm(RBX, RBX, 27);
				e->psrld1regimm(RBX, RBX, 27);
				e->vpsravd1regreg(RAX, RAX, RBX);
				//e->pshufd1regregimm(RAX, RAX, 0x08);
				e->pmovsxdq1regreg(RAX, RAX);

				ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
			}
#endif

		break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}


int32_t R5900::Recompiler::PADDB ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "PADDB";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PADDB;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
#ifdef USE_NEW_PADDB_CODE
		case 1:

#ifdef USE_NEW_R5900_ASSEMBLER_PADDB
				if (i.Rd)
				{
					if ((!i.Rs) && (!i.Rt))
					{
						//e->pxor1regreg(RAX, RAX, RAX);
						//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
						x->emit("vpxor xmm0, xmm0, xmm0");
						x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
					}
					else if ((!i.Rs) || (!i.Rt))
					{
						if (i.Rd != (i.Rs | i.Rt))
						{
							//e->movdqa1_regmem(RAX, &r->GPR[i.Rs | i.Rt].s);
							//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
							x->emit("vmovdqa xmm0, @ptr", &r->GPR[i.Rs | i.Rt].s);
							x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
						}
					}
					else if (i.Rs == i.Rt)
					{
						//e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
						//e->paddb1regreg(RAX, RAX, RAX);
						//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
						x->emit("vmovdqa xmm0, @ptr", &r->GPR[i.Rs].s);
						x->emit("vpaddb xmm0, xmm0, xmm0");
						x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
					}
					else
					{
						//e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
						//e->paddb1regmem(RAX, RAX, &r->GPR[i.Rt].s);
						//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
						x->emit("vmovdqa xmm0, @ptr", &r->GPR[i.Rs].s);
						x->emit("vpaddb xmm0, xmm0, @ptr", &r->GPR[i.Rt].s);
						x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
					}
				}

#else
				if (i.Rd)
				{
					if (!i.Rs)
					{
						if (!i.Rt)
						{
							e->pxor1regreg(RAX, RAX, RAX);
							ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
						}
						else if (i.Rd != i.Rt)
						{
							e->movdqa1_regmem(RAX, &r->GPR[i.Rt].s);
							ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
						}
					}
					else if (!i.Rt)
					{
						if (i.Rd != i.Rs)
						{
							e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
							ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
						}
					}
					else if (i.Rs == i.Rt)
					{
						e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
						e->paddb1regreg(RAX, RAX, RAX);
						ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					}
					else
					{
						e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
						e->paddb1regmem(RAX, RAX, &r->GPR[i.Rt].s);
						ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					}
				}
#endif

			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::PADDH ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "PADDH";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PADDH;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch (OpLevel)
	{
	case 0:
		if (i.Rd)
		{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX(RSP, c_lSEH_StackSize);
#endif

			e->LoadImm32(RCX, i.Value);
			ret = e->Call(c_vFunction);

#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX(RSP, c_lSEH_StackSize);
#endif
		}
		break;

#ifdef USE_NEW_PADDH_CODE
	case 1:

#ifdef USE_NEW_R5900_ASSEMBLER_PADDH
			if (i.Rd)
			{
				if ((!i.Rs) && (!i.Rt))
				{
					//e->pxor1regreg(RAX, RAX, RAX);
					//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					x->emit("vpxor xmm0, xmm0, xmm0");
					x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
				}
				else if ((!i.Rs) || (!i.Rt))
				{
					if (i.Rd != (i.Rs | i.Rt))
					{
						//e->movdqa1_regmem(RAX, &r->GPR[i.Rs | i.Rt].s);
						//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
						x->emit("vmovdqa xmm0, @ptr", &r->GPR[i.Rs | i.Rt].s);
						x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
					}
				}
				else if (i.Rs == i.Rt)
				{
					//e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
					//e->paddb1regreg(RAX, RAX, RAX);
					//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					x->emit("vmovdqa xmm0, @ptr", &r->GPR[i.Rs].s);
					x->emit("vpaddw xmm0, xmm0, xmm0");
					x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
				}
				else
				{
					//e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
					//e->paddb1regmem(RAX, RAX, &r->GPR[i.Rt].s);
					//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					x->emit("vmovdqa xmm0, @ptr", &r->GPR[i.Rs].s);
					x->emit("vpaddw xmm0, xmm0, @ptr", &r->GPR[i.Rt].s);
					x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
				}
			}

#else
			if (i.Rd)
			{
				if (!i.Rs)
				{
					if (!i.Rt)
					{
						e->pxor1regreg(RAX, RAX, RAX);
						ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					}
					else if (i.Rd != i.Rt)
					{
						e->movdqa1_regmem(RAX, &r->GPR[i.Rt].s);
						ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					}
				}
				else if (!i.Rt)
				{
					if (i.Rd != i.Rs)
					{
						e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
						ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					}
				}
				else if (i.Rs == i.Rt)
				{
					e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
					e->paddw1regreg(RAX, RAX, RAX);
					ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
				}
				else
				{
					e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
					e->paddw1regmem(RAX, RAX, &r->GPR[i.Rt].s);
					ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
				}
			}
#endif

			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::PADDW ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "PADDW";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PADDW;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch (OpLevel)
	{
	case 0:
		if (i.Rd)
		{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX(RSP, c_lSEH_StackSize);
#endif

			e->LoadImm32(RCX, i.Value);
			ret = e->Call(c_vFunction);

#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX(RSP, c_lSEH_StackSize);
#endif
		}
		break;

#ifdef USE_NEW_PADDW_CODE
	case 1:

#ifdef USE_NEW_R5900_ASSEMBLER_PADDW
			if (i.Rd)
			{
				if ((!i.Rs) && (!i.Rt))
				{
					//e->pxor1regreg(RAX, RAX, RAX);
					//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					x->emit("vpxor xmm0, xmm0, xmm0");
					x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
				}
				else if ((!i.Rs) || (!i.Rt))
				{
					if (i.Rd != (i.Rs | i.Rt))
					{
						//e->movdqa1_regmem(RAX, &r->GPR[i.Rs | i.Rt].s);
						//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
						x->emit("vmovdqa xmm0, @ptr", &r->GPR[i.Rs | i.Rt].s);
						x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
					}
				}
				else if (i.Rs == i.Rt)
				{
					//e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
					//e->paddb1regreg(RAX, RAX, RAX);
					//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					x->emit("vmovdqa xmm0, @ptr", &r->GPR[i.Rs].s);
					x->emit("vpaddd xmm0, xmm0, xmm0");
					x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
				}
				else
				{
					//e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
					//e->paddb1regmem(RAX, RAX, &r->GPR[i.Rt].s);
					//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					x->emit("vmovdqa xmm0, @ptr", &r->GPR[i.Rs].s);
					x->emit("vpaddd xmm0, xmm0, @ptr", &r->GPR[i.Rt].s);
					x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
				}
			}

#else
			if (i.Rd)
			{
				if (!i.Rs)
				{
					if (!i.Rt)
					{
						e->pxor1regreg(RAX, RAX, RAX);
						ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					}
					else if (i.Rd != i.Rt)
					{
						e->movdqa1_regmem(RAX, &r->GPR[i.Rt].s);
						ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					}
				}
				else if (!i.Rt)
				{
					if (i.Rd != i.Rs)
					{
						e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
						ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					}
				}
				else if (i.Rs == i.Rt)
				{
					e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
					e->paddd1regreg(RAX, RAX, RAX);
					ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
				}
				else
				{
					e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
					e->paddd1regmem(RAX, RAX, &r->GPR[i.Rt].s);
					ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
				}
			}
#endif

			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::PSUBB ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "PSUBB";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PSUBB;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
#ifdef USE_NEW_PSUBB_CODE
		case 1:

#ifdef USE_NEW_R5900_ASSEMBLER_PSUBB
				if (i.Rd)
				{
					if (((!i.Rs) && (!i.Rt)) || (i.Rs == i.Rt))
					{
						//e->pxor1regreg(RAX, RAX, RAX);
						//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
						x->emit("vpxor xmm0, xmm0, xmm0");
						x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
					}
					else if (!i.Rt)
					{
						if (i.Rd != i.Rs)
						{
							//e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
							//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
							x->emit("vmovdqa xmm0, @ptr", &r->GPR[i.Rs].s);
							x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
						}
					}
					else if (!i.Rs)
					{
						x->emit("vpxor xmm0, xmm0, xmm0");
						x->emit("vpsubb xmm0, xmm0, @ptr", &r->GPR[i.Rt].s);
						x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
					}
					else
					{
						//e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
						//e->psubb1regmem(RAX, RAX, &r->GPR[i.Rt].s);
						//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
						x->emit("vmovdqa xmm0, @ptr", &r->GPR[i.Rs].s);
						x->emit("vpsubb xmm0, xmm0, @ptr", &r->GPR[i.Rt].s);
						x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
					}
				}

#else
				if (i.Rd)
				{
					if (!i.Rs)
					{
						if (!i.Rt)
						{
							e->pxor1regreg(RAX, RAX, RAX);
							ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
						}
						else
						{
							e->pxor1regreg(RAX, RAX, RAX);
							e->psubb1regmem(RAX, RAX, &r->GPR[i.Rt].s);
							ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
						}
					}
					else if (!i.Rt)
					{
						if (i.Rd != i.Rs)
						{
							e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
							ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
						}
					}
					else if (i.Rs == i.Rt)
					{
						e->pxor1regreg(RAX, RAX, RAX);
						ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					}
					else
					{
						e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
						e->psubb1regmem(RAX, RAX, &r->GPR[i.Rt].s);
						ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					}
				}
#endif

			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::PSUBH ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "PSUBH";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PSUBH;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch (OpLevel)
	{
	case 0:
		if (i.Rd)
		{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX(RSP, c_lSEH_StackSize);
#endif

			e->LoadImm32(RCX, i.Value);
			ret = e->Call(c_vFunction);

#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX(RSP, c_lSEH_StackSize);
#endif
		}
		break;

#ifdef USE_NEW_PSUBH_CODE
	case 1:

#ifdef USE_NEW_R5900_ASSEMBLER_PSUBH
			if (i.Rd)
			{
				if (((!i.Rs) && (!i.Rt)) || (i.Rs == i.Rt))
				{
					//e->pxor1regreg(RAX, RAX, RAX);
					//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					x->emit("vpxor xmm0, xmm0, xmm0");
					x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
				}
				else if (!i.Rt)
				{
					if (i.Rd != i.Rs)
					{
						//e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
						//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
						x->emit("vmovdqa xmm0, @ptr", &r->GPR[i.Rs].s);
						x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
					}
				}
				else if (!i.Rs)
				{
					x->emit("vpxor xmm0, xmm0, xmm0");
					x->emit("vpsubw xmm0, xmm0, @ptr", &r->GPR[i.Rt].s);
					x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
				}
				else
				{
					//e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
					//e->psubb1regmem(RAX, RAX, &r->GPR[i.Rt].s);
					//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					x->emit("vmovdqa xmm0, @ptr", &r->GPR[i.Rs].s);
					x->emit("vpsubw xmm0, xmm0, @ptr", &r->GPR[i.Rt].s);
					x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
				}
			}

#else
			if (i.Rd)
			{
				if (!i.Rs)
				{
					if (!i.Rt)
					{
						e->pxor1regreg(RAX, RAX, RAX);
						ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					}
					else
					{
						e->pxor1regreg(RAX, RAX, RAX);
						e->psubw1regmem(RAX, RAX, &r->GPR[i.Rt].s);
						ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					}
				}
				else if (!i.Rt)
				{
					if (i.Rd != i.Rs)
					{
						e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
						ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					}
				}
				else if (i.Rs == i.Rt)
				{
					e->pxor1regreg(RAX, RAX, RAX);
					ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
				}
				else
				{
					e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
					e->psubw1regmem(RAX, RAX, &r->GPR[i.Rt].s);
					ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
				}
			}
#endif

		break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::PSUBW ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "PSUBW";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PSUBW;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
#ifdef USE_NEW_PSUBW_CODE
		case 1:

#ifdef USE_NEW_R5900_ASSEMBLER_PSUBW
				if (i.Rd)
				{
					if (((!i.Rs) && (!i.Rt)) || (i.Rs == i.Rt))
					{
						//e->pxor1regreg(RAX, RAX, RAX);
						//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
						x->emit("vpxor xmm0, xmm0, xmm0");
						x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
					}
					else if (!i.Rt)
					{
						if (i.Rd != i.Rs)
						{
							//e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
							//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
							x->emit("vmovdqa xmm0, @ptr", &r->GPR[i.Rs].s);
							x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
						}
					}
					else if (!i.Rs)
					{
						x->emit("vpxor xmm0, xmm0, xmm0");
						x->emit("vpsubd xmm0, xmm0, @ptr", &r->GPR[i.Rt].s);
						x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
					}
					else
					{
						//e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
						//e->psubb1regmem(RAX, RAX, &r->GPR[i.Rt].s);
						//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
						x->emit("vmovdqa xmm0, @ptr", &r->GPR[i.Rs].s);
						x->emit("vpsubd xmm0, xmm0, @ptr", &r->GPR[i.Rt].s);
						x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
					}
				}

#else

				if (i.Rd)
				{
					if (!i.Rs)
					{
						if (!i.Rt)
						{
							e->pxor1regreg(RAX, RAX, RAX);
							ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
						}
						else
						{
							e->pxor1regreg(RAX, RAX, RAX);
							e->psubd1regmem(RAX, RAX, &r->GPR[i.Rt].s);
							ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
						}
					}
					else if (!i.Rt)
					{
						if (i.Rd != i.Rs)
						{
							e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
							ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
						}
					}
					else if (i.Rs == i.Rt)
					{
						e->pxor1regreg(RAX, RAX, RAX);
						ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					}
					else
					{
						e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
						e->psubd1regmem(RAX, RAX, &r->GPR[i.Rt].s);
						ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					}
				}
#endif

			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}


int32_t R5900::Recompiler::PADDSB ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "PADDSB";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PADDSB;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch (OpLevel)
	{
	case 0:
		if (i.Rd)
		{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX(RSP, c_lSEH_StackSize);
#endif

			e->LoadImm32(RCX, i.Value);
			ret = e->Call(c_vFunction);

#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX(RSP, c_lSEH_StackSize);
#endif
		}
		break;

#ifdef USE_NEW_PADDSB_CODE
	case 1:

#ifdef USE_NEW_R5900_ASSEMBLER_PADDSB
			if (i.Rd)
			{
				if ((!i.Rs) && (!i.Rt))
				{
					//e->pxor1regreg(RAX, RAX, RAX);
					//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					x->emit("vpxor xmm0, xmm0, xmm0");
					x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
				}
				else if ((!i.Rs) || (!i.Rt))
				{
					if (i.Rd != (i.Rs | i.Rt))
					{
						//e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
						//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
						x->emit("vmovdqa xmm0, @ptr", &r->GPR[i.Rs | i.Rt].s);
						x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
					}
				}
				else if (i.Rs == i.Rt)
				{
					//e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
					//e->paddsb1regreg(RAX, RAX, RAX);
					//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					x->emit("vmovdqa xmm0, @ptr", &r->GPR[i.Rs].s);
					x->emit("vpaddsb xmm0, xmm0, xmm0");
					x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
				}
				else
				{
					//e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
					//e->paddsb1regmem(RAX, RAX, &r->GPR[i.Rt].s);
					//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					x->emit("vmovdqa xmm0, @ptr", &r->GPR[i.Rs].s);
					x->emit("vpaddsb xmm0, xmm0, @ptr", &r->GPR[i.Rt].s);
					x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
				}
			}
#else
			if (i.Rd)
			{
				if (!i.Rs)
				{
					if (!i.Rt)
					{
						e->pxor1regreg(RAX, RAX, RAX);
						ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					}
					else if (i.Rd != i.Rt)
					{
						e->movdqa1_regmem(RAX, &r->GPR[i.Rt].s);
						ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					}
				}
				else if (!i.Rt)
				{
					if (i.Rd != i.Rs)
					{
						e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
						ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					}
				}
				else if (i.Rs == i.Rt)
				{
					e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
					e->paddsb1regreg(RAX, RAX, RAX);
					ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
				}
				else
				{
					e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
					e->paddsb1regmem(RAX, RAX, &r->GPR[i.Rt].s);
					ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
				}
			}
#endif

		break;
#endif

	default:
		return -1;
		break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::PADDSH ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "PADDSH";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PADDSH;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
#ifdef USE_NEW_PADDSH_CODE
		case 1:

#ifdef USE_NEW_R5900_ASSEMBLER_PADDSH
				if (i.Rd)
				{
					if ((!i.Rs) && (!i.Rt))
					{
						//e->pxor1regreg(RAX, RAX, RAX);
						//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
						x->emit("vpxor xmm0, xmm0, xmm0");
						x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
					}
					else if ((!i.Rs) || (!i.Rt))
					{
						if (i.Rd != (i.Rs | i.Rt))
						{
							//e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
							//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
							x->emit("vmovdqa xmm0, @ptr", &r->GPR[i.Rs | i.Rt].s);
							x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
						}
					}
					else if (i.Rs == i.Rt)
					{
						//e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
						//e->paddsb1regreg(RAX, RAX, RAX);
						//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
						x->emit("vmovdqa xmm0, @ptr", &r->GPR[i.Rs].s);
						x->emit("vpaddsw xmm0, xmm0, xmm0");
						x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
					}
					else
					{
						//e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
						//e->paddsb1regmem(RAX, RAX, &r->GPR[i.Rt].s);
						//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
						x->emit("vmovdqa xmm0, @ptr", &r->GPR[i.Rs].s);
						x->emit("vpaddsw xmm0, xmm0, @ptr", &r->GPR[i.Rt].s);
						x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
					}
				}
#else
				if (i.Rd)
				{
					if (!i.Rs)
					{
						if (!i.Rt)
						{
							e->pxor1regreg(RAX, RAX, RAX);
							ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
						}
						else if (i.Rd != i.Rt)
						{
							e->movdqa1_regmem(RAX, &r->GPR[i.Rt].s);
							ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
						}
					}
					else if (!i.Rt)
					{
						if (i.Rd != i.Rs)
						{
							e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
							ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
						}
					}
					else if (i.Rs == i.Rt)
					{
						e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
						e->paddsw1regreg(RAX, RAX, RAX);
						ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					}
					else
					{
						e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
						e->paddsw1regmem(RAX, RAX, &r->GPR[i.Rt].s);
						ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					}
				}
#endif

			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::PADDSW ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "PADDSW";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PADDSW;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;

#ifdef USE_NEW_PADDSW_CODE
		case 1:
#ifdef ALLOW_AVX2_PADDSW
			if (iVectorType == VECTOR_TYPE_SSE)
#endif
			{
				if (i.Rd)
				{
					if (!i.Rs)
					{
						if (!i.Rt)
						{
							e->pxorregreg(RAX, RAX);
							ret = e->movdqa_memreg(&r->GPR[i.Rd].s, RAX);
						}
						else if (i.Rd != i.Rt)
						{
							e->movdqa_regmem(RAX, &r->GPR[i.Rt].s);
							ret = e->movdqa_memreg(&r->GPR[i.Rd].s, RAX);
						}
					}
					else if (!i.Rt)
					{
						if (i.Rd != i.Rs)
						{
							e->movdqa_regmem(RAX, &r->GPR[i.Rs].s);
							ret = e->movdqa_memreg(&r->GPR[i.Rd].s, RAX);
						}
					}
					else if (i.Rs == i.Rt)
					{
						e->movdqa_regmem(RAX, &r->GPR[i.Rs].s);

						// get max -> VR4
						e->pcmpeqbregreg(4, 4);
						e->psrldregimm(4, 1);

						// overflow = ~(a^b) & (a^(a+b))

						// A -> RCX
						e->movdqa_regreg(RCX, RAX);

						// b -> RBX
						e->movdqa_regreg(RBX, RCX);

						// (a+b) -> RCX,RDX
						e->padddregreg(RCX, RAX);
						e->movdqa_regreg(RDX, RCX);

						// (a^(a+b)) -> RCX
						e->pxorregreg(RCX, RAX);
						// (a^b) -> RAX
						e->pxorregreg(RAX, RBX);
						// ~(a^b) & (a^(a+b)) -> RAX
						e->pandnregreg(RAX, RCX);
						e->psradregimm(RAX, 31);

						// get sat
						e->psrldregimm(RBX, 31);
						e->padddregreg(4, RBX);

						// blend
						e->pblendvbregreg(RDX, 4);

						ret = e->movdqa_memreg(&r->GPR[i.Rd].s, RDX);
					}
					else
					{
						e->movdqa_regmem(RAX, &r->GPR[i.Rs].s);
						e->movdqa_regmem(RCX, &r->GPR[i.Rt].s);

						// get max -> VR4
						e->pcmpeqbregreg(4, 4);
						e->psrldregimm(4, 1);

						// overflow = ~(a^b) & (a^(a+b))

						// b -> RBX
						e->movdqa_regreg(RBX, RCX);

						// (a+b) -> RCX,RDX
						e->padddregreg(RCX, RAX);
						e->movdqa_regreg(RDX, RCX);

						// (a^(a+b)) -> RCX
						e->pxorregreg(RCX, RAX);
						// (a^b) -> RAX
						e->pxorregreg(RAX, RBX);
						// ~(a^b) & (a^(a+b)) -> RAX
						e->pandnregreg(RAX, RCX);
						e->psradregimm(RAX, 31);

						// get sat
						e->psrldregimm(RBX, 31);
						e->padddregreg(4, RBX);

						// blend
						e->pblendvbregreg(RDX, 4);

						ret = e->movdqa_memreg(&r->GPR[i.Rd].s, RDX);
					}
				}
			}
#ifdef ALLOW_AVX2_PADDSW
			else
			{
				if (i.Rd)
				{
					if (!i.Rs)
					{
						if (!i.Rt)
						{
							e->pxor1regreg(RAX, RAX, RAX);
							ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
						}
						else if (i.Rd != i.Rt)
						{
							e->movdqa1_regmem(RAX, &r->GPR[i.Rt].s);
							ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
						}
					}
					else if (!i.Rt)
					{
						if (i.Rd != i.Rs)
						{
							e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
							ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
						}
					}
					else
					{

						e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
						e->movdqa1_regmem(RCX, &r->GPR[i.Rt].s);

						//int sum = x + y; -> rbx
						e->paddd1regreg(RBX, RAX, RCX);

						// get minmax ->r5
						e->pcmpeqb1regreg(5, 5, 5);
						e->psrld1regimm(5, 5, 1);
						e->psrld1regimm(4, RAX, 31);
						e->paddd1regreg(5, 5, 4);

						//int w = (sizeof(int) << 3) - 1; ->31
						//int mask = (~(x ^ y) & (x ^ sum)) >> w; ->rcx
						e->pxor1regreg(RCX, RCX, RAX);
						e->pxor1regreg(RDX, RAX, RBX);
						e->pandn1regreg(RCX, RCX, RDX);
						e->psrad1regimm(RCX, RCX, 31);

						// select ->rax
						e->pblendvb1regreg(RAX, RBX, 5, RCX);

						ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					}
				}
			}
#endif


			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}


int32_t R5900::Recompiler::PSUBSB ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "PSUBSB";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PSUBSB;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch (OpLevel)
	{
	case 0:
		if (i.Rd)
		{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX(RSP, c_lSEH_StackSize);
#endif

			e->LoadImm32(RCX, i.Value);
			ret = e->Call(c_vFunction);

#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX(RSP, c_lSEH_StackSize);
#endif
		}
		break;

#ifdef USE_NEW_PSUBSB_CODE
	case 1:

#ifdef USE_NEW_R5900_ASSEMBLER_PSUBSB
			if (i.Rd)
			{
				if (i.Rs == i.Rt)
				{
					//e->pxor1regreg(RAX, RAX, RAX);
					//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					x->emit("vpxor xmm0, xmm0, xmm0");
					x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
				}
				else if (!i.Rt)
				{
					if (i.Rd != i.Rs)
					{
						//e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
						//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
						x->emit("vmovdqa xmm0, @ptr", &r->GPR[i.Rs].s);
						x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
					}
				}
				else if (!i.Rs)
				{
					x->emit("vpxor xmm0, xmm0, xmm0");
					x->emit("vpsubsb xmm0, xmm0, @ptr", &r->GPR[i.Rt].s);
					x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
				}
				else
				{
					//e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
					//e->psubsb1regmem(RAX, RAX, &r->GPR[i.Rt].s);
					//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					x->emit("vmovdqa xmm0, @ptr", &r->GPR[i.Rs].s);
					x->emit("vpsubsb xmm0, xmm0, @ptr", &r->GPR[i.Rt].s);
					x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
				}
			}

#else
			if (i.Rd)
			{
				if (!i.Rs)
				{
					if (!i.Rt)
					{
						e->pxor1regreg(RAX, RAX, RAX);
						ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					}
					else
					{
						//e->movdqa_regmem ( RAX, & r->GPR [ i.Rt ].s );
						e->pxor1regreg(RAX, RAX, RAX);
						e->psubsb1regmem(RAX, RAX, &r->GPR[i.Rt].s);
						ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					}
				}
				else if (!i.Rt)
				{
					if (i.Rd != i.Rs)
					{
						e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
						ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					}
				}
				else if (i.Rs == i.Rt)
				{
					e->pxor1regreg(RAX, RAX, RAX);
					ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
				}
				else
				{
					e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
					e->psubsb1regmem(RAX, RAX, &r->GPR[i.Rt].s);
					ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
				}
			}
#endif

			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}


int32_t R5900::Recompiler::PSUBSH ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "PSUBSH";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PSUBSH;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch (OpLevel)
	{
	case 0:
		if (i.Rd)
		{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX(RSP, c_lSEH_StackSize);
#endif

			e->LoadImm32(RCX, i.Value);
			ret = e->Call(c_vFunction);

#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX(RSP, c_lSEH_StackSize);
#endif
		}
		break;

#ifdef USE_NEW_PSUBSH_CODE
	case 1:

#ifdef USE_NEW_R5900_ASSEMBLER_PSUBSH
			if (i.Rd)
			{
				if (i.Rs == i.Rt)
				{
					//e->pxor1regreg(RAX, RAX, RAX);
					//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					x->emit("vpxor xmm0, xmm0, xmm0");
					x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
				}
				else if (!i.Rt)
				{
					if (i.Rd != i.Rs)
					{
						//e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
						//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
						x->emit("vmovdqa xmm0, @ptr", &r->GPR[i.Rs].s);
						x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
					}
				}
				else if (!i.Rs)
				{
					x->emit("vpxor xmm0, xmm0, xmm0");
					x->emit("vpsubsw xmm0, xmm0, @ptr", &r->GPR[i.Rt].s);
					x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
				}
				else
				{
					//e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
					//e->psubsb1regmem(RAX, RAX, &r->GPR[i.Rt].s);
					//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					x->emit("vmovdqa xmm0, @ptr", &r->GPR[i.Rs].s);
					x->emit("vpsubsw xmm0, xmm0, @ptr", &r->GPR[i.Rt].s);
					x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
				}
			}

#else

			if (i.Rd)
			{
				if (!i.Rs)
				{
					if (!i.Rt)
					{
						e->pxor1regreg(RAX, RAX, RAX);
						ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					}
					else
					{
						e->pxor1regreg(RAX, RAX, RAX);
						e->psubsw1regmem(RAX, RAX, &r->GPR[i.Rt].s);
						ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					}
				}
				else if (!i.Rt)
				{
					if (i.Rd != i.Rs)
					{
						e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
						ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					}
				}
				else if (i.Rs == i.Rt)
				{
					e->pxor1regreg(RAX, RAX, RAX);
					ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
				}
				else
				{
					e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
					e->psubsw1regmem(RAX, RAX, &r->GPR[i.Rt].s);
					ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
				}
			}
#endif

		break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}


int32_t R5900::Recompiler::PSUBSW ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "PSUBSW";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PSUBSW;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;

#ifdef USE_NEW_PSUBSW_CODE
		case 1:
#ifdef ALLOW_AVX2_PSUBSW
			if (iVectorType == VECTOR_TYPE_SSE)
#endif
			{
				if (i.Rd)
				{
					if (!i.Rt)
					{
						if (!i.Rs)
						{
							e->pxorregreg(RAX, RAX);
							ret = e->movdqa_memreg(&r->GPR[i.Rd].s, RAX);
						}
						else if (i.Rd != i.Rs)
						{
							e->movdqa_regmem(RAX, &r->GPR[i.Rs].s);
							ret = e->movdqa_memreg(&r->GPR[i.Rd].s, RAX);
						}
					}
					else if (i.Rs == i.Rt)
					{
						e->pxorregreg(RAX, RAX);
						ret = e->movdqa_memreg(&r->GPR[i.Rd].s, RAX);
					}
					else
					{
						e->movdqa_regmem(RAX, &r->GPR[i.Rs].s);
						e->movdqa_regmem(RCX, &r->GPR[i.Rt].s);

						// get max -> VR4
						e->pcmpeqbregreg(4, 4);

						// overflow = ~(a^b) & (a^(a+b))

						// a -> VR5
						e->movdqa_regreg(5, RAX);

						// b -> RBX
						e->movdqa_regreg(RBX, RCX);


						// (a+b) -> RCX,RDX
						e->pxorregreg(RCX, 4);
						e->psubdregreg(RCX, 4);
						e->padddregreg(RCX, RAX);
						//x->psubdregreg ( RCX, RAX );
						e->movdqa_regreg(RDX, RCX);

						e->psrldregimm(4, 1);

						// (a^(a+b)) -> RCX
						e->pxorregreg(RCX, RAX);
						// (a^b) -> RAX
						e->pxorregreg(RAX, RBX);
						// ~(a^b) & (a^(a+b)) -> RAX
						//x->pandnregreg ( RAX, RCX );
						e->pandregreg(RAX, RCX);
						e->psradregimm(RAX, 31);

						// get sat
						e->psrldregimm(5, 31);
						e->padddregreg(4, 5);

						// blend
						e->pblendvbregreg(RDX, 4);

						ret = e->movdqa_memreg(&r->GPR[i.Rd].s, RDX);
					}
				}
			}
#ifdef ALLOW_AVX2_PSUBSW
			else
			{
				if (i.Rd)
				{
					if (!i.Rt)
					{
						if (!i.Rs)
						{
							e->pxor1regreg(RAX, RAX, RAX);
							ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
						}
						else if (i.Rd != i.Rs)
						{
							e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
							ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
						}
					}
					else if (i.Rs == i.Rt)
					{
						e->pxor1regreg(RAX, RAX, RAX);
						ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					}
					else
					{
						e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
						e->movdqa1_regmem(RCX, &r->GPR[i.Rt].s);

						//int sum = x - y; -> rbx
						e->psubd1regreg(RBX, RAX, RCX);

						// get minmax ->r5
						e->pcmpeqb1regreg(5, 5, 5);
						e->psrld1regimm(5, 5, 1);
						e->psrld1regimm(4, RAX, 31);
						e->paddd1regreg(5, 5, 4);

						//int w = (sizeof(int) << 3) - 1; ->31
						//int mask = (~(x ^ y) & (x ^ sum)) >> w; ->rcx
						e->pxor1regreg(RCX, RCX, RAX);
						e->pxor1regreg(RDX, RAX, RBX);
						e->pandn1regreg(RCX, RCX, RDX);
						e->psrad1regimm(RCX, RCX, 31);

						// select ->rax
						e->pblendvb1regreg(RAX, RBX, 5, RCX);

						ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					}
				}
			}
#endif
			
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}


int32_t R5900::Recompiler::PADDUB ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "PADDUB";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PADDUB;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
#ifdef USE_NEW_PADDUB_CODE
		case 1:

#ifdef USE_NEW_R5900_ASSEMBLER_PADDUB
				if (i.Rd)
				{
					if ((!i.Rs) && (i.Rt))
					{
						//e->pxor1regreg(RAX, RAX, RAX);
						//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
						x->emit("vpxor xmm0, xmm0, xmm0");
						x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
					}
					else if ((!i.Rs) || (!i.Rt))
					{
						if (i.Rd != (i.Rs | i.Rt))
						{
							//e->movdqa1_regmem(RAX, &r->GPR[i.Rs | i.Rt].s);
							//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
							x->emit("vmovdqa xmm0, @ptr", &r->GPR[i.Rs | i.Rt].s);
							x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
						}
					}
					else if (i.Rs == i.Rt)
					{
						//e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
						//e->paddusb1regreg(RAX, RAX, RAX);
						//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
						x->emit("vmovdqa xmm0, @ptr", &r->GPR[i.Rs].s);
						x->emit("vpaddusb xmm0, xmm0, xmm0");
						x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
					}
					else
					{
						//e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
						//e->paddusb1regmem(RAX, RAX, &r->GPR[i.Rt].s);
						//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
						x->emit("vmovdqa xmm0, @ptr", &r->GPR[i.Rs].s);
						x->emit("vpaddusb xmm0, xmm0, @ptr", &r->GPR[i.Rt].s);
						x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
					}
				}

#else
				if (i.Rd)
				{
					if (!i.Rs)
					{
						if (!i.Rt)
						{
							e->pxor1regreg(RAX, RAX, RAX);
							ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
						}
						else if (i.Rd != i.Rt)
						{
							e->movdqa1_regmem(RAX, &r->GPR[i.Rt].s);
							ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
						}
					}
					else if (!i.Rt)
					{
						if (i.Rd != i.Rs)
						{
							e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
							ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
						}
					}
					else if (i.Rs == i.Rt)
					{
						e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
						e->paddusb1regreg(RAX, RAX, RAX);
						ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					}
					else
					{
						e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
						e->paddusb1regmem(RAX, RAX, &r->GPR[i.Rt].s);
						ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					}
				}
#endif

			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::PADDUH ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "PADDUH";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PADDUH;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
#ifdef USE_NEW_PADDUH_CODE
		case 1:

#ifdef USE_NEW_R5900_ASSEMBLER_PADDUH
				if (i.Rd)
				{
					if ((!i.Rs) && (i.Rt))
					{
						//e->pxor1regreg(RAX, RAX, RAX);
						//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
						x->emit("vpxor xmm0, xmm0, xmm0");
						x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
					}
					else if ((!i.Rs) || (!i.Rt))
					{
						if (i.Rd != (i.Rs | i.Rt))
						{
							//e->movdqa1_regmem(RAX, &r->GPR[i.Rs | i.Rt].s);
							//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
							x->emit("vmovdqa xmm0, @ptr", &r->GPR[i.Rs | i.Rt].s);
							x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
						}
					}
					else if (i.Rs == i.Rt)
					{
						//e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
						//e->paddusb1regreg(RAX, RAX, RAX);
						//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
						x->emit("vmovdqa xmm0, @ptr", &r->GPR[i.Rs].s);
						x->emit("vpaddusw xmm0, xmm0, xmm0");
						x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
					}
					else
					{
						//e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
						//e->paddusb1regmem(RAX, RAX, &r->GPR[i.Rt].s);
						//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
						x->emit("vmovdqa xmm0, @ptr", &r->GPR[i.Rs].s);
						x->emit("vpaddusw xmm0, xmm0, @ptr", &r->GPR[i.Rt].s);
						x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
					}
				}

#else

				if (i.Rd)
				{
					if (!i.Rs)
					{
						if (!i.Rt)
						{
							e->pxor1regreg(RAX, RAX, RAX);
							ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
						}
						else if (i.Rd != i.Rt)
						{
							e->movdqa1_regmem(RAX, &r->GPR[i.Rt].s);
							ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
						}
					}
					else if (!i.Rt)
					{
						if (i.Rd != i.Rs)
						{
							e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
							ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
						}
					}
					else if (i.Rs == i.Rt)
					{
						e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
						e->paddusw1regreg(RAX, RAX, RAX);
						ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					}
					else
					{
						e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
						e->paddusw1regmem(RAX, RAX, &r->GPR[i.Rt].s);
						ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					}
				}
#endif

			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::PADDUW ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "PADDUW";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PADDUW;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;

#ifdef USE_NEW_PADDUW_CODE
		case 1:
#ifdef ALLOW_AVX2_PADDUW
			if (iVectorType == VECTOR_TYPE_SSE)
#endif
			{
				if (i.Rd)
				{
					if (!i.Rs)
					{
						if (!i.Rt)
						{
							e->pxorregreg(RAX, RAX);
							ret = e->movdqa_memreg(&r->GPR[i.Rd].s, RAX);
						}
						else if (i.Rd != i.Rt)
						{
							e->movdqa_regmem(RAX, &r->GPR[i.Rt].s);
							ret = e->movdqa_memreg(&r->GPR[i.Rd].s, RAX);
						}
					}
					else if (!i.Rt)
					{
						if (i.Rd != i.Rs)
						{
							e->movdqa_regmem(RAX, &r->GPR[i.Rs].s);
							ret = e->movdqa_memreg(&r->GPR[i.Rd].s, RAX);
						}
					}
					else if (i.Rs == i.Rt)
					{
						e->movdqa_regmem(RAX, &r->GPR[i.Rs].s);

						e->pcmpeqbregreg(RDX, RDX);
						e->pslldregimm(RDX, 31);

						e->movdqa_regreg(RCX, RAX);
						e->padddregreg(RAX, RCX);

						e->pxorregreg(RAX, RDX);
						e->pxorregreg(RCX, RDX);
						e->pcmpgtdregreg(RCX, RAX);
						e->pxorregreg(RAX, RDX);

						e->porregreg(RAX, RCX);
						ret = e->movdqa_memreg(&r->GPR[i.Rd].s, RAX);
					}
					else
					{
						e->movdqa_regmem(RAX, &r->GPR[i.Rs].s);
						e->movdqa_regmem(RCX, &r->GPR[i.Rt].s);

						e->pcmpeqbregreg(RDX, RDX);
						e->pslldregimm(RDX, 31);

						//e->movdqa_regreg ( RCX, RAX );
						e->padddregreg(RAX, RCX);

						e->pxorregreg(RAX, RDX);
						e->pxorregreg(RCX, RDX);
						e->pcmpgtdregreg(RCX, RAX);
						e->pxorregreg(RAX, RDX);

						e->porregreg(RAX, RCX);
						ret = e->movdqa_memreg(&r->GPR[i.Rd].s, RAX);
					}
				}
			}
#ifdef ALLOW_AVX2_PADDUW
			else
			{
				if (i.Rd)
				{
					if (!i.Rs)
					{
						if (!i.Rt)
						{
							e->pxor1regreg(RAX, RAX, RAX);
							ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
						}
						else if (i.Rd != i.Rt)
						{
							e->movdqa1_regmem(RAX, &r->GPR[i.Rt].s);
							ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
						}
					}
					else if (!i.Rt)
					{
						if (i.Rd != i.Rs)
						{
							e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
							ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
						}
					}
					else
					{
						e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
						e->movdqa1_regmem(RCX, &r->GPR[i.Rt].s);

						e->pcmpeqb1regreg(RDX, RDX, RDX);
						e->pslld1regimm(RDX, RDX, 31);

						e->paddd1regreg(RAX, RAX, RCX);

						e->pxor1regreg(RAX, RAX, RDX);
						e->pxor1regreg(RCX, RCX, RDX);
						e->pcmpgtd1regreg(RCX, RCX, RAX);
						e->pxor1regreg(RAX, RAX, RDX);

						e->por1regreg(RAX, RAX, RCX);
						ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					}
				}
			}
#endif
			
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}


int32_t R5900::Recompiler::PSUBUB ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "PSUBUB";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PSUBUB;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
#ifdef USE_NEW_PSUBUB_CODE
		case 1:

#ifdef USE_NEW_R5900_ASSEMBLER_PSUBUB
				if (i.Rd)
				{
					if (i.Rs == i.Rt)
					{
						//e->pxor1regreg(RAX, RAX, RAX);
						//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
						x->emit("vpxor xmm0, xmm0, xmm0");
						x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
					}
					else if (!i.Rt)
					{
						if (i.Rd != i.Rs)
						{
							//e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
							//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
							x->emit("vmovdqa xmm0, @ptr", &r->GPR[i.Rs].s);
							x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
						}
					}
					else if (!i.Rs)
					{
						x->emit("vpxor xmm0, xmm0, xmm0");
						x->emit("vpsubusb xmm0, xmm0, @ptr", &r->GPR[i.Rt].s);
						x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
					}
					else
					{
						//e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
						//e->psubusb1regmem(RAX, RAX, &r->GPR[i.Rt].s);
						//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
						x->emit("vmovdqa xmm0, @ptr", &r->GPR[i.Rs].s);
						x->emit("vpsubusb xmm0, xmm0, @ptr", &r->GPR[i.Rt].s);
						x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
					}
				}

#else
				if (i.Rd)
				{
					if (!i.Rs)
					{
						e->pxor1regreg(RAX, RAX, RAX);
						ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					}
					else if (!i.Rt)
					{
						if (i.Rd != i.Rs)
						{
							e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
							ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
						}
					}
					else if (i.Rs == i.Rt)
					{
						e->pxor1regreg(RAX, RAX, RAX);
						ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					}
					else
					{
						e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
						e->psubusb1regmem(RAX, RAX, &r->GPR[i.Rt].s);
						ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					}
				}
#endif

			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::PSUBUH ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "PSUBUH";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PSUBUH;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
#ifdef USE_NEW_PSUBUH_CODE
		case 1:

#ifdef USE_NEW_R5900_ASSEMBLER_PSUBUH
				if (i.Rd)
				{
					if (i.Rs == i.Rt)
					{
						//e->pxor1regreg(RAX, RAX, RAX);
						//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
						x->emit("vpxor xmm0, xmm0, xmm0");
						x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
					}
					else if (!i.Rt)
					{
						if (i.Rd != i.Rs)
						{
							//e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
							//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
							x->emit("vmovdqa xmm0, @ptr", &r->GPR[i.Rs].s);
							x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
						}
					}
					else if (!i.Rs)
					{
						x->emit("vpxor xmm0, xmm0, xmm0");
						x->emit("vpsubusw xmm0, xmm0, @ptr", &r->GPR[i.Rt].s);
						x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
					}
					else
					{
						//e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
						//e->psubusb1regmem(RAX, RAX, &r->GPR[i.Rt].s);
						//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
						x->emit("vmovdqa xmm0, @ptr", &r->GPR[i.Rs].s);
						x->emit("vpsubusw xmm0, xmm0, @ptr", &r->GPR[i.Rt].s);
						x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
					}
				}

#else

				if (i.Rd)
				{
					if (!i.Rs)
					{
						e->pxor1regreg(RAX, RAX, RAX);
						ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					}
					else if (!i.Rt)
					{
						if (i.Rd != i.Rs)
						{
							e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
							ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
						}
					}
					else if (i.Rs == i.Rt)
					{
						e->pxor1regreg(RAX, RAX, RAX);
						ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					}
					else
					{
						e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
						e->psubusw1regmem(RAX, RAX, &r->GPR[i.Rt].s);
						ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					}
				}
#endif

			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::PSUBUW ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "PSUBUW";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PSUBUW;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;

#ifdef USE_NEW_PSUBUW_CODE
		case 1:
#ifdef ALLOW_AVX2_PSUBUW
			if (iVectorType == VECTOR_TYPE_SSE)
#endif
			{
				if (i.Rd)
				{
					if (!i.Rs)
					{
						e->pxorregreg(RAX, RAX);
						ret = e->movdqa_memreg(&r->GPR[i.Rd].s, RAX);
					}
					else if (!i.Rt)
					{
						if (i.Rd != i.Rs)
						{
							e->movdqa_regmem(RAX, &r->GPR[i.Rs].s);
							ret = e->movdqa_memreg(&r->GPR[i.Rd].s, RAX);
						}
					}
					else if (i.Rs == i.Rt)
					{
						e->pxorregreg(RAX, RAX);
						ret = e->movdqa_memreg(&r->GPR[i.Rd].s, RAX);
					}
					else
					{
						e->movdqa_regmem(RAX, &r->GPR[i.Rs].s);
						e->movdqa_regmem(RCX, &r->GPR[i.Rt].s);

						e->pcmpeqbregreg(RDX, RDX);
						e->pslldregimm(RDX, 31);
						e->movdqa_regreg(RBX, RDX);

						e->pxorregreg(RBX, RAX);
						e->pxorregreg(RDX, RCX);
						e->pcmpgtdregreg(RBX, RDX);

						e->psubdregreg(RAX, RCX);

						e->pandregreg(RAX, RBX);
						ret = e->movdqa_memreg(&r->GPR[i.Rd].s, RAX);
					}
				}
			}
#ifdef ALLOW_AVX2_PSUBUW
			else
			{
				if (i.Rd)
				{
					if (!i.Rs)
					{
						e->pxor1regreg(RAX, RAX, RAX);
						ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					}
					else if (!i.Rt)
					{
						if (i.Rd != i.Rs)
						{
							e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
							ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
						}
					}
					else if (i.Rs == i.Rt)
					{
						e->pxor1regreg(RAX, RAX, RAX);
						ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					}
					else
					{
						e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
						e->movdqa1_regmem(RCX, &r->GPR[i.Rt].s);

						e->pcmpeqb1regreg(RDX, RDX, RDX);
						e->pslld1regimm(RDX, RDX, 31);

						e->pxor1regreg(RBX, RAX, RDX);
						e->pxor1regreg(RDX, RCX, RDX);
						e->pcmpgtd1regreg(RBX, RBX, RDX);

						e->psubd1regreg(RAX, RAX, RCX);

						e->pand1regreg(RAX, RAX, RBX);
						ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					}
				}
			}
#endif
			
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}



int32_t R5900::Recompiler::PMAXH ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "PMAXH";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PMAXH;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
#ifdef USE_NEW_PMAXH_CODE
		case 1:

#ifdef USE_NEW_R5900_ASSEMBLER_PMAXH
				if (i.Rd)
				{
					if ((!i.Rs) && (!i.Rt))
					{
						//e->pxor1regreg(RAX, RAX, RAX);
						//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
						x->emit("vpxor xmm0, xmm0, xmm0");
						x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
					}
					else if (i.Rs == i.Rt)
					{
						if (i.Rd != i.Rs)
						{
							//e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
							//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
							x->emit("vmovdqa xmm0, @ptr", &r->GPR[i.Rs].s);
							x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
						}
					}
					else if ((!i.Rs) || (!i.Rt))
					{
						//e->pxor1regreg(RAX, RAX, RAX);
						//e->pmaxsw1regmem(RAX, RAX, &r->GPR[i.Rs | i.Rt].s);
						//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
						x->emit("vpxor xmm0, xmm0, xmm0");
						x->emit("vpmaxsw xmm0, xmm0, @ptr", &r->GPR[i.Rs | i.Rt].s);
						x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
					}
					else
					{
						//e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
						//e->pmaxsw1regmem(RAX, RAX, &r->GPR[i.Rt].s);
						//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
						x->emit("vmovdqa xmm0, @ptr", &r->GPR[i.Rs].s);
						x->emit("vpmaxsw xmm0, xmm0, @ptr", &r->GPR[i.Rt].s);
						x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
					}
				}
#else
				if (i.Rd)
				{
					if ((!i.Rs) && (!i.Rt))
					{
						e->pxor1regreg(RAX, RAX, RAX);
						ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					}
					else if (i.Rs == i.Rt)
					{
						if (i.Rd != i.Rs)
						{
							e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
							ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
						}
					}
					else if ((!i.Rs) || (!i.Rt))
					{
						e->pxor1regreg(RAX, RAX, RAX);
						e->pmaxsw1regmem(RAX, RAX, &r->GPR[i.Rs | i.Rt].s);
						ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					}
					else
					{
						e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
						e->pmaxsw1regmem(RAX, RAX, &r->GPR[i.Rt].s);
						ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					}
				}
#endif

			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::PMAXW ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "PMAXW";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PMAXW;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
#ifdef USE_NEW_PMAXW_CODE
		case 1:

#ifdef USE_NEW_R5900_ASSEMBLER_PMAXW
				if (i.Rd)
				{
					if ((!i.Rs) && (!i.Rt))
					{
						//e->pxor1regreg(RAX, RAX, RAX);
						//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
						x->emit("vpxor xmm0, xmm0, xmm0");
						x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
					}
					else if (i.Rs == i.Rt)
					{
						if (i.Rd != i.Rs)
						{
							//e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
							//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
							x->emit("vmovdqa xmm0, @ptr", &r->GPR[i.Rs].s);
							x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
						}
					}
					else if ((!i.Rs) || (!i.Rt))
					{
						//e->pxor1regreg(RAX, RAX, RAX);
						//e->pmaxsw1regmem(RAX, RAX, &r->GPR[i.Rs | i.Rt].s);
						//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
						x->emit("vpxor xmm0, xmm0, xmm0");
						x->emit("vpmaxsd xmm0, xmm0, @ptr", &r->GPR[i.Rs | i.Rt].s);
						x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
					}
					else
					{
						//e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
						//e->pmaxsw1regmem(RAX, RAX, &r->GPR[i.Rt].s);
						//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
						x->emit("vmovdqa xmm0, @ptr", &r->GPR[i.Rs].s);
						x->emit("vpmaxsd xmm0, xmm0, @ptr", &r->GPR[i.Rt].s);
						x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
					}
				}
#else

				if (i.Rd)
				{
					if ((!i.Rs) && (!i.Rt))
					{
						e->pxor1regreg(RAX, RAX, RAX);
						ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					}
					else if (i.Rs == i.Rt)
					{
						if (i.Rd != i.Rs)
						{
							e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
							ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
						}
					}
					else if ((!i.Rs) || (!i.Rt))
					{
						e->pxor1regreg(RAX, RAX, RAX);
						e->pmaxsd1regmem(RAX, RAX, &r->GPR[i.Rs | i.Rt].s);
						ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					}
					else
					{
						e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
						e->pmaxsd1regmem(RAX, RAX, &r->GPR[i.Rt].s);
						ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					}
				}
#endif

			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::PMINH ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "PMINH";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PMINH;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
#ifdef USE_NEW_PMINH_CODE
		case 1:

#ifdef USE_NEW_R5900_ASSEMBLER_PMINH
				if (i.Rd)
				{
					if ((!i.Rs) && (!i.Rt))
					{
						//e->pxor1regreg(RAX, RAX, RAX);
						//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
						x->emit("vpxor xmm0, xmm0, xmm0");
						x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
					}
					else if (i.Rs == i.Rt)
					{
						if (i.Rd != i.Rs)
						{
							//e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
							//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
							x->emit("vmovdqa xmm0, @ptr", &r->GPR[i.Rs].s);
							x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
						}
					}
					else if ((!i.Rs) || (!i.Rt))
					{
						//e->pxor1regreg(RAX, RAX, RAX);
						//e->pmaxsw1regmem(RAX, RAX, &r->GPR[i.Rs | i.Rt].s);
						//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
						x->emit("vpxor xmm0, xmm0, xmm0");
						x->emit("vpminsw xmm0, xmm0, @ptr", &r->GPR[i.Rs | i.Rt].s);
						x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
					}
					else
					{
						//e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
						//e->pmaxsw1regmem(RAX, RAX, &r->GPR[i.Rt].s);
						//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
						x->emit("vmovdqa xmm0, @ptr", &r->GPR[i.Rs].s);
						x->emit("vpminsw xmm0, xmm0, @ptr", &r->GPR[i.Rt].s);
						x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
					}
				}
#else

				if (i.Rd)
				{
					if ((!i.Rs) && (!i.Rt))
					{
						e->pxor1regreg(RAX, RAX, RAX);
						ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					}
					else if (i.Rs == i.Rt)
					{
						if (i.Rd != i.Rs)
						{
							e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
							ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
						}
					}
					else if ((!i.Rs) || (!i.Rt))
					{
						e->pxor1regreg(RAX, RAX, RAX);
						e->pminsw1regmem(RAX, RAX, &r->GPR[i.Rs | i.Rt].s);
						ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					}
					else
					{
						e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
						e->pminsw1regmem(RAX, RAX, &r->GPR[i.Rt].s);
						ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					}
				}
#endif

			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::PMINW ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "PMINW";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PMINW;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
#ifdef USE_NEW_PMINW_CODE
		case 1:

#ifdef USE_NEW_R5900_ASSEMBLER_PMINW
				if (i.Rd)
				{
					if ((!i.Rs) && (!i.Rt))
					{
						//e->pxor1regreg(RAX, RAX, RAX);
						//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
						x->emit("vpxor xmm0, xmm0, xmm0");
						x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
					}
					else if (i.Rs == i.Rt)
					{
						if (i.Rd != i.Rs)
						{
							//e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
							//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
							x->emit("vmovdqa xmm0, @ptr", &r->GPR[i.Rs].s);
							x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
						}
					}
					else if ((!i.Rs) || (!i.Rt))
					{
						//e->pxor1regreg(RAX, RAX, RAX);
						//e->pmaxsw1regmem(RAX, RAX, &r->GPR[i.Rs | i.Rt].s);
						//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
						x->emit("vpxor xmm0, xmm0, xmm0");
						x->emit("vpminsd xmm0, xmm0, @ptr", &r->GPR[i.Rs | i.Rt].s);
						x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
					}
					else
					{
						//e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
						//e->pmaxsw1regmem(RAX, RAX, &r->GPR[i.Rt].s);
						//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
						x->emit("vmovdqa xmm0, @ptr", &r->GPR[i.Rs].s);
						x->emit("vpminsd xmm0, xmm0, @ptr", &r->GPR[i.Rt].s);
						x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
					}
				}
#else

				if (i.Rd)
				{
					if ((!i.Rs) && (!i.Rt))
					{
						e->pxor1regreg(RAX, RAX, RAX);
						ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					}
					else if (i.Rs == i.Rt)
					{
						if (i.Rd != i.Rs)
						{
							e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
							ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
						}
					}
					else if ((!i.Rs) || (!i.Rt))
					{
						e->pxor1regreg(RAX, RAX, RAX);
						e->pminsd1regmem(RAX, RAX, &r->GPR[i.Rs | i.Rt].s);
						ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					}
					else
					{
						e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
						e->pminsd1regmem(RAX, RAX, &r->GPR[i.Rt].s);
						ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					}
				}
#endif

			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}




int32_t R5900::Recompiler::PPACB ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "PPACB";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PPACB;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
		
#ifdef USE_NEW_PPACB_CODE
		case 1:

#ifdef USE_NEW_R5900_ASSEMBLER_PPACB
				if (i.Rd)
				{
					if ((!i.Rs) && (!i.Rt))
					{
						//e->pxor1regreg(RAX, RAX, RAX);
						//ret = e->movdqa_memreg(&r->GPR[i.Rd].s, RAX);
						x->emit("vpxor xmm0, xmm0, xmm0");
						x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
					}
					else if (i.Rs == i.Rt)
					{
						//e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
						//e->psllw1regimm(RAX, RAX, 8);
						//e->psrlw1regimm(RAX, RAX, 8);
						//e->packuswb1regreg(RAX, RAX, RAX);
						x->emit("vmovdqa xmm0, @ptr", &r->GPR[i.Rs].s);
						x->emit("vpsllw xmm0, xmm0, 8");
						x->emit("vpsrlw xmm0, xmm0, 8");
						x->emit("vpackuswb xmm0, xmm0, xmm0");
						x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
					}
					else
					{
						if (i.Rt)
						{
							//e->movdqa1_regmem(RAX, &r->GPR[i.Rt].s);
							//e->psllw1regimm(RAX, RAX, 8);
							//e->psrlw1regimm(RAX, RAX, 8);
							x->emit("vmovdqa xmm0, @ptr", &r->GPR[i.Rt].s);
							x->emit("vpsllw xmm0, xmm0, 8");
							x->emit("vpsrlw xmm0, xmm0, 8");
						}
						else
						{
							//e->pxor1regreg(RAX, RAX, RAX);
							x->emit("vpxor xmm0, xmm0, xmm0");
						}

						if (i.Rs)
						{
							//e->movdqa1_regmem(RCX, &r->GPR[i.Rs].s);
							//e->psllw1regimm(RCX, RCX, 8);
							//e->psrlw1regimm(RCX, RCX, 8);
							x->emit("vmovdqa xmm1, @ptr", &r->GPR[i.Rs].s);
							x->emit("vpsllw xmm1, xmm1, 8");
							x->emit("vpsrlw xmm1, xmm1, 8");
						}
						else
						{
							//e->pxor1regreg(RCX, RCX, RCX);
							x->emit("vpxor xmm1, xmm1, xmm1");
						}

						//e->packuswb1regreg(RAX, RAX, RCX);
						x->emit("vpackuswb xmm0, xmm0, xmm1");

						//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
						x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
					}
				}
#else
				if (i.Rd)
				{
					if (i.Rs == i.Rt)
					{
						if (i.Rs)
						{
							e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);

							e->psllw1regimm(RAX, RAX, 8);
							e->psrlw1regimm(RAX, RAX, 8);

							e->packuswb1regreg(RAX, RAX, RAX);
						}
						else
						{
							e->pxor1regreg(RAX, RAX, RAX);
						}

						ret = e->movdqa_memreg(&r->GPR[i.Rd].s, RAX);
					}
					else
					{
						if (i.Rt)
						{
							e->movdqa1_regmem(RAX, &r->GPR[i.Rt].s);
							e->psllw1regimm(RAX, RAX, 8);
							e->psrlw1regimm(RAX, RAX, 8);
						}
						else
						{
							e->pxor1regreg(RAX, RAX, RAX);
						}

						if (i.Rs)
						{
							e->movdqa1_regmem(RCX, &r->GPR[i.Rs].s);
							e->psllw1regimm(RCX, RCX, 8);
							e->psrlw1regimm(RCX, RCX, 8);
						}
						else
						{
							e->pxor1regreg(RCX, RCX, RCX);
						}

						e->packuswb1regreg(RAX, RAX, RCX);

						ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					}
				}
#endif

			break;
#endif

			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::PPACH ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "PPACH";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PPACH;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch (OpLevel)
	{
	case 0:
		if (i.Rd)
		{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX(RSP, c_lSEH_StackSize);
#endif

			e->LoadImm32(RCX, i.Value);
			ret = e->Call(c_vFunction);

#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX(RSP, c_lSEH_StackSize);
#endif
		}
		break;

#ifdef USE_NEW_PPACH_CODE
	case 1:

#ifdef USE_NEW_R5900_ASSEMBLER_PPACH
			if (i.Rd)
			{
				if (i.Rs == i.Rt)
				{
					//e->pxor1regreg(RAX, RAX, RAX);
					x->emit("vpxor xmm0, xmm0, xmm0");
					if (i.Rs)
					{
						//e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
						//e->pxor1regreg(RDX, RDX, RDX);
						//e->pblendw1regregimm(RAX, RAX, RDX, 0xaa);
						//e->packusdw1regreg(RAX, RAX, RAX);
						x->emit("vpblendw xmm0, xmm0, @ptr, 0x55", &r->GPR[i.Rs].s);
						x->emit("vpackusdw xmm0, xmm0, xmm0");
					}

					//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
				}
				else
				{
					//e->pxor1regreg(RDX, RDX, RDX);
					x->emit("vpxor xmm1, xmm1, xmm1");
					if (i.Rt)
					{
						//e->pblendw1regmemimm(RAX, RDX, &r->GPR[i.Rt].s, 0x55);
						x->emit("vpblendw xmm0, xmm1, @ptr, 0x55", &r->GPR[i.Rt].s);
					}
					else
					{
						//e->movdqa1_regreg(RAX, RDX);
						x->emit("vmovdqa xmm0, xmm1");
					}

					if (i.Rs)
					{
						//e->pblendw1regmemimm(RCX, RDX, &r->GPR[i.Rs].s, 0x55);
						x->emit("vpblendw xmm1, xmm1, @ptr, 0x55", &r->GPR[i.Rs].s);

					}

					//e->packusdw1regreg(RAX, RAX, RCX);
					x->emit("vpackusdw xmm0, xmm0, xmm1");

					//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
				}

			}

#else
			if (i.Rd)
			{

				if (i.Rs == i.Rt)
				{
					if (i.Rs)
					{
						e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);

						e->pxor1regreg(RDX, RDX, RDX);
						e->pblendw1regregimm(RAX, RAX, RDX, 0xaa);

						e->packusdw1regreg(RAX, RAX, RAX);
					}
					else
					{
						e->pxor1regreg(RAX, RAX, RAX);
					}

					ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
				}
				else
				{
					e->pxor1regreg(RDX, RDX, RDX);
					if (i.Rt)
					{
						//e->movdqa1_regmem(RAX, &r->GPR[i.Rt].s);
						//e->pblendw1regregimm(RAX, RDX, 0xaa);
						e->pblendw1regmemimm(RAX, RDX, &r->GPR[i.Rt].s, 0x55);
					}
					else
					{
						//e->pxor1regreg(RAX, RAX, RAX);
						e->movdqa1_regreg(RAX, RDX);
					}

					if (i.Rs)
					{
						//e->movdqa1_regmem(RCX, &r->GPR[i.Rs].s);
						//e->pblendw1regregimm(RCX, RDX, 0xaa);
						e->pblendw1regmemimm(RCX, RDX, &r->GPR[i.Rs].s, 0x55);
					}
					else
					{
						//e->pxor1regreg(RCX, RCX);
						e->movdqa1_regreg(RCX, RDX);
					}

					e->packusdw1regreg(RAX, RAX, RCX);

					ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
				}

			}
#endif

		break;
#endif

	default:
		return -1;
		break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::PPACW ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "PPACW";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PPACW;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
#ifdef USE_NEW_PPACW_CODE
		case 1:

#ifdef USE_NEW_R5900_ASSEMBLER_PPACW
				if (i.Rd)
				{
					if (i.Rs == i.Rt)
					{
						//e->pshufd1regmemimm(RAX, &r->GPR[i.Rs].s, (2 << 6) + (0 << 4) + (2 << 2) + 0);
						//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
						x->emit("vpshufd xmm0, @ptr, @imm", &r->GPR[i.Rs].s, (2 << 6) + (0 << 4) + (2 << 2) + 0);
						x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
					}
					else
					{
						if (i.Rt)
						{
							//e->pshufd1regmemimm(RAX, &r->GPR[i.Rt].s, (2 << 2) + 0);
							x->emit("vpshufd xmm0, @ptr, @imm", &r->GPR[i.Rt].s, (2 << 2) + 0);
						}
						else
						{
							//e->pxor1regreg(RAX, RAX, RAX);
							x->emit("vpxor xmm0, xmm0, xmm0");
						}

						if (i.Rs)
						{
							//e->pshufd1regmemimm(RCX, &r->GPR[i.Rs].s, (2 << 6) + (0 << 4));
							x->emit("vpshufd xmm1, @ptr, @imm", &r->GPR[i.Rs].s, (2 << 6) + (0 << 4));
						}
						else
						{
							//e->pxor1regreg(RCX, RCX, RCX);
							x->emit("vpxor xmm1, xmm1, xmm1");
						}

						//e->pblendw1regregimm(RAX, RAX, RCX, 0xf0);
						x->emit("vpblendw xmm0, xmm0, xmm1, 0xf0");

						//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
						x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
					}
				}
#else
				if (i.Rd)
				{
					if (i.Rs == i.Rt)
					{
						e->pshufd1regmemimm(RAX, &r->GPR[i.Rs].s, (2 << 6) + (0 << 4) + (2 << 2) + 0);

						ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					}
					else
					{
						if (i.Rt)
						{
							e->pshufd1regmemimm(RAX, &r->GPR[i.Rt].s, (2 << 2) + 0);
						}
						else
						{
							e->pxor1regreg(RAX, RAX, RAX);
						}

						if (i.Rs)
						{
							e->pshufd1regmemimm(RCX, &r->GPR[i.Rs].s, (2 << 6) + (0 << 4));
						}
						else
						{
							e->pxor1regreg(RCX, RCX, RCX);
						}

						e->pblendw1regregimm(RAX, RAX, RCX, 0xf0);

						ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					}
				}
#endif

			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}


int32_t R5900::Recompiler::PEXT5 ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "PEXT5";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PEXT5;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
#ifdef USE_NEW_PEXT5_CODE
		case 1:

#ifdef USE_NEW_R5900_ASSEMBLER_PEXT5
				if (i.Rd)
				{
					//e->movdqa1_regmem(RAX, &r->GPR[i.Rt].s);
					x->emit("vmovdqa xmm0, @ptr", &r->GPR[i.Rt].s);

					// get a
					//e->psrld1regimm(RBX, RAX, 15);
					//e->pslld1regimm(RBX, RBX, 31);
					x->emit("vpsrld xmm1, xmm0, 15");
					x->emit("vpslld xmm1, xmm1, 31");

					// get c3
					//e->pslld1regimm(RCX, RAX, 22);
					//e->psrld1regimm(RCX, RCX, 8);
					x->emit("vpslld xmm2, xmm0, 22");
					x->emit("vpsrld xmm2, xmm2, 8");

					// get c2
					//e->psrld1regimm(RDX, RAX, 5);
					//e->pslld1regimm(RDX, RDX, 11);
					x->emit("vpsrld xmm3, xmm0, 5");
					x->emit("vpslld xmm3, xmm3, 11");

					// get c1
					//e->pslld1regimm(RAX, RAX, 27);
					//e->psrld1regimm(RAX, RAX, 24);
					x->emit("vpslld xmm0, xmm0, 27");
					x->emit("vpsrld xmm0, xmm0, 24");

					// combine
					//e->por1regreg(RBX, RBX, RCX);
					//e->por1regreg(RAX, RAX, RDX);
					//e->pblendw1regregimm(RAX, RAX, RBX, 0xf0);
					x->emit("vpor xmm1, xmm1, xmm2");
					x->emit("vpor xmm0, xmm0, xmm3");
					x->emit("vpblendw xmm0, xmm0, xmm1, 0xf0");

					//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
				}

#else
				if (i.Rd)
				{
					e->movdqa1_regmem(RAX, &r->GPR[i.Rt].s);

					// get a
					e->psrld1regimm(RBX, RAX, 15);
					e->pslld1regimm(RBX, RBX, 31);

					// get c3
					e->pslld1regimm(RCX, RAX, 22);
					e->psrld1regimm(RCX, RCX, 8);

					// get c2
					e->psrld1regimm(RDX, RAX, 5);
					e->pslld1regimm(RDX, RDX, 11);

					// get c1
					e->pslld1regimm(RAX, RAX, 27);
					e->psrld1regimm(RAX, RAX, 24);

					// combine
					e->por1regreg(RBX, RBX, RCX);
					e->por1regreg(RAX, RAX, RDX);
					e->pblendw1regregimm(RAX, RAX, RBX, 0xf0);

					ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
				}
#endif

			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::PPAC5 ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "PPAC5";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PPAC5;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch (OpLevel)
	{
	case 0:
		if (i.Rd)
		{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX(RSP, c_lSEH_StackSize);
#endif

			e->LoadImm32(RCX, i.Value);
			ret = e->Call(c_vFunction);

#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX(RSP, c_lSEH_StackSize);
#endif
		}
		break;

#ifdef USE_NEW_PPAC5_CODE
	case 1:

#ifdef USE_NEW_R5900_ASSEMBLER_PPAC5
			if (i.Rd)
			{
				//e->movdqa1_regmem(RAX, &r->GPR[i.Rt].s);
				x->emit("vmovdqa xmm0, @ptr", &r->GPR[i.Rt].s);

				// get c1
				//e->pslld1regimm(RBX, RAX, 24);
				//e->psrld1regimm(RBX, RBX, 27);
				x->emit("vpslld xmm1, xmm0, 24");
				x->emit("vpsrld xmm1, xmm1, 27");

				// get c2
				//e->pslld1regimm(RCX, RAX, 16);
				//e->psrld1regimm(RCX, RCX, 27);
				//e->pslld1regimm(RCX, RCX, 5);
				x->emit("vpslld xmm2, xmm0, 16");
				x->emit("vpsrld xmm2, xmm2, 27");
				x->emit("vpslld xmm2, xmm2, 5");

				// get c3
				//e->pslld1regimm(RDX, RAX, 8);
				//e->psrld1regimm(RDX, RDX, 27);
				//e->pslld1regimm(RDX, RDX, 10);
				x->emit("vpslld xmm3, xmm0, 8");
				x->emit("vpsrld xmm3, xmm3, 27");
				x->emit("vpslld xmm3, xmm3, 10");

				// get a
				//e->psrld1regimm(RAX, RAX, 31);
				//e->pslld1regimm(RAX, RAX, 15);
				x->emit("vpsrld xmm0, xmm0, 31");
				x->emit("vpslld xmm0, xmm0, 15");

				// combine
				//e->por1regreg(RAX, RAX, RBX);
				//e->por1regreg(RAX, RAX, RCX);
				//e->por1regreg(RAX, RAX, RDX);
				x->emit("vpor xmm0, xmm0, xmm1");
				x->emit("vpor xmm0, xmm0, xmm2");
				x->emit("vpor xmm0, xmm0, xmm3");

				//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
				x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
			}
#else
			if (i.Rd)
			{
				e->movdqa1_regmem(RAX, &r->GPR[i.Rt].s);

				// get c1
				//e->movdqa1_regreg(RBX, RAX);
				e->pslld1regimm(RBX, RAX, 24);
				e->psrld1regimm(RBX, RBX, 27);

				// get c2
				//e->movdqa1_regreg(RCX, RAX);
				e->pslld1regimm(RCX, RAX, 16);
				e->psrld1regimm(RCX, RCX, 27);
				e->pslld1regimm(RCX, RCX, 5);

				// get c3
				//e->movdqa1_regreg(RDX, RAX);
				e->pslld1regimm(RDX, RAX, 8);
				e->psrld1regimm(RDX, RDX, 27);
				e->pslld1regimm(RDX, RDX, 10);

				// get a
				e->psrld1regimm(RAX, RAX, 31);
				e->pslld1regimm(RAX, RAX, 15);

				// combine
				e->por1regreg(RAX, RAX, RBX);
				e->por1regreg(RAX, RAX, RCX);
				e->por1regreg(RAX, RAX, RDX);

				ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
			}
#endif

		break;
#endif

	default:
		return -1;
		break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}


int32_t R5900::Recompiler::PCGTB ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "PCGTB";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PCGTB;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
#ifdef USE_NEW_PCGTB_CODE
		case 1:

#ifdef USE_NEW_R5900_ASSEMBLER_PCGTB
				if (i.Rd)
				{
					if (i.Rs == i.Rt)
					{
						//e->pxor1regreg(RAX, RAX, RAX);
						//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
						x->emit("vpxor xmm0, xmm0, xmm0");
						x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
					}
					else if (!i.Rs)
					{
						x->emit("vpxor xmm0, xmm0, xmm0");
						x->emit("vpcmpgtb xmm0, xmm0, @ptr", &r->GPR[i.Rt].s);
						x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
					}
					else
					{
						//e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
						//e->pcmpgtb1regmem(RAX, RAX, &r->GPR[i.Rt].s);
						//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
						x->emit("vmovdqa xmm0, @ptr", &r->GPR[i.Rs].s);
						x->emit("vpcmpgtb xmm0, xmm0, @ptr", &r->GPR[i.Rt].s);
						x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
					}
				}
#else
				if (i.Rd)
				{
					if (i.Rs == i.Rt)
					{
						e->pxor1regreg(RAX, RAX, RAX);
						ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					}
					else
					{
						e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
						e->pcmpgtb1regmem(RAX, RAX, &r->GPR[i.Rt].s);
						ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					}
				}
#endif

			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::PCGTH ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "PCGTH";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PCGTH;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
#ifdef USE_NEW_PCGTH_CODE
		case 1:

#ifdef USE_NEW_R5900_ASSEMBLER_PCGTH
				if (i.Rd)
				{
					if (i.Rs == i.Rt)
					{
						//e->pxor1regreg(RAX, RAX, RAX);
						//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
						x->emit("vpxor xmm0, xmm0, xmm0");
						x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
					}
					else if (!i.Rs)
					{
						x->emit("vpxor xmm0, xmm0, xmm0");
						x->emit("vpcmpgtw xmm0, xmm0, @ptr", &r->GPR[i.Rt].s);
						x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
					}
					else
					{
						//e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
						//e->pcmpgtb1regmem(RAX, RAX, &r->GPR[i.Rt].s);
						//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
						x->emit("vmovdqa xmm0, @ptr", &r->GPR[i.Rs].s);
						x->emit("vpcmpgtw xmm0, xmm0, @ptr", &r->GPR[i.Rt].s);
						x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
					}
				}
#else
				if (i.Rd)
				{
					if (i.Rs == i.Rt)
					{
						e->pxor1regreg(RAX, RAX, RAX);
						ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					}
					else
					{
						e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
						e->pcmpgtw1regmem(RAX, RAX, &r->GPR[i.Rt].s);
						ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					}
				}
#endif

			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::PCGTW ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "PCGTW";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PCGTW;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
#ifdef USE_NEW_PCGTW_CODE
		case 1:

#ifdef USE_NEW_R5900_ASSEMBLER_PCGTW
				if (i.Rd)
				{
					if (i.Rs == i.Rt)
					{
						//e->pxor1regreg(RAX, RAX, RAX);
						//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
						x->emit("vpxor xmm0, xmm0, xmm0");
						x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
					}
					else if (!i.Rs)
					{
						x->emit("vpxor xmm0, xmm0, xmm0");
						x->emit("vpcmpgtd xmm0, xmm0, @ptr", &r->GPR[i.Rt].s);
						x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
					}
					else
					{
						//e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
						//e->pcmpgtb1regmem(RAX, RAX, &r->GPR[i.Rt].s);
						//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
						x->emit("vmovdqa xmm0, @ptr", &r->GPR[i.Rs].s);
						x->emit("vpcmpgtd xmm0, xmm0, @ptr", &r->GPR[i.Rt].s);
						x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
					}
				}
#else
				if (i.Rd)
				{
					if (i.Rs == i.Rt)
					{
						e->pxor1regreg(RAX, RAX, RAX);
						ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					}
					else
					{
						e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
						e->pcmpgtd1regmem(RAX, RAX, &r->GPR[i.Rt].s);
						ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					}
				}
#endif

			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}


int32_t R5900::Recompiler::PCEQB ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "PCEQB";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PCEQB;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
#ifdef USE_NEW_PCEQB_CODE
		case 1:

#ifdef USE_NEW_R5900_ASSEMBLER_PCEQB
				if (i.Rd)
				{
					if (i.Rs == i.Rt)
					{
						//e->pcmpeqb1regreg(RAX, RAX, RAX);
						//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
						x->emit("vpcmpeqb xmm0, xmm0, xmm0");
						x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
					}
					else if ((!i.Rs) || (!i.Rt))
					{
						x->emit("vpxor xmm0, xmm0, xmm0");
						x->emit("vpcmpeqb xmm0, xmm0, @ptr", &r->GPR[i.Rs | i.Rt].s);
						x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
					}
					else
					{
						//e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
						//e->pcmpeqb1regmem(RAX, RAX, &r->GPR[i.Rt].s);
						//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
						x->emit("vmovdqa xmm0, @ptr", &r->GPR[i.Rs].s);
						x->emit("vpcmpeqb xmm0, xmm0, @ptr", &r->GPR[i.Rt].s);
						x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
					}
				}

#else
				if (i.Rd)
				{
					if (i.Rs == i.Rt)
					{
						e->pcmpeqb1regreg(RAX, RAX, RAX);
						ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					}
					else
					{
						e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
						e->pcmpeqb1regmem(RAX, RAX, &r->GPR[i.Rt].s);
						ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					}
				}
#endif

			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::PCEQH ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "PCEQH";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PCEQH;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
#ifdef USE_NEW_PCEQH_CODE
		case 1:

#ifdef USE_NEW_R5900_ASSEMBLER_PCEQH
				if (i.Rd)
				{
					if (i.Rs == i.Rt)
					{
						//e->pcmpeqb1regreg(RAX, RAX, RAX);
						//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
						x->emit("vpcmpeqw xmm0, xmm0, xmm0");
						x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
					}
					else if ((!i.Rs) || (!i.Rt))
					{
						x->emit("vpxor xmm0, xmm0, xmm0");
						x->emit("vpcmpeqw xmm0, xmm0, @ptr", &r->GPR[i.Rs | i.Rt].s);
						x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
					}
					else
					{
						//e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
						//e->pcmpeqb1regmem(RAX, RAX, &r->GPR[i.Rt].s);
						//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
						x->emit("vmovdqa xmm0, @ptr", &r->GPR[i.Rs].s);
						x->emit("vpcmpeqw xmm0, xmm0, @ptr", &r->GPR[i.Rt].s);
						x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
					}
				}

#else
				if (i.Rd)
				{
					if (i.Rs == i.Rt)
					{
						e->pcmpeqd1regreg(RAX, RAX, RAX);
						ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					}
					else
					{
						e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
						e->pcmpeqw1regmem(RAX, RAX, &r->GPR[i.Rt].s);
						ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					}
				}
#endif

			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}


int32_t R5900::Recompiler::PCEQW ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "PCEQW";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PCEQW;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
#ifdef USE_NEW_PCEQW_CODE
		case 1:

#ifdef USE_NEW_R5900_ASSEMBLER_PCEQW
				if (i.Rd)
				{
					if (i.Rs == i.Rt)
					{
						//e->pcmpeqb1regreg(RAX, RAX, RAX);
						//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
						x->emit("vpcmpeqd xmm0, xmm0, xmm0");
						x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
					}
					else if ((!i.Rs) || (!i.Rt))
					{
						x->emit("vpxor xmm0, xmm0, xmm0");
						x->emit("vpcmpeqd xmm0, xmm0, @ptr", &r->GPR[i.Rs | i.Rt].s);
						x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
					}
					else
					{
						//e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
						//e->pcmpeqb1regmem(RAX, RAX, &r->GPR[i.Rt].s);
						//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
						x->emit("vmovdqa xmm0, @ptr", &r->GPR[i.Rs].s);
						x->emit("vpcmpeqd xmm0, xmm0, @ptr", &r->GPR[i.Rt].s);
						x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
					}
				}

#else
				if (i.Rd)
				{
					if (i.Rs == i.Rt)
					{
						e->pcmpeqd1regreg(RAX, RAX, RAX);
						ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					}
					else
					{
						e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
						e->pcmpeqd1regmem(RAX, RAX, &r->GPR[i.Rt].s);
						ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					}
				}
#endif

			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}




int32_t R5900::Recompiler::PEXTLB ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "PEXTLB";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PEXTLB;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
#ifdef USE_NEW_PEXTLB_CODE
		case 1:

#ifdef USE_NEW_R5900_ASSEMBLER_PEXTLB
				if (i.Rd)
				{
					//e->movdqa1_regmem(RAX, &r->GPR[i.Rt].s);
					//e->punpcklbw1regmem(RAX, RAX, &r->GPR[i.Rs].s);
					//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					x->emit("vmovdqa xmm0, @ptr", &r->GPR[i.Rt].s);
					x->emit("vpunpcklbw xmm0, xmm0, @ptr", &r->GPR[i.Rs].s);
					x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
				}
#else
				if (i.Rd)
				{
					e->movdqa1_regmem(RAX, &r->GPR[i.Rt].s);
					e->punpcklbw1regmem(RAX, RAX, &r->GPR[i.Rs].s);
					ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
				}
#endif

			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::PEXTLH ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "PEXTLH";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PEXTLH;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
#ifdef USE_NEW_PEXTLH_CODE
		case 1:

#ifdef USE_NEW_R5900_ASSEMBLER_PEXTLH
				if (i.Rd)
				{
					//e->movdqa1_regmem(RAX, &r->GPR[i.Rt].s);
					//e->punpcklwd1regmem(RAX, RAX, &r->GPR[i.Rs].s);
					//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					x->emit("vmovdqa xmm0, @ptr", &r->GPR[i.Rt].s);
					x->emit("vpunpcklwd xmm0, xmm0, @ptr", &r->GPR[i.Rs].s);
					x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
				}
#else
				if (i.Rd)
				{
					e->movdqa1_regmem(RAX, &r->GPR[i.Rt].s);
					e->punpcklwd1regmem(RAX, RAX, &r->GPR[i.Rs].s);
					ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
				}
#endif

			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::PEXTLW ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "PEXTLW";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PEXTLW;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
#ifdef USE_NEW_PEXTLW_CODE
		case 1:

#ifdef USE_NEW_R5900_ASSEMBLER_PEXTLW
				if (i.Rd)
				{
					//e->movdqa1_regmem(RAX, &r->GPR[i.Rt].s);
					//e->punpckldq1regmem(RAX, RAX, &r->GPR[i.Rs].s);
					//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					x->emit("vmovdqa xmm0, @ptr", &r->GPR[i.Rt].s);
					x->emit("vpunpckldq xmm0, xmm0, @ptr", &r->GPR[i.Rs].s);
					x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
				}

#else
				if (i.Rd)
				{
					e->movdqa1_regmem(RAX, &r->GPR[i.Rt].s);
					e->punpckldq1regmem(RAX, RAX, &r->GPR[i.Rs].s);
					ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
				}
#endif

			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::PEXTUB ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "PEXTUB";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PEXTUB;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
#ifdef USE_NEW_PEXTUB_CODE
		case 1:

#ifdef USE_NEW_R5900_ASSEMBLER_PEXTUB
				if (i.Rd)
				{
					//e->movdqa1_regmem(RAX, &r->GPR[i.Rt].s);
					//e->punpckhbw1regmem(RAX, RAX, &r->GPR[i.Rs].s);
					//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					x->emit("vmovdqa xmm0, @ptr", &r->GPR[i.Rt].s);
					x->emit("vpunpckhbw xmm0, xmm0, @ptr", &r->GPR[i.Rs].s);
					x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
				}
#else
				if (i.Rd)
				{
					e->movdqa1_regmem(RAX, &r->GPR[i.Rt].s);
					e->punpckhbw1regmem(RAX, RAX, &r->GPR[i.Rs].s);
					ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
				}
#endif

			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::PEXTUH ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "PEXTUH";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PEXTUH;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
#ifdef USE_NEW_PEXTUH_CODE
		case 1:

#ifdef USE_NEW_R5900_ASSEMBLER_PEXTUH
				if (i.Rd)
				{
					//e->movdqa1_regmem(RAX, &r->GPR[i.Rt].s);
					//e->punpckhbw1regmem(RAX, RAX, &r->GPR[i.Rs].s);
					//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					x->emit("vmovdqa xmm0, @ptr", &r->GPR[i.Rt].s);
					x->emit("vpunpckhwd xmm0, xmm0, @ptr", &r->GPR[i.Rs].s);
					x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
				}
#else
				if (i.Rd)
				{
					e->movdqa1_regmem(RAX, &r->GPR[i.Rt].s);
					e->punpckhwd1regmem(RAX, RAX, &r->GPR[i.Rs].s);
					ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
				}
#endif

			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::PEXTUW ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "PEXTUW";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PEXTUW;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
#ifdef USE_NEW_PEXTUW_CODE
		case 1:

#ifdef USE_NEW_R5900_ASSEMBLER_PEXTUW
				if (i.Rd)
				{
					//e->movdqa1_regmem(RAX, &r->GPR[i.Rt].s);
					//e->punpckhbw1regmem(RAX, RAX, &r->GPR[i.Rs].s);
					//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					x->emit("vmovdqa xmm0, @ptr", &r->GPR[i.Rt].s);
					x->emit("vpunpckhdq xmm0, xmm0, @ptr", &r->GPR[i.Rs].s);
					x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
				}
#else
				if (i.Rd)
				{
					e->movdqa1_regmem(RAX, &r->GPR[i.Rt].s);
					e->punpckhdq1regmem(RAX, RAX, &r->GPR[i.Rs].s);
					ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
				}
#endif

			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}








int32_t R5900::Recompiler::PMFLO ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "PMFLO";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PMFLO;
	
	int ret = 1;
	
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			//bStopEncodingAfter = true;
			//bStopEncodingBefore = true;
			
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
#ifdef USE_NEW_PMFLO_CODE
		case 1:
			// get maximum of busy until cycle in RDX (to be used as the cycle# Mul/Div unit is busy until)
			e->MovRegMem64 ( RCX, (int64_t*) & r->MulDiv_BusyUntil_Cycle );
			e->MovRegMem64 ( RDX, (int64_t*) & r->MulDiv_BusyUntil_Cycle1 );
			e->CmpRegReg64 ( RDX, RCX );
			e->CmovBRegReg64 ( RDX, RCX );
			
			// get current cyclecount in RAX
			e->MovRegMem64 ( RAX, (int64_t*) & r->CycleCount );
			//e->MovRegMem64 ( RCX, (int64_t*) & r->MulDiv_BusyUntil_Cycle );
			e->AddReg64ImmX ( RAX, LocalCycleCount );
			
			// save current cyclecount into RCX + cycles for divide
			//e->MovRegReg64 ( RCX, RAX );
			//e->AddReg64ImmX ( RCX, c_iMultiplyCycles );
			
			// get any cycles between current cyclecount and when Mul/Div unit is available
			e->SubRegReg64 ( RAX, RDX );
			e->Cqo ();
			e->AndRegReg64 ( RAX, RDX );
			
			// store the current cyclecount + time to Mul/Div unit available + cycles for divide
			//e->SubRegReg64 ( RCX, RAX );
			//e->MovMemReg64 ( (int64_t*) & r->MulDiv_BusyUntil_Cycle, RCX );
			//e->MovMemReg64 ( (int64_t*) & r->MulDiv_BusyUntil_Cycle1, RCX );
			
			// store cycle count minus one to the current cycle (because it adds one on return from recompiler for now)
			// offset current cyclecount with the number of cycles until mul/div unit is available
			//e->SubMemReg64 ( (int64_t*) & r->CycleCount, RDX );
			e->SubMemReg64 ( (int64_t*) & r->CycleCount, RAX );
			
			if (i.Rd)
			{
#ifdef ALLOW_AVX2_PMFLO
				if (iVectorType == VECTOR_TYPE_SSE)
#endif
				{
					e->movdqa_regmem(RAX, &r->LO.s);
					ret = e->movdqa_memreg(&r->GPR[i.Rd].s, RAX);
				}
#ifdef ALLOW_AVX2_PMFLO
				else
				{
					e->movdqa1_regmem(RAX, &r->LO.s);
					ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
				}
#endif
			}

			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::PMFHI ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "PMFHI";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PMFHI;
	
	int ret = 1;
	
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			//bStopEncodingAfter = true;
			//bStopEncodingBefore = true;
			
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
#ifdef USE_NEW_PMFHI_CODE
		case 1:
			// get maximum of busy until cycle in RDX (to be used as the cycle# Mul/Div unit is busy until)
			e->MovRegMem64 ( RCX, (int64_t*) & r->MulDiv_BusyUntil_Cycle );
			e->MovRegMem64 ( RDX, (int64_t*) & r->MulDiv_BusyUntil_Cycle1 );
			e->CmpRegReg64 ( RDX, RCX );
			e->CmovBRegReg64 ( RDX, RCX );
			
			// get current cyclecount in RAX
			e->MovRegMem64 ( RAX, (int64_t*) & r->CycleCount );
			//e->MovRegMem64 ( RCX, (int64_t*) & r->MulDiv_BusyUntil_Cycle );
			e->AddReg64ImmX ( RAX, LocalCycleCount );
			
			// save current cyclecount into RCX + cycles for divide
			//e->MovRegReg64 ( RCX, RAX );
			//e->AddReg64ImmX ( RCX, c_iMultiplyCycles );
			
			// get any cycles between current cyclecount and when Mul/Div unit is available
			e->SubRegReg64 ( RAX, RDX );
			e->Cqo ();
			e->AndRegReg64 ( RAX, RDX );
			
			// store the current cyclecount + time to Mul/Div unit available + cycles for divide
			//e->SubRegReg64 ( RCX, RAX );
			//e->MovMemReg64 ( (int64_t*) & r->MulDiv_BusyUntil_Cycle, RCX );
			//e->MovMemReg64 ( (int64_t*) & r->MulDiv_BusyUntil_Cycle1, RCX );
			
			// store cycle count minus one to the current cycle (because it adds one on return from recompiler for now)
			// offset current cyclecount with the number of cycles until mul/div unit is available
			//e->SubMemReg64 ( (int64_t*) & r->CycleCount, RDX );
			e->SubMemReg64 ( (int64_t*) & r->CycleCount, RAX );
			
			if (i.Rd)
			{
#ifdef ALLOW_AVX2_PMFHI
				if (iVectorType == VECTOR_TYPE_SSE)
#endif
				{
					e->movdqa_regmem(RAX, &r->HI.s);
					ret = e->movdqa_memreg(&r->GPR[i.Rd].s, RAX);
				}
#ifdef ALLOW_AVX2_PMFHI
				else
				{
					e->movdqa1_regmem(RAX, &r->HI.s);
					ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
				}
#endif
			}

			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}


int32_t R5900::Recompiler::PINTH ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "PINTH";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PINTH;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
#ifdef USE_NEW_PINTH_CODE
		case 1:

#ifdef USE_NEW_R5900_ASSEMBLER_PINTH
				if (i.Rd)
				{
					//e->pshufd1regmemimm(RAX, &r->GPR[i.Rt].s, (1 << 6) + (0 << 4));
					//e->punpckhwd1regmem(RAX, RAX, &r->GPR[i.Rs].s);
					//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					x->emit("vpshufd xmm0, @ptr, @imm", &r->GPR[i.Rt].s, (1 << 6) + (0 << 4));
					x->emit("vpunpckhwd xmm0, xmm0, @ptr", &r->GPR[i.Rs].s);
					x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
				}
#else
				if (i.Rd)
				{
					e->pshufd1regmemimm(RAX, &r->GPR[i.Rt].s, (1 << 6) + (0 << 4));
					e->punpckhwd1regmem(RAX, RAX, &r->GPR[i.Rs].s);
					ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
				}
#endif

			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::PINTEH ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "PINTEH";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PINTEH;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
#ifdef USE_NEW_PINTEH_CODE
		case 1:

#ifdef USE_NEW_R5900_ASSEMBLER_PINTEH
				if (i.Rd)
				{
					//e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
					//e->pslld1regimm(RAX, RAX, 16);
					//e->pblendw1regmemimm(RAX, RAX, &r->GPR[i.Rt].s, 0x55);
					//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					x->emit("vmovdqa xmm0, @ptr", &r->GPR[i.Rs].s);
					x->emit("vpslld xmm0, xmm0, 16");
					x->emit("vpblendw xmm0, xmm0, @ptr, 0x55");
					x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
				}
#else
				if (i.Rd)
				{
					e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
					//e->movdqa_regmem(RCX, &r->GPR[i.Rt].s);
					e->pslld1regimm(RAX, RAX, 16);
					//e->pblendw1regregimm(RAX, RCX, 0x55);
					e->pblendw1regmemimm(RAX, RAX, &r->GPR[i.Rt].s, 0x55);
					ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
				}
#endif

			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}



// multimedia multiply //


int32_t R5900::Recompiler::PMADDH ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "PMADDH";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PMADDH;
	
	static const int c_iMultiplyCycles = 4 / 2;

	int ret = 1;
	
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			//bStopEncodingAfter = true;
			//bStopEncodingBefore = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
#ifdef USE_NEW_PMADDH_CODE
		case 1:

			// get maximum of busy until cycle in RDX (to be used as the cycle# Mul/Div unit is busy until)
			e->MovRegMem64(RCX, (int64_t*)&r->MulDiv_BusyUntil_Cycle);
			e->MovRegMem64(RDX, (int64_t*)&r->MulDiv_BusyUntil_Cycle1);
			e->CmpRegReg64(RDX, RCX);
			e->CmovBRegReg64(RDX, RCX);

			// get current cyclecount in RAX
			e->MovRegMem64(RAX, (int64_t*)&r->CycleCount);
			//e->MovRegMem64 ( RCX, (int64_t*) & r->MulDiv_BusyUntil_Cycle );
			e->AddReg64ImmX(RAX, LocalCycleCount);

			// save current cyclecount into RCX + cycles for divide
			e->MovRegReg64(RCX, RAX);
			e->AddReg64ImmX(RCX, c_iMultiplyCycles);

			// get any cycles between current cyclecount and when Mul/Div unit is available
			e->SubRegReg64(RAX, RDX);
			e->Cqo();
			e->AndRegReg64(RAX, RDX);

			// store the current cyclecount + time to Mul/Div unit available + cycles for divide
			e->SubRegReg64(RCX, RAX);
			e->MovMemReg64((int64_t*)&r->MulDiv_BusyUntil_Cycle, RCX);
			e->MovMemReg64((int64_t*)&r->MulDiv_BusyUntil_Cycle1, RCX);

			// store cycle count minus one to the current cycle (because it adds one on return from recompiler for now)
			// offset current cyclecount with the number of cycles until mul/div unit is available
			//e->SubMemReg64 ( (int64_t*) & r->CycleCount, RDX );
			e->SubMemReg64((int64_t*)&r->CycleCount, RAX);

#ifdef ALLOW_AVX2_PMADDH
			if (iVectorType == VECTOR_TYPE_SSE)
#endif
			{
				e->movdqa_regmem(RAX, &r->GPR[i.Rs].s);
				e->movdqa_regmem(RCX, &r->GPR[i.Rt].s);
				e->movdqa_regreg(RBX, RAX);

				// put low values in A and high values in B
				e->pmullwregreg(RAX, RCX);
				e->pmulhwregreg(RBX, RCX);

				// get the values to add with Rd
				//e->movdqa_regmem ( RDX, & r->LO.s );
				//e->movdqa_regmem ( RCX, & r->HI.s );
				//e->pshufdregregimm ( RDX, RDX, ( 2 << 2 ) + 0 );
				//e->pshufdregregimm ( RCX, RCX, ( 2 << 2 ) + 0 );
				e->pshufdregmemimm(RDX, &r->LO.s, (2 << 2) + 0);
				e->pshufdregmemimm(RCX, &r->HI.s, (2 << 2) + 0);
				e->punpckhdqregreg(RDX, RCX);

				e->movdqa_regreg(RCX, RBX);
				e->pslldregimm(RCX, 16);
				e->pblendwregregimm(RCX, RAX, 0x55);

				// do the add
				e->padddregreg(RCX, RDX);

				if (i.Rd)
				{
					// store Rd
					e->movdqa_memreg(&r->GPR[i.Rd].s, RCX);
				}

				e->pshufdregregimm(RCX, RAX, (3 << 6) + (1 << 4) + (2 << 2) + 0);
				e->pshufdregregimm(RDX, RBX, (3 << 6) + (1 << 4) + (2 << 2) + 0);

				// store hi
				e->movdqa_regreg(RAX, RCX);
				e->punpckhwdregreg(RAX, RDX);

				// add with hi
				e->padddregmem(RAX, &r->HI.s);

				// store to hi
				e->movdqa_memreg(&r->HI.s, RAX);

				// store lo
				e->punpcklwdregreg(RCX, RDX);

				// add with lo
				e->padddregmem(RCX, &r->LO.s);

				// store to lo
				ret = e->movdqa_memreg(&r->LO.s, RCX);
			}
#ifdef ALLOW_AVX2_PMADDH
			else
			{
				e->movdqa1_regmem(RBX, &r->GPR[i.Rs].s);
				e->movdqa1_regmem(RCX, &r->GPR[i.Rt].s);

				e->pmullw1regreg(RAX, RBX, RCX);
				e->pmulhw1regreg(RBX, RBX, RCX);

				e->pshufd1regregimm(RCX, RAX, (3 << 6) + (1 << 4) + (2 << 2) + 0);
				e->pshufd1regregimm(RDX, RBX, (3 << 6) + (1 << 4) + (2 << 2) + 0);

				e->punpcklwd1regreg(4, RCX, RDX);
				e->punpckhwd1regreg(5, RCX, RDX);
				e->paddd1regmem(4, 4, &r->LO.s);
				e->paddd1regmem(5, 5, &r->HI.s);

				// store lo, hi
				e->movdqa1_memreg(&r->LO.s, 4);
				ret = e->movdqa1_memreg(&r->HI.s, 5);

				// get rd
				if (i.Rd)
				{
					e->pshufd1regregimm(5, 5, (2 << 6) + (2 << 4) + (0 << 2) + 0);
					e->pblendw1regregimm(4, 4, 5, 0xcc);
					ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, 4);
				}
			}
#endif

			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::PMADDW ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "PMADDW";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PMADDW;
	
	static const int c_iMultiplyCycles = 4 / 2;

	int ret = 1;
	
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			//bStopEncodingAfter = true;
			//bStopEncodingBefore = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
#ifdef USE_NEW_PMADDW_CODE
		case 1:

			// get maximum of busy until cycle in RDX (to be used as the cycle# Mul/Div unit is busy until)
			e->MovRegMem64 ( RCX, (int64_t*) & r->MulDiv_BusyUntil_Cycle );
			e->MovRegMem64 ( RDX, (int64_t*) & r->MulDiv_BusyUntil_Cycle1 );
			e->CmpRegReg64 ( RDX, RCX );
			e->CmovBRegReg64 ( RDX, RCX );
			
			// get current cyclecount in RAX
			e->MovRegMem64 ( RAX, (int64_t*) & r->CycleCount );
			//e->MovRegMem64 ( RCX, (int64_t*) & r->MulDiv_BusyUntil_Cycle );
			e->AddReg64ImmX ( RAX, LocalCycleCount );
			
			// save current cyclecount into RCX + cycles for divide
			e->MovRegReg64 ( RCX, RAX );
			e->AddReg64ImmX ( RCX, c_iMultiplyCycles );
			
			// get any cycles between current cyclecount and when Mul/Div unit is available
			e->SubRegReg64 ( RAX, RDX );
			e->Cqo ();
			e->AndRegReg64 ( RAX, RDX );
			
			// store the current cyclecount + time to Mul/Div unit available + cycles for divide
			e->SubRegReg64 ( RCX, RAX );
			e->MovMemReg64 ( (int64_t*) & r->MulDiv_BusyUntil_Cycle, RCX );
			e->MovMemReg64 ( (int64_t*) & r->MulDiv_BusyUntil_Cycle1, RCX );
			
			// store cycle count minus one to the current cycle (because it adds one on return from recompiler for now)
			// offset current cyclecount with the number of cycles until mul/div unit is available
			//e->SubMemReg64 ( (int64_t*) & r->CycleCount, RDX );
			e->SubMemReg64 ( (int64_t*) & r->CycleCount, RAX );
			
#ifdef ALLOW_AVX2_PMADDW
			if (iVectorType == VECTOR_TYPE_SSE)
#endif
			{
				e->movdqa_regmem(RAX, &r->GPR[i.Rs].s);
				e->movdqa_regmem(RCX, &r->GPR[i.Rt].s);

				// do the multiply
				e->pmuldqregreg(RAX, RCX);

				// get the values to add from hi/lo
				//e->movdqa_regmem ( RCX, & r->LO.s );
				//e->movdqa_regmem ( RDX, & r->HI.s );
				//e->pshufdregregimm ( RCX, RCX, ( 2 << 2 ) + 0 );
				//e->pshufdregregimm ( RDX, RDX, ( 2 << 2 ) + 0 );
				e->pshufdregmemimm(RCX, &r->LO.s, (2 << 2) + 0);
				e->pshufdregmemimm(RDX, &r->HI.s, (2 << 2) + 0);
				e->punpckldqregreg(RCX, RDX);

				// add the values
				e->paddqregreg(RAX, RCX);

				if (i.Rd)
				{
					// store 64-bit results
					e->movdqa_memreg(&r->GPR[i.Rd].s, RAX);
				}

				// get the hi result
				e->pshufdregregimm(RCX, RAX, (3 << 2) + (1 << 0));
				e->pmovsxdqregreg(RCX, RCX);
				e->movdqa_memreg(&r->HI.s, RCX);

				// get the lo result
				e->pshufdregregimm(RCX, RAX, (2 << 2) + (0 << 0));
				e->pmovsxdqregreg(RCX, RCX);
				ret = e->movdqa_memreg(&r->LO.s, RCX);
			}
#ifdef ALLOW_AVX2_PMADDW
			else
			{
				e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
				e->pmuldq1regmem(RAX, RAX, &r->GPR[i.Rt].s);
				e->pshufd1regmemimm(RCX, &r->HI.s, (2 << 6) | (2 << 4) | (0 << 2) | (0 << 0));
				e->pblendw1regmemimm(RCX, RCX, &r->LO.s, 0x33);
				e->paddq1regreg(RAX, RAX, RCX);

				if (i.Rd)
				{
					// store 64-bit results
					e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
				}

				// get the hi result
				//e->pshufd1regregimm(RCX, RAX, (3 << 2) + (1 << 0));
				//e->pmovsxdq1regreg(RCX, RCX);
				// get the lo result
				//e->pshufd1regregimm(RBX, RAX, (2 << 2) + (0 << 0));
				//e->pmovsxdq1regreg(RBX, RBX);

				e->pshufd1regregimm(RAX, RAX, (3 << 6) | (1 << 4) | (2 << 2) | (0 << 0));
				e->pmovsxdq2regreg(RAX, RAX);

				// store hi,lo result
				//e->movdqa1_memreg(&r->HI.s, RCX);
				//ret = e->movdqa1_memreg(&r->LO.s, RBX);
				e->vextracti128memreg(&r->HI.s, RAX, 1);
				ret = e->movdqa1_memreg(&r->LO.s, RAX);
			}
#endif

			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::PMADDUW ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "PMADDUW";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PMADDUW;
	
	static const int c_iMultiplyCycles = 4 / 2;

	int ret = 1;
	
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			//bStopEncodingAfter = true;
			//bStopEncodingBefore = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
#ifdef USE_NEW_PMADDUW_CODE
		case 1:

			// get maximum of busy until cycle in RDX (to be used as the cycle# Mul/Div unit is busy until)
			e->MovRegMem64 ( RCX, (int64_t*) & r->MulDiv_BusyUntil_Cycle );
			e->MovRegMem64 ( RDX, (int64_t*) & r->MulDiv_BusyUntil_Cycle1 );
			e->CmpRegReg64 ( RDX, RCX );
			e->CmovBRegReg64 ( RDX, RCX );
			
			// get current cyclecount in RAX
			e->MovRegMem64 ( RAX, (int64_t*) & r->CycleCount );
			//e->MovRegMem64 ( RCX, (int64_t*) & r->MulDiv_BusyUntil_Cycle );
			e->AddReg64ImmX ( RAX, LocalCycleCount );
			
			// save current cyclecount into RCX + cycles for divide
			e->MovRegReg64 ( RCX, RAX );
			e->AddReg64ImmX ( RCX, c_iMultiplyCycles );
			
			// get any cycles between current cyclecount and when Mul/Div unit is available
			e->SubRegReg64 ( RAX, RDX );
			e->Cqo ();
			e->AndRegReg64 ( RAX, RDX );
			
			// store the current cyclecount + time to Mul/Div unit available + cycles for divide
			e->SubRegReg64 ( RCX, RAX );
			e->MovMemReg64 ( (int64_t*) & r->MulDiv_BusyUntil_Cycle, RCX );
			e->MovMemReg64 ( (int64_t*) & r->MulDiv_BusyUntil_Cycle1, RCX );
			
			// store cycle count minus one to the current cycle (because it adds one on return from recompiler for now)
			// offset current cyclecount with the number of cycles until mul/div unit is available
			//e->SubMemReg64 ( (int64_t*) & r->CycleCount, RDX );
			e->SubMemReg64 ( (int64_t*) & r->CycleCount, RAX );
			
#ifdef ALLOW_AVX2_PMADDUW
			if (iVectorType == VECTOR_TYPE_SSE)
#endif
			{

				e->movdqa_regmem(RAX, &r->GPR[i.Rs].s);
				e->movdqa_regmem(RCX, &r->GPR[i.Rt].s);

				// do the multiply
				e->pmuludqregreg(RAX, RCX);

				// get the values to add from hi/lo
				//e->movdqa_regmem ( RCX, & r->LO.s );
				//e->movdqa_regmem ( RDX, & r->HI.s );
				//e->pshufdregregimm ( RCX, RCX, ( 2 << 2 ) + 0 );
				//e->pshufdregregimm ( RDX, RDX, ( 2 << 2 ) + 0 );
				e->pshufdregmemimm(RCX, &r->LO.s, (2 << 2) + 0);
				e->pshufdregmemimm(RDX, &r->HI.s, (2 << 2) + 0);
				e->punpckldqregreg(RCX, RDX);

				// add the values
				e->paddqregreg(RAX, RCX);

				if (i.Rd)
				{
					// store 64-bit results
					e->movdqa_memreg(&r->GPR[i.Rd].s, RAX);
				}

				// get the hi result
				e->pshufdregregimm(RCX, RAX, (3 << 2) + (1 << 0));
				e->pmovsxdqregreg(RCX, RCX);
				e->movdqa_memreg(&r->HI.s, RCX);

				// get the lo result
				e->pshufdregregimm(RCX, RAX, (2 << 2) + (0 << 0));
				e->pmovsxdqregreg(RCX, RCX);
				ret = e->movdqa_memreg(&r->LO.s, RCX);
			}
#ifdef ALLOW_AVX2_PMADDUW
			else
			{
				e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
				e->pmuludq1regmem(RAX, RAX, &r->GPR[i.Rt].s);
				e->pshufd1regmemimm(RCX, &r->HI.s, (2 << 6) | (2 << 4) | (0 << 2) | (0 << 0));
				e->pblendw1regmemimm(RCX, RCX, &r->LO.s, 0x33);
				e->paddq1regreg(RAX, RAX, RCX);

				if (i.Rd)
				{
					// store 64-bit results
					e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
				}

				// get the hi result
				//e->pshufd1regregimm(RCX, RAX, (3 << 2) + (1 << 0));
				//e->pmovsxdq1regreg(RCX, RCX);
				// get the lo result
				//e->pshufd1regregimm(RBX, RAX, (2 << 2) + (0 << 0));
				//e->pmovsxdq1regreg(RBX, RBX);

				e->pshufd1regregimm(RAX, RAX, (3 << 6) | (1 << 4) | (2 << 2) | (0 << 0));
				e->pmovsxdq2regreg(RAX, RAX);

				// store hi,lo result
				//e->movdqa1_memreg(&r->HI.s, RCX);
				//ret = e->movdqa1_memreg(&r->LO.s, RBX);
				e->vextracti128memreg(&r->HI.s, RAX, 1);
				ret = e->movdqa1_memreg(&r->LO.s, RAX);
			}
#endif

			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}


int32_t R5900::Recompiler::PMSUBH ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "PMSUBH";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PMSUBH;
	
	static const int c_iMultiplyCycles = 4 / 2;

	int ret = 1;
	
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			//bStopEncodingAfter = true;
			//bStopEncodingBefore = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
#ifdef USE_NEW_PMSUBH_CODE
		case 1:

			// get maximum of busy until cycle in RDX (to be used as the cycle# Mul/Div unit is busy until)
			e->MovRegMem64 ( RCX, (int64_t*) & r->MulDiv_BusyUntil_Cycle );
			e->MovRegMem64 ( RDX, (int64_t*) & r->MulDiv_BusyUntil_Cycle1 );
			e->CmpRegReg64 ( RDX, RCX );
			e->CmovBRegReg64 ( RDX, RCX );
			
			// get current cyclecount in RAX
			e->MovRegMem64 ( RAX, (int64_t*) & r->CycleCount );
			//e->MovRegMem64 ( RCX, (int64_t*) & r->MulDiv_BusyUntil_Cycle );
			e->AddReg64ImmX ( RAX, LocalCycleCount );
			
			// save current cyclecount into RCX + cycles for divide
			e->MovRegReg64 ( RCX, RAX );
			e->AddReg64ImmX ( RCX, c_iMultiplyCycles );
			
			// get any cycles between current cyclecount and when Mul/Div unit is available
			e->SubRegReg64 ( RAX, RDX );
			e->Cqo ();
			e->AndRegReg64 ( RAX, RDX );
			
			// store the current cyclecount + time to Mul/Div unit available + cycles for divide
			e->SubRegReg64 ( RCX, RAX );
			e->MovMemReg64 ( (int64_t*) & r->MulDiv_BusyUntil_Cycle, RCX );
			e->MovMemReg64 ( (int64_t*) & r->MulDiv_BusyUntil_Cycle1, RCX );
			
			// store cycle count minus one to the current cycle (because it adds one on return from recompiler for now)
			// offset current cyclecount with the number of cycles until mul/div unit is available
			//e->SubMemReg64 ( (int64_t*) & r->CycleCount, RDX );
			e->SubMemReg64 ( (int64_t*) & r->CycleCount, RAX );

#ifdef ALLOW_AVX2_PMSUBH
			if (iVectorType == VECTOR_TYPE_SSE)
#endif
			{
				e->movdqa_regmem(RAX, &r->GPR[i.Rs].s);
				e->movdqa_regmem(RCX, &r->GPR[i.Rt].s);
				e->movdqa_regreg(RBX, RAX);

				// put low values in A and high values in B
				e->pmullwregreg(RAX, RCX);
				e->pmulhwregreg(RBX, RCX);

				// get the values to add with Rd
				//e->movdqa_regmem ( RDX, & r->LO.s );
				//e->movdqa_regmem ( RCX, & r->HI.s );
				//e->pshufdregregimm ( RDX, RDX, ( 2 << 2 ) + 0 );
				//e->pshufdregregimm ( RCX, RCX, ( 2 << 2 ) + 0 );
				e->pshufdregmemimm(RDX, &r->LO.s, (2 << 2) + 0);
				e->pshufdregmemimm(RCX, &r->HI.s, (2 << 2) + 0);
				e->punpckhdqregreg(RDX, RCX);

				e->movdqa_regreg(RCX, RBX);
				e->pslldregimm(RCX, 16);
				e->pblendwregregimm(RCX, RAX, 0x55);

				// do the sub
				e->psubdregreg(RDX, RCX);

				if (i.Rd)
				{
					// store Rd
					e->movdqa_memreg(&r->GPR[i.Rd].s, RDX);
				}

				e->pshufdregregimm(RCX, RAX, (3 << 6) + (1 << 4) + (2 << 2) + 0);
				e->pshufdregregimm(RDX, RBX, (3 << 6) + (1 << 4) + (2 << 2) + 0);

				// store hi
				e->movdqa_regreg(RAX, RCX);
				e->punpckhwdregreg(RAX, RDX);

				// sub with hi
				e->movdqa_regmem(RBX, &r->HI.s);
				e->psubdregreg(RBX, RAX);

				// store to hi
				e->movdqa_memreg(&r->HI.s, RBX);

				// store lo
				e->punpcklwdregreg(RCX, RDX);

				// sub with lo
				e->movdqa_regmem(RBX, &r->HI.s);
				e->psubdregreg(RBX, RCX);

				// store to lo
				ret = e->movdqa_memreg(&r->LO.s, RBX);
			}
#ifdef ALLOW_AVX2_PMSUBH
			else
			{
				e->movdqa1_regmem(RBX, &r->GPR[i.Rs].s);
				e->movdqa1_regmem(RCX, &r->GPR[i.Rt].s);

				e->pmullw1regreg(RAX, RBX, RCX);
				e->pmulhw1regreg(RBX, RBX, RCX);

				e->pshufd1regregimm(RCX, RAX, (3 << 6) + (1 << 4) + (2 << 2) + 0);
				e->pshufd1regregimm(RDX, RBX, (3 << 6) + (1 << 4) + (2 << 2) + 0);

				e->movdqa1_regmem(RAX, &r->LO.s);
				e->movdqa1_regmem(RBX, &r->HI.s);

				e->punpcklwd1regreg(4, RCX, RDX);
				e->punpckhwd1regreg(5, RCX, RDX);
				e->psubd1regreg(4, RAX, 4);
				e->psubd1regreg(5, RBX, 5);

				// store lo, hi
				e->movdqa1_memreg(&r->LO.s, 4);
				ret = e->movdqa1_memreg(&r->HI.s, 5);

				// get rd
				if (i.Rd)
				{
					e->pshufd1regregimm(5, 5, (2 << 6) + (2 << 4) + (0 << 2) + 0);
					e->pblendw1regregimm(4, 4, 5, 0xcc);
					e->movdqa1_memreg(&r->GPR[i.Rd].s, 4);
				}
			}
#endif

			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}



int32_t R5900::Recompiler::PMSUBW ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "PMSUBW";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PMSUBW;
	
	static const int c_iMultiplyCycles = 4 / 2;

	int ret = 1;
	
	
	switch (OpLevel)
	{
	case 0:
		// for now, stop encoding after this instruction
		//bStopEncodingAfter = true;
		//bStopEncodingBefore = true;

#ifdef RESERVE_STACK_FRAME_FOR_CALL
		e->SubReg64ImmX(RSP, c_lSEH_StackSize);
#endif

		e->LoadImm32(RCX, i.Value);
		ret = e->Call(c_vFunction);

#ifdef RESERVE_STACK_FRAME_FOR_CALL
		ret = e->AddReg64ImmX(RSP, c_lSEH_StackSize);
#endif
		break;

#ifdef USE_NEW_PMSUBW_CODE
	case 1:
		// get maximum of busy until cycle in RDX (to be used as the cycle# Mul/Div unit is busy until)
		e->MovRegMem64(RCX, (int64_t*)&r->MulDiv_BusyUntil_Cycle);
		e->MovRegMem64(RDX, (int64_t*)&r->MulDiv_BusyUntil_Cycle1);
		e->CmpRegReg64(RDX, RCX);
		e->CmovBRegReg64(RDX, RCX);

		// get current cyclecount in RAX
		e->MovRegMem64(RAX, (int64_t*)&r->CycleCount);
		//e->MovRegMem64 ( RCX, (int64_t*) & r->MulDiv_BusyUntil_Cycle );
		e->AddReg64ImmX(RAX, LocalCycleCount);

		// save current cyclecount into RCX + cycles for divide
		e->MovRegReg64(RCX, RAX);
		e->AddReg64ImmX(RCX, c_iMultiplyCycles);

		// get any cycles between current cyclecount and when Mul/Div unit is available
		e->SubRegReg64(RAX, RDX);
		e->Cqo();
		e->AndRegReg64(RAX, RDX);

		// store the current cyclecount + time to Mul/Div unit available + cycles for divide
		e->SubRegReg64(RCX, RAX);
		e->MovMemReg64((int64_t*)&r->MulDiv_BusyUntil_Cycle, RCX);
		e->MovMemReg64((int64_t*)&r->MulDiv_BusyUntil_Cycle1, RCX);

		// store cycle count minus one to the current cycle (because it adds one on return from recompiler for now)
		// offset current cyclecount with the number of cycles until mul/div unit is available
		//e->SubMemReg64 ( (int64_t*) & r->CycleCount, RDX );
		e->SubMemReg64((int64_t*)&r->CycleCount, RAX);

#ifdef ALLOW_AVX2_PMSUBW
		if (iVectorType == VECTOR_TYPE_SSE)
#endif
		{

			e->movdqa_regmem(RAX, &r->GPR[i.Rs].s);
			e->movdqa_regmem(RCX, &r->GPR[i.Rt].s);

			// do the multiply
			e->pmuldqregreg(RAX, RCX);

			// get the values to add from hi/lo
			//e->movdqa_regmem ( RCX, & r->LO.s );
			//e->movdqa_regmem ( RDX, & r->HI.s );
			//e->pshufdregregimm ( RCX, RCX, ( 2 << 2 ) + 0 );
			//e->pshufdregregimm ( RDX, RDX, ( 2 << 2 ) + 0 );
			e->pshufdregmemimm(RCX, &r->LO.s, (2 << 2) + 0);
			e->pshufdregmemimm(RDX, &r->HI.s, (2 << 2) + 0);
			e->punpckldqregreg(RCX, RDX);

			// add the values
			e->psubqregreg(RCX, RAX);

			if (i.Rd)
			{
				// store 64-bit results
				e->movdqa_memreg(&r->GPR[i.Rd].s, RCX);
			}

			// get the hi result
			e->pshufdregregimm(RAX, RCX, (3 << 2) + (1 << 0));
			e->pmovsxdqregreg(RAX, RAX);
			e->movdqa_memreg(&r->HI.s, RAX);

			// get the lo result
			e->pshufdregregimm(RAX, RCX, (2 << 2) + (0 << 0));
			e->pmovsxdqregreg(RAX, RAX);
			ret = e->movdqa_memreg(&r->LO.s, RAX);
		}
#ifdef ALLOW_AVX2_PMSUBW
		else
		{
			e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
			e->pmuldq1regmem(RAX, RAX, &r->GPR[i.Rt].s);
			e->pshufd1regmemimm(RCX, &r->HI.s, (2 << 6) | (2 << 4) | (0 << 2) | (0 << 0));
			e->pblendw1regmemimm(RCX, RCX, &r->LO.s, 0x33);
			e->psubq1regreg(RAX, RCX, RAX);

			if (i.Rd)
			{
				// store 64-bit results
				e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
			}

			// get the hi result
			//e->pshufd1regregimm(RCX, RAX, (3 << 2) + (1 << 0));
			//e->pmovsxdq1regreg(RCX, RCX);
			// get the lo result
			//e->pshufd1regregimm(RBX, RAX, (2 << 2) + (0 << 0));
			//e->pmovsxdq1regreg(RBX, RBX);

			e->pshufd1regregimm(RAX, RAX, (3 << 6) | (1 << 4) | (2 << 2) | (0 << 0));
			e->pmovsxdq2regreg(RAX, RAX);

			// store hi,lo result
			//e->movdqa1_memreg(&r->HI.s, RCX);
			//ret = e->movdqa1_memreg(&r->LO.s, RBX);
			e->vextracti128memreg(&r->HI.s, RAX, 1);
			ret = e->movdqa1_memreg(&r->LO.s, RAX);
		}
#endif

		break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::PMULTH ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "PMULTH";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PMULTH;
	
	static const int c_iMultiplyCycles = 4 / 2;
	
	int ret = 1;
	
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			//bStopEncodingAfter = true;
			//bStopEncodingBefore = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
#ifdef USE_NEW_PMULTH_CODE
		case 1:
			// get maximum of busy until cycle in RDX (to be used as the cycle# Mul/Div unit is busy until)
			e->MovRegMem64 ( RCX, (int64_t*) & r->MulDiv_BusyUntil_Cycle );
			e->MovRegMem64 ( RDX, (int64_t*) & r->MulDiv_BusyUntil_Cycle1 );
			e->CmpRegReg64 ( RDX, RCX );
			e->CmovBRegReg64 ( RDX, RCX );
			
			// get current cyclecount in RAX
			e->MovRegMem64 ( RAX, (int64_t*) & r->CycleCount );
			//e->MovRegMem64 ( RCX, (int64_t*) & r->MulDiv_BusyUntil_Cycle );
			e->AddReg64ImmX ( RAX, LocalCycleCount );
			
			// save current cyclecount into RCX + cycles for divide
			e->MovRegReg64 ( RCX, RAX );
			e->AddReg64ImmX ( RCX, c_iMultiplyCycles );
			
			// get any cycles between current cyclecount and when Mul/Div unit is available
			e->SubRegReg64 ( RAX, RDX );
			e->Cqo ();
			e->AndRegReg64 ( RAX, RDX );
			
			// store the current cyclecount + time to Mul/Div unit available + cycles for divide
			e->SubRegReg64 ( RCX, RAX );
			e->MovMemReg64 ( (int64_t*) & r->MulDiv_BusyUntil_Cycle, RCX );
			e->MovMemReg64 ( (int64_t*) & r->MulDiv_BusyUntil_Cycle1, RCX );
			
			// store cycle count minus one to the current cycle (because it adds one on return from recompiler for now)
			// offset current cyclecount with the number of cycles until mul/div unit is available
			//e->SubMemReg64 ( (int64_t*) & r->CycleCount, RDX );
			e->SubMemReg64 ( (int64_t*) & r->CycleCount, RAX );
			
#ifdef ALLOW_AVX2_PMULTH
			if (iVectorType == VECTOR_TYPE_SSE)
#endif
			{
				e->movdqa_regmem(RAX, &r->GPR[i.Rs].s);
				e->movdqa_regmem(RCX, &r->GPR[i.Rt].s);
				e->movdqa_regreg(RBX, RAX);

				// put low values in A and high values in B
				e->pmullwregreg(RAX, RCX);
				e->pmulhwregreg(RBX, RCX);

				if (i.Rd)
				{
					e->movdqa_regreg(RCX, RBX);
					e->pslldregimm(RCX, 16);
					e->pblendwregregimm(RCX, RAX, 0x55);
					e->movdqa_memreg(&r->GPR[i.Rd].s, RCX);
				}

				e->pshufdregregimm(RCX, RAX, (3 << 6) + (1 << 4) + (2 << 2) + 0);
				e->pshufdregregimm(RDX, RBX, (3 << 6) + (1 << 4) + (2 << 2) + 0);

				// store hi
				e->movdqa_regreg(RAX, RCX);
				e->punpckhwdregreg(RAX, RDX);
				e->movdqa_memreg(&r->HI.s, RAX);

				// store lo
				e->punpcklwdregreg(RCX, RDX);
				ret = e->movdqa_memreg(&r->LO.s, RCX);
			}
#ifdef ALLOW_AVX2_PMULTH
			else
			{
				e->movdqa1_regmem(RBX, &r->GPR[i.Rs].s);
				e->movdqa1_regmem(RCX, &r->GPR[i.Rt].s);

				e->pmullw1regreg(RAX, RBX, RCX);
				e->pmulhw1regreg(RBX, RBX, RCX);

				e->pshufd1regregimm(RCX, RAX, (3 << 6) + (1 << 4) + (2 << 2) + 0);
				e->pshufd1regregimm(RDX, RBX, (3 << 6) + (1 << 4) + (2 << 2) + 0);

				e->punpcklwd1regreg(4, RCX, RDX);
				e->punpckhwd1regreg(5, RCX, RDX);
				//e->paddd1regmem(4, 4, &r->LO.s);
				//e->paddd1regmem(5, 5, &r->HI.s);

				// store lo, hi
				e->movdqa1_memreg(&r->LO.s, 4);
				ret = e->movdqa1_memreg(&r->HI.s, 5);

				// get rd
				if (i.Rd)
				{
					e->pshufd1regregimm(5, 5, (2 << 6) + (2 << 4) + (0 << 2) + 0);
					e->pblendw1regregimm(4, 4, 5, 0xcc);
					ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, 4);
				}
			}
#endif

			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::PMULTW ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "PMULTW";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PMULTW;
	
	static const int c_iMultiplyCycles = 4 / 2;

	int ret = 1;
	
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			//bStopEncodingAfter = true;
			//bStopEncodingBefore = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
#ifdef USE_NEW_PMULTW_CODE
		case 1:
			// get maximum of busy until cycle in RDX (to be used as the cycle# Mul/Div unit is busy until)
			e->MovRegMem64 ( RCX, (int64_t*) & r->MulDiv_BusyUntil_Cycle );
			e->MovRegMem64 ( RDX, (int64_t*) & r->MulDiv_BusyUntil_Cycle1 );
			e->CmpRegReg64 ( RDX, RCX );
			e->CmovBRegReg64 ( RDX, RCX );
			
			// get current cyclecount in RAX
			e->MovRegMem64 ( RAX, (int64_t*) & r->CycleCount );
			//e->MovRegMem64 ( RCX, (int64_t*) & r->MulDiv_BusyUntil_Cycle );
			e->AddReg64ImmX ( RAX, LocalCycleCount );
			
			// save current cyclecount into RCX + cycles for divide
			e->MovRegReg64 ( RCX, RAX );
			e->AddReg64ImmX ( RCX, c_iMultiplyCycles );
			
			// get any cycles between current cyclecount and when Mul/Div unit is available
			e->SubRegReg64 ( RAX, RDX );
			e->Cqo ();
			e->AndRegReg64 ( RAX, RDX );
			
			// store the current cyclecount + time to Mul/Div unit available + cycles for divide
			e->SubRegReg64 ( RCX, RAX );
			e->MovMemReg64 ( (int64_t*) & r->MulDiv_BusyUntil_Cycle, RCX );
			e->MovMemReg64 ( (int64_t*) & r->MulDiv_BusyUntil_Cycle1, RCX );
			
			// store cycle count minus one to the current cycle (because it adds one on return from recompiler for now)
			// offset current cyclecount with the number of cycles until mul/div unit is available
			//e->SubMemReg64 ( (int64_t*) & r->CycleCount, RDX );
			e->SubMemReg64 ( (int64_t*) & r->CycleCount, RAX );
			
#ifdef ALLOW_AVX2_PMULTW
			if (iVectorType == VECTOR_TYPE_SSE)
#endif
			{
				e->movdqa_regmem(RAX, &r->GPR[i.Rs].s);
				e->movdqa_regmem(RCX, &r->GPR[i.Rt].s);

				// do the multiply
				e->pmuldqregreg(RAX, RCX);

				if (i.Rd)
				{
					// store 64-bit results
					e->movdqa_memreg(&r->GPR[i.Rd].s, RAX);
				}

				// get the hi result
				e->pshufdregregimm(RCX, RAX, (3 << 2) + (1 << 0));
				e->pmovsxdqregreg(RCX, RCX);
				e->movdqa_memreg(&r->HI.s, RCX);

				// get the lo result
				e->pshufdregregimm(RCX, RAX, (2 << 2) + (0 << 0));
				e->pmovsxdqregreg(RCX, RCX);
				ret = e->movdqa_memreg(&r->LO.s, RCX);
			}
#ifdef ALLOW_AVX2_PMULTW
			else
			{
				e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
				e->pmuldq1regmem(RAX, RAX, &r->GPR[i.Rt].s);
				//e->pshufd1regmemimm(RCX, &r->HI.s, (2 << 6) | (2 << 4) | (0 << 2) | (0 << 0));
				//e->pblendw1regmemimm(RCX, RCX, &r->LO.s, 0x33);
				//e->paddq1regreg(RAX, RAX, RCX);

				if (i.Rd)
				{
					// store 64-bit results
					e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
				}

				// get the hi result
				//e->pshufd1regregimm(RCX, RAX, (3 << 2) + (1 << 0));
				//e->pmovsxdq1regreg(RCX, RCX);
				// get the lo result
				//e->pshufd1regregimm(RBX, RAX, (2 << 2) + (0 << 0));
				//e->pmovsxdq1regreg(RBX, RBX);

				e->pshufd1regregimm(RAX, RAX, (3 << 6) | (1 << 4) | (2 << 2) | (0 << 0));
				e->pmovsxdq2regreg(RAX, RAX);

				// store hi,lo result
				//e->movdqa1_memreg(&r->HI.s, RCX);
				//ret = e->movdqa1_memreg(&r->LO.s, RBX);
				e->vextracti128memreg(&r->HI.s, RAX, 1);
				ret = e->movdqa1_memreg(&r->LO.s, RAX);
			}
#endif

			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::PMULTUW ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "PMULTUW";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PMULTUW;
	
	static const int c_iMultiplyCycles = 4 / 2;

	int ret = 1;
	
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			//bStopEncodingAfter = true;
			//bStopEncodingBefore = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
#ifdef USE_NEW_PMULTUW_CODE
		case 1:
			// get maximum of busy until cycle in RDX (to be used as the cycle# Mul/Div unit is busy until)
			e->MovRegMem64 ( RCX, (int64_t*) & r->MulDiv_BusyUntil_Cycle );
			e->MovRegMem64 ( RDX, (int64_t*) & r->MulDiv_BusyUntil_Cycle1 );
			e->CmpRegReg64 ( RDX, RCX );
			e->CmovBRegReg64 ( RDX, RCX );
			
			// get current cyclecount in RAX
			e->MovRegMem64 ( RAX, (int64_t*) & r->CycleCount );
			//e->MovRegMem64 ( RCX, (int64_t*) & r->MulDiv_BusyUntil_Cycle );
			e->AddReg64ImmX ( RAX, LocalCycleCount );
			
			// save current cyclecount into RCX + cycles for divide
			e->MovRegReg64 ( RCX, RAX );
			e->AddReg64ImmX ( RCX, c_iMultiplyCycles );
			
			// get any cycles between current cyclecount and when Mul/Div unit is available
			e->SubRegReg64 ( RAX, RDX );
			e->Cqo ();
			e->AndRegReg64 ( RAX, RDX );
			
			// store the current cyclecount + time to Mul/Div unit available + cycles for divide
			e->SubRegReg64 ( RCX, RAX );
			e->MovMemReg64 ( (int64_t*) & r->MulDiv_BusyUntil_Cycle, RCX );
			e->MovMemReg64 ( (int64_t*) & r->MulDiv_BusyUntil_Cycle1, RCX );
			
			// store cycle count minus one to the current cycle (because it adds one on return from recompiler for now)
			// offset current cyclecount with the number of cycles until mul/div unit is available
			//e->SubMemReg64 ( (int64_t*) & r->CycleCount, RDX );
			e->SubMemReg64 ( (int64_t*) & r->CycleCount, RAX );
			
#ifdef ALLOW_AVX2_PMULTUW
			if (iVectorType == VECTOR_TYPE_SSE)
#endif
			{
				e->movdqa_regmem(RAX, &r->GPR[i.Rs].s);
				e->movdqa_regmem(RCX, &r->GPR[i.Rt].s);

				// do the multiply
				e->pmuludqregreg(RAX, RCX);

				if (i.Rd)
				{
					// store 64-bit results
					e->movdqa_memreg(&r->GPR[i.Rd].s, RAX);
				}

				// get the hi result
				e->pshufdregregimm(RCX, RAX, (3 << 2) + (1 << 0));
				e->pmovsxdqregreg(RCX, RCX);
				e->movdqa_memreg(&r->HI.s, RCX);

				// get the lo result
				e->pshufdregregimm(RCX, RAX, (2 << 2) + (0 << 0));
				e->pmovsxdqregreg(RCX, RCX);
				ret = e->movdqa_memreg(&r->LO.s, RCX);
			}
#ifdef ALLOW_AVX2_PMULTUW
			else
			{
				e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
				e->pmuludq1regmem(RAX, RAX, &r->GPR[i.Rt].s);
				//e->pshufd1regmemimm(RCX, &r->HI.s, (2 << 6) | (2 << 4) | (0 << 2) | (0 << 0));
				//e->pblendw1regmemimm(RCX, RCX, &r->LO.s, 0x33);
				//e->paddq1regreg(RAX, RAX, RCX);

				if (i.Rd)
				{
					// store 64-bit results
					e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
				}

				// get the hi result
				//e->pshufd1regregimm(RCX, RAX, (3 << 2) + (1 << 0));
				//e->pmovsxdq1regreg(RCX, RCX);
				// get the lo result
				//e->pshufd1regregimm(RBX, RAX, (2 << 2) + (0 << 0));
				//e->pmovsxdq1regreg(RBX, RBX);

				e->pshufd1regregimm(RAX, RAX, (3 << 6) | (1 << 4) | (2 << 2) | (0 << 0));
				e->pmovsxdq2regreg(RAX, RAX);

				// store hi,lo result
				//e->movdqa1_memreg(&r->HI.s, RCX);
				//ret = e->movdqa1_memreg(&r->LO.s, RBX);
				e->vextracti128memreg(&r->HI.s, RAX, 1);
				ret = e->movdqa1_memreg(&r->LO.s, RAX);
			}
#endif

			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}






int32_t R5900::Recompiler::PHMADH ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "PHMADH";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PHMADH;
	
	static const int c_iMultiplyCycles = 4 / 2;

	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
#ifdef USE_NEW_PHMADH_CODE
		case 1:
			// get maximum of busy until cycle in RDX (to be used as the cycle# Mul/Div unit is busy until)
			e->MovRegMem64 ( RCX, (int64_t*) & r->MulDiv_BusyUntil_Cycle );
			e->MovRegMem64 ( RDX, (int64_t*) & r->MulDiv_BusyUntil_Cycle1 );
			e->CmpRegReg64 ( RDX, RCX );
			e->CmovBRegReg64 ( RDX, RCX );
			
			// get current cyclecount in RAX
			e->MovRegMem64 ( RAX, (int64_t*) & r->CycleCount );
			//e->MovRegMem64 ( RCX, (int64_t*) & r->MulDiv_BusyUntil_Cycle );
			e->AddReg64ImmX ( RAX, LocalCycleCount );
			
			// save current cyclecount into RCX + cycles for divide
			e->MovRegReg64 ( RCX, RAX );
			e->AddReg64ImmX ( RCX, c_iMultiplyCycles );
			
			// get any cycles between current cyclecount and when Mul/Div unit is available
			e->SubRegReg64 ( RAX, RDX );
			e->Cqo ();
			e->AndRegReg64 ( RAX, RDX );
			
			// store the current cyclecount + time to Mul/Div unit available + cycles for divide
			e->SubRegReg64 ( RCX, RAX );
			e->MovMemReg64 ( (int64_t*) & r->MulDiv_BusyUntil_Cycle, RCX );
			e->MovMemReg64 ( (int64_t*) & r->MulDiv_BusyUntil_Cycle1, RCX );
			
			// store cycle count minus one to the current cycle (because it adds one on return from recompiler for now)
			// offset current cyclecount with the number of cycles until mul/div unit is available
			//e->SubMemReg64 ( (int64_t*) & r->CycleCount, RDX );
			e->SubMemReg64 ( (int64_t*) & r->CycleCount, RAX );
			
#ifdef ALLOW_AVX2_PHMADH
			if (iVectorType == VECTOR_TYPE_SSE)
#endif
			{
				e->movdqa_regmem(RAX, &r->GPR[i.Rs].s);
				e->movdqa_regmem(RCX, &r->GPR[i.Rt].s);

				// do the multiply-add
				e->pmaddwdregreg(RAX, RCX);

				if (i.Rd)
				{
					// store result to Rd
					e->movdqa_memreg(&r->GPR[i.Rd].s, RAX);
				}

				// get hi result and store to hi
				e->pshufdregregimm(RCX, RAX, (1 << 2) + (3 << 0));
				e->movdqa_memreg(&r->HI.s, RCX);

				// get lo result and store to lo
				e->pshufdregregimm(RCX, RAX, (2 << 2) + (0 << 0));
				ret = e->movdqa_memreg(&r->LO.s, RCX);
			}
#ifdef ALLOW_AVX2_PHMADH
			else
			{
				e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
				//e->movdqa_regmem(RCX, &r->GPR[i.Rt].s);

				// do the multiply-add
				//e->pmaddwdregreg(RAX, RCX);
				e->pmaddwd1regmem(RAX, RAX, &r->GPR[i.Rt].s);

				if (i.Rd)
				{
					// store result to Rd
					e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
				}

				// get lo result and store to lo
				//e->pshufd1regregimm(RCX, RAX, (2 << 2) + (0 << 0));
				//ret = e->movdqa1_memreg(&r->LO.s, RCX);

				e->pblendw1regmemimm(RCX, RAX, &r->LO.s, 0xcc);
				e->pshufd1regregimm(RDX, RAX, (3 << 2) + (1 << 0));
				e->pblendw1regmemimm(RDX, RDX, &r->HI.s, 0xcc);

				e->movdqa1_memreg(&r->LO.s, RCX);

				// get hi result and store to hi
				//e->pshufd1regregimm(RCX, RAX, (3 << 2) + (1 << 0));
				e->movdqa1_memreg(&r->HI.s, RDX);

			}
#endif

			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}



int32_t R5900::Recompiler::PHMSBH ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "PHMSBH";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PHMSBH;
	
	static const int c_iMultiplyCycles = 4 / 2;

	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
#ifdef USE_NEW_PHMSBH_CODE
		case 1:
			// get maximum of busy until cycle in RDX (to be used as the cycle# Mul/Div unit is busy until)
			e->MovRegMem64 ( RCX, (int64_t*) & r->MulDiv_BusyUntil_Cycle );
			e->MovRegMem64 ( RDX, (int64_t*) & r->MulDiv_BusyUntil_Cycle1 );
			e->CmpRegReg64 ( RDX, RCX );
			e->CmovBRegReg64 ( RDX, RCX );
			
			// get current cyclecount in RAX
			e->MovRegMem64 ( RAX, (int64_t*) & r->CycleCount );
			//e->MovRegMem64 ( RCX, (int64_t*) & r->MulDiv_BusyUntil_Cycle );
			e->AddReg64ImmX ( RAX, LocalCycleCount );
			
			// save current cyclecount into RCX + cycles for divide
			e->MovRegReg64 ( RCX, RAX );
			e->AddReg64ImmX ( RCX, c_iMultiplyCycles );
			
			// get any cycles between current cyclecount and when Mul/Div unit is available
			e->SubRegReg64 ( RAX, RDX );
			e->Cqo ();
			e->AndRegReg64 ( RAX, RDX );
			
			// store the current cyclecount + time to Mul/Div unit available + cycles for divide
			e->SubRegReg64 ( RCX, RAX );
			e->MovMemReg64 ( (int64_t*) & r->MulDiv_BusyUntil_Cycle, RCX );
			e->MovMemReg64 ( (int64_t*) & r->MulDiv_BusyUntil_Cycle1, RCX );
			
			// store cycle count minus one to the current cycle (because it adds one on return from recompiler for now)
			// offset current cyclecount with the number of cycles until mul/div unit is available
			//e->SubMemReg64 ( (int64_t*) & r->CycleCount, RDX );
			e->SubMemReg64 ( (int64_t*) & r->CycleCount, RAX );
			
#ifdef ALLOW_AVX2_PHMSBH
			if (iVectorType == VECTOR_TYPE_SSE)
#endif
			{
				e->movdqa_regmem(RAX, &r->GPR[i.Rs].s);
				e->movdqa_regmem(RCX, &r->GPR[i.Rt].s);

				// even 16-bit values on the right side need to be negated
				e->pxorregreg(RDX, RDX);
				e->psubwregreg(RDX, RCX);
				e->pblendwregregimm(RCX, RDX, 0x55);

				// do the multiply-add
				e->pmaddwdregreg(RAX, RCX);

				if (i.Rd)
				{
					// store result to Rd
					e->movdqa_memreg(&r->GPR[i.Rd].s, RAX);
				}

				// get hi result and store to hi
				e->pshufdregregimm(RCX, RAX, (1 << 2) + (3 << 0));
				e->movdqa_memreg(&r->HI.s, RCX);

				// get lo result and store to lo
				e->pshufdregregimm(RCX, RAX, (2 << 2) + (0 << 0));
				ret = e->movdqa_memreg(&r->LO.s, RCX);
			}
#ifdef ALLOW_AVX2_PHMSBH
			else
			{
				e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
				e->movdqa_regmem(RCX, &r->GPR[i.Rt].s);

				// even 16-bit values on the right side need to be negated
				e->pxor1regreg(RDX, RDX, RDX);
				e->psubw1regreg(RDX, RCX, RDX);
				e->pblendw1regregimm(RCX, RCX, RDX, 0x55);

				// do the multiply-add
				e->pmaddwd1regreg(RAX, RAX, RCX);
				//e->pmaddwd1regmem(RAX, RAX, &r->GPR[i.Rt].s);

				if (i.Rd)
				{
					// store result to Rd
					e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
				}

				// get lo result and store to lo
				//e->pshufd1regregimm(RCX, RAX, (2 << 2) + (0 << 0));
				//ret = e->movdqa1_memreg(&r->LO.s, RCX);

				e->pblendw1regmemimm(RCX, RAX, &r->LO.s, 0xcc);
				e->pshufd1regregimm(RDX, RAX, (3 << 2) + (1 << 0));
				e->pblendw1regmemimm(RDX, RDX, &r->HI.s, 0xcc);

				e->movdqa1_memreg(&r->LO.s, RCX);

				// get hi result and store to hi
				//e->pshufd1regregimm(RCX, RAX, (3 << 2) + (1 << 0));
				e->movdqa1_memreg(&r->HI.s, RDX);
			}
#endif

			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}



// multimedia divide //

int32_t R5900::Recompiler::PDIVW ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "PDIVW";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PDIVW;
	
	// 37 cycles
	// divide by 2 here since r5900 is currently only running at bus speed for testing
	static const int c_iDivideCycles = 37 / 2;
	
	int ret = 1;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			//bStopEncodingAfter = true;
			//bStopEncodingBefore = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
#ifdef USE_NEW_PDIVW_CODE
		case 1:
			// check if mul/div unit is in use
			//if ( r->MulDiv_BusyUntil_Cycle > r->CycleCount )
			//{
			//	// for now, just add onto memory latency
			//	r->CycleCount = r->MulDiv_BusyUntil_Cycle;
			//}
			
			// get maximum of busy until cycle in RDX (to be used as the cycle# Mul/Div unit is busy until)
			e->MovRegMem64 ( RCX, (int64_t*) & r->MulDiv_BusyUntil_Cycle );
			e->MovRegMem64 ( RDX, (int64_t*) & r->MulDiv_BusyUntil_Cycle1 );
			e->CmpRegReg64 ( RDX, RCX );
			e->CmovBRegReg64 ( RDX, RCX );
			
			// get current cyclecount in RAX
			e->MovRegMem64 ( RAX, (int64_t*) & r->CycleCount );
			//e->MovRegMem64 ( RCX, (int64_t*) & r->MulDiv_BusyUntil_Cycle );
			e->AddReg64ImmX ( RAX, LocalCycleCount );
			
			// save current cyclecount into RCX + cycles for divide
			e->MovRegReg64 ( RCX, RAX );
			e->AddReg64ImmX ( RCX, c_iDivideCycles );
			
			// get any cycles between current cyclecount and when Mul/Div unit is available
			e->SubRegReg64 ( RAX, RDX );
			e->Cqo ();
			e->AndRegReg64 ( RAX, RDX );
			
			// store the current cyclecount + time to Mul/Div unit available + cycles for divide
			e->SubRegReg64 ( RCX, RAX );
			e->MovMemReg64 ( (int64_t*) & r->MulDiv_BusyUntil_Cycle, RCX );
			e->MovMemReg64 ( (int64_t*) & r->MulDiv_BusyUntil_Cycle1, RCX );
			
			// store cycle count minus one to the current cycle (because it adds one on return from recompiler for now)
			// offset current cyclecount with the number of cycles until mul/div unit is available
			//e->SubMemReg64 ( (int64_t*) & r->CycleCount, RDX );
			e->SubMemReg64 ( (int64_t*) & r->CycleCount, RAX );
			
			// now do the division //
			
#ifdef USE_EXCEPTIONS_R5900_PDIVW

			e->MovRegMem32(RAX, (int32_t*)&r->GPR[i.Rs].sw0);
			e->MovRegMem32(RCX, (int32_t*)&r->GPR[i.Rt].sw0);
			e->Cdq();

			e->IdivRegReg32(RCX);

			e->Cdqe();
			e->MovsxdReg64Reg32(RDX, RDX);

			e->MovMemReg64(&r->LO.sq0, RAX);
			e->MovMemReg64(&r->HI.sq0, RDX);

			e->MovRegMem32(RAX, (int32_t*)&r->GPR[i.Rs].sw2);
			e->MovRegMem32(RCX, (int32_t*)&r->GPR[i.Rt].sw2);
			e->Cdq();

			e->IdivRegReg32(RCX);

			e->Cdqe();
			e->MovsxdReg64Reg32(RDX, RDX);

			e->MovMemReg64(&r->LO.sq1, RAX);
			e->MovMemReg64(&r->HI.sq1, RDX);

#else

			e->MovsxdReg64Mem32(RAX, &r->GPR[i.Rs].sw0);
			e->MovsxdReg64Mem32 ( RCX, & r->GPR [ i.Rt ].sw0 );

			e->Cqo();
			e->NotReg64(RDX);
			e->OrReg64ImmX(RDX, 1);

			e->Jmp8_ECXZ ( 0, 0 );
			
			e->Cdq ();
			//e->IdivRegReg64 ( RCX );
			e->IdivRegReg32 ( RCX );

			e->Cdqe();
			e->XchgRegReg64(RAX, RDX);
			e->Cdqe();

			e->SetJmpTarget8(0);


			e->MovMemReg64(&r->HI.s, RAX);
			e->MovMemReg64(&r->LO.s, RDX);

			e->MovsxdReg64Mem32(RAX, &r->GPR[i.Rs].sw2);
			e->MovsxdReg64Mem32 ( RCX, & r->GPR [ i.Rt ].sw2 );

			e->Cqo();
			e->NotReg64(RDX);
			e->OrReg64ImmX(RDX, 1);

			e->Jmp8_ECXZ ( 0, 0 );
			
			e->Cdq ();
			//e->IdivRegReg64 ( RCX );
			e->IdivRegReg32 ( RCX );

			e->Cdqe();
			e->XchgRegReg64(RAX, RDX);
			e->Cdqe();

			e->SetJmpTarget8(0);

			e->MovMemReg64(&r->HI.sq1, RAX);
			e->MovMemReg64(&r->LO.sq1, RDX);

#endif

			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::PDIVUW ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "PDIVUW";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PDIVUW;
	
	// 37 cycles
	// divide by 2 here since r5900 is currently only running at bus speed for testing
	static const int c_iDivideCycles = 37 / 2;
	
	int ret = 1;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			//bStopEncodingAfter = true;
			//bStopEncodingBefore = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
#ifdef USE_NEW_PDIVUW_CODE
		case 1:
			// check if mul/div unit is in use
			//if ( r->MulDiv_BusyUntil_Cycle > r->CycleCount )
			//{
			//	// for now, just add onto memory latency
			//	r->CycleCount = r->MulDiv_BusyUntil_Cycle;
			//}
			
			// get maximum of busy until cycle in RDX (to be used as the cycle# Mul/Div unit is busy until)
			e->MovRegMem64 ( RCX, (int64_t*) & r->MulDiv_BusyUntil_Cycle );
			e->MovRegMem64 ( RDX, (int64_t*) & r->MulDiv_BusyUntil_Cycle1 );
			e->CmpRegReg64 ( RDX, RCX );
			e->CmovBRegReg64 ( RDX, RCX );
			
			// get current cyclecount in RAX
			e->MovRegMem64 ( RAX, (int64_t*) & r->CycleCount );
			//e->MovRegMem64 ( RCX, (int64_t*) & r->MulDiv_BusyUntil_Cycle );
			e->AddReg64ImmX ( RAX, LocalCycleCount );
			
			// save current cyclecount into RCX + cycles for divide
			e->MovRegReg64 ( RCX, RAX );
			e->AddReg64ImmX ( RCX, c_iDivideCycles );
			
			// get any cycles between current cyclecount and when Mul/Div unit is available
			e->SubRegReg64 ( RAX, RDX );
			e->Cqo ();
			e->AndRegReg64 ( RAX, RDX );
			
			// store the current cyclecount + time to Mul/Div unit available + cycles for divide
			e->SubRegReg64 ( RCX, RAX );
			e->MovMemReg64 ( (int64_t*) & r->MulDiv_BusyUntil_Cycle, RCX );
			e->MovMemReg64 ( (int64_t*) & r->MulDiv_BusyUntil_Cycle1, RCX );
			
			// store cycle count minus one to the current cycle (because it adds one on return from recompiler for now)
			// offset current cyclecount with the number of cycles until mul/div unit is available
			//e->SubMemReg64 ( (int64_t*) & r->CycleCount, RDX );
			e->SubMemReg64 ( (int64_t*) & r->CycleCount, RAX );
			
			// now do the division //
			
#ifdef USE_EXCEPTIONS_R5900_PDIVUW

			e->MovRegMem32(RAX, (int32_t*)&r->GPR[i.Rs].sw0);
			e->MovRegMem32(RCX, (int32_t*)&r->GPR[i.Rt].sw0);
			e->XorRegReg32(RDX, RDX);

			e->IdivRegReg32(RCX);

			e->Cdqe();
			e->MovsxdReg64Reg32(RDX, RDX);

			e->MovMemReg64(&r->LO.sq0, RAX);
			e->MovMemReg64(&r->HI.sq0, RDX);

			e->MovRegMem32(RAX, (int32_t*)&r->GPR[i.Rs].sw2);
			e->MovRegMem32(RCX, (int32_t*)&r->GPR[i.Rt].sw2);
			e->XorRegReg32(RDX, RDX);

			e->IdivRegReg32(RCX);

			e->Cdqe();
			e->MovsxdReg64Reg32(RDX, RDX);

			e->MovMemReg64(&r->LO.sq1, RAX);
			e->MovMemReg64(&r->HI.sq1, RDX);

#else

			e->MovRegMem32 ( RCX, & r->GPR [ i.Rt ].sw0 );
			e->MovRegMem32 ( RAX, & r->GPR [ i.Rs ].sw0 );

			e->MovReg64ImmX(RDX, -1);

			e->Jmp8_ECXZ ( 0, 0 );
			
			e->XorRegReg32 ( RDX, RDX );
			e->DivRegReg32 ( RCX );


			e->Cdqe();
			e->XchgRegReg64(RAX, RDX);
			e->Cdqe();

			e->SetJmpTarget8(0);


			e->MovMemReg64(&r->HI.s, RAX);
			e->MovMemReg64(&r->LO.s, RDX);


			e->MovRegMem32 ( RCX, & r->GPR [ i.Rt ].sw2 );
			e->MovRegMem32 ( RAX, & r->GPR [ i.Rs ].sw2 );

			e->MovReg64ImmX(RDX, -1);

			e->Jmp8_ECXZ ( 0, 0 );
			
			e->XorRegReg32 ( RDX, RDX );
			e->DivRegReg32 ( RCX );

			e->Cdqe();
			e->XchgRegReg64(RAX, RDX);
			e->Cdqe();

			e->SetJmpTarget8(0);


			e->MovMemReg64(&r->HI.sq1, RAX);
			e->MovMemReg64(&r->LO.sq1, RDX);

#endif

			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::PDIVBW ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "PDIVBW";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PDIVBW;
	
	// 37 cycles
	// divide by 2 here since r5900 is currently only running at bus speed for testing
	static const int c_iDivideCycles = 37 / 2;
	
	int ret = 1;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			//bStopEncodingAfter = true;
			//bStopEncodingBefore = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
#ifdef USE_NEW_PDIVBW_CODE
		case 1:
			// check if mul/div unit is in use
			//if ( r->MulDiv_BusyUntil_Cycle > r->CycleCount )
			//{
			//	// for now, just add onto memory latency
			//	r->CycleCount = r->MulDiv_BusyUntil_Cycle;
			//}
			
			// get maximum of busy until cycle in RDX (to be used as the cycle# Mul/Div unit is busy until)
			e->MovRegMem64 ( RCX, (int64_t*) & r->MulDiv_BusyUntil_Cycle );
			e->MovRegMem64 ( RDX, (int64_t*) & r->MulDiv_BusyUntil_Cycle1 );
			e->CmpRegReg64 ( RDX, RCX );
			e->CmovBRegReg64 ( RDX, RCX );
			
			// get current cyclecount in RAX
			e->MovRegMem64 ( RAX, (int64_t*) & r->CycleCount );
			//e->MovRegMem64 ( RCX, (int64_t*) & r->MulDiv_BusyUntil_Cycle );
			e->AddReg64ImmX ( RAX, LocalCycleCount );
			
			// save current cyclecount into RCX + cycles for divide
			e->MovRegReg64 ( RCX, RAX );
			e->AddReg64ImmX ( RCX, c_iDivideCycles );
			
			// get any cycles between current cyclecount and when Mul/Div unit is available
			e->SubRegReg64 ( RAX, RDX );
			e->Cqo ();
			e->AndRegReg64 ( RAX, RDX );
			
			// store the current cyclecount + time to Mul/Div unit available + cycles for divide
			e->SubRegReg64 ( RCX, RAX );
			e->MovMemReg64 ( (int64_t*) & r->MulDiv_BusyUntil_Cycle, RCX );
			e->MovMemReg64 ( (int64_t*) & r->MulDiv_BusyUntil_Cycle1, RCX );
			
			// store cycle count minus one to the current cycle (because it adds one on return from recompiler for now)
			// offset current cyclecount with the number of cycles until mul/div unit is available
			//e->SubMemReg64 ( (int64_t*) & r->CycleCount, RDX );
			e->SubMemReg64 ( (int64_t*) & r->CycleCount, RAX );
			
			// now do the division //

#ifdef USE_EXCEPTIONS_R5900_PDIVBW

			e->MovRegMem32(RAX, &r->GPR[i.Rs].sw0);
			e->MovsxReg32Mem16(RCX, &r->GPR[i.Rt].sh0);
			e->Cdq();

			e->IdivRegReg32(RCX);

			e->MovMemReg32(&r->LO.sw0, RAX);
			e->MovMemReg32(&r->HI.sw0, RDX);

			e->MovRegMem32(RAX, &r->GPR[i.Rs].sw1);
			e->Cdq();

			e->IdivRegReg32(RCX);

			e->MovMemReg32(&r->LO.sw1, RAX);
			e->MovMemReg32(&r->HI.sw1, RDX);

			e->MovRegMem32(RAX, &r->GPR[i.Rs].sw2);
			e->Cdq();

			e->IdivRegReg32(RCX);

			e->MovMemReg32(&r->LO.sw2, RAX);
			e->MovMemReg32(&r->HI.sw2, RDX);

			e->MovRegMem32(RAX, &r->GPR[i.Rs].sw3);
			e->Cdq();

			e->IdivRegReg32(RCX);

			e->MovMemReg32(&r->LO.sw3, RAX);
			e->MovMemReg32(&r->HI.sw3, RDX);
#else

			//e->MovsxdReg64Mem32(RAX, &r->GPR[i.Rs].sw0);
			//e->MovRegMem32 ( RCX, & r->GPR [ i.Rt ].sw0 );
			e->MovsxReg32Mem16(RCX, &r->GPR[i.Rt].sh0);
			e->MovRegMem32(RAX, &r->GPR[i.Rs].sw0);


			// sign-extend the word
			//e->MovsxReg64Reg16 ( RCX, RCX );
			//e->MovsxReg32Reg16(RCX, RCX);

			e->Jmp8_ECXZ ( 0, 0 );
			
			e->Cdq();
			e->IdivRegReg32(RCX);

			//e->XchgRegReg32(RAX, RDX);
			//e->Cwde();
			e->MovsxReg32Reg16(RDX, RDX);

			e->MovMemReg32(&r->HI.sw0, RDX);
			e->MovMemReg32(&r->LO.sw0, RAX);

			//e->MovsxdReg64Mem32(RAX, &r->GPR[i.Rs].sw0);
			e->MovRegMem32(RAX, &r->GPR[i.Rs].sw1);

			e->Cdq();
			e->IdivRegReg32(RCX);
			e->MovsxReg32Reg16(RDX, RDX);

			e->MovMemReg32(&r->HI.sw1, RDX);
			e->MovMemReg32(&r->LO.sw1, RAX);

			e->MovRegMem32(RAX, &r->GPR[i.Rs].sw2);

			e->Cdq();
			e->IdivRegReg32(RCX);
			e->MovsxReg32Reg16(RDX, RDX);

			e->MovMemReg32(&r->HI.sw2, RDX);
			e->MovMemReg32(&r->LO.sw2, RAX);

			e->MovRegMem32(RAX, &r->GPR[i.Rs].sw3);

			e->Cdq();
			e->IdivRegReg32(RCX);
			e->MovsxReg32Reg16(RDX, RDX);

			e->MovMemReg32(&r->HI.sw3, RDX);
			e->MovMemReg32(&r->LO.sw3, RAX);

			e->Jmp8(0, 1);

			e->SetJmpTarget8(0);

#ifdef ALLOW_AVX2_PDIVBW
			if (iVectorType == VECTOR_TYPE_SSE)
#endif
			{
				e->movdqa_regmem(RAX, &r->GPR[i.Rs].s);
				e->pcmpeqbregreg(RDX, RDX);
				e->movdqa_regreg(RCX, RAX);
				e->psradregimm(RCX, 31);
				e->pxorregreg(RCX, RDX);
				e->psrldregimm(RDX, 31);
				e->porregreg(RDX, RCX);

				// for PDIVBW, it appears that remainder (HI) is not sign extended on division by zero ??
				e->movdqa_memreg(&r->HI.sw0, RAX);
				e->movdqa_memreg(&r->LO.sw0, RDX);
			}
#ifdef ALLOW_AVX2_PDIVBW
			else
			{
				e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
				e->pcmpeqb1regreg(RDX, RDX, RDX);
				//e->movdqa1_regreg(RCX, RAX);
				e->psrad1regimm(RCX, RAX, 31);
				e->pxor1regreg(RCX, RCX, RDX);
				e->psrld1regimm(RDX, RDX, 31);
				e->por1regreg(RDX, RDX, RCX);

				// for PDIVBW, it appears that remainder (HI) is not sign extended on division by zero ??
				e->movdqa1_memreg(&r->HI.sw0, RAX);
				e->movdqa1_memreg(&r->LO.sw0, RDX);
			}
#endif

			e->SetJmpTarget8(1);

#endif

			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}




int32_t R5900::Recompiler::PREVH ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "PREVH";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PREVH;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
#ifdef USE_NEW_PREVH_CODE
		case 1:

#ifdef USE_NEW_R5900_ASSEMBLER_PREVH
				if (i.Rd)
				{
					//e->pshufhw1regmemimm(RAX, &r->GPR[i.Rt].s, (0 << 6) + (1 << 4) + (2 << 2) + (3));
					//e->pshuflw1regregimm(RAX, RAX, (0 << 6) + (1 << 4) + (2 << 2) + (3));
					//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					x->emit("vpshufhw xmm0, @ptr, @imm", &r->GPR[i.Rt].s, (0 << 6) + (1 << 4) + (2 << 2) + (3));
					x->emit("vpshuflw xmm0, xmm0, @imm", (0 << 6) + (1 << 4) + (2 << 2) + (3));
					x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
				}

#else
				if (i.Rd)
				{
					//e->movdqa1_regmem(RAX, &r->GPR[i.Rt].s);
					e->pshufhw1regmemimm(RAX, &r->GPR[i.Rt].s, (0 << 6) + (1 << 4) + (2 << 2) + (3));
					//e->pshufhw1regregimm(RAX, RAX, (0 << 6) + (1 << 4) + (2 << 2) + (3));
					e->pshuflw1regregimm(RAX, RAX, (0 << 6) + (1 << 4) + (2 << 2) + (3));
					ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
				}
#endif

			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}




int32_t R5900::Recompiler::PEXEH ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "PEXEH";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PEXEH;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch (OpLevel)
	{
	case 0:
		if (i.Rd)
		{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX(RSP, c_lSEH_StackSize);
#endif

			e->LoadImm32(RCX, i.Value);
			ret = e->Call(c_vFunction);

#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX(RSP, c_lSEH_StackSize);
#endif
		}
		break;

#ifdef USE_NEW_PEXEH_CODE
	case 1:

#ifdef USE_NEW_R5900_ASSEMBLER_PEXEH
			if (i.Rd)
			{
				//e->pshufhw1regmemimm(RAX, &r->GPR[i.Rt].s, (3 << 6) + (0 << 4) + (1 << 2) + (2));
				//e->pshuflw1regregimm(RAX, RAX, (3 << 6) + (0 << 4) + (1 << 2) + (2));
				//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
				x->emit("vpshufhw xmm0, @ptr, @imm", &r->GPR[i.Rt].s, (3 << 6) + (0 << 4) + (1 << 2) + (2));
				x->emit("vpshuflw xmm0, xmm0, @imm", (3 << 6) + (0 << 4) + (1 << 2) + (2));
				x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
			}
#else
			if (i.Rd)
			{
				//e->movdqa1_regmem(RAX, &r->GPR[i.Rt].s);
				e->pshufhw1regmemimm(RAX, &r->GPR[i.Rt].s, (3 << 6) + (0 << 4) + (1 << 2) + (2));
				//e->pshufhw1regregimm(RAX, RAX, (3 << 6) + (0 << 4) + (1 << 2) + (2));
				e->pshuflw1regregimm(RAX, RAX, (3 << 6) + (0 << 4) + (1 << 2) + (2));
				ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
			}
#endif

		break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::PEXEW ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "PEXEW";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PEXEW;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
#ifdef USE_NEW_PEXEW_CODE
		case 1:

#ifdef USE_NEW_R5900_ASSEMBLER_PEXEW
				if (i.Rd)
				{
					//e->pshufd1regmemimm(RAX, &r->GPR[i.Rt].s, (3 << 6) + (0 << 4) + (1 << 2) + (2));
					//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					x->emit("vpshufd xmm0, @ptr, @imm", &r->GPR[i.Rt].s, (3 << 6) + (0 << 4) + (1 << 2) + (2));
					x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
				}
#else
				if (i.Rd)
				{
					e->pshufd1regmemimm(RAX, &r->GPR[i.Rt].s, (3 << 6) + (0 << 4) + (1 << 2) + (2));
					ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
				}
#endif

			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::PROT3W ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "PROT3W";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PROT3W;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
#ifdef USE_NEW_PROT3W_CODE
		case 1:

#ifdef USE_NEW_R5900_ASSEMBLER_PROT3W
				if (i.Rd)
				{
					//e->pshufd1regmemimm(RAX, &r->GPR[i.Rt].s, (3 << 6) + (0 << 4) + (2 << 2) + (1));
					//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					x->emit("vpshufd xmm0, @ptr, @imm", &r->GPR[i.Rt].s, (3 << 6) + (0 << 4) + (2 << 2) + (1));
					x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
				}
#else
				if (i.Rd)
				{
					e->pshufd1regmemimm(RAX, &r->GPR[i.Rt].s, (3 << 6) + (0 << 4) + (2 << 2) + (1));
					ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
				}
#endif

			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}



int32_t R5900::Recompiler::PMTHI ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "PMTHI";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PMTHI;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch (OpLevel)
	{
	case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
		e->SubReg64ImmX(RSP, c_lSEH_StackSize);
#endif

		e->LoadImm32(RCX, i.Value);
		ret = e->Call(c_vFunction);

#ifdef RESERVE_STACK_FRAME_FOR_CALL
		ret = e->AddReg64ImmX(RSP, c_lSEH_StackSize);
#endif
		break;

#ifdef USE_NEW_PMTHI_CODE
	case 1:

#ifdef ALLOW_AVX2_PMTHI
		if (iVectorType == VECTOR_TYPE_SSE)
#endif
		{
			if (i.Rs)
			{
				e->movdqa_regmem(RAX, &r->GPR[i.Rs].s);
			}
			else
			{
				e->pxorregreg(RAX, RAX);
			}

			ret = e->movdqa_memreg(&r->HI.s, RAX);
		}
#ifdef ALLOW_AVX2_PMTHI
		else
		{
			if (i.Rs)
			{
				e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
			}
			else
			{
				e->pxor1regreg(RAX, RAX, RAX);
			}

			ret = e->movdqa1_memreg(&r->HI.s, RAX);
		}
#endif

		break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::PMTLO ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "PMTLO";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PMTLO;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
#ifdef USE_NEW_PMTLO_CODE
		case 1:
#ifdef ALLOW_AVX2_PMTLO
			if (iVectorType == VECTOR_TYPE_SSE)
#endif
			{
				if (i.Rs)
				{
					e->movdqa_regmem(RAX, &r->GPR[i.Rs].s);
				}
				else
				{
					e->pxorregreg(RAX, RAX);
				}
				ret = e->movdqa_memreg(&r->LO.s, RAX);
			}
#ifdef ALLOW_AVX2_PMTLO
			else
			{
				if (i.Rs)
				{
					e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
				}
				else
				{
					e->pxor1regreg(RAX, RAX, RAX);
				}
				ret = e->movdqa1_memreg(&r->LO.s, RAX);
			}
#endif

			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}



int32_t R5900::Recompiler::PCPYLD ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "PCPYLD";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PCPYLD;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
#ifdef USE_NEW_PCPYLD_CODE
		case 1:

#ifdef USE_NEW_R5900_ASSEMBLER_PCPYLD
				if (i.Rd)
				{
					//e->movdqa1_regmem(RAX, &r->GPR[i.Rt].s);
					//e->punpcklqdq1regmem(RAX, RAX, &r->GPR[i.Rs].s);
					//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					x->emit("vmovdqa xmm0, @ptr", &r->GPR[i.Rt].s);
					x->emit("vpunpcklqdq xmm0, xmm0, @ptr", &r->GPR[i.Rs].s);
					x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
				}

#else
				if (i.Rd)
				{
					e->movdqa1_regmem(RAX, &r->GPR[i.Rt].s);
					e->punpcklqdq1regmem(RAX, RAX, &r->GPR[i.Rs].s);
					ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
				}
#endif

			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::PCPYUD ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "PCPYUD";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PCPYUD;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
#ifdef USE_NEW_PCPYUD_CODE
		case 1:

#ifdef USE_NEW_R5900_ASSEMBLER_PCPYUD
				if (i.Rd)
				{
					//e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
					//e->punpckhqdq1regmem(RAX, RAX, &r->GPR[i.Rt].s);
					//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					x->emit("vmovdqa xmm0, @ptr", &r->GPR[i.Rs].s);
					x->emit("vpunpckhqdq xmm0, xmm0, @ptr", &r->GPR[i.Rt].s);
					x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
				}
#else
				if (i.Rd)
				{
					e->movdqa1_regmem(RAX, &r->GPR[i.Rs].s);
					e->punpckhqdq1regmem(RAX, RAX, &r->GPR[i.Rt].s);
					ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
				}
#endif

			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::PCPYH ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "PCPYH";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PCPYH;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
#ifdef USE_NEW_PCPYH_CODE
		case 1:

#ifdef USE_NEW_R5900_ASSEMBLER_PCPYH
				if (i.Rd)
				{
					//e->pshufhw1regmemimm(RAX, &r->GPR[i.Rt].s, 0);
					//e->pshuflw1regregimm(RAX, RAX, 0);
					//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					x->emit("vpshufhw xmm0, @ptr, 0", &r->GPR[i.Rt].s);
					x->emit("vpshuflw xmm0, xmm0, 0");
					x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
				}
#else
				if (i.Rd)
				{
					//e->movdqa1_regmem(RAX, &r->GPR[i.Rt].s);
					e->pshufhw1regmemimm(RAX, &r->GPR[i.Rt].s, 0);
					//e->pshufhwregregimm(RAX, RAX, 0);
					e->pshuflw1regregimm(RAX, RAX, 0);
					ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
				}
#endif

			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}


int32_t R5900::Recompiler::PEXCH ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "PEXCH";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PEXCH;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
#ifdef USE_NEW_PEXCH_CODE
		case 1:

#ifdef USE_NEW_R5900_ASSEMBLER_PEXCH
				if (i.Rd)
				{
					//e->pshufhw1regmemimm(RAX, &r->GPR[i.Rt].s, (3 << 6) + (1 << 4) + (2 << 2) + (0));
					//e->pshuflw1regregimm(RAX, RAX, (3 << 6) + (1 << 4) + (2 << 2) + (0));
					//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					x->emit("vpshufhw xmm0, @ptr, @imm", &r->GPR[i.Rt].s, (3 << 6) + (1 << 4) + (2 << 2) + (0));
					x->emit("vpshuflw xmm0, xmm0, @imm", (3 << 6) + (1 << 4) + (2 << 2) + (0));
					x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
				}

#else
				if (i.Rd)
				{
					//e->movdqa1_regmem(RAX, &r->GPR[i.Rt].s);
					e->pshufhw1regmemimm(RAX, &r->GPR[i.Rt].s, (3 << 6) + (1 << 4) + (2 << 2) + (0));
					//e->pshufhw1regregimm(RAX, RAX, (3 << 6) + (1 << 4) + (2 << 2) + (0));
					e->pshuflw1regregimm(RAX, RAX, (3 << 6) + (1 << 4) + (2 << 2) + (0));
					ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
				}
#endif

			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::PEXCW ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "PEXCW";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PEXCW;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
#ifdef USE_NEW_PEXCW_CODE
		case 1:

#ifdef USE_NEW_R5900_ASSEMBLER_PEXCW
				if (i.Rd)
				{
					//e->pshufd1regmemimm(RAX, &r->GPR[i.Rt].s, (3 << 6) + (1 << 4) + (2 << 2) + (0));
					//ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
					x->emit("vpshufd xmm0, @ptr, @imm", &r->GPR[i.Rt].s, (3 << 6) + (1 << 4) + (2 << 2) + (0));
					x->emit("vmovdqa @ptr, xmm0", &r->GPR[i.Rd].s);
				}
#else
				if (i.Rd)
				{
					e->pshufd1regmemimm(RAX, &r->GPR[i.Rt].s, (3 << 6) + (1 << 4) + (2 << 2) + (0));
					ret = e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);
				}
#endif

			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::QFSRV ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "QFSRV";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::QFSRV;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
#ifdef USE_NEW_QFSRV_CODE
		case 1:

#ifdef ALLOW_AVX2_QFSRV
			if (iVectorType == VECTOR_TYPE_SSE)
#endif
			{
				if (i.Rd)
				{
					e->LeaRegMem64(RAX, recompiler_r5900_temp);
					e->movdqa_regmem(RAX, &r->GPR[i.Rt].s);

					if (i.Rs != i.Rt)
					{
						e->movdqa_regmem(RCX, &r->GPR[i.Rs].s);
					}

					e->MovRegMem32(RCX, (int32_t*)&r->SA);

					e->movdqa_to_mem128(RAX, RAX, NO_INDEX, SCALE_NONE, 0);

					if (i.Rs == i.Rt)
					{
						e->movdqa_to_mem128(RAX, RAX, NO_INDEX, SCALE_NONE, 16);
					}
					else
					{
						e->movdqa_to_mem128(RCX, RAX, NO_INDEX, SCALE_NONE, 16);
					}

					e->movdqu_from_mem128(RAX, RAX, RCX, SCALE_NONE, 0);
					e->movdqa_memreg(&r->GPR[i.Rd].s, RAX);
				}
			}
#ifdef ALLOW_AVX2_QFSRV
			else
			{
				/*
				-VPSHUFB uses a control mask to rearrange bytes in each 128 - bit lane.
				- We precompute 16 masks(for shifts 015), each 32 bytes int32_t.
				- For each shift amount, the mask selects the appropriate source byte or inserts 0x80 (which zeroes the byte).
				- This gives us a full 256 - bit variable - byte left shift with zero fill
				*/


				// ***todo*** could load the values for shuffle when sa is set
				e->movdqa1_regmem(RAX, &r->GPR[i.Rt].s);
				e->LeaRegMem64(RAX, recompiler_r5900_temp);

				if (i.Rs != i.Rt)
				{
					//e->movdqa_regmem(RCX, &r->GPR[i.Rs].s);
					e->vinserti128regmem(RAX, RAX, &r->GPR[i.Rs].s, 1);
				}
				else
				{
					e->vinserti128regreg(RAX, RAX, RAX, 1);
				}

				e->MovRegMem32(RCX, (int32_t*)&r->SA);

				//e->movdqa_to_mem128(RAX, RAX, NO_INDEX, SCALE_NONE, 0);
				//if (i.Rs == i.Rt)
				//{
				//	e->movdqa_to_mem128(RAX, RAX, NO_INDEX, SCALE_NONE, 16);
				//}
				//else
				//{
				//	e->movdqa_to_mem128(RCX, RAX, NO_INDEX, SCALE_NONE, 16);
				//}

				e->movdqa2_memreg(RAX, RAX, NO_INDEX, SCALE_NONE, 0);

				e->movdqu1_regmem(RAX, RAX, RCX, SCALE_NONE, 0);
				e->movdqa1_memreg(&r->GPR[i.Rd].s, RAX);

			}
#endif

			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}





// * R5900 COP0 instructions * //


int32_t R5900::Recompiler::EI ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "EI";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::EI;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;

	
	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::DI ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "DI";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::DI;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::CFC0 ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "CFC0";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::CFC0;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::CTC0 ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "CTC0";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::CTC0;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}




int32_t R5900::Recompiler::SYNC ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "SYNC";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::SYNC;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		//case 1:
			// this instruction doesn't do anything currently
			//break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}


int32_t R5900::Recompiler::CACHE ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "CACHE";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::CACHE;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::PREF ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "PREF";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PREF;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
			// this instruction doesn't do anything currently
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::TLBR ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "TLBR";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::TLBR;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
			// this instruction doesn't do anything currently
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::TLBWI ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "TLBWI";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::TLBWI;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
			// this instruction doesn't do anything currently
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::TLBWR ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "TLBWR";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::TLBWR;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
			// this instruction doesn't do anything currently
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::TLBP ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "TLBP";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::TLBP;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
			// this instruction doesn't do anything currently
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::ERET ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "ERET";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::ERET;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	// this instruction always modifies the NextPC
	Local_NextPCModified = true;
	
	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}



int32_t R5900::Recompiler::DERET ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "DERET";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::DERET;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
			// this instruction doesn't do anything currently
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::WAIT ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "WAIT";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::WAIT;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
			// this instruction doesn't do anything currently
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}





// * COP1 (floating point) instructions * //


int32_t R5900::Recompiler::MFC1 ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "MFC1";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::MFC1;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::MTC1 ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "MTC1";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::MTC1;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::CFC1 ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "CFC1";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::CFC1;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::CTC1 ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "CTC1";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::CTC1;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}


int32_t R5900::Recompiler::LWC1 ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "LWC1";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::LWC1;
	
	int ret = 1;
	
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			//bStopEncodingBefore = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

#ifdef ENABLE_R5900_DCACHE
			e->AddMemImm64 ( (int64_t*) & r->CycleCount, LocalCycleCount - MemCycles );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );

#ifdef ENABLE_R5900_DCACHE
			e->SubMemImm64 ( (int64_t*) & r->CycleCount, LocalCycleCount - MemCycles );
#endif
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
#ifdef USE_NEW_LOAD_CODE
		case 1:

#ifdef ENABLE_PS2_VIRTUAL_MACHINE_LWC1

			if (!bitget_hwrw_bitmap(Address))
			{
				ret = Generate_Virtual_Load(i, Address, 0x3, (void*)Playstation2::DataBus::Read_t<0xffffffffULL>);
			}
			else
			{
				ret = Generate_Basic_Load(i, Address, 0x3, (void*)Playstation2::DataBus::Read_t<0xffffffffULL>);
			}
#else

			ret = Generate_Normal_Load(i, Address, 0x3, (void*)Playstation2::DataBus::Read_t<0xffffffffULL>);
#endif

			
			// store result //
			
			// store
			ret = e->MovMemReg32 ( & r->CPR1 [ i.Rt ].s, RAX );
			
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::SWC1 ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "SWC1";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::SWC1;
	
	int ret = 1;
	
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			//bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

#ifdef ENABLE_R5900_DCACHE
			e->AddMemImm64 ( (int64_t*) & r->CycleCount, LocalCycleCount - MemCycles );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );

#ifdef ENABLE_R5900_DCACHE
			e->SubMemImm64 ( (int64_t*) & r->CycleCount, LocalCycleCount - MemCycles );
#endif
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
#ifdef USE_NEW_STORE_CODE
		case 1:

#ifdef ENABLE_PS2_VIRTUAL_MACHINE_SWC1
			if (!bitget_hwrw_bitmap(Address))
			{
				ret = Generate_Virtual_Store(i, Address, 0x3, (void*)Playstation2::DataBus::Write_t<0xffffffffULL>);
			}
			else
#endif
			{
				ret = Generate_Normal_Store(i, Address, 0x3, (void*)Playstation2::DataBus::Write_t<0xffffffffULL>);
			}

			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}





int32_t R5900::Recompiler::ABS_S ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "ABS_S";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::ABS_S;
	
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
#ifdef ENABLE_FPU_LATENCY
	static constexpr uint64_t c_ullLatency = 4;
	
	// check if next instruction uses dest from this one
	if ( ( 1ull << i.Fd ) & GetCop1_SrcRegs( NextInst ) )
	{
		// add latency
		LocalCycleCount += ( c_ullLatency - 2 ) >> 1;
	}
#endif
	
	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
#ifdef USE_NEW_ABS_S_CODE
		case 1:
			//r->CPR1 [ i.Fd ].s = r->CPR1 [ i.Fs ].s & 0x7fffffff;
			// flags affected:
			// clears flags o,u (bits 14,15)
			//r->CPC1 [ 31 ] &= ~0x0000c000;
			if ( i.Fd == i.Fs )
			{
				e->AndMem32ImmX ( &r->CPR1 [ i.Fs ].s, 0x7fffffff );
				//e->BtrMem32Imm ( &r->CPR1 [ i.Fs ].s, 31 );
				ret = e->AndMem32ImmX ( &r->CPC1 [ 31 ], ~0x0000c000 );
			}
			else
			{
				e->MovRegMem32 ( RAX, &r->CPR1 [ i.Fs ].s );
				e->AndReg32ImmX ( RAX, 0x7fffffff );
				//e->BtrRegImm32 ( RAX, 31 );
				e->MovMemReg32 ( &r->CPR1 [ i.Fd ].s, RAX );
				ret = e->AndMem32ImmX ( &r->CPC1 [ 31 ], ~0x0000c000 );
			}
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}


int32_t R5900::Recompiler::ADD_S ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "ADD_S";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::ADD_S;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
#ifdef ENABLE_FPU_LATENCY
	static constexpr uint64_t c_ullLatency = 4;
	
	// check if next instruction uses dest from this one
	if ( ( 1ull << i.Fd ) & GetCop1_SrcRegs( NextInst ) )
	{
		// add latency
		LocalCycleCount += ( c_ullLatency - 2 ) >> 1;
	}
#endif

	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
#ifdef USE_NEW_ADD_S_CODE
		case 1:

			Generate_FADDp(e, i.Value);
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}


int32_t R5900::Recompiler::ADDA_S ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "ADDA_S";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::ADDA_S;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_ADDA_S_CODE
		case 1:

			Generate_FADDp(e, i.Value);
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}



int32_t R5900::Recompiler::CVT_S_W ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "CVT_S_W";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::CVT_S_W;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
#ifdef ENABLE_FPU_LATENCY
	static constexpr uint64_t c_ullLatency = 4;
	
	// check if next instruction uses dest from this one
	if ( ( 1ull << i.Fd ) & GetCop1_SrcRegs( NextInst ) )
	{
		// add latency
		LocalCycleCount += ( c_ullLatency - 2 ) >> 1;
	}
#endif

	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
#ifdef USE_NEW_CVT_S_W_CODE
		case 1:

#define TEST_NEW_CVT_S_W_CODE
#ifdef TEST_NEW_CVT_S_W_CODE

			ret = Generate_FITOFp(e, i.Value);

#else

			e->movd_regmem(RAX, &r->CPR1[i.Fs].s);
			e->cvtdq2psregreg(RAX, RAX);
			ret = e->movd_memreg(&r->CPR1[i.Fd].s, RAX);

#endif

			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}


int32_t R5900::Recompiler::SUB_S ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "SUB_S";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::SUB_S;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
#ifdef ENABLE_FPU_LATENCY
	static constexpr uint64_t c_ullLatency = 4;
	
	// check if next instruction uses dest from this one
	if ( ( 1ull << i.Fd ) & GetCop1_SrcRegs( NextInst ) )
	{
		// add latency
		LocalCycleCount += ( c_ullLatency - 2 ) >> 1;
	}
#endif

	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
#ifdef USE_NEW_SUB_S_CODE
		case 1:

			Generate_FADDp(e, i.Value);
			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::MUL_S ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "MUL_S";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::MUL_S;
	
	int ret = 1;
	
	R5900::Instruction::Format ii0, ii1, ii2, ii3;

	ii0.Value = i.Value;
	//ii1.Value = i1;
	//ii2.Value = i2;
	//ii3.Value = i3;


	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
#ifdef ENABLE_FPU_LATENCY
	static constexpr uint64_t c_ullLatency = 4;
	
	// check if next instruction uses dest from this one
	if ( ( 1ull << i.Fd ) & GetCop1_SrcRegs( NextInst ) )
	{
		// add latency
		LocalCycleCount += ( c_ullLatency - 2 ) >> 1;
	}
#endif

	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
#ifdef USE_NEW_MUL_S_CODE
		case 1:

			Generate_FMULp(e, i.Value);
			break;
#endif	// end #ifdef USE_NEW_MUL_S_CODE
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::MULA_S ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "MULA_S";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::MULA_S;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_MULA_S_CODE
		case 1:

			Generate_FMULp(e, i.Value);
			break;
#endif	// end #ifdef USE_NEW_MULA_S_CODE

			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}


int32_t R5900::Recompiler::DIV_S ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "DIV_S";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::DIV_S;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
#ifdef ENABLE_FPU_LATENCY
	static constexpr uint64_t c_ullLatency = 8;
	
	// check if next instruction uses dest from this one
	if ( ( 1ull << i.Fd ) & GetCop1_SrcRegs( NextInst ) )
	{
		// add latency
		LocalCycleCount += ( c_ullLatency - 2 ) >> 1;
	}
#endif
	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
#ifdef USE_NEW_DIV_S_CODE
		case 1:
			
			e->movd1_regmem(RAX, (int32_t*)&r->CPR1[i.Fs].s);
			e->movd1_regmem(RCX, (int32_t*)&r->CPR1[i.Ft].s);

			// make constant multiplier ->rbx
			//e->MovReg64ImmX(RAX, 127ull << 52);
			e->MovReg64ImmX(RAX, 896ull << 23);
			e->movq_to_sse128(RBX, RAX);

			// check if fs,ft is float zero
			// 0 -> r5
			e->pxor1regreg(RDX, RDX, RDX);
			e->paddd1regreg(4, RAX, RAX);
			e->pcmpeqb1regreg(4, 4, RDX);
			e->paddd1regreg(5, RCX, RCX);
			e->pcmpeqb1regreg(5, 5, RDX);

			// make masks
			e->pcmpgtd1regreg(4, RDX, 4);
			e->pcmpgtd1regreg(5, RDX, 5);


			// check if fs==0 and ft==0 -> invalid ->r4
			e->pand1regreg(4, 4, 5);

			// check if fs!=0 and ft==0 -> div by zero -> r5
			//e->pandn1regreg(5, 4, 5);

			e->movd_from_sse128(RAX, 4);
			e->movd_from_sse128(RCX, 5);

			// sign ->rdx
			e->pxor1regreg(RDX, RAX, RCX);

			// adjust fs if 0/0
			e->por1regreg(RAX, RAX, 4);


			// cvt float to double
			e->psllq1regimm(RAX, RAX, 33);
			e->psrlq1regimm(RAX, RAX, 4);
			e->psllq1regimm(RCX, RCX, 33);
			e->psrlq1regimm(RCX, RCX, 4);


			// divide
			e->vdivsd(RAX, RAX, RCX);

			// multiply with multiplier
			//e->vmulsd(RAX, RAX, RBX);

			// make adjustment ->r4
			e->MovReg64ImmX(RDX, 1ull << 28);
			e->movq_to_sse128(4, RDX);

			// adjust result
			e->paddq1regreg(RAX, RAX, 4);

			// get result
			e->psrlq1regimm(RAX, RAX, 29);

			// offset exponent
			e->psubq1regreg(RAX, RAX, RBX);

			// clear on underflow or zero
			e->pxor1regreg(5, 5, 5);
			e->pcmpgtq1regreg(4, 5, RAX);
			e->pandn1regreg(RAX, 4, RAX);

			// maximize on overflow
			e->pcmpeqb1regreg(5, 5, 5);
			e->psrlq1regimm(4, 5, 33);
			e->pcmpgtq1regreg(RBX, RAX, 4);
			e->por1regreg(RAX, RAX, RBX);
			e->pand1regreg(RAX, RAX, 4);

			// put sign in
			e->pandn1regreg(RDX, 4, RDX);
			e->por1regreg(RAX, RAX, RDX);


			// store result
			e->movd1_memreg((int32_t*)&r->CPR1[i.Fd].s, RAX);


			// get flags
			e->MovRegMem32(RDX, (int32_t*)&r->CPC1[31]);
			e->XorRegReg32(RCX, RAX);
			e->AndReg32ImmX(RAX, 0x20040);
			e->AndReg32ImmX(RCX, 0x10020);
			e->OrRegReg32(RAX, RCX);
			e->AndReg32ImmX(RDX, ~0x30000);
			e->OrRegReg32(RAX, RDX);
			ret = e->MovMemReg32((int32_t*)&r->CPC1[31], RAX);

			/*
			// clear bits 16 and 17 in the flag register first
			e->AndMem32ImmX ( &r->CPC1 [ 31 ], ~0x00030000 );		// r->CPC1 [ 31 ], ~0x00030000 );
			
			// flush ps2 float to zero
			e->MovRegMem32 ( RAX, &r->CPR1 [ i.Ft ].s );
			e->XorRegReg32 ( 11, 11 );
			e->MovReg32ImmX ( 8, 0x00030060 );
			e->MovReg64ImmX ( RCX, 896ULL << 23 );
			e->Cdq ();
			e->AndReg32ImmX ( RAX, 0x7fffffff );
			//e->LeaRegRegReg64 ( RDX, RAX, RCX );
			e->AddRegReg64 ( RCX, RAX );
			//e->TestReg32ImmX ( RAX, 0x7f800000 );
			e->AndReg32ImmX ( RAX, 0x7f800000 );
			e->CmovNERegReg32 ( 8, 11 );
			e->CmovNERegReg64 ( RAX, RCX );
			e->ShlRegImm64 ( RAX, 29 );
			e->movq_to_sse ( RCX, RAX );
			
			
			e->MovRegMem32 ( RAX, &r->CPR1 [ i.Fs ].s );
			//e->MovReg64ImmX ( RCX, 896ULL << 23 );
			//e->XorRegReg32 ( 8, RAX );
			e->XorRegReg32 ( RDX, RAX );
			e->AndReg32ImmX ( RAX, 0x7fffffff );
			//e->LeaRegRegReg64 ( RDX, RAX, RCX );
			//e->AddRegReg64 ( RCX, RAX );
			//e->AndReg32ImmX ( RAX, 0x7f800000 );
			e->TestReg32ImmX ( RAX, 0x7f800000 );
			e->MovReg32ImmX ( 9, 0x00010020 );
			e->MovReg32ImmX ( 10, 0x00020040 );
			e->CmovERegReg32 ( 9, 10 );
			e->CmovERegReg32 ( RAX, 11 );
			e->ShlRegImm64 ( RAX, 29 );
			e->movq_to_sse ( RAX, RAX );

			
			// get sign in R8
			e->AndReg32ImmX ( RDX, 0x80000000 );
			
			// set flags
			e->AndRegReg32 ( 8, 9 );
			e->OrMemReg32 ( &r->CPC1 [ 31 ], 8 );
			
			// perform div
			e->divsd ( RAX, RCX );


			// get result
			e->movq_from_sse ( RAX, RAX );

			// round up ?
			e->AddReg64ImmX(RAX, 0x10000000);
			
			// shift back down without sign
			e->ShrRegImm64 ( RAX, 29 );
			
			
			// clear on underflow or zero
			e->TestReg32ImmX ( RAX, 0xff800000 );
			e->CmovERegReg32 ( RAX, 11 );
			
			
			// set to max on overflow
			e->MovReg32ImmX ( RCX, 0x7fffffff );
			e->CmovSRegReg32 ( RAX, RCX );
			
			// or if any flags are set
			e->OrRegReg32 ( 8, 8 );
			e->CmovNERegReg32 ( RAX, RCX );
			
			// set sign
			e->OrRegReg32 ( RAX, RDX );

			// store result
			e->MovMemReg32 ( &r->CPR1 [ i.Fd ].s, RAX );		// &r->CPR1 [ i.Fd ].s, RAX );
			*/

			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::SQRT_S ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "SQRT_S";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::SQRT_S;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
#ifdef ENABLE_FPU_LATENCY
	static constexpr uint64_t c_ullLatency = 8;
	
	// check if next instruction uses dest from this one
	if ( ( 1ull << i.Fd ) & GetCop1_SrcRegs( NextInst ) )
	{
		// add latency
		LocalCycleCount += ( c_ullLatency - 2 ) >> 1;
	}
#endif

	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
#ifdef USE_NEW_SQRT_S_CODE
		case 1:

			e->movd1_regmem(RAX, (int32_t*)&r->CPR1[i.Ft].s);
			//e->movd1_regmem(RCX, (int32_t*)&vt.uw0);

			// make constant multiplier
			e->MovReg64ImmX(RAX, (1023ull + 896ull) << 52);
			e->movq_to_sse128(RBX, RAX);

			// make adjustment
			e->MovReg64ImmX(RAX, 3ull << 25);
			e->movq_to_sse128(RDX, RAX);

			// get initial I-flag ->r5
			e->psrad1regimm(5, RAX, 31);

			// cvt float to double
			e->psllq1regimm(RAX, RAX, 33);
			e->psrlq1regimm(RAX, RAX, 4);
			//e->psllq1regimm(RCX, RCX, 33);
			//e->psrlq1regimm(RCX, RCX, 4);


			// multiply with multiplier
			e->vmulsd(RAX, RAX, RBX);


			// check for zero ->r4
			e->pxor1regreg(4, 4, 4);
			e->pcmpeqq1regreg(4, 4, RAX);

			// only set I-flag if negative number not zero ?
			e->pandn1regreg(5, 4, 5);


			// get final I-flag ->rcx
			e->movd_from_sse128(RCX, 5);


			// sqrt
			e->vsqrtsd(RAX, RAX);

			// adjust result
			e->paddq1regreg(RAX, RAX, RDX);

			// get result
			e->cvtsd2ss1regreg(RAX, RAX);

			// store result
			e->movd1_memreg((int32_t*)&r->CPR1[i.Fd].s, RAX);

			// get flags
			e->MovRegMem32(RAX, (int32_t*)&r->CPC1[31]);
			e->AndReg32ImmX(RCX, 0x20040);
			e->AndReg32ImmX(RAX, ~0x30000);
			e->OrRegReg32(RAX, RCX);
			ret = e->MovMemReg32((int32_t*)&r->CPC1[31], RAX);

			/*
			// clear bits 16 and 17 in the flag register first
			e->AndMem32ImmX ( &r->CPC1 [ 31 ], ~0x00030000 );
			
			// flush ps2 float to zero
			e->MovRegMem32 ( RAX, &r->CPR1 [ i.Ft ].s );
			e->MovReg64ImmX ( RCX, 896ULL << 23 );
			
			// get flags
			e->Cdq();
			e->AndReg32ImmX ( RDX, 0x20040 );
			
			
			e->AndReg32ImmX ( RAX, 0x7fffffff );
			e->LeaRegRegReg64 ( 8, RAX, RCX );
			e->AndReg32ImmX ( RAX, 0x7f800000 );
			e->CmovERegReg32 ( RDX, RAX );
			e->CmovNERegReg64 ( RAX, 8 );
			e->ShlRegImm64 ( RAX, 29 );
			
			
			// set flags
			e->OrMemReg32 ( &r->CPC1 [ 31 ], RDX );
			
			
			// move the registers now to floating point unit
			e->movq_to_sse ( RAX, RAX );
			//e->movq_to_sse ( RCX, RDX );
			
			
			// sqrt
			e->sqrtsd ( RAX, RAX );
			e->movq_from_sse ( RAX, RAX );
			
			// ??
			e->AddReg64ImmX ( RAX, 0x10000000 );
			
			
			
			// shift back down without sign
			e->ShrRegImm64 ( RAX, 29 );
			
			// if zero, then clear RCX
			e->CmovERegReg64 ( RCX, RAX );
			
			// subtract exponent
			e->SubRegReg64 ( RAX, RCX );
			
			
			// set result
			ret = e->MovMemReg32 ( &r->CPR1 [ i.Fd ].s, RAX );
			*/

			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}


int32_t R5900::Recompiler::RSQRT_S ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "RSQRT_S";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::RSQRT_S;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
#ifdef ENABLE_FPU_LATENCY
	static constexpr uint64_t c_ullLatency = 14;
	
	// check if next instruction uses dest from this one
	if ( ( 1ull << i.Fd ) & GetCop1_SrcRegs( NextInst ) )
	{
		// add latency
		LocalCycleCount += ( c_ullLatency - 2 ) >> 1;
	}
#endif

	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
			
#ifdef USE_NEW_RSQRT_S_CODE
		case 1:
			/*
			// clear bits 14 and 15 in the flag register first
			e->AndMem32ImmX ( &r->CPC1 [ 31 ], ~0x00030000 );
			
			// flush ps2 float to zero
			e->MovRegMem32 ( RAX, &r->CPR1 [ i.Ft ].s );
			e->XorRegReg32 ( 11, 11 );
			e->MovReg64ImmX ( RCX, 896ULL << 23 );
			
			// get flags
			e->Cdq();
			e->AndReg32ImmX ( RDX, 0x20040 );
			
			e->AndReg32ImmX ( RAX, 0x7fffffff );
			//e->LeaRegRegReg64 ( 8, RAX, RCX );
			e->AddRegReg64 ( RCX, RAX );
			e->AndReg32ImmX ( RAX, 0x7f800000 );
			e->MovReg32ImmX ( 8, 0x10020 );
			e->CmovNERegReg32 ( 8, RDX );
			e->CmovNERegReg64 ( RAX, RCX );
			e->ShlRegImm64 ( RAX, 29 );
			
			// set flags
			e->OrMemReg32 ( &r->CPC1 [ 31 ], 8 );
			
			// move the registers now to floating point unit
			e->movq_to_sse ( RAX, RAX );
			//e->movq_to_sse ( RCX, RDX );
			
			// sqrt
			e->sqrtsd(RCX, RAX);

			e->MovRegMem32 ( RAX, &r->CPR1 [ i.Fs ].s );
			//e->MovRegReg32 ( RCX, RAX );
			e->Cdq ();
			e->AndReg32ImmX ( RAX, 0x7fffffff );
			//e->LeaRegRegReg64 ( RDX, RAX, RCX );
			e->TestReg32ImmX ( RAX, 0x7f800000 );
			e->CmovERegReg64 ( RAX, 11 );
			//e->ShrRegImm32 ( 10, 31 );
			//e->ShlRegImm64 ( 10, 63 );
			e->ShlRegImm64 ( RAX, 29 );
			//e->OrRegReg64 ( RAX, 10 );
			e->movq_to_sse ( RAX, RAX );

			// divide
			e->divsd ( RAX, RCX );
			
			// get result
			e->movq_from_sse ( RAX, RAX );
			
			// shift back down without sign
			e->ShrRegImm64 ( RAX, 29 );
			
			// subtract exponent
			//e->XorRegReg32 ( 10, 10 );
			//e->MovRegReg32 ( RDX, RAX );
			//e->AndReg64ImmX ( RAX, ~0x007fffff );
			//e->SubRegReg64 ( RAX, RCX );
			e->TestReg32ImmX ( RAX, 0xff800000 );
			
			// clear on underflow or zero
			//e->CmovLERegReg32 ( RAX, 10 );
			//e->CmovLERegReg32 ( RDX, 10 );
			e->CmovERegReg32 ( RAX, 11 );
			
			
			// set to max on overflow
			e->MovReg32ImmX ( RCX, 0x7fffffff );
			//e->OrRegReg32 ( RDX, RDX );
			e->CmovSRegReg32 ( RAX, RCX );
			
			
			// or if any flags are set indicating denominator is zero
			e->AndReg32ImmX ( 8, 0x00020 );
			e->CmovNERegReg32 ( RAX, RCX );

			
			// set sign
			e->AndReg32ImmX ( RDX, 0x80000000 );
			e->OrRegReg32 ( RAX, RDX );
			
			// store result
			e->MovMemReg32 ( &r->CPR1 [ i.Fd ].s, RAX );		// &r->CPR1 [ i.Fd ].s, RAX );
			*/

			e->movd1_regmem(RAX, (int32_t*)&r->CPR1[i.Fs].s);
			e->movd1_regmem(RCX, (int32_t*)&r->CPR1[i.Ft].s);

			// make constant multiplier
			e->MovReg64ImmX(RAX, (1023ull + 896ull) << 52);
			e->movq_to_sse128(RBX, RAX);

			// check if ft(rcx) is zero (D flag) (ft=0) ->r5
			e->pxor1regreg(RDX, RDX, RDX);
			e->paddd1regreg(5, RCX, RCX);
			e->pcmpeqb1regreg(5, 5, RDX);

			// check if fs(rax) is zero -> r4
			e->paddd1regreg(4, RAX, RAX);
			e->pcmpeqb1regreg(4, 4, RDX);

			// check if both fs==0 and ft==0 ->r4
			e->pand1regreg(4, 4, 5);

			// get full flags
			e->pcmpgtd1regreg(4, RDX, 4);
			e->pcmpgtd1regreg(5, RDX, 5);

			// if fs and ft are both float zero, adjust fs
			e->psrld1regimm(4, 4, 1);
			e->por1regreg(RAX, RAX, 4);


			// get I-flag (ft(rcx)<0) ->r4
			e->pcmpgtd1regreg(4, RDX, RCX);
			e->pandn1regreg(4, 5, 4);

			// get flags for later
			e->movd_from_sse128(RCX, 4);
			e->movd_from_sse128(RDX, 5);

			// make constant adjustment
			e->MovReg64ImmX(RAX, 3ull << 25);
			e->movq_to_sse128(RDX, RAX);

			// make constant multiplier
			//e->MovReg64ImmX(RAX, 127ull << 52);
			//e->movq_to_sse128(4, RAX);

			// get I-flag (ft<0) ->rcx
			//e->psrad1regimm(5, RCX, 31);

			// cvt float to double
			e->psllq1regimm(RCX, RCX, 33);
			e->psrlq1regimm(RCX, RCX, 4);


			// multiply with multiplier
			e->vmulsd(RCX, RCX, RBX);


			// check if ft is zero (D flag) (ft=0) ->rdx
			//e->pxor1regreg(RBX, RBX, RBX);
			//e->pcmpeqq1regreg(RBX, RCX, RBX);

			// not less than zero if minus zero or zero
			//e->pandn1regreg(5, RBX, 5);

			//e->movd_from_sse128(RCX, 5);
			//e->movd_from_sse128(RDX, RBX);


			// sqrt
			e->vsqrtsd(RCX, RCX);

			// adjust result
			e->paddq1regreg(RCX, RCX, RDX);

			// get result
			e->cvtsd2ss1regreg(RCX, RCX);


			// save sign ->rdx
			e->psrad1regimm(RDX, RAX, 31);

			// make constant multiplier
			//e->MovReg64ImmX(RAX, 127ull << 52);
			e->MovReg64ImmX(RAX, 896ull << 23);
			e->movq_to_sse128(4, RAX);


			// convert sqrt back to double
			e->psllq1regimm(RAX, RAX, 33);
			e->psrlq1regimm(RAX, RAX, 4);
			e->psllq1regimm(RCX, RCX, 33);
			e->psrlq1regimm(RCX, RCX, 4);


			// divide
			e->vdivsd(RAX, RAX, RCX);


			// multiply with multiplier
			//e->vmulsd(RAX, RAX, 4);


			// adjust result
			//e->paddq1regreg(RAX, RAX, 4);

			// get result
			e->psrlq1regimm(RAX, RAX, 29);

			// offset exponent
			e->psubq1regreg(RAX, RAX, 4);

			// clear on underflow or zero
			e->pxor1regreg(5, 5, 5);
			e->pcmpgtq1regreg(4, 5, RAX);
			e->pandn1regreg(RAX, 4, RAX);

			// maximize on overflow
			e->pcmpeqb1regreg(5, 5, 5);
			e->psrlq1regimm(4, 5, 33);
			e->pcmpgtq1regreg(RBX, RAX, 4);
			e->por1regreg(RAX, RAX, RBX);
			e->pand1regreg(RAX, RAX, 4);


			// put sign in
			e->pandn1regreg(RDX, 4, RDX);
			e->por1regreg(RAX, RAX, RDX);

			// store result
			e->movd1_memreg((int32_t*)&r->CPR1[i.Fd].s, RAX);


			// get flags
			e->MovRegMem32(RAX, (int32_t*)&r->CPC1[31]);
			e->AndReg32ImmX(RCX, 0x20040);
			e->AndReg32ImmX(RDX, 0x10020);
			e->OrRegReg32(RCX, RDX);
			e->AndReg32ImmX(RAX, ~0x30000);
			e->OrRegReg32(RAX, RCX);
			e->MovMemReg32((int32_t*)&r->CPC1[31], RAX);

			
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}




int32_t R5900::Recompiler::MOV_S ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "MOV_S";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::MOV_S;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
#ifdef ENABLE_FPU_LATENCY
	static constexpr uint64_t c_ullLatency = 4;
	
	// check if next instruction uses dest from this one
	if ( ( 1ull << i.Fd ) & GetCop1_SrcRegs( NextInst ) )
	{
		// add latency
		LocalCycleCount += ( c_ullLatency - 2 ) >> 1;
	}
#endif

	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
#ifdef USE_NEW_MOV_S_CODE
		case 1:
			//r->CPR1 [ i.Fd ].s = r->CPR1 [ i.Fs ].u;
			// flags affected: none
			if ( i.Fd != i.Fs )
			{
				e->MovRegMem32 ( RAX, &r->CPR1 [ i.Fs ].s );
				ret = e->MovMemReg32 ( &r->CPR1 [ i.Fd ].s, RAX );
			}
			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::NEG_S ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "NEG_S";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::NEG_S;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
#ifdef ENABLE_FPU_LATENCY
	static constexpr uint64_t c_ullLatency = 4;
	
	// check if next instruction uses dest from this one
	if ( ( 1ull << i.Fd ) & GetCop1_SrcRegs( NextInst ) )
	{
		// add latency
		LocalCycleCount += ( c_ullLatency - 2 ) >> 1;
	}
#endif

	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
#ifdef USE_NEW_NEG_S_CODE
		case 1:
			//r->CPR1 [ i.Fd ].s = r->CPR1 [ i.Fs ].s ^ 0x80000000;
			// flags affected:
			// clears flags o,u (bits 14,15)
			//r->CPC1 [ 31 ] &= ~0x0000c000;
			if ( i.Fd == i.Fs )
			{
				e->XorMem32ImmX ( &r->CPR1 [ i.Fs ].s, 0x80000000 );
				ret = e->AndMem32ImmX ( &r->CPC1 [ 31 ], ~0x0000c000 );
			}
			else
			{
				e->MovRegMem32 ( RAX, &r->CPR1 [ i.Fs ].s );
				e->XorReg32ImmX ( RAX, 0x80000000 );
				e->MovMemReg32 ( &r->CPR1 [ i.Fd ].s, RAX );
				ret = e->AndMem32ImmX ( &r->CPC1 [ 31 ], ~0x0000c000 );
			}
			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}



int32_t R5900::Recompiler::SUBA_S ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "SUBA_S";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::SUBA_S;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
#ifdef USE_NEW_SUBA_S_CODE
		case 1:

			Generate_FADDp(e, i.Value);
			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::MADD_S ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "MADD_S";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::MADD_S;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
#ifdef ENABLE_FPU_LATENCY
	static constexpr uint64_t c_ullLatency = 4;
	
	// check if next instruction uses dest from this one
	if ( ( 1ull << i.Fd ) & GetCop1_SrcRegs( NextInst ) )
	{
		// add latency
		LocalCycleCount += ( c_ullLatency - 2 ) >> 1;
	}
#endif

	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
			
#ifdef USE_NEW_MADD_S_CODE
		case 1:

			Generate_FMADDp(e, i.Value);
			break;
#endif

			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}


int32_t R5900::Recompiler::MSUB_S ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "MSUB_S";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::MSUB_S;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
#ifdef ENABLE_FPU_LATENCY
	static constexpr uint64_t c_ullLatency = 4;
	
	// check if next instruction uses dest from this one
	if ( ( 1ull << i.Fd ) & GetCop1_SrcRegs( NextInst ) )
	{
		// add latency
		LocalCycleCount += ( c_ullLatency - 2 ) >> 1;
	}
#endif

	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;


#ifdef USE_NEW_MSUB_S_CODE
		case 1:

			Generate_FMADDp(e, i.Value);
			break;
#endif

			
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::MSUBA_S ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "MSUBA_S";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::MSUBA_S;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;


#ifdef USE_NEW_MSUBA_S_CODE
		case 1:

			Generate_FMADDp(e, i.Value);
			break;
#endif


			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::MADDA_S ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "MADDA_S";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::MADDA_S;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;


#ifdef USE_NEW_MADDA_S_CODE
		case 1:

			Generate_FMADDp(e, i.Value);
			break;
#endif


			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::CVT_W_S ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "CVT_W_S";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::CVT_W_S;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
#ifdef ENABLE_FPU_LATENCY
	static constexpr uint64_t c_ullLatency = 4;
	
	// check if next instruction uses dest from this one
	if ( ( 1ull << i.Fd ) & GetCop1_SrcRegs( NextInst ) )
	{
		// add latency
		LocalCycleCount += ( c_ullLatency - 2 ) >> 1;
	}
#endif

	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
#ifdef USE_NEW_CVT_W_S_CODE
		case 1:

			ret = Generate_FFTOIp(e, i.Value);
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::MAX_S ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "MAX_S";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::MAX_S;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
#ifdef ENABLE_FPU_LATENCY
	static constexpr uint64_t c_ullLatency = 4;
	
	// check if next instruction uses dest from this one
	if ( ( 1ull << i.Fd ) & GetCop1_SrcRegs( NextInst ) )
	{
		// add latency
		LocalCycleCount += ( c_ullLatency - 2 ) >> 1;
	}
#endif

	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
#ifdef USE_NEW_MAX_S_CODE
		case 1:

#define TEST_NEW_MAX_S_CODE
#ifdef TEST_NEW_MAX_S_CODE

			ret = Generate_FMAXp(e, i.Value);

#else

			//lfs = ( lfs >= 0 ) ? lfs : ~( lfs & 0x7fffffff );
			//lft = ( lft >= 0 ) ? lft : ~( lft & 0x7fffffff );
			// compare as integer and return original value?
			//fResult = ( ( lfs > lft ) ? fs : ft );
			e->MovRegMem32 ( RAX, &r->CPR1 [ i.Fs ].s );
			e->Cdq ();
			e->MovRegReg32 ( 9, RAX );
			//e->AndReg32ImmX ( RAX, 0x7fffffff );
			e->ShrRegImm32 ( RDX, 1 );
			e->XorRegReg32 ( RDX, RAX );
			e->MovRegReg32 ( RCX, RDX );
			e->MovRegMem32 ( RAX, &r->CPR1 [ i.Ft ].s );
			e->Cdq ();
			e->MovRegReg32 ( 8, RAX );
			//e->AndReg32ImmX ( RAX, 0x7fffffff );
			e->ShrRegImm32 ( RDX, 1 );
			e->XorRegReg32 ( RDX, RAX );
			e->CmpRegReg32 ( RCX, RDX );
			e->CmovGRegReg32 ( 8, 9 );
			e->MovMemReg32 ( &r->CPR1 [ i.Fd ].s, 8 );

#endif

			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::MIN_S ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "MIN_S";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::MIN_S;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
#ifdef ENABLE_FPU_LATENCY
	static constexpr uint64_t c_ullLatency = 4;
	
	// check if next instruction uses dest from this one
	if ( ( 1ull << i.Fd ) & GetCop1_SrcRegs( NextInst ) )
	{
		// add latency
		LocalCycleCount += ( c_ullLatency - 2 ) >> 1;
	}
#endif

	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
#ifdef USE_NEW_MIN_S_CODE
		case 1:

#define TEST_NEW_MIN_S_CODE
#ifdef TEST_NEW_MIN_S_CODE

			ret = Generate_FMINp(e, i.Value);

#else

			//lfs = ( lfs >= 0 ) ? lfs : ~( lfs & 0x7fffffff );
			//lft = ( lft >= 0 ) ? lft : ~( lft & 0x7fffffff );
			// compare as integer and return original value?
			//fResult = ( ( lfs < lft ) ? fs : ft );
			e->MovRegMem32 ( RAX, &r->CPR1 [ i.Fs ].s );
			e->Cdq ();
			e->MovRegReg32 ( 9, RAX );
			//e->AndReg32ImmX ( RAX, 0x7fffffff );
			e->ShrRegImm32 ( RDX, 1 );
			e->XorRegReg32 ( RDX, RAX );
			e->MovRegReg32 ( RCX, RDX );
			e->MovRegMem32 ( RAX, &r->CPR1 [ i.Ft ].s );
			e->Cdq ();
			e->MovRegReg32 ( 8, RAX );
			//e->AndReg32ImmX ( RAX, 0x7fffffff );
			e->ShrRegImm32 ( RDX, 1 );
			e->XorRegReg32 ( RDX, RAX );
			e->CmpRegReg32 ( RCX, RDX );
			e->CmovLRegReg32 ( 8, 9 );
			e->MovMemReg32 ( &r->CPR1 [ i.Fd ].s, 8 );

#endif

			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::C_F_S ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "C_F_S";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::C_F_S;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
#ifdef USE_NEW_C_F_S_CODE
		case 1:
			// clears bit 23 in FCR31
			//r->CPC1 [ 31 ] &= ~0x00800000;
			ret = e->AndMem32ImmX ( &r->CPC1 [ 31 ], ~0x00800000 );
			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::C_EQ_S ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "C_EQ_S";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::C_EQ_S;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
#ifdef USE_NEW_C_EQ_S_CODE
		case 1:
			//inline static int32_t FlushConvertToComparableInt_f ( float& f1 )
			//if ( ! ( lf1 & c_lFloat_ExpMask ) ) lf1 = 0;
			//if ( lf1 < 0 ) lf1 = -( lf1 & 0x7fffffff );
		
			//fs = r->CPR1 [ i.Fs ].f;
			//ft = r->CPR1 [ i.Ft ].f;
			//lfs = PS2Float::FlushConvertToComparableInt_f ( fs );
			//lft = PS2Float::FlushConvertToComparableInt_f ( ft );
			//if ( lfs == lft ) r->CPC1 [ 31 ] |= 0x00800000; else r->CPC1 [ 31 ] &= ~0x00800000;
			
			// clear the flag first
			e->AndMem32ImmX ( &r->CPC1 [ 31 ], ~0x00800000 );
			
			/*
			e->MovRegMem32 ( RAX, &r->CPR1 [ i.Ft ].s );
			e->MovRegReg32 ( RDX, RAX );
			e->AndReg32ImmX ( RAX, 0x7f800000 );
			e->CmovNERegReg32 ( RAX, RDX );
			*/
			e->MovRegMem32 ( RCX, &r->CPR1 [ i.Ft ].s );
			e->MovRegMem32 ( RAX, &r->CPR1 [ i.Fs ].s );
			
			e->MovRegReg32 ( RDX, RCX );
			e->AndReg32ImmX ( RCX, 0x7f800000 );
			e->CmovNERegReg32 ( RCX, RDX );
			//e->Cdq ();
			//e->AndReg32ImmX ( RAX, 0x7fffffff );
			//e->XorRegReg32 ( RAX, RDX );

			//e->MovRegReg32 ( RCX, RAX );

			e->MovRegReg32 ( RDX, RAX );
			e->AndReg32ImmX ( RAX, 0x7f800000 );
			e->CmovNERegReg32 ( RAX, RDX );
			//e->Cdq ();
			//e->AndReg32ImmX ( RAX, 0x7fffffff );
			//e->XorRegReg32 ( RAX, RDX );
			
			e->CmpRegReg32 ( RAX, RCX );
			e->Set_E ( RAX );
			e->Cbw ();
			e->ShlRegImm32 ( RAX, 23 );
			ret = e->OrMemReg32 ( &r->CPC1 [ 31 ], RAX );
			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::C_LT_S ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "C_LT_S";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::C_LT_S;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
#ifdef USE_NEW_C_LT_S_CODE
		case 1:
			//inline static int32_t FlushConvertToComparableInt_f ( float& f1 )
			//if ( ! ( lf1 & c_lFloat_ExpMask ) ) lf1 = 0;
			//if ( lf1 < 0 ) lf1 = -( lf1 & 0x7fffffff );
		
			//fs = r->CPR1 [ i.Fs ].f;
			//ft = r->CPR1 [ i.Ft ].f;
			//lfs = PS2Float::FlushConvertToComparableInt_f ( fs );
			//lft = PS2Float::FlushConvertToComparableInt_f ( ft );
			//if ( lfs < lft ) r->CPC1 [ 31 ] |= 0x00800000; else r->CPC1 [ 31 ] &= ~0x00800000;
			
			// clear the flag first
			e->AndMem32ImmX ( &r->CPC1 [ 31 ], ~0x00800000 );

			e->MovRegMem32 ( RAX, &r->CPR1 [ i.Ft ].s );
			e->MovRegReg32 ( RDX, RAX );
			e->AndReg32ImmX ( RAX, 0x7f800000 );
			e->CmovNERegReg32 ( RAX, RDX );
			e->Cdq ();
			//e->AndReg32ImmX ( RAX, 0x7fffffff );
			e->ShrRegImm32 ( RDX, 1 );
			e->XorRegReg32 ( RAX, RDX );
			
			e->MovRegReg32 ( RCX, RAX );

			e->MovRegMem32 ( RAX, &r->CPR1 [ i.Fs ].s );
			e->MovRegReg32 ( RDX, RAX );
			e->AndReg32ImmX ( RAX, 0x7f800000 );
			e->CmovNERegReg32 ( RAX, RDX );
			e->Cdq ();
			//e->AndReg32ImmX ( RAX, 0x7fffffff );
			e->ShrRegImm32 ( RDX, 1 );
			e->XorRegReg32 ( RAX, RDX );
			
			//e->XorRegReg32 ( RDX, RDX );
			e->CmpRegReg32 ( RAX, RCX );
			//e->MovReg32ImmX ( RCX, 0x00800000 );
			e->Set_L ( RAX );
			e->Cbw ();
			e->ShlRegImm32 ( RAX, 23 );
			//e->MovMemReg32 ( &r->testvar [ 7 ], RAX );

			//e->NegReg32 ( RDX );
			//e->AndReg32ImmX ( RDX, 0x00800000 );
			//e->CmovLRegReg32 ( RDX, RCX );
			ret = e->OrMemReg32 ( &r->CPC1 [ 31 ], RAX );
			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::C_LE_S ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "C_LE_S";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::C_LE_S;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
#ifdef USE_NEW_C_LE_S_CODE
		case 1:
			//inline static int32_t FlushConvertToComparableInt_f ( float& f1 )
			//if ( ! ( lf1 & c_lFloat_ExpMask ) ) lf1 = 0;
			//if ( lf1 < 0 ) lf1 = -( lf1 & 0x7fffffff );
		
			//fs = r->CPR1 [ i.Fs ].f;
			//ft = r->CPR1 [ i.Ft ].f;
			//lfs = PS2Float::FlushConvertToComparableInt_f ( fs );
			//lft = PS2Float::FlushConvertToComparableInt_f ( ft );
			//if ( lfs <= lft ) r->CPC1 [ 31 ] |= 0x00800000; else r->CPC1 [ 31 ] &= ~0x00800000;
			
			// clear the flag first
			e->AndMem32ImmX ( &r->CPC1 [ 31 ], ~0x00800000 );

			e->MovRegMem32 ( RAX, &r->CPR1 [ i.Ft ].s );
			e->MovRegReg32 ( RDX, RAX );
			e->AndReg32ImmX ( RAX, 0x7f800000 );
			e->CmovNERegReg32 ( RAX, RDX );
			e->Cdq ();
			//e->AndReg32ImmX ( RAX, 0x7fffffff );
			e->ShrRegImm32 ( RDX, 1 );
			e->XorRegReg32 ( RAX, RDX );
			
			e->MovRegReg32 ( RCX, RAX );

			e->MovRegMem32 ( RAX, &r->CPR1 [ i.Fs ].s );
			e->MovRegReg32 ( RDX, RAX );
			e->AndReg32ImmX ( RAX, 0x7f800000 );
			e->CmovNERegReg32 ( RAX, RDX );
			e->Cdq ();
			//e->AndReg32ImmX ( RAX, 0x7fffffff );
			e->ShrRegImm32 ( RDX, 1 );
			e->XorRegReg32 ( RAX, RDX );
			
			e->CmpRegReg32 ( RAX, RCX );
			e->Set_LE ( RAX );
			e->Cbw ();
			e->ShlRegImm32 ( RAX, 23 );
			ret = e->OrMemReg32 ( &r->CPC1 [ 31 ], RAX );
			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}



// * COP2 (VU0) instrutions * //



// PS2 has LQC2/SQC2 instead of LWC2/SWC2 //
int32_t R5900::Recompiler::LQC2 ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "LQC2";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::LQC2;
	
	int ret = 1;
	
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

#ifdef ENABLE_R5900_DCACHE
			e->AddMemImm64 ( (int64_t*) & r->CycleCount, LocalCycleCount - MemCycles );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );

#ifdef ENABLE_R5900_DCACHE
			e->SubMemImm64 ( (int64_t*) & r->CycleCount, LocalCycleCount - MemCycles );
#endif
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_LQC2_CODE
		case 1:

#ifdef ENABLE_PS2_VIRTUAL_MACHINE_LQC2

			if (!bitget_hwrw_bitmap(Address))
			{
				ret = Generate_Virtual_Load(i, Address, 0xf, (void*)Playstation2::DataBus::Read_t<0>);
			}
			else
			{
				ret = Generate_Basic_Load(i, Address, 0xf, (void*)Playstation2::DataBus::Read_t<0>);
			}
#else

			ret = Generate_Normal_Load(i, Address, 0xf, (void*)Playstation2::DataBus::Read_t<0>);
#endif

			// store result //
			
			if ( i.Ft )
			{
				// store
				ret = e->movdqa_memreg ( & VU0::_VU0->vf [ i.Ft ].sq0, RAX );
			}
			
			break;
#endif

			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::SQC2 ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "SQC2";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::SQC2;
	
	int ret = 1;
	
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

#ifdef ENABLE_R5900_DCACHE
			e->AddMemImm64 ( (int64_t*) & r->CycleCount, LocalCycleCount - MemCycles );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );

#ifdef ENABLE_R5900_DCACHE
			e->SubMemImm64 ( (int64_t*) & r->CycleCount, LocalCycleCount - MemCycles );
#endif
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
#ifdef USE_NEW_SQC2_CODE
		case 1:
#ifdef ENABLE_PS2_VIRTUAL_MACHINE_SQC2
			if (!bitget_hwrw_bitmap(Address))
			{
				ret = Generate_Virtual_Store(i, Address, 0xf, (void*)Playstation2::DataBus::Write_t<0>);
			}
			else
#endif
			{
				ret = Generate_Normal_Store(i, Address, 0xf, (void*)Playstation2::DataBus::Write_t<0>);
			}


			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}


int32_t R5900::Recompiler::QMFC2_NI ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "QMFC2_NI";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::QMFC2_NI;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_QMFC2_NI_CODE
		case 1:
			if ( i.Rt )
			{
				switch ( i.Rd )
				{
					case 0:
						e->MovMemImm64 ( &r->GPR [ i.Rt ].sq0, 0 );
						e->MovMemImm64 ( &r->GPR [ i.Rt ].sq1, 0 );
						e->MovMemImm32 ( &r->GPR [ i.Rt ].sw3, 0x3f800000 );
						break;
						
					default:
						e->movdqa_regmem ( RAX, &VU0::_VU0->vf [ i.Rd ].s );
						e->movdqa_memreg ( &r->GPR [ i.Rt ].s, RAX );
						break;
				}
			}
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::QMFC2_I ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "QMFC2_I";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::QMFC2_I;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// should assume NextPC might get modified
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::QMTC2_NI ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "QMTC2_NI";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::QMTC2_NI;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_QMTC2_NI_CODE
		case 1:
			if ( i.Rd )
			{
				switch ( i.Rt )
				{
					case 0:
						e->pxorregreg ( RAX, RAX );
						e->movdqa_memreg ( &VU0::_VU0->vf [ i.Rd ].s, RAX );
						break;
						
					default:
						e->movdqa_regmem ( RAX, &r->GPR [ i.Rt ].s );
						e->movdqa_memreg ( &VU0::_VU0->vf [ i.Rd ].s, RAX );
						break;
				}
			}
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::QMTC2_I ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "QMTC2_I";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::QMTC2_I;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// should assume NextPC might get modified
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}



int32_t R5900::Recompiler::Generate_VPrefix ( u32 Address )
{
	int32_t ret;
	
	ret = 1;

#ifdef ENABLE_VIRTUAL_MACHINE_MACRO_RUN

	if (!bitget_macro_bitmap(Address))
	{
		e->MovRegMem32(RAX, (int32_t*)&VU0::_VU0->VifRegs.STAT.Value);
		e->AndReg32ImmX(RAX, 4);
		e->ShlRegImm64(RAX, 36-2);
		e->MovRegFromMem32(RAX, RAX, NO_INDEX, SCALE_NONE, (int32_t)&r->NextPC);
	}
	else
#endif	// end #ifdef ENABLE_VIRTUAL_MACHINE_MACRO_MODE
	{
		//if ( VU0::_VU0->VifRegs.STAT.VEW )
		//{
		//	// vu#0 is running //
		e->BtMemImm32((int32_t*)&VU0::_VU0->VifRegs.STAT.Value, 2);

#ifdef USE_NEW_VPREFIX_SEQUENCE_R5900

		e->MovRegImm32(RCX, Address);
		e->MovRegImm32(RDX, LocalCycleCount);
		e->JMP_B((void*)Exit_Recompiler);

#else
		e->Jmp8_AE(0, 0);

#ifdef ENABLE_FORCE_VU0_COMPLETION
		// set to force vu0 to finish first
		e->MovMemImm8((char*)&r->Status.Force_Vu0_Finish, 1);
#endif
		
		//	// don't go anywhere until it is done for now
		//	r->NextPC = r->PC;
		e->MovMemImm32((int32_t*)&r->NextPC, Address);

		// update CPU CycleCount
		//e->AddMem64ImmX ( (int64_t*) & r->CycleCount, LocalCycleCount - MemCycles );
		e->AddMem64ImmX((int64_t*)&r->CycleCount, LocalCycleCount);

		// done for now - return
		ret = e->Ret();

		//}

		e->SetJmpTarget8(0);
#endif
	}

	return ret;
}

int32_t R5900::Recompiler::Generate_VABSp ( R5900::Instruction::Format i )
{
	int32_t ret;
	
	ret = 1;
	
	if ( i.Ft && i.xyzw )
	{
		if ( !i.Fs )
		{
			e->movdqa_regmem ( RCX, & VU0::_VU0->vf [ i.Fs ].sw0 );
			
		}
		else
		{
			e->movdqa_regmem(RCX, &VU0::_VU0->vf[i.Fs].sw0);

			//e->pslldregimm ( RCX, 1 );
			e->padddregreg(RCX, RCX);
			e->psrldregimm(RCX, 1);

		}

#ifdef USE_NEW_VECTOR_DISPATCH_VABS_R5900

		ret = Dispatch_Result_AVX2(i, false, RCX, i.Ft);

#else

		if (i.xyzw != 0xf)
		{
			//e->pblendwregregimm ( RCX, RAX, ~( ( i.destx * 0x03 ) | ( i.desty * 0x0c ) | ( i.destz * 0x30 ) | ( i.destw * 0xc0 ) ) );
			e->pblendwregmemimm(RCX, &VU0::_VU0->vf[i.Ft].sw0, ~((i.destx * 0x03) | (i.desty * 0x0c) | (i.destz * 0x30) | (i.destw * 0xc0)));
		}

		ret = e->movdqa_memreg(&VU0::_VU0->vf[i.Ft].sw0, RCX);

#endif

	}
	
	return ret;
}




int32_t R5900::Recompiler::Generate_VMAXp ( R5900::Instruction::Format i, u32 *pFt, u32 FtComponent )
{
	//lfs = ( lfs >= 0 ) ? lfs : ~( lfs & 0x7fffffff );
	//lft = ( lft >= 0 ) ? lft : ~( lft & 0x7fffffff );
	// compare as integer and return original value?
	//fResult = ( ( lfs > lft ) ? fs : ft );
	int32_t ret;
	
	ret = 1;
	
	
	if (i.Fd && i.xyzw)
	{
		e->movdqa_regmem(RBX, &VU0::_VU0->vf[i.Fs].sw0);

		if (!pFt)
		{
			e->movdqa_regmem(RCX, &VU0::_VU0->vf[i.Ft].sw0);
		}
		else
		{
			e->movd_regmem(RCX, (int32_t*)pFt);
		}

		/*
		e->movdqa_regreg ( RDX, RBX );
		e->movdqa_regreg ( 4, RBX );
		e->pslldregimm ( RDX, 1 );
		e->psrldregimm ( RDX, 1 );
		e->psradregimm ( 4, 31 );
		e->pxorregreg ( RDX, 4 );
		*/
		e->movdqa_regreg(RDX, RBX);
		//e->movdqa_regreg ( 4, RBX );
		//e->pslldregimm ( RDX, 1 );
		e->psradregimm(RDX, 31);
		e->psrldregimm(RDX, 1);
		e->pxorregreg(RDX, RBX);

		if (pFt)
		{
			// need to "broadcast" the value in sse ??
			e->pshufdregregimm(RCX, RCX, 0);
		}

		/*
		e->movdqa_regreg ( RAX, RCX );
		e->movdqa_regreg ( 4, RCX );
		e->pslldregimm ( RAX, 1 );
		e->psrldregimm ( RAX, 1 );
		e->psradregimm ( 4, 31 );
		e->pxorregreg ( RAX, 4 );
		*/
		e->movdqa_regreg(RAX, RCX);
		//e->movdqa_regreg ( 4, RCX );
		//e->pslldregimm ( RAX, 1 );
		e->psradregimm(RAX, 31);
		e->psrldregimm(RAX, 1);
		e->pxorregreg(RAX, RCX);

		e->pcmpgtdregreg(RAX, RDX);
		e->pblendvbregreg(RBX, RCX);

#ifdef USE_NEW_VECTOR_DISPATCH_VMAX_R5900

		ret = Dispatch_Result_AVX2(i, false, RBX, i.Fd);

#else
		if (i.xyzw != 0xf)
		{
			//e->pblendwregregimm ( RBX, 5, ~( ( i.destx * 0x03 ) | ( i.desty * 0x0c ) | ( i.destz * 0x30 ) | ( i.destw * 0xc0 ) ) );
			e->pblendwregmemimm(RBX, &VU0::_VU0->vf[i.Fd].sw0, ~((i.destx * 0x03) | (i.desty * 0x0c) | (i.destz * 0x30) | (i.destw * 0xc0)));
		}

		ret = e->movdqa_memreg(&VU0::_VU0->vf[i.Fd].sw0, RBX);
#endif
	}
	
	
	return ret;
}



int32_t R5900::Recompiler::Generate_VMINp ( R5900::Instruction::Format i, u32 *pFt, u32 FtComponent )
{
	//lfs = ( lfs >= 0 ) ? lfs : ~( lfs & 0x7fffffff );
	//lft = ( lft >= 0 ) ? lft : ~( lft & 0x7fffffff );
	// compare as integer and return original value?
	//fResult = ( ( lfs > lft ) ? fs : ft );
	int32_t ret;
	
	ret = 1;
	
	if ( i.Fd && i.xyzw )
	{
		e->movdqa_regmem ( RBX, & VU0::_VU0->vf [ i.Fs ].sw0 );
		
		if ( !pFt )
		{
			e->movdqa_regmem ( RCX, & VU0::_VU0->vf [ i.Ft ].sw0 );
		}
		else
		{
			e->movd_regmem( RCX, (int32_t*) pFt );
		}
				
		/*
		e->movdqa_regreg ( RAX, RBX );
		e->movdqa_regreg ( 4, RBX );
		e->pslldregimm ( RAX, 1 );
		e->psrldregimm ( RAX, 1 );
		e->psradregimm ( 4, 31 );
		e->pxorregreg ( RAX, 4 );
		*/
		e->movdqa_regreg ( RAX, RBX );
		//e->movdqa_regreg ( 4, RBX );
		//e->pslldregimm ( RAX, 1 );
		e->psradregimm ( RAX, 31 );
		e->psrldregimm ( RAX, 1 );
		e->pxorregreg ( RAX, RBX );

		if ( pFt )
		{
			// need to "broadcast" the value in sse ??
			e->pshufdregregimm ( RCX, RCX, 0 );
		}
		
		/*
		e->movdqa_regreg ( RDX, RCX );
		e->movdqa_regreg ( 4, RCX );
		e->pslldregimm ( RDX, 1 );
		e->psrldregimm ( RDX, 1 );
		e->psradregimm ( 4, 31 );
		e->pxorregreg ( RDX, 4 );
		*/
		e->movdqa_regreg ( RDX, RCX );
		//e->movdqa_regreg ( 4, RCX );
		//e->pslldregimm ( RDX, 1 );
		e->psradregimm ( RDX, 31 );
		e->psrldregimm ( RDX, 1 );
		e->pxorregreg ( RDX, RCX );
		
		e->pcmpgtdregreg ( RAX, RDX );
		e->pblendvbregreg ( RBX, RCX );
		
#ifdef USE_NEW_VECTOR_DISPATCH_VMIN_R5900

		ret = Dispatch_Result_AVX2(i, false, RBX, i.Fd);

#else

		if ( i.xyzw != 0xf )
		{
			//e->pblendwregregimm ( RBX, 5, ~( ( i.destx * 0x03 ) | ( i.desty * 0x0c ) | ( i.destz * 0x30 ) | ( i.destw * 0xc0 ) ) );
			e->pblendwregmemimm ( RBX, & VU0::_VU0->vf [ i.Fd ].sw0, ~( ( i.destx * 0x03 ) | ( i.desty * 0x0c ) | ( i.destz * 0x30 ) | ( i.destw * 0xc0 ) ) );
		}
		
		ret = e->movdqa_memreg ( & VU0::_VU0->vf [ i.Fd ].sw0, RBX );
#endif
	}
	
	
	return ret;
}


int32_t R5900::Recompiler::Generate_FFTOIp(x64Encoder* e, u32 i0)
{
	int32_t ret;

	R5900::Instruction::Format i, ii0;

	u64 start, end, addr;

	u32 Address = e->x64CurrentSourceAddress;

	i.Value = i0;

	ii0.Value = i0;

	ret = 1;

	if (iVectorType == VECTOR_TYPE_AVX2)
	{

		//e->movdqa1_regmem(RAX, &v->vf[i.Fs].sw0);
		e->movd1_regmem(RAX, &r->CPR1[i.Fs].s);

#ifdef USE_NEW_FFTOIX_AVX2_R5900

		e->cvttps2dq1regreg(RCX, RAX);
		e->pxor1regreg(RDX, RAX, RCX);
		e->psrld1regimm(RDX, RDX, 31);
		e->psignd1regreg(RDX, RDX, RCX);
		e->psubd1regreg(RAX, RCX, RDX);

#else

		// make mask -> R5
		//e->pcmpeqb1regreg(5, 5, 5);

		// make sure exp is less or equal to 0x4e800000
		e->MovReg32ImmX(RAX, 0x9d);
		e->movd_to_sse128(RBX, RAX);
		//e->pshufd1regregimm(RBX, RBX, 0);

		// make sure value in range
		e->paddd1regreg(RCX, RAX, RAX);
		e->psrld1regimm(RCX, RCX, 24);
		e->pcmpgtd1regreg(RCX, RCX, RBX);

		// save sign and clear if outside range
		e->psrld1regimm(RDX, RAX, 31);
		e->pandn1regreg(RAX, RCX, RAX);
		e->pand1regreg(RDX, RDX, RCX);

		// make mask
		e->psrld1regimm(RCX, RCX, 1);
		e->paddd1regreg(RDX, RDX, RCX);

		// convert to int -> RCX
		//e->cvttss2si1regreg(RCX, RAX);
		e->cvttps2dq1regreg(RCX, RAX);

		// or with mask
		e->por1regreg(RAX, RCX, RDX);

#endif

		// get result
		ret = e->movd1_memreg((int32_t*)&r->CPR1[i.Fd].s, RAX);

	}	// end if (iVectorType == VECTOR_TYPE_AVX2)

	return ret;
}


int32_t R5900::Recompiler::Generate_FITOFp(x64Encoder* e, u32 i0)
{
	int32_t ret;

	R5900::Instruction::Format i, ii0;

	i.Value = i0;

	ii0.Value = i0;

	ret = 1;

	if (iVectorType == VECTOR_TYPE_AVX2)
	{
		//e->movd1_regmem(RAX, &r->CPR1[i.Fs].s);

		// convert to float
		//e->cvtdq2ps1regreg(RAX, RAX);
		e->cvtsi2ss1regmem(RAX, RAX, &r->CPR1[i.Fs].s);


		// store result
		ret = e->movd1_memreg((int32_t*)&r->CPR1[i.Fd].s, RAX);

	}	// end if (iVectorType == VECTOR_TYPE_AVX2)

	return ret;
}


int32_t R5900::Recompiler::Generate_FMINp(x64Encoder* e, u32 i0)
{
	int32_t ret;

	R5900::Instruction::Format i, ii0;

	i.Value = i0;

	ii0.Value = i0;

	ret = 1;

	if (iVectorType == VECTOR_TYPE_AVX2)
	{
		//e->movdqa1_regmem(RBX, &v->vf[i.Fs].sw0);
		e->movd1_regmem(RBX, &r->CPR1[i.Fs].s);
		e->movd1_regmem(RCX, &r->CPR1[i.Ft].s);

		//e->movdqa_regreg(RAX, RBX);
		e->psrad1regimm(RAX, RBX, 31);
		e->psrld1regimm(RAX, RAX, 1);
		e->pxor1regreg(RAX, RAX, RBX);

		//e->movdqa_regreg(RDX, RCX);
		e->psrad1regimm(RDX, RCX, 31);
		e->psrld1regimm(RDX, RDX, 1);
		e->pxor1regreg(RDX, RDX, RCX);

		e->pcmpgtd1regreg(RAX, RAX, RDX);
		e->pblendvb1regreg(RBX, RBX, RCX, RAX);

		//ret = e->movdqa1_memreg(&v->vf[i.Fd].sw0, RBX);
		ret = e->movd1_memreg((int32_t*)&r->CPR1[i.Fd].s, RBX);

	}	// end if (iVectorType == VECTOR_TYPE_AVX2)

	return ret;
}


int32_t R5900::Recompiler::Generate_FMAXp(x64Encoder* e, u32 i0)
{
	int32_t ret;

	R5900::Instruction::Format i, ii0;

	i.Value = i0;

	ii0.Value = i0;

	ret = 1;

	if (iVectorType == VECTOR_TYPE_AVX2)
	{
		//e->movdqa1_regmem(RBX, &v->vf[i.Fs].sw0);
		e->movd1_regmem(RBX, &r->CPR1[i.Fs].s);
		e->movd1_regmem(RCX, &r->CPR1[i.Ft].s);


		//e->movdqa_regreg(RDX, RBX);
		e->psrad1regimm(RDX, RBX, 31);
		e->psrld1regimm(RDX, RDX, 1);
		e->pxor1regreg(RDX, RDX, RBX);

		//e->movdqa_regreg(RAX, RCX);
		e->psrad1regimm(RAX, RCX, 31);
		e->psrld1regimm(RAX, RAX, 1);
		e->pxor1regreg(RAX, RAX, RCX);

		e->pcmpgtd1regreg(RAX, RAX, RDX);
		e->pblendvb1regreg(RBX, RBX, RCX, RAX);

		//ret = e->movdqa1_memreg(&v->vf[i.Fd].sw0, RBX);
		ret = e->movd1_memreg((int32_t*)&r->CPR1[i.Fd].s, RBX);

	}	// end if (iVectorType == VECTOR_TYPE_AVX2)

	return ret;
}




int32_t R5900::Recompiler::Generate_FMADDp(x64Encoder* e, u32 i0, u32 i1, u32 i2, u32 i3)
{
	static constexpr int64_t max_double_float = 0x47ffffffe0000000ull;

	static constexpr int64_t max_double = 0x47ffffffffffffffull;
	static constexpr int64_t min_double = 0x3800000000000000ull;

	static constexpr int64_t test_ovf_double = 0x47ffffffe0000000ull;


	static constexpr int64_t bit1_double = 0x0010000000000000ull;
	static constexpr int64_t bit1_double_mask = 0x4000000000000000ull;
	static constexpr int32_t bit1_float = 0x00800000;
	static constexpr int32_t bit1_float_mask = 0x40000000;

	static constexpr int64_t flt_double_mask = 0xffffffffe0000000ull;
	static constexpr int64_t ps2_mul1_double_mask = 0xffffffffc0000000ull;

	static constexpr int64_t mantissa_double_mask = 0xfffffe0000000000ull;

	static constexpr int64_t zero_double = 0ull;

	static constexpr int32_t ovf_float_flag = 0x8010;
	static constexpr int32_t und_float_flag = 0x4008;
	static constexpr int32_t sticky_und_float_flag = 0x0008;
	static constexpr int32_t sticky_flag_mask = ~0xc000;

	int32_t ret;

	R5900::Instruction::Format i, ii0, ii1, ii2, ii3;

	u64 start, end, addr;

	u32 Address = e->x64CurrentSourceAddress;

	i.Value = i0;

	ii0.Value = i0;
	ii1.Value = i1;
	ii2.Value = i2;
	ii3.Value = i3;


	ret = 1;

//#define ALLOW_AVX2_FMADDX4
#ifdef ALLOW_AVX2_FMADDX4
	if (iVectorType == VECTOR_TYPE_AVX512)
#endif
	{
		e->movd_to_sse_rm128(RAX, (int32_t*)&r->CPR1[i.Fs].s);
		e->vinsertd_rmi128(RAX, RAX, (void*)&r->CPR1[i.Ft].s, 1);

		// also load acc here
		e->vinsertd_rmi128(RAX, RAX, (void*)&r->dACC.l, 2);

		e->vptestmd_rrb128(2, RAX, (int32_t*)&bit1_float_mask);
		e->psubd_rrb128(RAX, RAX, (int32_t*)&bit1_float, 2);
		e->cvtps2pd_rr256(RAX, RAX);
		//e->paddq_rrb128(RAX, RAX, (int64_t*)&bit1_double, 2);
		e->paddq_rrb256(RAX, RAX, (int64_t*)&bit1_double, 2);
		e->pshufd_rri128(RCX, RAX, 0x0e);

		// put acc into r5
		e->vextracti32x4_rri256(5, RAX, 1);


		// TESTING
		//e->movdqa32_mr128((void*)&v1.uq0, RAX);

		// testing
		//e->movq_to_x64_mr128((int64_t*)&v1.uq0, RAX);
		//e->movq_to_x64_mr128((int64_t*)&v1.uq1, 5);
		//e->vextracti32x4_mri256((void*)&v1.uq0, RAX, 1);



#define ENABLE_MUL_INACCURACY_AVX3
#ifdef ENABLE_MUL_INACCURACY_AVX3

	// do x*y adjustment here
	//e->vpternlogd_rrr128(5, 5, 5, 0xff);
	//e->psrld_rri128(4, 5, 9);
	//e->pand_rrr128(RDX, RCX, 4);
	//e->vpcmpdeq_rrr128(2, RDX, 4);
	//e->paddd_rrr128(RCX, RCX, 5, 2);

		e->psllq_rri128(RDX, RCX, 12);
		e->vpcmpqeq_rrb128(2, RDX, (int64_t*)&mantissa_double_mask);
		e->pandq_rrb128(RCX, RCX, (int64_t*)&ps2_mul1_double_mask, 2);

#endif


		e->vmulsd_rrr128(RAX, RAX, RCX);


		// testing
		//e->movq_to_x64_mr128((int64_t*)&v2.uq0, RAX);


		e->vrangesd_rmi64(RBX, RAX, (void*)&max_double, 2);
		//e->vrangesd_rmi64(RCX, RAX, (void*)&min_double, 2);
		e->cvtsd2ss_rr64(RCX, RAX);


		// testing
		//e->movq_to_x64_mr128((int64_t*)&v3.uq0, RAX);
		//e->movq_to_x64_mr128((int64_t*)&v3.uq1, RBX);


		// overflow -> k2
		e->cmpsdne_rrr128(2, RAX, RBX);

		// zero -> k4
		// sticky underflow -> k6
		e->pxor_rrr128(RDX, RDX, RDX);
		e->cmpsseq_rrr128(4, RCX, RDX);
		e->cmpsdne_rrr128(6, RBX, RDX, 4);

		// zero result on underflow
		e->vrangesd_rri64(RBX, RBX, RDX, 2, 4);
		e->pandq_rrb128(RAX, RBX, (int64_t*)&flt_double_mask);


		// negate result if sub
		if (isFloat_MSUB(ii0) || isFloat_MSUBA(ii0))
		{
			e->vsubsd_rrr128(RAX, RDX, RAX);
		}

		// on overflow, copy result to acc
		e->movdqa64_rr128(5, RAX, 2);


		// on acc overflow copy to result
		e->vrangesd_rmi64(4, 5, (void*)&test_ovf_double, 2);
		e->cmpsdne_rrr128(4, 4, 5);
		e->movdqa64_rr128(RAX, 5, 4);

		//if (isFloat_MSUB(ii0) || isFloat_MSUBA(ii0))
		//{
		//	e->pand_rrr128(RBX, RAX, 5);
		//}
		//else
		{
			e->pxor_rrr128(RBX, RAX, 5);
		}

		// get guard mask
		e->psrlq_rri128(RBX, RBX, 63);
		e->psllq_rri128(RBX, RBX, 27);


		//e->vaddsd_rrr128(RAX, RBX, 5);
		//if (isFloat_MSUB(ii0) || isFloat_MSUBA(ii0))
		//{
		//	e->vsubsd_rrr128(RAX, RAX, 5);
		//}
		//else
		{
			e->vaddsd_rrr128(RAX, RAX, 5);
		}

		e->paddq_rrr128(RAX, RAX, RBX);


		// testing
		//e->movq_to_x64_mr128((int64_t*)&v2.uq0, RAX);


		e->vrangesd_rmi64(RBX, RAX, (void*)&max_double, 2);
		//e->vrangesd_rmi64(RCX, RAX, (void*)&min_double, 2);


		// testing
		//e->movq_to_x64_mr128((int64_t*)&v3.uq0, RAX);
		//e->movq_to_x64_mr128((int64_t*)&v3.uq1, RBX);


		// overflow -> k2
		e->cmpsdne_rrr128(2, RAX, RBX);


		// zero result on underflow
		// note: need these two instructions if caching double values
		//e->vrangesd_rri64(RBX, RBX, RDX, 2, 3);
		//e->pandq_rrm128(RBX, RBX, (void*)&flt_double_mask2);


		// testing value
		//e->movq_to_sse_rm128(RBX, (int64_t*)&test_value);


		// testing
		//e->movq_to_x64_mr128((int64_t*)&v4.uw0, RBX);
		//e->movq_to_x64_mr128((int64_t*)&v4.uq1, RCX);



		// convert result(rbx) to float ->rax
		e->vptestmq_rrb128(5, RBX, (int64_t*)&bit1_double_mask);
		e->psubq_rrb128(RBX, RBX, (int64_t*)&bit1_double, 5);
		e->cvtsd2ss_rr64(RAX, RBX);
		e->paddd_rrb128(RAX, RAX, (int32_t*)&bit1_float, 5);

		// zero -> k4
		// underflow -> k3
		//e->pxor_rrr128(RDX, RDX, RDX);
		e->cmpsseq_rrr128(4, RAX, RDX);
		e->cmpsdne_rrr128(3, RBX, RDX, 4);

		// store result
		//e->movd_to_x64_mr128((int32_t*)&vd.uw0, RAX);
		// store result
		if (isFloat_MADDA(ii0) || isFloat_MSUBA(ii0))
			e->movd_to_x64_mr128((int32_t*)&r->dACC.l, RAX);
		else
			e->movd_to_x64_mr128((int32_t*)&r->CPR1[i.Fd].s, RAX);


		// get flags
		e->movd_to_sse_rm128(RAX, (int32_t*)&r->CPC1[31]);
		e->pandd_rrb128(RAX, RAX, (int32_t*)&sticky_flag_mask);
		e->pord_rrb128(RAX, RAX, (int32_t*)&ovf_float_flag, 2);
		e->pord_rrb128(RAX, RAX, (int32_t*)&und_float_flag, 3);
		e->pord_rrb128(RAX, RAX, (int32_t*)&sticky_und_float_flag, 6);
		ret = e->movd_to_x64_mr128((int32_t*)&r->CPC1[31], RAX);

		return ret;

	}
#ifdef ALLOW_AVX2_FMADDX4
	else if (iVectorType == VECTOR_TYPE_AVX2)
	{

#ifdef USE_NEW_FMADD_AVX2

		e->movd1_regmem(RAX, (int32_t*)&r->CPR1[i.Fs].s);
		e->pinsrd1regmem(RAX, RAX, (int32_t*)&r->CPR1[i.Ft].s, 1);
		e->pinsrd1regmem(RAX, RAX, (int32_t*)&r->dACC.l, 2);
		e->vsubps(RBX, RAX, RAX);
		e->psrld1regimm(RBX, RBX, 7);
		e->psubd1regreg(RAX, RAX, RBX);
		e->cvtps2pd2regreg(RAX, RAX);
		e->pmovsxdq2regreg(RBX, RBX);
		e->psllq2regimm(RBX, RBX, 29);
		e->paddq2regreg(RAX, RAX, RBX);
		e->pshufd1regregimm(RCX, RAX, 0x0e);
		e->vextracti128regreg(5, RAX, 1);

#define ENABLE_MADD_INACCURACY_AVX2
#ifdef ENABLE_MADD_INACCURACY_AVX2

		// do x*y adjustment here

		e->MovReg64ImmX(RAX, (int64_t)mantissa_double_mask);
		e->movq_to_sse128(4, RAX);

		e->pand1regreg(RBX, RCX, 4);
		e->pcmpeqq1regreg(RBX, RBX, 4);
		e->paddq1regreg(RBX, RBX, RCX);
		e->pand1regreg(RCX, RCX, RBX);

#endif


		e->vmulsd(RAX, RAX, RCX);


		// testing
		//e->movq_to_x64_mr128((int64_t*)&v2.uq0, RAX);


		// convert result(rax) to float -> rcx
		e->psllq1regimm(RBX, RAX, 1);
		e->psrlq1regimm(RBX, RBX, 63);
		e->psllq1regimm(RBX, RBX, 52);
		e->psubq1regreg(RCX, RAX, RBX);
		e->cvtsd2ss1regreg(RCX, RCX);

		// convert back (rdx) -> r4
		e->cvtss2sd1regreg(RCX, RCX);

		// these two only needed when writing back as float
		// result -> rcx
		//e->psrlq1regimm(RCX, RBX, 29);
		//e->paddd1regreg(RCX, RCX, RDX);

		// restore clamped value -> rbx
		e->paddq1regreg(RBX, RBX, RCX);


		// get overflow -> rcx
		// clamped result in (rbx)
		// un-clamped result in (rax)
		e->pand1regreg(RCX, RAX, RBX);
		e->cmpnesd(RCX, RCX, RBX);

		// get underflow -> rax
		e->pxor1regreg(RDX, RDX, RDX);
		e->cmpeqsd(RAX, RAX, RDX);
		e->cmpeqsd(RAX, RAX, RBX);


		// save sticky underflow
		e->movd_from_sse128(RDX, RAX);


		// negate result(rbx) if sub
		if (isFloat_MSUB(ii0) || isFloat_MSUBA(ii0))
		{
			e->vsubsd(RBX, RDX, RBX);
		}


		// copy mul result (rbx) to acc (r5) on overflow (rcx) -> rcx
		e->pblendvb1regreg(RCX, 5, RBX, RCX);

		// check for acc overflow -> r4
		e->MovReg64ImmX(RAX, (int64_t)max_double_float);
		e->movq_to_sse128(4, RAX);
		e->pand1regreg(5, 4, RCX);
		e->pcmpeqq1regreg(4, 4, 5);

		// copy acc(rcx) to result(rax) on overflow (r4)
		e->pblendvb1regreg(RAX, RBX, RCX, 4);


		// get guard mask
		e->pxor1regreg(RBX, RAX, RCX);
		e->psrlq1regimm(RBX, RBX, 63);
		e->psllq1regimm(RBX, RBX, 27);

		e->vaddsd(RAX, RAX, RCX);


		// testing
		//e->movq_to_x64_mr128((int64_t*)&v1.uq0, RAX);
		//e->movq_to_x64_mr128((int64_t*)&v2.uq0, RCX);


		e->paddq1regreg(RAX, RAX, RBX);


		// convert result(rax) to float -> rcx
		e->psllq1regimm(RBX, RAX, 1);
		e->psrlq1regimm(RBX, RBX, 63);
		e->psllq1regimm(RBX, RBX, 52);
		e->psubq1regreg(RCX, RAX, RBX);
		e->cvtsd2ss1regreg(RCX, RCX);

		// convert back (rdx) -> r4
		e->cvtss2sd1regreg(4, RCX);

		// these two only needed when writing back as float
		// result -> rcx
		e->psrlq1regimm(5, RBX, 29);
		e->paddd1regreg(RCX, RCX, 5);

		// restore clamped value -> rbx
		e->paddq1regreg(RBX, RBX, 4);


		// store result (rcx)
		//e->movd1_memreg((int32_t*)&vd.uw0, RCX);
		if (isFloat_MADDA(ii0) || isFloat_MSUBA(ii0))
			e->movd1_memreg((int32_t*)&r->dACC.l, RCX);
		else
			e->movd1_memreg((int32_t*)&r->CPR1[i.Fd].s, RCX);

		// get overflow -> rcx
		// clamped result in (rbx)
		// un-clamped result in (rax)
		e->pand1regreg(RCX, RAX, RBX);
		e->cmpnesd(RCX, RCX, RBX);

		// get underflow -> rax
		//e->pxor1regreg(RDX, RDX, RDX);
		e->cmpeqsd(RAX, RAX, RDX);
		e->cmpeqsd(RAX, RAX, RBX);


		// get flags
		e->movd_from_sse128(RAX, RAX);
		e->movd_from_sse128(RCX, RCX);

		e->AndReg32ImmX(RAX, 0x4008);
		e->AndReg32ImmX(RCX, 0x8010);
		e->AndReg32ImmX(RDX, 0x0008);
		e->OrRegReg32(RAX, RCX);
		e->OrRegReg32(RAX, RDX);
		e->OrRegMem8(RAX, (char*)&r->CPC1[31]);
		ret = e->MovMemReg16((short*)&r->CPC1[31], RAX);

#else
		// load fs,ft
		e->movd1_regmem(RAX, &r->CPR1[i.Fs].s);
		e->movd1_regmem(RCX, &r->CPR1[i.Ft].s);

		// create mask
		e->pcmpeqb1regreg(5, 5, 5);

#define ENABLE_MADD_INACCURACY_AVX2
#ifdef ENABLE_MADD_INACCURACY_AVX2
		// do x*y adjustment here
		e->psrld1regimm(4, 5, 9);
		e->pand1regreg(RDX, RCX, 4);
		e->pcmpeqd1regreg(RDX, RDX, 4);
		e->paddd1regreg(RCX, RCX, RDX);
#endif

		// get sign ->rdx
		e->pxor1regreg(RDX, RAX, RCX);

		// cvt w/ sign extend
		//e->pmovsxdq1regreg(RAX, RAX);
		//e->pmovsxdq1regreg(RCX, RCX);

		// cvt float to double
		e->psllq1regimm(RAX, RAX, 33);
		e->psrlq1regimm(RAX, RAX, 4);
		e->psllq1regimm(RCX, RCX, 33);
		e->psrlq1regimm(RCX, RCX, 4);


		// get multipliers
		// 1023+1023 << 52 ->r4
		e->psrlq1regimm(4, 5, 54);
		e->psllq1regimm(4, 4, 53);

		// use multiplier
		e->vmulsd(RCX, RCX, 4);


		// mul
		e->vmulsd(RAX, RAX, RCX);

		// get zero ->r4
		e->pxor1regreg(4, 4, 4);

		// get sign ->rdx
		//e->pcmpgtd1regreg(RDX, 4, RDX);

		// get result ->rax
		//e->paddq1regreg(RAX, RAX, RAX);
		//e->psrlq1regimm(RAX, RAX, 30);
		e->psrlq1regimm(RAX, RAX, 29);

		// check for zero before ->rcx
		e->pcmpeqq1regreg(RCX, RAX, 4);


		// get multipliers
		// 127 << 23 ->rbx
		e->psrlq1regimm(RBX, 5, 57);
		e->psllq1regimm(RBX, RBX, 23);


		// subtract 127(rbx) from exponent
		e->psubq1regreg(RAX, RAX, RBX);

		// clear result(rax) if it was originally zero(rcx)
		e->pandn1regreg(RAX, RCX, RAX);

		// check for zero exponent ->rcx
		e->psrlq1regimm(RCX, RAX, 23);
		e->pcmpeqq1regreg(RCX, RCX, 4);

		// get underflow | overflow ->rbx
		//e->psrad1regimm(RBX, RAX, 31);

		// clear result again on zero
		//e->pandn1regreg(RAX, RCX, RAX);

		// get underflow ->rbx
		e->pcmpgtq1regreg(RBX, 4, RAX);

		// only underflow(rbx) if not zero(rcx)
		//e->pandn1regreg(RBX, RCX, RBX);

		// also zero(rcx) on underflow(rbx)
		e->por1regreg(RCX, RCX, RBX);

		// clear result(rax) on zero(rcx)
		e->pandn1regreg(RAX, RCX, RAX);

		// could combine sign and zero here for simd

		// can load acc here
		e->movd1_regmem(RCX, (int32_t*)&r->dACC.l);

		// get overflow ->r4
		// might need to use the first method for simd
		//e->psrlq1regimm(5, RAX, 31);
		//e->pcmpgtq1regreg(5, 5, 4);
		e->psrad1regimm(4, RAX, 31);

		// get sticky underflow(rbx)
		e->movd_from_sse128(8, RBX);
		//e->movd_from_sse128(RDX, 4);

		// create mask ->rbx
		//e->pslld1regimm(RBX, 5, 31);
		e->psrld1regimm(RBX, 5, 1);

		// max result(rax) on overflow(r4)
		//e->por1regreg(RAX, RAX, 4);
		e->pminud1regreg(RAX, RAX, RBX);

		// clear sign bit in result(RAX)
		//e->pandn1regreg(RAX, RBX, RAX);

		// add sign(rdx)
		//e->pand1regreg(RDX, RDX, RBX);
		e->pandn1regreg(RDX, RBX, RDX);
		e->por1regreg(RAX, RAX, RDX);

		// might need to refresh sign here for simd



		// ---------- ADD -------------


		// change sign for multiply result if needed
		if (isFloat_MSUB(ii0) || isFloat_MSUBA(ii0))
		{
			e->pslld1regimm(RDX, 5, 31);
			e->pxor1regreg(RAX, RAX, RDX);
		}

		// if mul overflow(r4), then copy result(rax) to acc(rcx)
		e->pblendvb1regreg(RCX, RCX, RAX, 4);

		// if acc +/-max then copy acc(rcx) to result(rax)
		//e->pandn1regreg(RBX, RBX, RCX);
		e->pand1regreg(RBX, RBX, RCX);
		e->psrld1regimm(4, 5, 1);
		e->pcmpeqd1regreg(RBX, RBX, 4);
		e->pblendvb1regreg(RAX, RAX, RCX, RBX);


		// get mask
		e->psrlq1regimm(4, 5, 61);
		e->psllq1regimm(4, 4, 60);


		// cvt w/ sign extend
		e->pmovsxdq1regreg(RAX, RAX);
		e->pmovsxdq1regreg(RCX, RCX);

		// cvt float to double
		e->psllq1regimm(RAX, RAX, 29);
		e->psllq1regimm(RCX, RCX, 29);
		e->pandn1regreg(RAX, 4, RAX);
		e->pandn1regreg(RCX, 4, RCX);

		// get multipliers
		// 127 << 23 ->rbx
		// 1023+127 << 52 ->r4
		e->psrlq1regimm(4, 5, 54);
		e->psrlq1regimm(RBX, 5, 57);
		e->paddq1regreg(4, 4, RBX);
		e->psllq1regimm(RBX, RBX, 23);
		e->psllq1regimm(4, 4, 52);

		// get guard mask
		e->pxor1regreg(RDX, RAX, RCX);
		e->psrlq1regimm(RDX, RDX, 63);
		e->psllq1regimm(RDX, RDX, 27);

		// use multiplier
		e->vmulsd(RAX, RAX, 4);
		e->vmulsd(RCX, RCX, 4);

		// add
		e->vaddsd(RAX, RAX, RCX);

		// adjust ??
		e->paddq1regreg(RAX, RAX, RDX);

		// get zero ->r4
		e->pxor1regreg(4, 4, 4);

		// get sign ->rdx
		e->pcmpgtq1regreg(RDX, 4, RAX);

		// get result ->rax
		e->paddq1regreg(RAX, RAX, RAX);
		e->psrlq1regimm(RAX, RAX, 30);

		// check for zero before ->rcx
		e->pcmpeqq1regreg(RCX, RAX, 4);

		// subtract 31(rbx) from exponent
		e->psubq1regreg(RAX, RAX, RBX);

		// clear result(rax) if it was originally zero(rcx)
		e->pandn1regreg(RAX, RCX, RAX);

		// check for zero exponent ->rcx
		e->psrlq1regimm(RCX, RAX, 23);
		e->pcmpeqq1regreg(RCX, RCX, 4);

		// get underflow | overflow ->rbx
		//e->psrad1regimm(RBX, RAX, 31);

		// clear result again on zero
		//e->pandn1regreg(RAX, RCX, RAX);

		// get underflow ->rbx
		e->pcmpgtq1regreg(RBX, 4, RAX);

		// only underflow(rbx) if not zero(rcx)
		//e->pandn1regreg(RBX, RCX, RBX);

		// also zero(rcx) on underflow(rbx)
		e->por1regreg(RCX, RCX, RBX);

		// clear result(rax) on zero(rcx)
		e->pandn1regreg(RAX, RCX, RAX);

		// could combine sign and zero here for simd

		// get overflow ->r4
		// might need to use the first method for simd
		e->psrad1regimm(4, RAX, 31);

		// get mask ->r5
		//e->pslld1regimm(5, 5, 31);
		e->psrld1regimm(5, 5, 1);

		// max result(rax) on overflow(r5)
		//e->por1regreg(RAX, RAX, 4);
		e->pminud1regreg(RAX, RAX, 5);


		// clear sign bit in result(RAX)
		//e->pandn1regreg(RAX, 5, RAX);

		// add sign(rdx)
		//e->pand1regreg(RDX, RDX, 5);
		e->pandn1regreg(RDX, 5, RDX);
		e->por1regreg(RAX, RAX, RDX);

		// might need to refresh sign flag here if simd

		e->movd_from_sse128(RCX, RBX);
		e->movd_from_sse128(RDX, 4);


		// store result
		if (isFloat_MADDA(ii0) || isFloat_MSUBA(ii0))
			e->movd1_memreg((int32_t*)&r->dACC.l, RAX);
		else
			e->movd1_memreg((int32_t*)&r->CPR1[i.Fd].s, RAX);


		// set the flags
		e->MovRegMem32(RAX, (int32_t*)&r->CPC1[31]);

		// get overflow flag
		e->AndReg32ImmX(RDX, 0x8010);

		// get underflow flag
		e->AndReg32ImmX(RCX, 0x4008);
		e->AndReg32ImmX(8, 0x8);

		// combine with underflow flag
		e->OrRegReg32(RCX, RDX);
		e->OrRegReg32(RCX, 8);

		// clear non sticky flags
		e->AndReg32ImmX(RAX, ~0xc000);
		e->OrRegReg32(RAX, RCX);
		ret = e->MovMemReg32((int32_t*)&r->CPC1[31], RAX);

#endif
	}
#endif

	return ret;

}

int32_t R5900::Recompiler::Generate_FADDp(x64Encoder* e, u32 i0, u32 i1, u32 i2, u32 i3)
{
	static constexpr int64_t max_double = 0x47ffffffffffffffull;
	static constexpr int64_t min_double = 0x3800000000000000ull;

	static constexpr int64_t bit1_double = 0x0010000000000000ull;
	static constexpr int64_t bit1_double_mask = 0x4000000000000000ull;
	static constexpr int32_t bit1_float = 0x00800000;
	static constexpr int32_t bit1_float_mask = 0x40000000;

	static constexpr int64_t flt_double_mask = 0xffffffffe0000000ull;
	static constexpr int64_t ps2_mul1_double_mask = 0xffffffffc0000000ull;

	static constexpr int64_t mantissa_double_mask = 0xfffffe0000000000ull;

	static constexpr int64_t zero_double = 0ull;

	static constexpr int32_t ovf_float_flag = 0x8010;
	static constexpr int32_t und_float_flag = 0x4008;
	static constexpr int32_t sticky_flag_mask = ~0xc000;

	int32_t ret;

	R5900::Instruction::Format i, ii0, ii1, ii2, ii3;

	u32 Address = e->x64CurrentSourceAddress;

	u64 start, end, addr;

	i.Value = i0;

	ii0.Value = i0;
	ii1.Value = i1;
	ii2.Value = i2;
	ii3.Value = i3;


	ret = 1;

//#define ALLOW_AVX2_FADDX4
#ifdef ALLOW_AVX2_FADDX4
	if (iVectorType == VECTOR_TYPE_AVX512)
#endif
	{
		e->movd_to_sse_rm128(RAX, (int32_t*)&r->CPR1[ii0.Fs].s);
		e->vinsertd_rmi128(RAX, RAX, (void*)&r->CPR1[ii0.Ft].s, 1);
		e->vptestmd_rrb128(2, RAX, (int32_t*)&bit1_float_mask);
		e->psubd_rrb128(RAX, RAX, (int32_t*)&bit1_float, 2);
		e->cvtps2pd_rr128(RAX, RAX);
		e->paddq_rrb128(RAX, RAX, (int64_t*)&bit1_double, 2);
		e->pshufd_rri128(RCX, RAX, 0x0e);

		// change sign for sub
		if (isFloat_SUB(ii0) || isFloat_SUBA(ii0))
		{
			//e->pxor_rrr128(RCX, RCX, 19);
			e->pand_rrr128(RDX, RAX, RCX);
		}
		else
		{
			e->pxor_rrr128(RDX, RAX, RCX);
		}

		// get guard mask
		//e->pxor1regreg(RDX, RAX, RCX);
		//e->psrlq1regimm(RDX, RDX, 63);
		//e->psllq1regimm(RDX, RDX, 27);
		e->psrlq_rri128(RDX, RDX, 63);
		e->psllq_rri128(RDX, RDX, 27);

		if (isFloat_SUB(ii0) || isFloat_SUBA(ii0))
		{
			e->vsubsd_rrr128(RAX, RAX, RCX);
		}
		else
		{
			e->vaddsd_rrr128(RAX, RAX, RCX);
		}

		e->paddq_rrr128(RAX, RAX, RDX);


		// testing
		//e->movq_to_x64_mr128((int64_t*)&v2.uq0, RAX);


		e->vrangesd_rmi64(RBX, RAX, (void*)&max_double, 2);
		//e->vrangesd_rmi64(RCX, RAX, (void*)&min_double, 2);


		// testing
		//e->movq_to_x64_mr128((int64_t*)&v3.uq0, RAX);
		//e->movq_to_x64_mr128((int64_t*)&v3.uq1, RBX);


		// overflow -> k2
		e->cmpsdne_rrr128(2, RAX, RBX);


		// zero result on underflow
		// note: need these two instructions if caching double values
		//e->vrangesd_rri64(RBX, RBX, RDX, 2, 3);
		//e->pandq_rrm128(RBX, RBX, (void*)&flt_double_mask2);


		// testing value
		//e->movq_to_sse_rm128(RBX, (int64_t*)&test_value);


		// testing
		//e->movq_to_x64_mr128((int64_t*)&v4.uw0, RBX);
		//e->movq_to_x64_mr128((int64_t*)&v4.uq1, RCX);


		// convert result(rbx) to float ->rax
		e->vptestmq_rrb128(5, RBX, (int64_t*)&bit1_double_mask);
		e->psubq_rrb128(RBX, RBX, (int64_t*)&bit1_double, 5);
		e->cvtsd2ss_rr64(RAX, RBX);
		e->paddd_rrb128(RAX, RAX, (int32_t*)&bit1_float, 5);

		// zero -> k4
		// underflow -> k3
		e->pxor_rrr128(RDX, RDX, RDX);
		e->cmpsseq_rrr128(4, RAX, RDX);
		e->cmpsdne_rrr128(3, RBX, RDX, 4);

		// store result
		//e->movd_to_x64_mr128((int32_t*)&vd.uw0, RAX);
		if (isFloat_ADDA(ii0) || isFloat_SUBA(ii0))
			e->movd_to_x64_mr128(&r->dACC.l, RAX);
		else
			e->movd_to_x64_mr128(&r->CPR1[ii0.Fd].s, RAX);


		// get flags
		//e->kunpackbw(2, 2, 3);
		//e->kmovdmemmsk((int32_t*)&statflag, 2);

		e->movd_to_sse_rm128(RAX, (int32_t*)&r->CPC1[31]);
		e->pandd_rrb128(RAX, RAX, (int32_t*)&sticky_flag_mask);
		e->pord_rrb128(RAX, RAX, (int32_t*)&ovf_float_flag, 2);
		e->pord_rrb128(RAX, RAX, (int32_t*)&und_float_flag, 3);
		ret = e->movd_to_x64_mr128((int32_t*)&r->CPC1[31], RAX);

		return ret;
	}
#ifdef ALLOW_AVX2_FADDX4
	else if (iVectorType == VECTOR_TYPE_AVX2)
	{

#ifdef USE_NEW_FADD_AVX2

		e->movd1_regmem(RAX, (int32_t*)&r->CPR1[i.Fs].s);
		e->pinsrd1regmem(RAX, RAX, (int32_t*)&r->CPR1[i.Ft].s, 1);
		e->vsubps(RBX, RAX, RAX);
		e->psrld1regimm(RBX, RBX, 7);
		e->psubd1regreg(RAX, RAX, RBX);
		e->cvtps2pd1regreg(RAX, RAX);
		e->pmovsxdq1regreg(RBX, RBX);
		e->psllq1regimm(RBX, RBX, 29);
		e->paddq1regreg(RAX, RAX, RBX);
		e->pshufd1regregimm(RCX, RAX, 0x0e);

		// get guard mask
		//e->pxor1regreg(RBX, RAX, RCX);
		e->pxor1regreg(RBX, RAX, RCX);

		if (isFloat_SUB(ii0) || isFloat_SUBA(ii0))
		{
			//e->pand2regreg(RBX, RAX, RCX);
			e->pcmpeqb1regreg(RDX, RDX, RDX);
			e->pxor1regreg(RBX, RBX, RDX);
		}

		e->psrlq1regimm(RBX, RBX, 63);
		e->psllq1regimm(RBX, RBX, 27);

		//e->vaddsd(RAX, RAX, RCX);
		if (isFloat_SUB(ii0) || isFloat_SUBA(ii0))
		{
			// sub
			e->vsubsd(RAX, RAX, RCX);
		}
		else
		{
			// add
			e->vaddsd(RAX, RAX, RCX);
		}

		e->paddq1regreg(RAX, RAX, RBX);


		// testing
		//e->movq_to_x64_mr128((int64_t*)&v2.uq0, RAX);


		// convert result(rax) to float -> rcx
		e->psllq1regimm(RBX, RAX, 1);
		e->psrlq1regimm(RBX, RBX, 63);
		e->psllq1regimm(RBX, RBX, 52);
		e->psubq1regreg(RDX, RAX, RBX);
		e->cvtsd2ss1regreg(RDX, RDX);

		// convert back (rdx) -> r4
		e->cvtss2sd1regreg(4, RDX);

		// these two only needed when writing back as float
		// result -> rcx
		e->psrlq1regimm(RCX, RBX, 29);
		e->paddd1regreg(RCX, RCX, RDX);

		// restore clamped value -> rbx
		e->paddq1regreg(RBX, RBX, 4);


		// store result (rcx)
		//e->movd1_memreg((int32_t*)&vd.uw0, RCX);
		if (isFloat_ADDA(ii0) || isFloat_SUBA(ii0))
			e->movd1_memreg((int32_t*)&r->dACC.l, RCX);
		else
			e->movd1_memreg((int32_t*)&r->CPR1[i.Fd].s, RCX);


		// get overflow -> rcx
		// clamped result in (rbx)
		// un-clamped result in (rax)
		e->pand1regreg(RCX, RAX, RBX);
		e->cmpnesd(RCX, RCX, RBX);

		// get underflow -> rax
		e->pxor1regreg(RDX, RDX, RDX);
		e->cmpeqsd(RAX, RAX, RDX);
		e->cmpeqsd(RAX, RAX, RBX);

		// get flags
		e->movd_from_sse128(RAX, RAX);
		e->movd_from_sse128(RCX, RCX);

		e->AndReg32ImmX(RAX, 0x4008);
		e->AndReg32ImmX(RCX, 0x8010);
		e->OrRegReg32(RAX, RCX);
		e->OrRegMem8(RAX, (char*)&r->CPC1[31]);
		ret = e->MovMemReg16((short*)&r->CPC1[31], RAX);

#else

		// load fs,ft
		e->movd1_regmem(RAX, (int32_t*)&r->CPR1[i.Fs].s);
		e->movd1_regmem(RCX, (int32_t*)&r->CPR1[i.Ft].s);

		// create mask
		e->pcmpeqb1regreg(5, 5, 5);

		// check if doing subtraction instead of addition
		//if (isFloat_SUB(ii0) || isFloat_SUBA(ii0))
		//{
		//	// toggle the sign on RCX (right-hand argument) for subtraction for now
		//	e->pslld1regimm(4, 5, 31);
		//	e->pxor1regreg(RCX, RCX, 4);
		//}

		// get mask
		e->psrlq1regimm(4, 5, 61);
		e->psllq1regimm(4, 4, 60);

		// cvt w/ sign extend
		e->pmovsxdq1regreg(RAX, RAX);
		e->pmovsxdq1regreg(RCX, RCX);

		// cvt float to double
		e->psllq1regimm(RAX, RAX, 29);
		e->psllq1regimm(RCX, RCX, 29);
		e->pandn1regreg(RAX, 4, RAX);
		e->pandn1regreg(RCX, 4, RCX);

		// get multipliers
		// 127 << 23 ->rbx
		// 1023+127 << 52 ->r4
		e->psrlq1regimm(4, 5, 54);
		e->psrlq1regimm(RBX, 5, 57);
		e->paddq1regreg(4, 4, RBX);
		e->psllq1regimm(RBX, RBX, 23);
		e->psllq1regimm(4, 4, 52);

		// get guard mask
		if (isFloat_SUB(ii0) || isFloat_SUBA(ii0))
		{
			e->pand2regreg(RDX, RAX, RCX);
		}
		else
		{
			e->pxor2regreg(RDX, RAX, RCX);
		}

		e->psrlq1regimm(RDX, RDX, 63);
		e->psllq1regimm(RDX, RDX, 27);

		// use multiplier
		e->vmulsd(RAX, RAX, 4);
		e->vmulsd(RCX, RCX, 4);

		if (isFloat_SUB(ii0) || isFloat_SUBA(ii0))
		{
			// sub
			e->vsubsd(RAX, RAX, RCX);
		}
		else
		{
			// add
			e->vaddsd(RAX, RAX, RCX);
		}

		// adjust ??
		e->paddq1regreg(RAX, RAX, RDX);

		// get zero ->r4
		e->pxor1regreg(4, 4, 4);

		// get sign ->rdx
		e->pcmpgtq1regreg(RDX, 4, RAX);

		// get result ->rax
		e->paddq1regreg(RAX, RAX, RAX);
		e->psrlq1regimm(RAX, RAX, 30);

		// check for zero before ->rcx
		e->pcmpeqq1regreg(RCX, RAX, 4);

		// subtract 31(rbx) from exponent
		e->psubq1regreg(RAX, RAX, RBX);

		// clear result(rax) if it was originally zero(rcx)
		e->pandn1regreg(RAX, RCX, RAX);

		// check for zero exponent ->rcx
		e->psrlq1regimm(RCX, RAX, 23);
		e->pcmpeqq1regreg(RCX, RCX, 4);

		// get underflow | overflow ->rbx
		//e->psrad1regimm(RBX, RAX, 31);

		// clear result again on zero
		//e->pandn1regreg(RAX, RCX, RAX);

		// get underflow ->rbx
		e->pcmpgtq1regreg(RBX, 4, RAX);

		// only underflow(rbx) if not zero(rcx)
		//e->pandn1regreg(RBX, RCX, RBX);

		// also zero(rcx) on underflow(rbx)
		e->por1regreg(RCX, RCX, RBX);

		// clear result(rax) on zero(rcx)
		e->pandn1regreg(RAX, RCX, RAX);

		// could combine sign and zero here for simd

		// get overflow ->r4
		// might need to use the first method for simd
		//e->psrlq1regimm(5, RAX, 31);
		//e->pcmpgtq1regreg(5, 5, 4);
		e->psrad1regimm(4, RAX, 31);

		// get mask ->r5
		e->psrld1regimm(5, 5, 1);

		// max result(rax) on overflow(r4)
		//e->por1regreg(RAX, RAX, 4);
		e->pminud1regreg(RAX, RAX, 5);

		// get mask
		//e->pslld1regimm(5, 5, 31);

		// clear sign bit in result(RAX)
		//e->pandn1regreg(RAX, 5, RAX);

		// add sign(rdx)
		//e->pand1regreg(RDX, RDX, 5);
		e->pandn1regreg(RDX, 5, RDX);
		e->por1regreg(RAX, RAX, RDX);

		// might need to refresh sign flag here if simd


		// might need to refresh sign flag here if simd


		// store result
		if (isFloat_ADDA(ii0) || isFloat_SUBA(ii0))
			e->movd1_memreg((int32_t*)&r->dACC.l, RAX);
		else
			e->movd1_memreg((int32_t*)&r->CPR1[i.Fd].s, RAX);

		e->movd_from_sse128(RCX, RBX);
		e->movd_from_sse128(RDX, 4);

		// get the flags
		e->MovRegMem32(RAX, (int32_t*)&r->CPC1[31]);

		// get underflow flag
		e->AndReg32ImmX(RCX, 0x4008);

		// get overflow flag
		e->AndReg32ImmX(RDX, 0x8010);

		// combine with underflow flag
		e->OrRegReg32(RCX, RDX);

		// clear non sticky flags
		e->AndReg32ImmX(RAX, ~0xc000);
		e->OrRegReg32(RAX, RCX);
		ret = e->MovMemReg32((int32_t*)&r->CPC1[31], RAX);

#endif
	}
#endif

	// write zero to flags here
	//ret = e->MovMemImm32((int32_t*)&xcomp, 0);

	return ret;
}


int32_t R5900::Recompiler::Generate_FARGSp(x64Encoder* e, R5900::Instruction::Format i, int iIndexX)
{
	int32_t ret = 1;

//#define ALLOW_AVX2_FARGS
#ifdef ALLOW_AVX2_FARGS
	if (iVectorType == VECTOR_TYPE_AVX512)
#endif
	{
		ret = e->OrMem32ImmX((int32_t*)&xcomp, 1 << (iIndexX));

	}
#ifdef ALLOW_AVX2_FARGS
	else if (iVectorType == VECTOR_TYPE_AVX2)
	{
		// set parallel computation to happen in the future
		ret = e->OrMem32ImmX ((int32_t*)&xcomp, 0xff << (iIndexX<<3));
		//ret = e->MovMemImm32((int32_t*)&xcomp, flag_mask_lut32[i.xyzw]);
	}
#endif	// end #ifdef ALLOW_AVX2_FARGS

	// save the instruction in history so it can be used later
	FInstHist[iIndexX] = i.Value;

	return ret;

}


int32_t R5900::Recompiler::Generate_FMULp(x64Encoder* e, u32 i0, u32 i1, u32 i2, u32 i3)
{
	static constexpr int64_t max_double = 0x47ffffffffffffffull;
	static constexpr int64_t min_double = 0x3800000000000000ull;

	static constexpr int64_t bit1_double = 0x0010000000000000ull;
	static constexpr int64_t bit1_double_mask = 0x4000000000000000ull;
	static constexpr int32_t bit1_float = 0x00800000;
	static constexpr int32_t bit1_float_mask = 0x40000000;

	static constexpr int64_t flt_double_mask = 0xffffffffe0000000ull;
	static constexpr int64_t ps2_mul1_double_mask = 0xffffffffc0000000ull;

	static constexpr int64_t mantissa_double_mask = 0xfffffe0000000000ull;

	static constexpr int64_t zero_double = 0ull;

	static constexpr int32_t ovf_float_flag = 0x8010;
	static constexpr int32_t und_float_flag = 0x4008;
	static constexpr int32_t sticky_flag_mask = ~0xc000;

	int32_t ret;

	R5900::Instruction::Format i, ii0, ii1, ii2, ii3;

	u32 Address = e->x64CurrentSourceAddress;

	u64 start, end, diff, addr;

	i.Value = i0;

	ii0.Value = i0;
	ii1.Value = i1;
	ii2.Value = i2;
	ii3.Value = i3;


	ret = 1;

//#define ALLOW_AVX2_FMULX4
#ifdef ALLOW_AVX2_FMULX4
	if (iVectorType == VECTOR_TYPE_AVX512)
#endif
	{

		e->movd_to_sse_rm128(RAX, (int32_t*)&r->CPR1[ii0.Fs].s);
		e->vinsertd_rmi128(RAX, RAX, (void*)&r->CPR1[ii0.Ft].s, 1);
		e->vptestmd_rrb128(2, RAX, (int32_t*)&bit1_float_mask);
		e->psubd_rrb128(RAX, RAX, (int32_t*)&bit1_float, 2);
		e->cvtps2pd_rr128(RAX, RAX);
		e->paddq_rrb128(RAX, RAX, (int64_t*)&bit1_double, 2);
		e->pshufd_rri128(RCX, RAX, 0x0e);

#define ENABLE_MUL_INACCURACY_AVX512
#ifdef ENABLE_MUL_INACCURACY_AVX512
		// check mantissa
		e->psllq_rri128(RDX, RCX, 12);
		e->vpcmpqeq_rrb128(2, RDX, (int64_t*)&mantissa_double_mask);
		e->pandq_rrb128(RCX, RCX, (int64_t*)&ps2_mul1_double_mask, 2);
#endif

		e->vmulsd_rrr128(RAX, RAX, RCX);


		// testing
		//e->movq_to_x64_mr128((int64_t*)&v2.uq0, RAX);


		e->vrangesd_rmi64(RBX, RAX, (int64_t*)&max_double, 2);
		//e->vrangesd_rmi64(RCX, RAX, (int64_t*)&min_double, 2);


		// overflow -> k2
		e->cmpsdne_rrr128(2, RAX, RBX);


		// zero result on underflow
		// note: need these two instructions if caching double values
		//e->vrangesd_rri64(RBX, RBX, RDX, 2, 3);
		//e->pandq_rrm128(RBX, RBX, (void*)&flt_double_mask2);


		// testing value
		//e->movq_to_sse_rm128(RBX, (int64_t*)&test_value);


		// testing
		//e->movq_to_x64_mr128((int64_t*)&v4.uw0, RBX);
		//e->movq_to_x64_mr128((int64_t*)&v4.uq1, RCX);


		// convert result(rbx) to float ->rax
		e->vptestmq_rrb128(5, RBX, (int64_t*)&bit1_double_mask);
		e->psubq_rrb128(RBX, RBX, (int64_t*)&bit1_double, 5);
		e->cvtsd2ss_rr64(RAX, RBX);
		e->paddd_rrb128(RAX, RAX, (int32_t*)&bit1_float, 5);

		// zero -> k4
		// underflow -> k3
		e->pxor_rrr128(RDX, RDX, RDX);
		e->cmpsseq_rrr128(4, RAX, RDX);
		e->cmpsdne_rrr128(3, RBX, RDX, 4);

		// store result
		//e->movd_to_x64_mr128((int32_t*)&vd.uw0, RAX);
		if (isFloat_MULA(ii0))
			e->movd_to_x64_mr128(&r->dACC.l, RAX);
		else
			e->movd_to_x64_mr128(&r->CPR1[ii0.Fd].s, RAX);


		// get flags
		//e->kunpackbw(2, 2, 3);
		//e->kmovdmemmsk((int32_t*)&statflag, 2);

		e->movd_to_sse_rm128(RAX, (int32_t*)&r->CPC1[31]);
		e->pandd_rrb128(RAX, RAX, (int32_t*)&sticky_flag_mask);
		e->pord_rrb128(RAX, RAX, (int32_t*)&ovf_float_flag, 2);
		e->pord_rrb128(RAX, RAX, (int32_t*)&und_float_flag, 3);
		ret = e->movd_to_x64_mr128((int32_t*)&r->CPC1[31], RAX);

		return ret;

	}
#ifdef ALLOW_AVX2_FMULX4
	else if (iVectorType == VECTOR_TYPE_AVX2)
	{

#ifdef USE_NEW_FMUL_AVX2

		e->movd1_regmem(RAX, (int32_t*)&r->CPR1[i.Fs].s);
		e->pinsrd1regmem(RAX, RAX, (int32_t*)&r->CPR1[i.Ft].s, 1);
		e->vsubps(RBX, RAX, RAX);
		e->psrld1regimm(RBX, RBX, 7);
		e->psubd1regreg(RAX, RAX, RBX);
		e->cvtps2pd1regreg(RAX, RAX);
		e->pmovsxdq1regreg(RBX, RBX);
		e->psllq1regimm(RBX, RBX, 29);
		e->paddq1regreg(RAX, RAX, RBX);
		e->pshufd1regregimm(RCX, RAX, 0x0e);

#define ENABLE_MUL_INACCURACY_AVX2
#ifdef ENABLE_MUL_INACCURACY_AVX2

		// do x*y adjustment here

		e->MovReg64ImmX(RAX, (int64_t)mantissa_double_mask);
		e->movq_to_sse128(4, RAX);


		e->pand1regreg(RBX, RCX, 4);
		e->pcmpeqq1regreg(RBX, RBX, 4);
		e->paddq1regreg(RBX, RBX, RCX);
		e->pand1regreg(RCX, RCX, RBX);

#endif


		e->vmulsd(RAX, RAX, RCX);

		// testing
		//e->ldmxcsr((int32_t*)&macflag);

		// convert result(rax) to float -> rcx
		e->psllq1regimm(RBX, RAX, 1);
		e->psrlq1regimm(RBX, RBX, 63);
		e->psllq1regimm(RBX, RBX, 52);
		e->psubq1regreg(RDX, RAX, RBX);
		e->cvtsd2ss1regreg(RDX, RDX);

		// convert back (rdx) -> r4
		e->cvtss2sd1regreg(4, RDX);

		// these two only needed when writing back as float
		// result -> rcx
		e->psrlq1regimm(RCX, RBX, 29);
		e->paddd1regreg(RCX, RCX, RDX);

		// restore clamped value -> r4
		e->paddq1regreg(RBX, RBX, 4);


		// store result (rcx)
		//e->movd1_memreg((int32_t*)&vd.uw0, RCX);
		// output result
		if (isFloat_MULA(ii0))
			e->movd1_memreg((int32_t*)&r->dACC.l, RCX);
		else
			e->movd1_memreg((int32_t*)&r->CPR1[i.Fd].s, RCX);


		// get overflow -> rcx
		// clamped result in (rbx)
		// un-clamped result in (rax)
		e->pand1regreg(RCX, RAX, RBX);
		e->cmpnesd(RCX, RCX, RBX);

		// get underflow -> rax
		e->pxor1regreg(RDX, RDX, RDX);
		e->cmpeqsd(RAX, RAX, RDX);
		e->cmpeqsd(RAX, RAX, RBX);


		// get flags
		e->movd_from_sse128(RAX, RAX);
		e->movd_from_sse128(RCX, RCX);

		e->AndReg32ImmX(RAX, 0x4008);
		e->AndReg32ImmX(RCX, 0x8010);
		e->OrRegReg32(RAX, RCX);
		e->OrRegMem8(RAX, (char*)&r->CPC1[31]);
		ret = e->MovMemReg16((short*)&r->CPC1[31], RAX);

#else

		// load fs,ft
		e->movd1_regmem(RAX, (int32_t*)&r->CPR1[i.Fs].s);
		e->movd1_regmem(RCX, (int32_t*)&r->CPR1[i.Ft].s);

		// create mask
		e->pcmpeqb1regreg(5, 5, 5);

#define ENABLE_MUL_INACCURACY_AVX2
#ifdef ENABLE_MUL_INACCURACY_AVX2
		// do x*y adjustment here
		e->psrld1regimm(4, 5, 9);
		e->pand1regreg(RDX, RCX, 4);
		e->pcmpeqd1regreg(RDX, RDX, 4);
		e->paddd1regreg(RCX, RCX, RDX);
#endif

		// get sign ->rdx
		e->pxor1regreg(RDX, RAX, RCX);

		// cvt w/ sign extend
		//e->pmovsxdq1regreg(RAX, RAX);
		//e->pmovsxdq1regreg(RCX, RCX);

		// cvt float to double
		e->psllq1regimm(RAX, RAX, 33);
		e->psrlq1regimm(RAX, RAX, 4);
		e->psllq1regimm(RCX, RCX, 33);
		e->psrlq1regimm(RCX, RCX, 4);


		// get multipliers
		// 1023+1023 << 52 ->r4
		e->psrlq1regimm(4, 5, 54);
		e->psllq1regimm(4, 4, 53);

		// use multiplier
		e->vmulsd(RCX, RCX, 4);


		// mul
		e->vmulsd(RAX, RAX, RCX);

		// get zero ->r4
		e->pxor1regreg(4, 4, 4);

		// get sign ->rdx
		//e->pcmpgtd1regreg(RDX, 4, RDX);

		// get result ->rax
		//e->paddq1regreg(RAX, RAX, RAX);
		//e->psrlq1regimm(RAX, RAX, 30);
		e->psrlq1regimm(RAX, RAX, 29);

		// check for zero before ->rcx
		e->pcmpeqq1regreg(RCX, RAX, 4);


		// get multipliers
		// 127 << 23 ->rbx
		e->psrlq1regimm(RBX, 5, 57);
		e->psllq1regimm(RBX, RBX, 23);


		// subtract 127(rbx) from exponent
		e->psubq1regreg(RAX, RAX, RBX);

		// clear result(rax) if it was originally zero(rcx)
		e->pandn1regreg(RAX, RCX, RAX);

		// check for zero exponent ->rcx
		e->psrlq1regimm(RCX, RAX, 23);
		e->pcmpeqq1regreg(RCX, RCX, 4);

		// get underflow | overflow ->rbx
		//e->psrad1regimm(RBX, RAX, 31);

		// clear result again on zero
		//e->pandn1regreg(RAX, RCX, RAX);

		// get underflow ->rbx
		e->pcmpgtq1regreg(RBX, 4, RAX);

		// only underflow(rbx) if not zero(rcx)
		//e->pandn1regreg(RBX, RCX, RBX);

		// also zero(rcx) on underflow(rbx)
		e->por1regreg(RCX, RCX, RBX);

		// clear result(rax) on zero(rcx)
		e->pandn1regreg(RAX, RCX, RAX);

		// could combine sign and zero here for simd

		// get overflow ->r4
		// might need to use the first method for simd
		//e->psrlq1regimm(5, RAX, 31);
		//e->pcmpgtq1regreg(5, 5, 4);
		e->psrad1regimm(4, RAX, 31);


		// get mask ->r5
		e->psrld1regimm(5, 5, 1);

		// max result(rax) on overflow(r4)
		//e->por1regreg(RAX, RAX, 4);
		e->pminud1regreg(RAX, RAX, 5);


		// get mask ->rbx
		//e->pslld1regimm(RBX, 5, 31);

		// clear sign bit in result(RAX)
		//e->pandn1regreg(RAX, RBX, RAX);

		// add sign(rdx)
		//e->pand1regreg(RDX, RDX, RBX);
		e->pandn1regreg(RDX, 5, RDX);
		e->por1regreg(RAX, RAX, RDX);


		// output result
		if (isFloat_MULA(ii0))
			e->movd1_memreg((int32_t*)&r->dACC.l, RAX);
		else
			e->movd1_memreg((int32_t*)&r->CPR1[i.Fd].s, RAX);


		// get underflow(rbx) ->rcx
		e->movd_from_sse128(RCX, RBX);

		// get overflow(r4) ->rdx
		e->movd_from_sse128(RDX, 4);


		// set the flags
		e->MovRegMem32(RAX, (int32_t*)&r->CPC1[31]);

		// get underflow,overflow flag
		e->AndReg32ImmX(RCX, 0x4008);
		e->AndReg32ImmX(RDX, 0x8010);

		// combine with underflow flag
		e->OrRegReg32(RCX, RDX);

		// clear non sticky flags
		e->AndReg32ImmX(RAX, ~0xc000);
		e->OrRegReg32(RAX, RCX);
		ret = e->MovMemReg32((int32_t*)&r->CPC1[31], RAX);

#endif

	}
#endif

	// write zero to flags here
	//if (i1 || i2 || i3)
	//{
	//	ret = e->MovMemImm32((int32_t*)&xcomp, 0);
	//}

	return ret;
}


int32_t R5900::Recompiler::Generate_VFTOIXp ( R5900::Instruction::Format i, u32 IX )
{
	int32_t ret;

	u64 start, end, addr;
	
	u32 Address = e->x64CurrentSourceAddress;

	ret = 1;

	if ( i.Ft && i.xyzw )
	{
		if (iVectorType == VECTOR_TYPE_AVX2)
		{

			e->movdqa1_regmem(RAX, &VU0::_VU0->vf[i.Fs].sw0);

#ifdef USE_NEW_VFTOIX_AVX2_R5900

			if (IX)
			{
				e->MovReg32ImmX(RAX, (127 + IX) << 23);
				e->movd_to_sse128(RCX, RAX);
				e->vpbroadcastd1regreg(RCX, RCX);
				e->vmulps(RAX, RAX, RCX);
			}

			e->cvttps2dq1regreg(RCX, RAX);
			e->pxor1regreg(RDX, RAX, RCX);
			e->psrld1regimm(RDX, RDX, 31);
			e->psignd1regreg(RDX, RDX, RCX);
			ret = e->psubd1regreg(RAX, RCX, RDX);

#else

			// make mask -> R5
			e->pcmpeqb1regreg(5, 5, 5);

			// add IX to exponent -> RCX
			if (IX)
			{
				// make a mask 127 -> RDX
				//e->psrld1regimm(RDX, 5, 25);

				switch (IX)
				{
				case 4:
					e->psrld1regimm(4, 5, 31);
					e->pslld1regimm(4, 4, (2 + 23));
					//e->pslld1regimm(4, 4, 2);
					break;

				case 12:
					e->psrld1regimm(4, 5, 30);
					e->pslld1regimm(4, 4, (2 + 23));
					//e->pslld1regimm(4, 4, 2);
					break;

				case 15:
					e->psrld1regimm(4, 5, 28);
					e->pslld1regimm(4, 4, (0 + 23));
					break;
				}

				// add 127 + IX -> RDX
				//e->paddd1regreg(RDX, RDX, 4);
				//e->pslld1regimm(RDX, RDX, 23);

				// move decimal point over
				//e->vmulps(RAX, RAX, RDX);

				// add and max on overflow
				e->paddd1regreg(RBX, RAX, 4);

				// check for overflow
				e->pxor1regreg(RCX, RAX, RBX);
				e->psrad1regimm(RCX, RCX, 31);
				e->psrld1regimm(RCX, RCX, 1);

				// max on overflow
				e->por1regreg(RAX, RBX, RCX);

			}

			// make sure exp is less or equal to 0x4e800000
			e->MovReg32ImmX(RAX, 0x9d);
			e->movd_to_sse128(RBX, RAX);
			e->pshufd1regregimm(RBX, RBX, 0);

			// make sure value in range
			e->paddd1regreg(RCX, RAX, RAX);
			e->psrld1regimm(RCX, RCX, 24);
			e->pcmpgtd1regreg(RCX, RCX, RBX);

			// save sign and clear if outside range
			e->psrld1regimm(RDX, RAX, 31);
			e->pandn1regreg(RAX, RCX, RAX);
			e->pand1regreg(RDX, RDX, RCX);

			// make mask
			e->psrld1regimm(RCX, RCX, 1);
			e->paddd1regreg(RDX, RDX, RCX);

			// convert to int -> RCX
			e->cvttps2dq1regreg(RCX, RAX);

			// or with mask
			e->por1regreg(RAX, RCX, RDX);

#endif



#ifdef USE_NEW_VECTOR_DISPATCH_FTOIX_R5900

			ret = Dispatch_Result_AVX2(i, false, RAX, i.Ft);

#else
			if (i.xyzw != 0xf)
			{
				e->pblendw1regmemimm(RAX, RAX, &VU0::_VU0->vf[i.Ft].sw0, ~((i.destx * 0x03) | (i.desty * 0x0c) | (i.destz * 0x30) | (i.destw * 0xc0)));
			}

			// get result
			ret = e->movdqa1_memreg(&VU0::_VU0->vf[i.Ft].sw0, RAX);

#endif

		}	// end if (iVectorType == VECTOR_TYPE_AVX2)
		else
		{
			//e->MovRegMem32 ( RAX, ( &VU0::_VU0->vf [ i.Fs ].sw0 ) + FsComponent );
			e->movdqa_regmem(RBX, &VU0::_VU0->vf[i.Fs].sw0);

			//if ( i.xyzw != 0xf )
			//{
			//	e->movdqa_regmem ( 5, & VU0::_VU0->vf [ i.Ft ].sw0 );
			//}

			if (IX)
			{
				e->MovRegImm32(RAX, IX << 23);
				e->movd_to_sse(RCX, RAX);
				e->pshufdregregimm(RCX, RCX, 0);
				e->padddregreg(RCX, RBX);
			}
			else
			{
				//e->MovRegReg32 ( RCX, RAX );
				e->movdqa_regreg(RCX, RBX);
			}

			// move the registers now to floating point unit
			//e->movd_to_sse ( RAX, RCX );

			// convert single precision to signed 
			//e->cvttss2si ( RCX, RAX );
			e->cvttps2dq_regreg(RCX, RCX);

			//e->Cdq ();
			//e->AndReg32ImmX ( RAX, 0x7f800000 );
			//e->CmovERegReg32 ( RDX, RAX );


			// compare exponent of magnitude and maximize if needed
			//e->CmpReg32ImmX ( RAX, 0x4e800000 - ( IX << 23 ) );
			//e->MovReg32ImmX ( RAX, 0x7fffffff );
			//e->CmovLERegReg32 ( RAX, RCX );
			//e->ShlRegImm32 ( RDX, 31 );
			//e->OrRegReg32 ( RAX, RDX );
			e->MovRegImm32(RAX, 0x4f000000 - (IX << 23) - 1);
			e->movd_to_sse(RDX, RAX);
			e->pshufdregregimm(RDX, RDX, 0);
			e->pcmpeqbregreg(RAX, RAX);
			e->psrldregimm(RAX, 1);

			e->movdqa_regreg(5, RAX);

			e->pandregreg(RAX, RBX);

			e->psrldregimm(RBX, 31);
			e->padddregreg(RBX, 5);

			//if ( i.xyzw != 0xf )
			//{
			//	e->movdqa_regmem ( 5, & VU0::_VU0->vf [ i.Ft ].sw0 );
			//}

			e->pcmpgtdregreg(RAX, RDX);

			e->pblendvbregreg(RCX, RBX);

			if (i.xyzw != 0xf)
			{
				//e->pblendwregregimm ( RCX, 5, ~( ( i.destx * 0x03 ) | ( i.desty * 0x0c ) | ( i.destz * 0x30 ) | ( i.destw * 0xc0 ) ) );
				e->pblendwregmemimm(RCX, &VU0::_VU0->vf[i.Ft].sw0, ~((i.destx * 0x03) | (i.desty * 0x0c) | (i.destz * 0x30) | (i.destw * 0xc0)));
			}

			// set result
			//ret = e->MovMemReg32 ( ( & v->vf [ i.Ft ].sw0 ) + FtComponent, RAX );
			ret = e->movdqa_memreg(&VU0::_VU0->vf[i.Ft].sw0, RCX);
		}
	}

	return ret;
}


int32_t R5900::Recompiler::Generate_VITOFXp ( R5900::Instruction::Format i, u64 FX )
{
	int32_t ret;
	
	ret = 1;

	if ( i.Ft && i.xyzw )
	{
		if (iVectorType == VECTOR_TYPE_AVX2)
		{

			e->movdqa1_regmem(RAX, &VU0::_VU0->vf[i.Fs].sw0);

#ifdef USE_NEW_VITOFX_AVX2_R5900

			// convert to float
			e->cvtdq2ps1regreg(RCX, RAX);

			if (FX)
			{
				e->MovReg32ImmX(RAX, (127 - FX) << 23);
				e->movd_to_sse128(RAX, RAX);
				e->vpbroadcastd1regreg(RAX, RAX);
				e->vmulps(RCX, RCX, RAX);
			}

#else

			// convert to float
			e->cvtdq2ps1regreg(RCX, RAX);


			if (FX)
			{
				// make mask to test if RBX is zero -> R4
				//e->pxor1regreg(4, 4, 4);
				//e->pcmpeqd1regreg(4, 4, RBX);

				// make constant 127 -> RDX
				e->pcmpeqb1regreg(5, 5, 5);
				//e->psrld1regimm(RDX, 5, 25);

				switch (FX)
				{
				case 4:
					e->psrld1regimm(4, 5, 31);
					//e->pslld1regimm(4, 4, (2 + 23));
					e->pslld1regimm(4, 4, 2);
					break;

				case 12:
					e->psrld1regimm(4, 5, 30);
					//e->pslld1regimm(4, 4, (2 + 23));
					e->pslld1regimm(4, 4, 2);
					break;

				case 15:
					e->psrld1regimm(4, 5, 28);
					//e->pslld1regimm(4, 4, (0 + 23));
					break;
				}

				// clear mask if RBX is zero
				//e->pandn1regreg(5, 4, 5);

				// subtract from exponent
				//e->psubd1regreg(RCX, RCX, 5);
				//e->psubd1regreg(RDX, RDX, 4);
				e->pslld1regimm(RDX, 4, 23);
				e->pxor1regreg(4, 4, 4);
				e->pcmpeqd1regreg(RAX, RAX, 4);
				e->pandn1regreg(RDX, RAX, RDX);
				//e->vmulps(RAX, RCX, RDX);
				e->psubd1regreg(RCX, RCX, RDX);
			}

			// debug -> positive float after decimal placement
			//e->movdqa_memreg(&v3, RCX);


			// add the sign
			//e->psrld1regimm(RAX, RAX, 31);
			//e->pslld1regimm(RAX, RAX, 31);
			//e->por1regreg(RAX, RAX, RCX);

#endif


#ifdef USE_NEW_VECTOR_DISPATCH_ITOFX_R5900

			ret = Dispatch_Result_AVX2(i, false, RCX, i.Ft);

#else
			// select result
			if (i.xyzw != 0xf)
			{
				// todo: use avx2
				//e->pblendwregmemimm(RAX, &v->vf[i.Ft].sw0, ~((i.destx * 0x03) | (i.desty * 0x0c) | (i.destz * 0x30) | (i.destw * 0xc0)));
				e->pblendw1regmemimm(RCX, RCX, &VU0::_VU0->vf[i.Ft].sw0, ~((i.destx * 0x03) | (i.desty * 0x0c) | (i.destz * 0x30) | (i.destw * 0xc0)));
			}

			// store result
			ret = e->movdqa1_memreg(&VU0::_VU0->vf[i.Ft].sw0, RCX);

#endif

		}	// end if (iVectorType == VECTOR_TYPE_AVX2)
		else
		{

			//e->MovRegMem32 ( RAX, ( &VU0::_VU0->vf [ i.Fs ].sw0 ) + FsComponent );
			e->movdqa_regmem(RBX, &VU0::_VU0->vf[i.Fs].sw0);

			// convert single precision to signed 
			//e->cvtsi2sd ( RAX, RAX );
			//e->movq_from_sse ( RAX, RAX );
			e->cvtdq2pd(RCX, RBX);


			//e->MovReg64ImmX ( RCX, ( 896 << 23 ) + ( FX << 23 ) );
			//e->Cqo();
			e->MovReg64ImmX(RAX, (896ull << 23) + (FX << 23));
			e->movq_to_sse(RDX, RAX);
			e->movddup_regreg(RDX, RDX);

			//e->ShrRegImm64 ( RAX, 29 );
			//e->CmovERegReg64 ( RCX, RDX );
			//e->SubRegReg64 ( RAX, RCX );
			e->movdqa_regreg(4, RCX);
			e->psrlqregimm(4, 63);
			e->pslldregimm(4, 31);
			e->psrlqregimm(RCX, 29);
			e->psubqregreg(RCX, RDX);
			e->porregreg(RCX, 4);

			e->pshufdregregimm(5, RBX, (3 << 2) | (2 << 0));
			e->cvtdq2pd(5, 5);

			e->movdqa_regreg(RAX, 5);
			e->psrlqregimm(RAX, 63);
			e->pslldregimm(RAX, 31);
			e->psrlqregimm(5, 29);
			e->psubqregreg(5, RDX);
			e->porregreg(5, RAX);

			// combine RCX (bottom) and 5 (top)
			e->pshufdregregimm(RCX, RCX, (2 << 2) | (0 << 0));
			e->pshufdregregimm(RDX, 5, (2 << 6) | (0 << 4));
			e->pblendwregregimm(RCX, RDX, 0xf0);

			// load destination register
			//if ( i.xyzw != 0xf )
			//{
			//	e->movdqa_regmem ( 5, & VU0::_VU0->vf [ i.Ft ].sw0 );
			//}

			// clear zeros
			e->pxorregreg(RAX, RAX);
			e->pcmpeqdregreg(RAX, RBX);
			e->pandnregreg(RAX, RCX);

			// select result
			if (i.xyzw != 0xf)
			{
				//e->pblendwregregimm ( RAX, 5, ~( ( i.destx * 0x03 ) | ( i.desty * 0x0c ) | ( i.destz * 0x30 ) | ( i.destw * 0xc0 ) ) );
				e->pblendwregmemimm(RAX, &VU0::_VU0->vf[i.Ft].sw0, ~((i.destx * 0x03) | (i.desty * 0x0c) | (i.destz * 0x30) | (i.destw * 0xc0)));
			}

			// store result
			ret = e->movdqa_memreg(&VU0::_VU0->vf[i.Ft].sw0, RAX);

			//e->ShlRegImm32 ( RDX, 31 );
			//e->OrRegReg32 ( RAX, RDX );

			// set result
			//ret = e->MovMemReg32 ( ( &VU0::_VU0->vf [ i.Ft ].sw0 ) + FtComponent, RAX );
		}
	}

	return ret;
}



int32_t R5900::Recompiler::Generate_VMOVEp ( R5900::Instruction::Format i )
{
	int32_t ret;
	
	ret = 1;

	if ( i.Ft && i.xyzw )
	{
		e->movdqa_regmem ( RCX, & VU0::_VU0->vf [ i.Fs ].sw0 );
		
		if ( i.xyzw != 0xf )
		{
			//e->movdqa_regmem ( RAX, & VU0::_VU0->vf [ i.Ft ].sw0 );
			//e->pblendwregregimm ( RCX, RAX, ~( ( i.destx * 0x03 ) | ( i.desty * 0x0c ) | ( i.destz * 0x30 ) | ( i.destw * 0xc0 ) ) );
			e->pblendwregmemimm ( RCX, & VU0::_VU0->vf [ i.Ft ].sw0, ~( ( i.destx * 0x03 ) | ( i.desty * 0x0c ) | ( i.destz * 0x30 ) | ( i.destw * 0xc0 ) ) );
		}
		
		ret = e->movdqa_memreg ( & VU0::_VU0->vf [ i.Ft ].sw0, RCX );
	}

	return ret;
}


int32_t R5900::Recompiler::Generate_VMR32p ( R5900::Instruction::Format i )
{
	int32_t ret;
	
	ret = 1;

	if ( i.Ft && i.xyzw )
	{
		//e->movdqa_regmem ( RCX, & VU0::_VU0->vf [ i.Fs ].sw0 );
		
		//if ( i.xyzw != 0xf )
		//{
		//	e->movdqa_regmem ( RAX, & VU0::_VU0->vf [ i.Ft ].sw0 );
		//}
		
		//e->pshufdregregimm ( RCX, RCX, ( 0 << 6 ) | ( 3 << 4 ) | ( 2 << 2 ) | ( 1 << 0 ) );
		e->pshufdregmemimm ( RCX, & VU0::_VU0->vf [ i.Fs ].sw0, ( 0 << 6 ) | ( 3 << 4 ) | ( 2 << 2 ) | ( 1 << 0 ) );
		
		if ( i.xyzw != 0xf )
		{
			//e->pblendwregregimm ( RCX, RAX, ~( ( i.destx * 0x03 ) | ( i.desty * 0x0c ) | ( i.destz * 0x30 ) | ( i.destw * 0xc0 ) ) );
			e->pblendwregmemimm ( RCX, & VU0::_VU0->vf [ i.Ft ].sw0, ~( ( i.destx * 0x03 ) | ( i.desty * 0x0c ) | ( i.destz * 0x30 ) | ( i.destw * 0xc0 ) ) );
		}
		
		ret = e->movdqa_memreg ( & VU0::_VU0->vf [ i.Ft ].sw0, RCX );
	}

	return ret;
}



int32_t R5900::Recompiler::Generate_VMFIRp ( R5900::Instruction::Format i )
{
	int32_t ret;
	
	ret = 1;

	if ( i.Ft && i.xyzw )
	{
		// flush ps2 float to zero
		if ( !( i.is & 0xf ) )
		{
			//if ( i.xyzw != 0xf )
			//{
			//	e->movdqa_regmem ( RAX, & VU0::_VU0->vf [ i.Ft ].sw0 );
			//}
			
			e->pxorregreg ( RCX, RCX );
			
			if ( i.xyzw != 0xf )
			{
				//e->pblendwregregimm ( RCX, RAX, ~( ( i.destx * 0x03 ) | ( i.desty * 0x0c ) | ( i.destz * 0x30 ) | ( i.destw * 0xc0 ) ) );
				e->pblendwregmemimm ( RCX, & VU0::_VU0->vf [ i.Ft ].sw0, ~( ( i.destx * 0x03 ) | ( i.desty * 0x0c ) | ( i.destz * 0x30 ) | ( i.destw * 0xc0 ) ) );
			}
			
			ret = e->movdqa_memreg ( & VU0::_VU0->vf [ i.Ft ].sw0, RCX );
		}
		else
		{
			// flush ps2 float to zero
			e->MovRegMem32 ( RAX, ( &VU0::_VU0->vi [ i.is & 0xf ].s ) );
			
			//if ( i.xyzw != 0xf )
			//{
			//	e->movdqa_regmem ( RAX, & VU0::_VU0->vf [ i.Ft ].sw0 );
			//}
			
			// sign-extend from 16-bit to 32-bit
			e->Cwde();
			
			e->movd_to_sse ( RCX, RAX );
			e->pshufdregregimm ( RCX, RCX, 0 );
			
			if ( i.xyzw != 0xf )
			{
				//e->pblendwregregimm ( RCX, RAX, ~( ( i.destx * 0x03 ) | ( i.desty * 0x0c ) | ( i.destz * 0x30 ) | ( i.destw * 0xc0 ) ) );
				e->pblendwregmemimm ( RCX, & VU0::_VU0->vf [ i.Ft ].sw0, ~( ( i.destx * 0x03 ) | ( i.desty * 0x0c ) | ( i.destz * 0x30 ) | ( i.destw * 0xc0 ) ) );
			}
			
			// set result
			//ret = e->MovMemReg32 ( ( &VU0::_VU0->vf [ i.Ft ].sw0 ) + FtComponent, RAX );
			ret = e->movdqa_memreg ( & VU0::_VU0->vf [ i.Ft ].sw0, RCX );
		}
		
	}

	return ret;
}




int32_t R5900::Recompiler::Generate_VMTIRp ( R5900::Instruction::Format i )
{
	int32_t ret;
	
	ret = 1;

	if ( ( i.it & 0xf ) )
	{
		//v->Set_IntDelaySlot ( i.it & 0xf, (u16) v->vf [ i.Fs ].vsw [ i.fsf ] );
		
		// flush ps2 float to zero
		if ( ( !i.Fs ) && ( i.fsf < 3 ) )
		{
			//e->MovMemImm32 ( ( & VU0::_VU0->vf [ i.Ft ].sw0 ) + FtComponent, 0 );
			e->MovMemImm32 ( & VU0::_VU0->vi [ i.it & 0xf ].s, 0 );
		}
		else
		{
			// flush ps2 float to zero
			e->MovRegMem32 ( RAX, & VU0::_VU0->vf [ i.Fs ].vsw [ i.fsf ] );
			e->AndRegImm32 ( RAX, 0xffff );
			
			// set result
			ret = e->MovMemReg32 ( & VU0::_VU0->vi [ i.it & 0xf ].s, RAX );
		}
		
	}

	return ret;
}



// set bSub to 1 for subtraction
int32_t R5900::Recompiler::Generate_VADDp(u32 bSub, R5900::Instruction::Format i, u32 FtComponent, void* pFd, u32* pFt)
{
	static constexpr int64_t max_double = 0x47ffffffffffffffull;
	static constexpr int64_t min_double = 0x3800000000000000ull;

	static constexpr int64_t bit1_double = 0x0010000000000000ull;
	static constexpr int64_t bit1_double_mask = 0x4000000000000000ull;
	static constexpr int32_t bit1_float = 0x00800000;
	static constexpr int32_t bit1_float_mask = 0x40000000;

	static constexpr int64_t flt_double_mask = 0xffffffffe0000000ull;
	static constexpr int64_t ps2_mul1_double_mask = 0xffffffffc0000000ull;

	static constexpr int64_t mantissa_double_mask = 0xfffffe0000000000ull;

	static constexpr int64_t zero_double = 0ull;

	int32_t ret;

	u64 start, end, addr;

	u32 Address = e->x64CurrentSourceAddress;

	ret = 1;


	if (i.xyzw)
	{

//#define ALLOW_AVX2_ADDX1
#ifdef ALLOW_AVX2_ADDX1
		if (iVectorType == VECTOR_TYPE_AVX512)
#endif
		{
			int32_t kreg = 0;
			if (i.xyzw != 0xf)
			{
				kreg = 1;
				e->kmovdmskmem(kreg, (int32_t*)&(xyzw_rev_mask_lut32[i.xyzw]));
			}


			e->movdqa32_rm128(RAX, (void*)&VU0::_VU0->vf[i.Fs].sw0);

			if (isADDBC(i) || isADDABC(i) || isSUBBC(i) || isSUBABC(i))
			{
				e->vpbroadcastd_rm128(RCX, (int32_t*)&VU0::_VU0->vf[i.Ft].vuw[i.bc]);
			}
			else if (isADDi(i) || isADDAi(i) || isSUBi(i) || isSUBAi(i))
			{
				e->vpbroadcastd_rm128(RCX, (int32_t*)&VU0::_VU0->vi[VU::REG_I].sw0);
			}
			else if (isADDq(i) || isADDAq(i) || isSUBq(i) || isSUBAq(i))
			{
				e->vpbroadcastd_rm128(RCX, (int32_t*)&VU0::_VU0->vi[VU::REG_Q].sw0);
			}
			else
			{
				e->movdqa32_rm128(RCX, &VU0::_VU0->vf[i.Ft].sw0);
			}


			e->vinserti32x4_rri256(RAX, RAX, RCX, 1);

			//e->movdqa32_rm128(RAX, (void*)&vs.uw0);
			//e->vinserti32x4_rmi256(RAX, RAX, (void*)&vt.uw0, 1);
			e->vptestmd_rrb256(2, RAX, (int32_t*)&bit1_float_mask);
			e->psubd_rrb256(RAX, RAX, (int32_t*)&bit1_float, 2);
			e->cvtps2pd_rr512(RAX, RAX);
			e->paddq_rrb512(RAX, RAX, (int64_t*)&bit1_double, 2);
			//e->pshufd_rri128(RCX, RAX, 0x0e);
			e->vextracti64x4_rri512(RCX, RAX, 1);


			// testing
			//e->movq_to_x64_mr128((int64_t*)&v1.uq0, RAX);
			//e->movq_to_x64_mr128((int64_t*)&v1.uq1, RCX);
			//e->movdqa32_mr128((void*)&v1.uq0, RAX);
			//e->kmovdmemmsk((int32_t*)&v2.uw0, 2);

			// testing
			//e->movq_to_x64_mr128((int64_t*)&v3.uq0, RAX);
			//e->movq_to_x64_mr128((int64_t*)&v3.uq1, RCX);




			// get guard mask
			//e->pxor_rrr256(RDX, RAX, RCX);
			if (bSub)
			{
				e->pand_rrr256(RDX, RAX, RCX);
			}
			else
			{
				e->pxor_rrr256(RDX, RAX, RCX);
			}
			e->psrlq_rri256(RDX, RDX, 63);
			e->psllq_rri256(RDX, RDX, 27);

			//e->vaddpd_rrr256(RAX, RAX, RCX);
			if (bSub)
			{
				// sub
				e->vsubpd_rrr256(RAX, RAX, RCX);
			}
			else
			{
				// add
				e->vaddpd_rrr256(RAX, RAX, RCX);
			}

			e->paddq_rrr256(RAX, RAX, RDX);


			// testing
			//e->movq_to_x64_mr128((int64_t*)&v2.uq0, RAX);


			e->vrangepd_rbi256(RBX, RAX, (int64_t*)&max_double, 2);
			//e->vrangepd_rbi256(RCX, RAX, (int64_t*)&min_double, 2);


			// overflow -> k2
			e->cmppdne_rrr256(2, RAX, RBX, kreg);

			// underflow -> k3
			//e->pxor_rrr256(RDX, RDX, RDX);
			//e->cmppdeq_rrr256(3, RAX, RCX);
			//e->cmppdne_rrr256(3, RAX, RDX, 3);


			// zero result on underflow
			// note: need these two instructions if caching double values
			//e->vrangepd_rri256(RBX, RBX, RDX, 2, 3);
			//e->pandq_rrm128(RBX, RBX, (void*)&flt_double_mask2);


			// testing value
			//e->movq_to_sse_rm128(RBX, (int64_t*)&test_value);


			// testing
			//e->movq_to_x64_mr128((int64_t*)&v4.uw0, RBX);
			//e->movq_to_x64_mr128((int64_t*)&v4.uq1, RCX);


			// convert result(rbx) to float ->rax
			e->vptestmq_rrb256(5, RBX, (int64_t*)&bit1_double_mask);
			e->psubq_rrb256(RBX, RBX, (int64_t*)&bit1_double, 5);
			e->cvtpd2ps_rr256(RAX, RBX);
			e->paddd_rrb128(RAX, RAX, (int32_t*)&bit1_float, 5);

			// zero -> k4
			// underflow -> k3
			e->pxor_rrr128(RDX, RDX, RDX);
			e->cmppseq_rrr128(4, RAX, RDX, kreg);
			e->cmppdne_rrr256(3, RBX, RDX, 4);

			// sign -> k5
			e->cmppdlt_rrr256(5, RBX, RDX, kreg);

			// store result
			//e->movdqa32_mr128((int32_t*)&vd.uw0, RAX);
			if (pFd)
			{
				//e->movdqa1_memreg(pFd, RAX);
				e->movdqa32_mr128(pFd, RAX, kreg);
			}
			else
			{
				if (i.Fd)
				{
					//e->movdqa1_memreg(&VU0::_VU0->vf[i.Fd].sw0, RAX);
					e->movdqa32_mr128(&VU0::_VU0->vf[i.Fd].sw0, RAX, kreg);
				}
			}

			// get flags
			//e->movd_to_sse_rm128(RAX, (int32_t*)&statflag);
			//e->pandd_rrb128(RAX, RAX, (int32_t*)&sticky_flag_mask);
			//e->pord_rrb128(RAX, RAX, (int32_t*)&ovf_float_flag, 2);
			//e->pord_rrb128(RAX, RAX, (int32_t*)&und_float_flag, 3);
			//e->movd_to_x64_mr128((int32_t*)&statflag, RAX);

			// ousz flags
			e->kshiftlb(5, 5, 4);
			e->kshiftlb(2, 2, 4);
			e->korb(4, 4, 5);
			e->korb(2, 2, 3);
			e->kunpackbw(2, 2, 4);

			e->vpmovm2d_rr512(RAX, 2);
			e->pshufd_rri512(RAX, RAX, (0 << 6) | (1 << 4) | (2 << 2) | (3 << 0));
			e->vpmovd2m_rr512(2, RAX);
			e->kmovdmemmsk(&VU0::_VU0->vi[VU::REG_MACFLAG].s, 2);

			e->vpmovm2b_rr128(RAX, 2);
			e->vpcmpdne_rrr128(3, RAX, RDX);
			e->kshiftld(4, 3, 6);
			e->kord(3, 3, 4);
			e->kmovdregmsk(RAX, 3);

			e->AndMem32ImmX(&VU0::_VU0->vi[VU::REG_STATUSFLAG].s, ~0xf);
			ret = e->OrMemReg32(&VU0::_VU0->vi[VU::REG_STATUSFLAG].s, RAX);

			return ret;
		}
#ifdef ALLOW_AVX2_ADDX1

		else if (iVectorType == VECTOR_TYPE_AVX2)
		{

#ifdef USE_NEW_VADD_AVX2

			//e->movdqa32_rm128(RAX, (void*)&VU0::_VU0->vf[i.Fs].sw0);
			e->pshufd1regmemimm(RAX, (void*)&VU0::_VU0->vf[i.Fs].sw0, (0 << 6) | (1 << 4) | (2 << 2) | (3 << 0));

			if (isADDBC(i) || isADDABC(i) || isSUBBC(i) || isSUBABC(i))
			{
				e->vpbroadcastd1regmem(RCX, (int32_t*)&VU0::_VU0->vf[i.Ft].vuw[i.bc]);
			}
			else if (isADDi(i) || isADDAi(i) || isSUBi(i) || isSUBAi(i))
			{
				e->vpbroadcastd1regmem(RCX, (int32_t*)&VU0::_VU0->vi[VU::REG_I].sw0);
			}
			else if (isADDq(i) || isADDAq(i) || isSUBq(i) || isSUBAq(i))
			{
				e->vpbroadcastd1regmem(RCX, (int32_t*)&VU0::_VU0->vi[VU::REG_Q].sw0);
			}
			else
			{
				//e->movdqa32_rm128(RCX, &VU0::_VU0->vf[i.Ft].sw0);
				e->pshufd1regmemimm(RCX, (void*)&VU0::_VU0->vf[i.Ft].sw0, (0 << 6) | (1 << 4) | (2 << 2) | (3 << 0));
			}
			

			e->vinserti128regreg(RCX, RAX, RCX, 1);

			//e->movdqa1_regmem(RCX, (void*)&vs.uw0);
			//e->vinserti128regmem(RCX, RCX, (void*)&vt.uw0, 1);
			e->vsubps2(RBX, RCX, RCX);
			e->psrld2regimm(RBX, RBX, 7);
			e->psubd2regreg(RCX, RCX, RBX);
			e->cvtps2pd2regreg(RAX, RCX);
			e->pmovsxdq2regreg(RDX, RBX);
			e->psllq2regimm(RDX, RDX, 29);
			e->paddq2regreg(RAX, RAX, RDX);
			e->vextracti128regreg(RBX, RBX, 1);
			e->vextracti128regreg(RCX, RCX, 1);
			e->cvtps2pd2regreg(RCX, RCX);
			e->pmovsxdq2regreg(RBX, RBX);
			e->psllq2regimm(RBX, RBX, 29);
			e->paddq2regreg(RCX, RCX, RBX);


			// get guard mask
			//e->pxor2regreg(RBX, RAX, RCX);
			e->pxor2regreg(RBX, RAX, RCX);

			if (bSub)
			{
				//e->pand2regreg(RBX, RAX, RCX);
				e->pcmpeqb2regreg(RDX, RDX, RDX);
				e->pxor2regreg(RBX, RBX, RDX);
			}

			e->psrlq2regimm(RBX, RBX, 63);
			e->psllq2regimm(RBX, RBX, 27);


			//e->vaddpd2(RAX, RAX, RCX);
			if (bSub)
			{
				// sub
				e->vsubpd2(RAX, RAX, RCX);
			}
			else
			{
				// add
				e->vaddpd2(RAX, RAX, RCX);
			}

			e->paddq2regreg(RAX, RAX, RBX);


			// testing
			//e->ldmxcsr((int32_t*)&macflag);

			// convert result(rax) to float -> rcx
			e->psllq2regimm(RBX, RAX, 1);
			e->psrlq2regimm(RBX, RBX, 63);
			e->psllq2regimm(RBX, RBX, 52);
			e->psubq2regreg(RCX, RAX, RBX);
			e->cvtpd2ps2regreg(RCX, RCX);


			// convert back (rcx) -> r4
			e->cvtps2pd2regreg(4, RCX);


			// these two only needed when writing back as float
			// result -> rcx
			// todo: need pshufps ?
			e->psrlq2regimm(RDX, RBX, 29);

			// pshufps
			e->vextracti128regreg(5, RDX, 1);


			// testing
			//e->movdqa1_memreg((void*)&v0.uq0, RCX);
			//e->movdqa1_memreg((void*)&v1.uq0, 5);


			e->pshufps1regregimm(RDX, RDX, 5, 0x88);

			e->paddd1regreg(RDX, RDX, RCX);


			// restore clamped value -> rbx
			e->paddq2regreg(RBX, RBX, 4);

			// reverse float value (rdx) for storage -> rdx
			e->pshufd1regregimm(RDX, RDX, (0 << 6) | (1 << 4) | (2 << 2) | (3 << 0));

#ifdef USE_NEW_VECTOR_DISPATCH_VADD_R5900

			if (pFd)
			{
				Dispatch_Result_AVX2(i, true, RDX, i.Fd);
			}
			else
			{
				Dispatch_Result_AVX2(i, false, RDX, i.Fd);
			}

#else
			// store result (rcx)
			//e->movdqa1_memreg((void*)&vd.uw0, RCX);
			if (i.xyzw != 0xf)
			{
				if (pFd)
				{
					e->pblendw1regmemimm(RDX, RDX, pFd, ~((i.destx * 0x03) | (i.desty * 0x0c) | (i.destz * 0x30) | (i.destw * 0xc0)));
				}
				else
				{
					if (i.Fd)
					{
						e->pblendw1regmemimm(RDX, RDX, &VU0::_VU0->vf[i.Fd].sw0, ~((i.destx * 0x03) | (i.desty * 0x0c) | (i.destz * 0x30) | (i.destw * 0xc0)));
					}
				}
			}

			if (pFd)
			{
				e->movdqa1_memreg(pFd, RDX);
			}
			else
			{
				if (i.Fd)
				{
					e->movdqa1_memreg(&VU0::_VU0->vf[i.Fd].sw0, RDX);
				}
			}

#endif

			// get overflow -> r4
			// clamped result in (rbx)
			// un-clamped result in (rax)
			e->pand2regreg(4, RAX, RBX);
			e->cmpnepd(4, 4, RBX);

			// get underflow -> rax
			e->pxor2regreg(RDX, RDX, RDX);
			e->cmpeqpd(RAX, RAX, RDX);
			e->cmpeqpd(RAX, RAX, RBX);

			// overflow (r4) -> rbx
			// underflow (rax) -> rax
			e->cvtpd2ps2regreg(RBX, 4);
			e->cvtpd2ps2regreg(RAX, RAX);


			// sign flag -> r4
			// zero flag -> rcx
			//e->cmpgtps(4, RDX, RCX);
			e->pcmpgtd1regreg(4, RDX, RCX);
			e->cmpeqps(RCX, RDX, RCX);

			// testing
			//e->stmxcsr((int32_t*)& macflag);


			// get flags
			// could combine sign(r4) | zero(rcx) here for simd ->rcx
			e->packsdw1regreg(RCX, RCX, 4);
			e->packsdw1regreg(RAX, RAX, RBX);


			// flags
			if (i.xyzw != 0xf)
			{
				e->pblendw1regregimm(RCX, RCX, RDX, ~((i.destx * 0x88) | (i.desty * 0x44) | (i.destz * 0x22) | (i.destw * 0x11)));
				e->pblendw1regregimm(RAX, RAX, RDX, ~((i.destx * 0x88) | (i.desty * 0x44) | (i.destz * 0x22) | (i.destw * 0x11)));
			}

			e->packswb1regreg(RAX, RCX, RAX);

			// now get stat
			e->psrld1regimm(RCX, RAX, 7);
			e->pcmpgtd1regreg(RCX, RCX, RDX);


			// now pull mac(RAX)->RCX and stat(RCX)->RAX
			e->movmskb1regreg(RCX, RAX);
			e->movmskps1regreg(RAX, RCX);

			// store mac
			// set MAC flags (RCX)
			//e->MovMemReg32((int32_t*)&macflag, RCX);
			ret = e->MovMemReg32((int32_t*)&VU0::_VU0->vi[VU::REG_MACFLAG].s, RCX);

			// update stat
			// check if the lower instruction set stat flag already (there's only like one instruction that does this)
			//if (!v->SetStatus_Flag)
			{
				e->MovRegReg32(RCX, RAX);

				e->ShlRegImm32(RAX, 6);
				//e->OrRegMem32(RAX, (int32_t*)&statflag);
				e->OrRegMem32(RAX, (int32_t*)&VU0::_VU0->vi[VU::REG_STATUSFLAG].s);

				// these two instructions are if you need to set non-sticky flags
				e->AndReg32ImmX(RAX, ~0xf);
				e->OrRegReg32(RAX, RCX);

				//e->MovMemReg32((int32_t*)&statflag, RAX);
				ret = e->MovMemReg32((int32_t*)&VU0::_VU0->vi[VU::REG_STATUSFLAG].s, RAX);

			}	// end if ( !v->SetStatus_Flag )

#else

			if (pFt)
			{
				//e->movd1_regmem(RCX, (int32_t*)pFt);
				//e->pshufd1regregimm(RCX, RCX, (FtComponent << 6) | (FtComponent << 4) | (FtComponent << 2) | (FtComponent << 0));
				e->vpbroadcastd1regmem(RCX, (int32_t*)pFt);
			}
			else
			{

				if (FtComponent < 4)
				{
					e->pshufd1regmemimm(RCX, &VU0::_VU0->vf[i.Ft].sw0, (FtComponent << 6) | (FtComponent << 4) | (FtComponent << 2) | (FtComponent << 0));
				}
				else
				{
					e->pshufd1regmemimm(RCX, &VU0::_VU0->vf[i.Ft].sw0, (0 << 6) | (1 << 4) | (2 << 2) | (3 << 0));
				}
			}

			e->pshufd1regmemimm(RAX, &VU0::_VU0->vf[i.Fs].sw0, (0 << 6) | (1 << 4) | (2 << 2) | (3 << 0));


			// create mask
			e->pcmpeqb2regreg(5, 5, 5);

			// check if doing subtraction instead of addition
			//if (bSub)
			//{
			//	// toggle the sign on RCX (right-hand argument) for subtraction for now
			//	e->pslld1regimm(4, 5, 31);
			//	e->pxor1regreg(RCX, RCX, 4);
			//}

			// get mask
			e->psrlq2regimm(4, 5, 61);
			e->psllq2regimm(4, 4, 60);

			// cvt w/ sign extend
			e->pmovsxdq2regreg(RAX, RAX);
			e->pmovsxdq2regreg(RCX, RCX);


			// cvt float to double
			e->psllq2regimm(RAX, RAX, 29);
			e->psllq2regimm(RCX, RCX, 29);
			e->pandn2regreg(RAX, 4, RAX);
			e->pandn2regreg(RCX, 4, RCX);

			// get multipliers
			// 127 << 23 ->rbx
			// 1023+127 << 52 ->r4
			e->psrlq2regimm(4, 5, 54);
			e->psrlq2regimm(RBX, 5, 57);
			e->paddq2regreg(4, 4, RBX);
			e->psllq2regimm(RBX, RBX, 23);
			e->psllq2regimm(4, 4, 52);

			// get guard mask
			if (bSub)
			{
				e->pand2regreg(RDX, RAX, RCX);
			}
			else
			{
				e->pxor2regreg(RDX, RAX, RCX);
			}

			e->psrlq2regimm(RDX, RDX, 63);
			e->psllq2regimm(RDX, RDX, 27);

			// use multiplier
			e->vmulpd2(RAX, RAX, 4);
			e->vmulpd2(RCX, RCX, 4);

			if (bSub)
			{
				// sub
				e->vsubpd2(RAX, RAX, RCX);
			}
			else
			{
				// add
				e->vaddpd2(RAX, RAX, RCX);
			}

			// adjust ??
			e->paddq2regreg(RAX, RAX, RDX);

			// get zero ->r4
			e->pxor2regreg(4, 4, 4);

			// get sign ->rdx
			//e->pcmpgtq2regreg(RDX, 4, RAX);
			//e->vextracti128regreg(RCX, RDX, 1);
			//e->packsdw1regreg(RDX, RDX, RCX);
			e->vextracti128regreg(RDX, RAX, 1);
			e->packsdw1regreg(RDX, RAX, RDX);

			// get result ->rax
			e->paddq2regreg(RAX, RAX, RAX);
			e->psrlq2regimm(RAX, RAX, 30);

			// check for zero before ->rcx
			e->pcmpeqq2regreg(RCX, RAX, 4);

			// subtract 127(rbx) from exponent
			e->psubq2regreg(RAX, RAX, RBX);

			// clear result(rax) if it was originally zero(rcx)
			e->pandn2regreg(RAX, RCX, RAX);

			// get underflow ->rbx
			e->pshufd2regregimm(RAX, RAX, 0xd8);
			e->vextracti128regreg(RCX, RAX, 1);
			e->punpckhqdq1regreg(RBX, RAX, RCX);

			// get float result ->rax
			e->punpcklqdq1regreg(RAX, RAX, RCX);

			// check for zero exponent ->rcx
			e->psrld1regimm(RCX, RAX, 23);
			e->pcmpeqd1regreg(RCX, RCX, 4);


			// also zero(rcx) on underflow(rbx)
			e->por1regreg(RCX, RCX, RBX);

			// clear result(rax) on zero(rcx)
			e->pandn1regreg(RAX, RCX, RAX);

			// mask sign(rdx) ->rdx
			e->psrld1regimm(5, 5, 1);
			e->pandn1regreg(RDX, 5, RDX);

			// max result on overflow ->r5
			e->pminud1regreg(5, 5, RAX);

			// combine overflow(rax) | underflow(rbx) ->rbx
			e->pcmpgtd1regreg(RAX, 4, RAX);
			e->packsdw1regreg(RBX, RBX, RAX);

			// combine sign(rdx) and result(r5) ->rax
			e->por1regreg(RAX, RDX, 5);

			// combine sign(rdx) | zero(rcx) here for simd ->rcx
			// sign flag set on negative number not zero
			e->pandn1regreg(5, RCX, RDX);
			e->packsdw1regreg(RCX, RCX, 5);


			// get overflow ->r5
			// might need to use the first method for simd
			//e->pcmpgtd1regreg(5, 4, RAX);

			// max result(rax) on overflow(r5)
			//e->por1regreg(RAX, RAX, 5);

			// combine overflow(r5) | underflow(rbx) ->rbx
			//e->packsdw1regreg(RBX, RBX, 5);

			// clear sign bit in result(RAX)
			//e->paddd1regreg(RAX, RAX, RAX);
			//e->psrld1regimm(RAX, RAX, 1);

			// add sign(rdx)
			//e->pslld1regimm(RDX, RDX, 31);
			//e->por1regreg(RAX, RAX, RDX);

			// set result
			e->pshufd1regregimm(RAX, RAX, (0 << 6) | (1 << 4) | (2 << 2) | (3 << 0));

			if (i.xyzw != 0xf)
			{
				if (pFd)
				{
					e->pblendw1regmemimm(RAX, RAX, pFd, ~((i.destx * 0x03) | (i.desty * 0x0c) | (i.destz * 0x30) | (i.destw * 0xc0)));
				}
				else
				{
					if (i.Fd)
					{
						e->pblendw1regmemimm(RAX, RAX, &VU0::_VU0->vf[i.Fd].sw0, ~((i.destx * 0x03) | (i.desty * 0x0c) | (i.destz * 0x30) | (i.destw * 0xc0)));
					}
				}
			}

			if (pFd)
			{
				e->movdqa1_memreg(pFd, RAX);
			}
			else
			{
				if (i.Fd)
				{
					e->movdqa1_memreg(&VU0::_VU0->vf[i.Fd].sw0, RAX);
				}
			}

			// flags
			if (i.xyzw != 0xf)
			{
				e->pblendw1regregimm(RCX, RCX, 4, ~((i.destx * 0x88) | (i.desty * 0x44) | (i.destz * 0x22) | (i.destw * 0x11)));
				e->pblendw1regregimm(RBX, RBX, 4, ~((i.destx * 0x88) | (i.desty * 0x44) | (i.destz * 0x22) | (i.destw * 0x11)));
			}

			e->packswb1regreg(RAX, RCX, RBX);

			// now get stat
			e->psrld1regimm(RCX, RAX, 7);
			e->pcmpgtd1regreg(RCX, RCX, 4);

			// now pull mac(RAX)->RCX and stat(RCX)->RAX
			e->movmskb1regreg(RCX, RAX);
			e->movmskps1regreg(RAX, RCX);


			// store mac
			// set MAC flags (RCX)
			//e->MovMemReg32((int32_t*)&macflag, RCX);
			e->MovMemReg32((int32_t*)&VU0::_VU0->vi[VU::REG_MACFLAG].s, RCX);


			// update stat
			// check if the lower instruction set stat flag already (there's only like one instruction that does this)
			//if (!v->SetStatus_Flag)
			{
				e->MovRegReg32(RCX, RAX);

				e->ShlRegImm32(RAX, 6);
				//e->OrRegMem32(RAX, (int32_t*)&statflag);
				e->OrRegMem32(RAX, (int32_t*)&VU0::_VU0->vi[VU::REG_STATUSFLAG].s);


				// these two instructions are if you need to set non-sticky flags
				e->AndReg32ImmX(RAX, ~0xf);
				e->OrRegReg32(RAX, RCX);

				//e->MovMemReg32((int32_t*)&statflag, RAX);
				e->MovMemReg32((int32_t*)&VU0::_VU0->vi[VU::REG_STATUSFLAG].s, RAX);

			}	// end if ( !v->SetStatus_Flag )

#endif	// end #ifdef #else USE_NEW_VADD_AVX2

		}	// end if (iVectorType == VECTOR_TYPE_AVX2)

#endif	// #ifdef ALLOW_AVX2_ADDX1

	}	// end if ( i.xyzw )


	return ret;
}



int32_t R5900::Recompiler::Dispatch_Result_AVX2(R5900::Instruction::Format i, int32_t Accum, int32_t sseSrcReg, int32_t VUDestReg)
{
	int32_t ret = 1;

	if (i.xyzw)
	{
		if (Accum)
		{
			if (i.xyzw == 0xf)
			{
				ret = e->movdqa1_memreg(&VU0::_VU0->dACC[0].l, sseSrcReg);
			}
			else
			{
				if ((i.xyzw & 0xc) == 0xc)
				{
					ret = e->movq1_memreg((int64_t*)&VU0::_VU0->dACC[0].l, sseSrcReg);
				}
				else if ((i.xyzw & 0xc) == 0x8)
				{
					ret = e->movd1_memreg((int32_t*)&VU0::_VU0->dACC[0].l, sseSrcReg);
				}
				else if ((i.xyzw & 0xc) == 0x4)
				{
					ret = e->pextrd1memreg((int32_t*)&VU0::_VU0->dACC[1].l, sseSrcReg, 1);
				}

				if ((i.xyzw & 0x3) == 0x3)
				{
					ret = e->pextrq1memreg((int64_t*)&VU0::_VU0->dACC[2].l, sseSrcReg, 1);
				}
				else if ((i.xyzw & 0x3) == 0x2)
				{
					ret = e->pextrd1memreg((int32_t*)&VU0::_VU0->dACC[2].l, sseSrcReg, 2);
				}
				else if ((i.xyzw & 0x3) == 0x1)
				{
					ret = e->pextrd1memreg((int32_t*)&VU0::_VU0->dACC[3].l, sseSrcReg, 3);
				}

			}	// end if (i.xyzw == 0xf) else

		}
		else
		{
			if (VUDestReg)
			{
				if (i.xyzw == 0xf)
				{
					ret = e->movdqa1_memreg(&VU0::_VU0->vf[VUDestReg].sw0, sseSrcReg);
				}
				else
				{
					if ((i.xyzw & 0xc) == 0xc)
					{
						ret = e->movq1_memreg((int64_t*)&VU0::_VU0->vf[VUDestReg].sw0, sseSrcReg);
					}
					else if ((i.xyzw & 0xc) == 0x8)
					{
						ret = e->movd1_memreg((int32_t*)&VU0::_VU0->vf[VUDestReg].sw0, sseSrcReg);
					}
					else if ((i.xyzw & 0xc) == 0x4)
					{
						ret = e->pextrd1memreg((int32_t*)&VU0::_VU0->vf[VUDestReg].sw1, sseSrcReg, 1);
					}

					if ((i.xyzw & 0x3) == 0x3)
					{
						ret = e->pextrq1memreg((int64_t*)&VU0::_VU0->vf[VUDestReg].sq1, sseSrcReg, 1);
					}
					else if ((i.xyzw & 0x3) == 0x2)
					{
						ret = e->pextrd1memreg((int32_t*)&VU0::_VU0->vf[VUDestReg].sw2, sseSrcReg, 2);
					}
					else if ((i.xyzw & 0x3) == 0x1)
					{
						ret = e->pextrd1memreg((int32_t*)&VU0::_VU0->vf[VUDestReg].sw3, sseSrcReg, 3);
					}

				}	// end if (i.xyzw == 0xf) else

			}	// end if (VUDestReg)

		}	// end if (Accum) else

	}	// end if (i.xyzw)

	return ret;
}


int32_t R5900::Recompiler::Generate_VMULp(R5900::Instruction::Format i, u32 FtComponentp, void* pFd, u32* pFt, u32 FsComponentp)
{
	static constexpr int64_t max_double = 0x47ffffffffffffffull;
	static constexpr int64_t min_double = 0x3800000000000000ull;

	static constexpr int64_t bit1_double = 0x0010000000000000ull;
	static constexpr int64_t bit1_double_mask = 0x4000000000000000ull;
	static constexpr int32_t bit1_float = 0x00800000;
	static constexpr int32_t bit1_float_mask = 0x40000000;

	static constexpr int64_t flt_double_mask = 0xffffffffe0000000ull;
	static constexpr int64_t ps2_mul1_double_mask = 0xffffffffc0000000ull;

	static constexpr int64_t mantissa_double_mask = 0xfffffe0000000000ull;

	static constexpr int64_t zero_double = 0ull;

	int32_t ret;

	u64 start, end, addr;

	u32 Address = e->x64CurrentSourceAddress;

	ret = 1;

	if (i.xyzw)
	{
//#define ALLOW_AVX2_MULX1
#ifdef ALLOW_AVX2_MULX1
		if (iVectorType == VECTOR_TYPE_AVX512)
#endif
		{
			int32_t kreg = 0;
			if (i.xyzw != 0xf)
			{
				kreg = 1;
				e->kmovdmskmem(kreg, (int32_t*)&(xyzw_rev_mask_lut32[i.xyzw]));
			}


			if (isOPMULA(i))
			{
				e->pshufd_rmi128(RAX, &VU0::_VU0->vf[i.Fs].sw0, 0x09);
			}
			else
			{
				e->movdqa32_rm128(RAX, (void*)&VU0::_VU0->vf[i.Fs].sw0);
			}


			if (isMULBC(i) || isMULABC(i))
			{
				e->vpbroadcastd_rm128(RCX, (int32_t*)&VU0::_VU0->vf[i.Ft].vuw[i.bc]);
			}
			else if (isMULi(i) || isMULAi(i))
			{
				e->vpbroadcastd_rm128(RCX, (int32_t*)&VU0::_VU0->vi[VU::REG_I].sw0);
			}
			else if (isMULq(i) || isMULAq(i))
			{
				e->vpbroadcastd_rm128(RCX, (int32_t*)&VU0::_VU0->vi[VU::REG_Q].sw0);
			}
			else if (isOPMULA(i))
			{
				e->pshufd_rmi128(RCX, &VU0::_VU0->vf[i.Ft].sw0, 0x12);
			}
			else
			{
				e->movdqa32_rm128(RCX, &VU0::_VU0->vf[i.Ft].sw0);
			}


			e->vinserti32x4_rri256(RAX, RAX, RCX, 1);

			//e->movdqa32_rm128(RAX, (void*)&vs.uw0);
			//e->vinserti32x4_rmi256(RAX, RAX, (void*)&vt.uw0, 1);
			e->vptestmd_rrb256(2, RAX, (int32_t*)&bit1_float_mask);
			e->psubd_rrb256(RAX, RAX, (int32_t*)&bit1_float, 2);
			e->cvtps2pd_rr512(RAX, RAX);
			e->paddq_rrb512(RAX, RAX, (int64_t*)&bit1_double, 2);
			//e->pshufd_rri128(RCX, RAX, 0x0e);
			e->vextracti64x4_rri512(RCX, RAX, 1);


			// testing
			//e->movq_to_x64_mr128((int64_t*)&v1.uq0, RAX);
			//e->movq_to_x64_mr128((int64_t*)&v1.uq1, RCX);
			//e->movdqa32_mr128((void*)&v1.uq0, RAX);
			//e->kmovdmemmsk((int32_t*)&v2.uw0, 2);

			// testing
			//e->movq_to_x64_mr128((int64_t*)&v3.uq0, RAX);
			//e->movq_to_x64_mr128((int64_t*)&v3.uq1, RCX);


#define ENABLE_MUL_INACCURACY_AVX3
#ifdef ENABLE_MUL_INACCURACY_AVX3

	// do x*y adjustment here
	//e->vpternlogd_rrr128(5, 5, 5, 0xff);
	//e->psrld_rri128(4, 5, 9);
	//e->pand_rrr128(RDX, RCX, 4);
	//e->vpcmpdeq_rrr128(2, RDX, 4);
	//e->paddd_rrr128(RCX, RCX, 5, 2);

			e->psllq_rri256(RDX, RCX, 12);
			e->vpcmpqeq_rrb256(2, RDX, (int64_t*)&mantissa_double_mask);
			e->pandq_rrb256(RCX, RCX, (int64_t*)&ps2_mul1_double_mask, 2);

#endif


			e->vmulpd_rrr256(RAX, RAX, RCX);


			// testing
			//e->movq_to_x64_mr128((int64_t*)&v2.uq0, RAX);


			e->vrangepd_rbi256(RBX, RAX, (int64_t*)&max_double, 2);
			//e->vrangepd_rbi256(RCX, RAX, (int64_t*)&min_double, 2);


			// overflow -> k2
			e->cmppdne_rrr256(2, RAX, RBX, kreg);


			// convert result(rbx) to float ->rax
			e->vptestmq_rrb256(5, RBX, (int64_t*)&bit1_double_mask);
			e->psubq_rrb256(RBX, RBX, (int64_t*)&bit1_double, 5);
			e->cvtpd2ps_rr256(RAX, RBX);
			e->paddd_rrb128(RAX, RAX, (int32_t*)&bit1_float, 5);

			// zero -> k4
			// underflow -> k3
			e->pxor_rrr128(RDX, RDX, RDX);
			e->cmppseq_rrr128(4, RAX, RDX, kreg);
			e->cmppdne_rrr256(3, RBX, RDX, 4);

			// sign -> k5
			e->cmppdlt_rrr256(5, RBX, RDX, kreg);

			// store result
			//e->movdqa32_mr128((int32_t*)&vd.uw0, RAX);
			if (pFd)
			{
				//e->movdqa1_memreg(pFd, RAX);
				e->movdqa32_mr128(pFd, RAX, kreg);
			}
			else
			{
				if (i.Fd)
				{
					//e->movdqa1_memreg(&VU0::_VU0->vf[i.Fd].sw0, RAX);
					e->movdqa32_mr128(&VU0::_VU0->vf[i.Fd].sw0, RAX, kreg);
				}
			}

			// ousz flags
			e->kshiftlb(5, 5, 4);
			e->kshiftlb(2, 2, 4);
			e->korb(4, 4, 5);
			e->korb(2, 2, 3);
			e->kunpackbw(2, 2, 4);

			e->vpmovm2d_rr512(RAX, 2);
			e->pshufd_rri512(RAX, RAX, (0 << 6) | (1 << 4) | (2 << 2) | (3 << 0));
			e->vpmovd2m_rr512(2, RAX);
			e->kmovdmemmsk(&VU0::_VU0->vi[VU::REG_MACFLAG].s, 2);

			e->vpmovm2b_rr128(RAX, 2);
			e->vpcmpdne_rrr128(3, RAX, RDX);
			e->kshiftld(4, 3, 6);
			e->kord(3, 3, 4);
			e->kmovdregmsk(RAX, 3);

			e->AndMem32ImmX(&VU0::_VU0->vi[VU::REG_STATUSFLAG].s, ~0xf);
			ret = e->OrMemReg32(&VU0::_VU0->vi[VU::REG_STATUSFLAG].s, RAX);

			return ret;
		}
#ifdef ALLOW_AVX2_MULX1
		else if (iVectorType == VECTOR_TYPE_AVX2)
		{
#ifdef ENABLE_MACRO_MODE_TIMING
			// check the source registers against current number of cycles
			e->MovRegMem64(RAX, (int64_t*)&r->CycleCount);
			e->AddRegReg64(RAX, LocalCycleCount);

			// save the current cycle count
			e->MovRegReg64(RCX, RAX);

			// put the number of cycles needed for destination register
			if (i.Fs)
			{
				e->CmpRegMem64(RAX, (int64_t*)&(VU0::_VU0->FReg_BusyUntil[i.Fs]));
				e->CmovBRegMem64(RAX, (int64_t*)&(VU0::_VU0->FReg_BusyUntil[i.Fs]));
			}

			if (i.Ft && !isMULi(i) && !isMULq(i) && !isMULAi(i) && !isMULAq(i))
			{
				e->CmpRegMem64(RAX, (int64_t*)&(VU0::_VU0->FReg_BusyUntil[i.Ft]));
				e->CmovBRegMem64(RAX, (int64_t*)&(VU0::_VU0->FReg_BusyUntil[i.Ft]));
			}

			// get cycle difference and add to cycles
			e->SubRegReg64(RCX, RAX);
			e->SubMemReg64((int64_t*)&r->CycleCount, RCX);

			if (i.Fd && !isMULA(i))
			{
				// store the cycle# destination reg is busy until
				e->AddReg64ImmX(RAX, 4);
				e->MovMemReg64((int64_t*)&(VU0::_VU0->FReg_BusyUntil[i.Fd]), RAX);
			}
#endif

#ifdef USE_NEW_VMUL_AVX2

			if (isOPMULA(i))
			{
				//e->pshufd1regmemimm(RAX, &VU0::_VU0->vf[i.Fs].sw0, 0x09);
				e->pshufd1regmemimm(RAX, &VU0::_VU0->vf[i.Fs].sw0, 0x60);
			}
			else
			{
				//e->movdqa1_regmem(RAX, (void*)&VU0::_VU0->vf[i.Fs].sw0);
				e->pshufd1regmemimm(RAX, (void*)&VU0::_VU0->vf[i.Fs].sw0, (0 << 6) | (1 << 4) | (2 << 2) | (3 << 0));

			}


			if (isMULBC(i) || isMULABC(i))
			{
				e->vpbroadcastd1regmem(RCX, (int32_t*)&VU0::_VU0->vf[i.Ft].vuw[i.bc]);
			}
			else if (isMULi(i) || isMULAi(i))
			{
				e->vpbroadcastd1regmem(RCX, (int32_t*)&VU0::_VU0->vi[VU::REG_I].sw0);
			}
			else if (isMULq(i) || isMULAq(i))
			{
				e->vpbroadcastd1regmem(RCX, (int32_t*)&VU0::_VU0->vi[VU::REG_Q].sw0);
			}
			else if (isOPMULA(i))
			{
				//e->pshufd1regmemimm(RCX, &VU0::_VU0->vf[i.Ft].sw0, 0x12);
				e->pshufd1regmemimm(RCX, &VU0::_VU0->vf[i.Ft].sw0, 0x84);
			}
			else
			{
				//e->movdqa32_rm128(RCX, &VU0::_VU0->vf[i.Ft].sw0);
				e->pshufd1regmemimm(RCX, (void*)&VU0::_VU0->vf[i.Ft].sw0, (0 << 6) | (1 << 4) | (2 << 2) | (3 << 0));
			}

			e->vinserti128regreg(RCX, RAX, RCX, 1);

			//e->movdqa1_regmem(RCX, (void*)&vs.uw0);
			//e->vinserti128regmem(RCX, RCX, (void*)&vt.uw0, 1);
			e->vsubps2(RBX, RCX, RCX);
			e->psrld2regimm(RBX, RBX, 7);
			e->psubd2regreg(RCX, RCX, RBX);
			e->cvtps2pd2regreg(RAX, RCX);
			e->pmovsxdq2regreg(RDX, RBX);
			e->psllq2regimm(RDX, RDX, 29);
			e->paddq2regreg(RAX, RAX, RDX);
			e->vextracti128regreg(RBX, RBX, 1);
			e->vextracti128regreg(RCX, RCX, 1);
			e->cvtps2pd2regreg(RCX, RCX);
			e->pmovsxdq2regreg(RBX, RBX);
			e->psllq2regimm(RBX, RBX, 29);
			e->paddq2regreg(RCX, RCX, RBX);


#define ENABLE_MUL_INACCURACY_AVX2
#ifdef ENABLE_MUL_INACCURACY_AVX2

			// do x*y adjustment here

			e->pcmpeqb2regreg(5, 5, 5);
			e->psrlq2regimm(4, 5, 41);
			e->psllq2regimm(4, 4, 29);

			e->pand2regreg(RBX, RCX, 4);
			e->pcmpeqq2regreg(RBX, RBX, 4);
			e->paddq2regreg(RBX, RBX, RCX);
			e->pand2regreg(RCX, RCX, RBX);

#endif

			e->vmulpd2(RAX, RAX, RCX);


			// testing
			//e->ldmxcsr((int32_t*)&macflag);

			// convert result(rax) to float -> rcx
			e->psllq2regimm(RBX, RAX, 1);
			e->psrlq2regimm(RBX, RBX, 63);
			e->psllq2regimm(RBX, RBX, 52);
			e->psubq2regreg(RCX, RAX, RBX);
			e->cvtpd2ps2regreg(RCX, RCX);


			// convert back (rcx) -> r4
			e->cvtps2pd2regreg(4, RCX);


			// these two only needed when writing back as float
			// result -> rcx
			// todo: need pshufps ?
			e->psrlq2regimm(RDX, RBX, 29);

			// pshufps
			e->vextracti128regreg(5, RDX, 1);


			// testing
			//e->movdqa1_memreg((void*)&v0.uq0, RCX);
			//e->movdqa1_memreg((void*)&v1.uq0, 5);


			e->pshufps1regregimm(RDX, RDX, 5, 0x88);

			e->paddd1regreg(RDX, RDX, RCX);


			// restore clamped value -> rbx
			e->paddq2regreg(RBX, RBX, 4);

			// reverse float value (rdx) for storage -> rdx
			e->pshufd1regregimm(RDX, RDX, (0 << 6) | (1 << 4) | (2 << 2) | (3 << 0));

#ifdef USE_NEW_VECTOR_DISPATCH_VMUL_R5900

			if (pFd)
			{
				Dispatch_Result_AVX2(i, true, RDX, i.Fd);
			}
			else
			{
				Dispatch_Result_AVX2(i, false, RDX, i.Fd);
			}

#else

			// store result (rcx)
			//e->movdqa1_memreg((void*)&vd.uw0, RCX);
			if (i.xyzw != 0xf)
			{
				if (pFd)
				{
					e->pblendw1regmemimm(RDX, RDX, pFd, ~((i.destx * 0x03) | (i.desty * 0x0c) | (i.destz * 0x30) | (i.destw * 0xc0)));
				}
				else
				{
					if (i.Fd)
					{
						e->pblendw1regmemimm(RDX, RDX, &VU0::_VU0->vf[i.Fd].sw0, ~((i.destx * 0x03) | (i.desty * 0x0c) | (i.destz * 0x30) | (i.destw * 0xc0)));
					}
				}
			}

			if (pFd)
			{
				e->movdqa1_memreg(pFd, RDX);
			}
			else
			{
				if (i.Fd)
				{
					e->movdqa1_memreg(&VU0::_VU0->vf[i.Fd].sw0, RDX);
				}
			}

#endif

			// get overflow -> r4
			// clamped result in (rbx)
			// un-clamped result in (rax)
			e->pand2regreg(4, RAX, RBX);
			e->cmpnepd(4, 4, RBX);

			// get underflow -> rax
			e->pxor2regreg(RDX, RDX, RDX);
			e->cmpeqpd(RAX, RAX, RDX);
			e->cmpeqpd(RAX, RAX, RBX);

			// overflow (r4) -> rbx
			// underflow (rax) -> rax
			e->cvtpd2ps2regreg(RBX, 4);
			e->cvtpd2ps2regreg(RAX, RAX);


			// sign flag -> r4
			// zero flag -> rcx
			//e->cmpgtps(4, RDX, RCX);
			e->pcmpgtd1regreg(4, RDX, RCX);
			e->cmpeqps(RCX, RDX, RCX);

			// testing
			//e->stmxcsr((int32_t*)& macflag);


			// get flags
			// could combine sign(r4) | zero(rcx) here for simd ->rcx
			e->packsdw1regreg(RCX, RCX, 4);
			e->packsdw1regreg(RAX, RAX, RBX);


			// flags
			if (i.xyzw != 0xf)
			{
				e->pblendw1regregimm(RCX, RCX, RDX, ~((i.destx * 0x88) | (i.desty * 0x44) | (i.destz * 0x22) | (i.destw * 0x11)));
				e->pblendw1regregimm(RAX, RAX, RDX, ~((i.destx * 0x88) | (i.desty * 0x44) | (i.destz * 0x22) | (i.destw * 0x11)));
			}

			e->packswb1regreg(RAX, RCX, RAX);

			// now get stat
			e->psrld1regimm(RCX, RAX, 7);
			e->pcmpgtd1regreg(RCX, RCX, RDX);


			// now pull mac(RAX)->RCX and stat(RCX)->RAX
			e->movmskb1regreg(RCX, RAX);
			e->movmskps1regreg(RAX, RCX);

			// store mac
			// set MAC flags (RCX)
			//e->MovMemReg32((int32_t*)&macflag, RCX);
			ret = e->MovMemReg32((int32_t*)&VU0::_VU0->vi[VU::REG_MACFLAG].s, RCX);

			// update stat
			// check if the lower instruction set stat flag already (there's only like one instruction that does this)
			//if (!v->SetStatus_Flag)
			{
				e->MovRegReg32(RCX, RAX);

				e->ShlRegImm32(RAX, 6);
				//e->OrRegMem32(RAX, (int32_t*)&statflag);
				e->OrRegMem32(RAX, (int32_t*)&VU0::_VU0->vi[VU::REG_STATUSFLAG].s);

				// these two instructions are if you need to set non-sticky flags
				e->AndReg32ImmX(RAX, ~0xf);
				e->OrRegReg32(RAX, RCX);

				//e->MovMemReg32((int32_t*)&statflag, RAX);
				ret = e->MovMemReg32((int32_t*)&VU0::_VU0->vi[VU::REG_STATUSFLAG].s, RAX);

			}	// end if ( !v->SetStatus_Flag )

#else
			if (pFt)
			{
				e->vpbroadcastd1regmem(RCX, (int32_t*)pFt);
			}
			else
			{
				e->pshufd1regmemimm(RCX, &VU0::_VU0->vf[i.Ft].sw0, FtComponentp);
			}

			e->pshufd1regmemimm(RAX, &VU0::_VU0->vf[i.Fs].sw0, FsComponentp);


			// create mask
			e->pcmpeqb2regreg(5, 5, 5);

#define ENABLE_MUL_INACCURACY_AVX2
#ifdef ENABLE_MUL_INACCURACY_AVX2
			// do x*y adjustment here
			e->psrld1regimm(4, 5, 9);
			e->pand1regreg(RDX, RCX, 4);
			e->pcmpeqd1regreg(RDX, RDX, 4);
			e->paddd1regreg(RCX, RCX, RDX);
#endif

			// get sign ->rdx
			e->pxor1regreg(RDX, RAX, RCX);

			// cvt w/ sign extend
			e->pmovsxdq2regreg(RAX, RAX);
			e->pmovsxdq2regreg(RCX, RCX);

			// cvt float to double
			e->psllq2regimm(RAX, RAX, 33);
			e->psrlq2regimm(RAX, RAX, 4);
			e->psllq2regimm(RCX, RCX, 33);
			e->psrlq2regimm(RCX, RCX, 4);


			// get multipliers
			// 1023+1023 << 52 ->r4
			e->psrlq2regimm(4, 5, 54);
			e->psllq2regimm(4, 4, 53);

			// use multiplier
			e->vmulpd2(RCX, RCX, 4);


			// mul
			e->vmulpd2(RAX, RAX, RCX);


			// get zero ->r4
			e->pxor2regreg(4, 4, 4);

			// get sign
			//e->pcmpgtd1regreg(RDX, 4, RDX);

			// get result ->rax
			e->psrlq2regimm(RAX, RAX, 29);


			// check for zero before ->rcx
			e->pcmpeqq2regreg(RCX, RAX, 4);

			// get multipliers
			// 127 << 23 ->rbx
			e->psrlq2regimm(RBX, 5, 57);
			e->psllq2regimm(RBX, RBX, 23);


			// subtract 127(rbx) from exponent
			e->psubq2regreg(RAX, RAX, RBX);

			// clear result(rax) if it was originally zero(rcx)
			e->pandn2regreg(RAX, RCX, RAX);


			// get underflow ->rbx
			e->pshufd2regregimm(RAX, RAX, 0xd8);
			e->vextracti128regreg(RCX, RAX, 1);
			e->punpckhqdq1regreg(RBX, RAX, RCX);

			// get float result ->rax
			e->punpcklqdq1regreg(RAX, RAX, RCX);

			// check for zero exponent ->rcx
			e->psrld1regimm(RCX, RAX, 23);
			e->pcmpeqd1regreg(RCX, RCX, 4);

			// also zero(rcx) on underflow(rbx)
			e->por1regreg(RCX, RCX, RBX);

			// clear result(rax) on zero(rcx)
			e->pandn1regreg(RAX, RCX, RAX);

			// mask sign(rdx) ->rdx
			e->psrld1regimm(5, 5, 1);
			e->pandn1regreg(RDX, 5, RDX);

			// max result on overflow ->r5
			e->pminud1regreg(5, 5, RAX);

			// combine overflow(rax) | underflow(rbx) ->rbx
			e->pcmpgtd1regreg(RAX, 4, RAX);
			e->packsdw1regreg(RBX, RBX, RAX);

			// combine sign(rdx) and result(r5) ->rax
			e->por1regreg(RAX, RDX, 5);

			// could combine sign(rdx) | zero(rcx) here for simd ->rcx
			// sign flag set on negative numbers not zero
			e->pandn1regreg(5, RCX, RDX);
			e->packsdw1regreg(RCX, RCX, 5);


			// set result
			e->pshufd1regregimm(RAX, RAX, (0 << 6) | (1 << 4) | (2 << 2) | (3 << 0));

			if (i.xyzw != 0xf)
			{
				if (pFd)
				{
					e->pblendw1regmemimm(RAX, RAX, pFd, ~((i.destx * 0x03) | (i.desty * 0x0c) | (i.destz * 0x30) | (i.destw * 0xc0)));
				}
				else
				{
					if (i.Fd)
					{
						e->pblendw1regmemimm(RAX, RAX, &VU0::_VU0->vf[i.Fd].sw0, ~((i.destx * 0x03) | (i.desty * 0x0c) | (i.destz * 0x30) | (i.destw * 0xc0)));
					}
				}
			}

			if (pFd)
			{
				e->movdqa1_memreg(pFd, RAX);
			}
			else
			{
				if (i.Fd)
				{
					e->movdqa1_memreg(&VU0::_VU0->vf[i.Fd].sw0, RAX);
				}
			}

			// flags
			if (i.xyzw != 0xf)
			{
				e->pblendw1regregimm(RCX, RCX, 4, ~((i.destx * 0x88) | (i.desty * 0x44) | (i.destz * 0x22) | (i.destw * 0x11)));
				e->pblendw1regregimm(RBX, RBX, 4, ~((i.destx * 0x88) | (i.desty * 0x44) | (i.destz * 0x22) | (i.destw * 0x11)));
			}

			e->packswb1regreg(RAX, RCX, RBX);

			// now get stat
			e->psrld1regimm(RCX, RAX, 7);
			e->pcmpgtd1regreg(RCX, RCX, 4);

			// now pull mac(RAX)->RCX and stat(RCX)->RAX
			e->movmskb1regreg(RCX, RAX);
			e->movmskps1regreg(RAX, RCX);



			// store mac
			// set MAC flags (RCX)
			//ret = e->MovMemReg32((int32_t*)&macflag, RCX);
			ret = e->MovMemReg32((int32_t*)&VU0::_VU0->vi[VU::REG_MACFLAG].s, RCX);

			// update stat
			// check if the lower instruction set stat flag already (there's only like one instruction that does this)
			//if (!v->SetStatus_Flag)
			{
				e->MovRegReg32(RCX, RAX);

				e->ShlRegImm32(RAX, 6);
				//e->OrRegMem32(RAX, (int32_t*)&statflag);
				e->OrRegMem32(RAX, (int32_t*)&VU0::_VU0->vi[VU::REG_STATUSFLAG].s);

				// these two instructions are if you need to set non-sticky flags
				e->AndReg32ImmX(RAX, ~0xf);
				e->OrRegReg32(RAX, RCX);

				//ret = e->MovMemReg32((int32_t*)&statflag, RAX);
				ret = e->MovMemReg32((int32_t*)&VU0::_VU0->vi[VU::REG_STATUSFLAG].s, RAX);

			}	// end if ( !v->SetStatus_Flag )

#endif

		}

#endif	// end #ifdef ALLOW_AVX2_MULX1

	}	// end if ( i.xyzw )

	return ret;
}



int32_t R5900::Recompiler::Generate_VMADDp(u32 bSub, R5900::Instruction::Format i, u32 FtComponentp, void* pFd, u32* pFt, u32 FsComponentp)
{
	static constexpr int64_t max_double_float = 0x47ffffffe0000000ull;

	static constexpr int64_t max_double = 0x47ffffffffffffffull;
	static constexpr int64_t min_double = 0x3800000000000000ull;

	static constexpr int64_t test_ovf_double = 0x47ffffffe0000000ull;


	static constexpr int64_t bit1_double = 0x0010000000000000ull;
	static constexpr int64_t bit1_double_mask = 0x4000000000000000ull;
	static constexpr int32_t bit1_float = 0x00800000;
	static constexpr int32_t bit1_float_mask = 0x40000000;

	static constexpr int64_t flt_double_mask = 0xffffffffe0000000ull;
	static constexpr int64_t ps2_mul1_double_mask = 0xffffffffc0000000ull;

	static constexpr int64_t mantissa_double_mask = 0xfffffe0000000000ull;

	static constexpr int64_t zero_double = 0ull;

	int32_t ret;

	u64 start, end, addr;

	u32 Address = e->x64CurrentSourceAddress;

	ret = 1;

	if (i.xyzw)
	{
//#define ALLOW_AVX2_MADDX1
#ifdef ALLOW_AVX2_MADDX1

		if (iVectorType == VECTOR_TYPE_AVX512)
#endif
		{
			int32_t kreg = 0;
			if (i.xyzw != 0xf)
			{
				kreg = 1;
				e->kmovdmskmem(1, (int32_t*)&(xyzw_rev_mask_lut32[i.xyzw]));
			}

			if (isOPMSUB(i))
			{
				e->pshufd_rmi128(RAX, &VU0::_VU0->vf[i.Fs].sw0, 0x09);
			}
			else
			{
				e->movdqa32_rm128(RAX, (void*)&VU0::_VU0->vf[i.Fs].sw0);
			}


			if (isMADDBC(i) || isMADDABC(i) || isMSUBBC(i) || isMSUBABC(i))
			{
				e->vpbroadcastd_rm128(RCX, (int32_t*)&VU0::_VU0->vf[i.Ft].vuw[i.bc]);
			}
			else if (isMADDi(i) || isMADDAi(i) || isMSUBi(i) || isMSUBAi(i))
			{
				e->vpbroadcastd_rm128(RCX, (int32_t*)&VU0::_VU0->vi[VU::REG_I].sw0);
			}
			else if (isMADDq(i) || isMADDAq(i) || isMSUBq(i) || isMSUBAq(i))
			{
				e->vpbroadcastd_rm128(RCX, (int32_t*)&VU0::_VU0->vi[VU::REG_Q].sw0);
			}
			else if (isOPMSUB(i))
			{
				e->pshufd_rmi128(RCX, &VU0::_VU0->vf[i.Ft].sw0, 0x12);
			}
			else
			{
				e->movdqa32_rm128(RCX, &VU0::_VU0->vf[i.Ft].sw0);
			}

			e->vinserti32x4_rri256(RAX, RAX, RCX, 1);

			//e->movdqa32_rm128(RAX, (void*)&vs.uw0);
			//e->vinserti32x4_rmi256(RAX, RAX, (void*)&vt.uw0, 1);
			e->vptestmd_rrb256(2, RAX, (int32_t*)&bit1_float_mask);
			e->psubd_rrb256(RAX, RAX, (int32_t*)&bit1_float, 2);
			e->cvtps2pd_rr512(RAX, RAX);
			e->paddq_rrb512(RAX, RAX, (int64_t*)&bit1_double, 2);
			//e->pshufd_rri128(RCX, RAX, 0x0e);
			e->vextracti64x4_rri512(RCX, RAX, 1);


			// testing
			//e->movq_to_x64_mr128((int64_t*)&v1.uq0, RAX);
			//e->movq_to_x64_mr128((int64_t*)&v1.uq1, RCX);
			//e->movdqa32_mr128((void*)&v1.uq0, RAX);
			//e->kmovdmemmsk((int32_t*)&v2.uw0, 2);

			// testing
			//e->movq_to_x64_mr128((int64_t*)&v3.uq0, RAX);
			//e->movq_to_x64_mr128((int64_t*)&v3.uq1, RCX);


#define ENABLE_MUL_INACCURACY_AVX3
#ifdef ENABLE_MUL_INACCURACY_AVX3

	// do x*y adjustment here
	//e->vpternlogd_rrr128(5, 5, 5, 0xff);
	//e->psrld_rri128(4, 5, 9);
	//e->pand_rrr128(RDX, RCX, 4);
	//e->vpcmpdeq_rrr128(2, RDX, 4);
	//e->paddd_rrr128(RCX, RCX, 5, 2);

			e->psllq_rri256(RDX, RCX, 12);
			e->vpcmpqeq_rrb256(2, RDX, (int64_t*)&mantissa_double_mask);
			e->pandq_rrb256(RCX, RCX, (int64_t*)&ps2_mul1_double_mask, 2);

#endif


			e->vmulpd_rrr256(RAX, RAX, RCX);


			// testing
			//e->movq_to_x64_mr128((int64_t*)&v2.uq0, RAX);


			e->vrangepd_rbi256(RBX, RAX, (int64_t*)&max_double, 2);
			e->cvtpd2ps_rr256(RCX, RAX);


			// testing
			//e->movq_to_x64_mr128((int64_t*)&v3.uq0, RAX);
			//e->movq_to_x64_mr128((int64_t*)&v3.uq1, RBX);


			// overflow -> k3
			e->cmppdne_rrr256(3, RAX, RBX);

			// zero -> k4
			// sticky underflow -> k6
			e->pxor_rrr256(RDX, RDX, RDX);
			e->cmppseq_rrr128(4, RCX, RDX, kreg);
			e->cmppdne_rrr256(6, RBX, RDX, 4);

			// zero result on underflow or zero
			// note: need these two instructions if caching double values
			e->vrangepd_rri256(RBX, RBX, RDX, 2, 4);
			e->pandq_rrb256(RAX, RBX, (int64_t*)&flt_double_mask);

			// if sub, then negate the result
			if (bSub)
			{
				e->vsubpd_rrr256(RAX, RDX, RAX);
			}

			// load acc
			e->movdqa32_rm128(5, (void*)&VU0::_VU0->dACC[0].l);
			e->vptestmd_rrb128(2, 5, (int32_t*)&bit1_float_mask);
			e->psubd_rrb128(5, 5, (int32_t*)&bit1_float, 2);
			e->cvtps2pd_rr256(5, 5);
			e->paddq_rrb256(5, 5, (int64_t*)&bit1_double, 2);

			// on overflow, copy result to acc
			e->movdqa64_rr256(5, RAX, 3);

			// on acc overflow copy to result
			e->vrangepd_rbi256(4, 5, (int64_t*)&test_ovf_double, 2);
			e->cmppdne_rrr256(4, 4, 5);
			e->movdqa64_rr256(RAX, 5, 4);

			// get guard mask
			//e->pxor_rrr256(RDX, RAX, RCX);
			//if (bSub)
			//{
			//	e->pand_rrr256(RBX, RAX, 5);
			//}
			//else
			{
				e->pxor_rrr256(RBX, RAX, 5);
			}
			e->psrlq_rri256(RBX, RBX, 63);
			e->psllq_rri256(RBX, RBX, 27);

			//e->vaddpd_rrr256(RAX, RAX, RCX);
			//if (bSub)
			//{
			//	// sub
			//	e->vsubpd_rrr256(RAX, RAX, 5);
			//}
			//else
			{
				// add
				e->vaddpd_rrr256(RAX, RAX, 5);
			}

			e->paddq_rrr256(RAX, RAX, RBX);


			// testing
			//e->movq_to_x64_mr128((int64_t*)&v2.uq0, RAX);


			e->vrangepd_rbi256(RBX, RAX, (int64_t*)&max_double, 2);
			//e->vrangesd_rmi64(RCX, RAX, (void*)&min_double, 2);


			// testing
			//e->movq_to_x64_mr128((int64_t*)&v3.uq0, RAX);
			//e->movq_to_x64_mr128((int64_t*)&v3.uq1, RBX);


			// overflow -> k2
			e->cmppdne_rrr256(2, RAX, RBX, kreg);


			// zero result on underflow
			// note: need these two instructions if caching double values
			//e->vrangepd_rri256(RBX, RBX, RDX, 2, 3);
			//e->pandq_rrb256(RBX, RBX, (int64_t*)&flt_double_mask2);


			// testing value
			//e->movq_to_sse_rm128(RBX, (int64_t*)&test_value);


			// testing
			//e->movq_to_x64_mr128((int64_t*)&v4.uw0, RBX);
			//e->movq_to_x64_mr128((int64_t*)&v4.uq1, RCX);


			// convert result(rbx) to float ->rax
			e->vptestmq_rrb256(5, RBX, (int64_t*)&bit1_double_mask);
			e->psubq_rrb256(RBX, RBX, (int64_t*)&bit1_double, 5);
			e->cvtpd2ps_rr256(RAX, RBX);
			e->paddd_rrb128(RAX, RAX, (int32_t*)&bit1_float, 5);

			// zero -> k4
			// underflow -> k3
			//e->pxor_rrr128(RDX, RDX, RDX);
			e->cmppseq_rrr128(4, RAX, RDX, kreg);
			e->cmppdne_rrr256(3, RBX, RDX, 4);

			// sign -> k5
			e->cmppdlt_rrr256(5, RBX, RDX, kreg);

			// store result
			//e->movdqa32_mr128((int32_t*)&vd.uw0, RAX);
			if (pFd)
			{
				e->movdqa32_mr128(pFd, RAX, kreg);
			}
			else
			{
				if (i.Fd)
				{
					e->movdqa32_mr128(&VU0::_VU0->vf[i.Fd].sw0, RAX, kreg);
				}
			}


			// get flags
			//e->movd_to_sse_rm128(RAX, (int32_t*)&statflag);
			//e->pandd_rrb128(RAX, RAX, (int32_t*)&sticky_flag_mask);
			//e->pord_rrb128(RAX, RAX, (int32_t*)&ovf_float_flag, 2);
			//e->pord_rrb128(RAX, RAX, (int32_t*)&sticky_und_float_flag, 3);
			//e->pord_rrb128(RAX, RAX, (int32_t*)&und_float_flag, 6);
			//e->movd_to_x64_mr128((int32_t*)&statflag, RAX);

			// ousz flags
			e->kshiftlb(5, 5, 4);
			e->kshiftlb(2, 2, 4);
			e->korb(4, 4, 5);
			e->korb(2, 2, 3);
			e->kunpackbw(2, 2, 4);

			e->vpmovm2d_rr512(RAX, 2);
			e->pshufd_rri512(RAX, RAX, (0 << 6) | (1 << 4) | (2 << 2) | (3 << 0));
			e->vpmovd2m_rr512(2, RAX);
			e->kmovdmemmsk((int32_t*)&VU0::_VU0->vi[VU::REG_MACFLAG].s, 2);

			e->vpmovm2b_rr128(RAX, 2);
			e->vpcmpdne_rrr128(3, RAX, RDX);
			e->kshiftld(4, 3, 6);
			e->kord(3, 3, 4);
			e->kmovdregmsk(RAX, 3);

			// sticky underflow flag
			e->kmovdregmsk(RCX, 6);
			e->NegReg32(RCX);
			e->SbbRegReg32(RCX, RCX);
			e->AndReg32ImmX(RCX, 0x100);
			e->OrRegReg32(RAX, RCX);

			e->AndMem32ImmX((int32_t*)&VU0::_VU0->vi[VU::REG_STATUSFLAG].s, ~0xf);
			ret = e->OrMemReg32((int32_t*)&VU0::_VU0->vi[VU::REG_STATUSFLAG].s, RAX);

			return ret;
		}

#ifdef ALLOW_AVX2_MADDX1

		else if (iVectorType == VECTOR_TYPE_AVX2)
		{

#ifdef USE_NEW_VMADD_AVX2

			/*
			if (isOPMSUB(i))
			{
				//e->pshufd_rmi128(RAX, &VU0::_VU0->vf[i.Fs].sw0, 0x09);
				e->pshufd1regmemimm(RAX, &VU0::_VU0->vf[i.Fs].sw0, 0x60);
			}
			else
			{
				//e->movdqa32_rm128(RAX, (void*)&VU0::_VU0->vf[i.Fs].sw0);
				e->movdqa1_regmem(RAX, (void*)&VU0::_VU0->vf[i.Fs].sw0);
			}


			if (isMADDBC(i) || isMADDABC(i) || isMSUBBC(i) || isMSUBABC(i))
			{
				//e->vpbroadcastd_rm128(RCX, (int32_t*)&VU0::_VU0->vf[i.Ft].vuw[i.bc]);
				e->vpbroadcastd1regmem(RCX, (int32_t*)&VU0::_VU0->vf[i.Ft].vuw[i.bc]);
			}
			else if (isMADDi(i) || isMADDAi(i) || isMSUBi(i) || isMSUBAi(i))
			{
				//e->vpbroadcastd_rm128(RCX, (int32_t*)&VU0::_VU0->vi[VU::REG_I].sw0);
				e->vpbroadcastd1regmem(RCX, (int32_t*)&VU0::_VU0->vi[VU::REG_I].sw0);
			}
			else if (isMADDq(i) || isMADDAq(i) || isMSUBq(i) || isMSUBAq(i))
			{
				//e->vpbroadcastd_rm128(RCX, (int32_t*)&VU0::_VU0->vi[VU::REG_Q].sw0);
				e->vpbroadcastd1regmem(RCX, (int32_t*)&VU0::_VU0->vi[VU::REG_Q].sw0);
			}
			else if (isOPMSUB(i))
			{
				//e->pshufd_rmi128(RCX, &VU0::_VU0->vf[i.Ft].sw0, 0x12);
				e->pshufd1regmemimm(RCX, &VU0::_VU0->vf[i.Ft].sw0, 0x84);
			}
			else
			{
				//e->movdqa32_rm128(RCX, &VU0::_VU0->vf[i.Ft].sw0);
				e->movdqa1_regmem(RCX, (void*)&VU0::_VU0->vf[i.Ft].sw0);
			}
			*/

			if (pFt)
			{
				e->vpbroadcastd1regmem(RCX, (int32_t*)pFt);
			}
			else
			{
				e->pshufd1regmemimm(RCX, &VU0::_VU0->vf[i.Ft].sw0, FtComponentp);
			}

			e->pshufd1regmemimm(RAX, &VU0::_VU0->vf[i.Fs].sw0, FsComponentp);


			e->vinserti128regreg(RCX, RAX, RCX, 1);

			//e->movdqa1_regmem(RCX, (void*)&vs.uw0);
			//e->vinserti128regmem(RCX, RCX, (void*)&vt.uw0, 1);
			e->vsubps2(RBX, RCX, RCX);
			e->psrld2regimm(RBX, RBX, 7);
			e->psubd2regreg(RCX, RCX, RBX);
			e->cvtps2pd2regreg(RAX, RCX);
			e->pmovsxdq2regreg(RDX, RBX);
			e->psllq2regimm(RDX, RDX, 29);
			e->paddq2regreg(RAX, RAX, RDX);
			e->vextracti128regreg(RBX, RBX, 1);
			e->vextracti128regreg(RCX, RCX, 1);
			e->cvtps2pd2regreg(RCX, RCX);
			e->pmovsxdq2regreg(RBX, RBX);
			e->psllq2regimm(RBX, RBX, 29);
			e->paddq2regreg(RCX, RCX, RBX);


#define ENABLE_MUL_INACCURACY_AVX2
#ifdef ENABLE_MUL_INACCURACY_AVX2

			// do x*y adjustment here

			e->pcmpeqb2regreg(5, 5, 5);
			e->psrlq2regimm(4, 5, 41);
			e->psllq2regimm(4, 4, 29);

			e->pand2regreg(RBX, RCX, 4);
			e->pcmpeqq2regreg(RBX, RBX, 4);
			e->paddq2regreg(RBX, RBX, RCX);
			e->pand2regreg(RCX, RCX, RBX);

#endif


			e->vmulpd2(RAX, RAX, RCX);


			// testing
			//e->movdqa1_memreg((void*)&v0.uq0, RAX);


			// testing value
			//e->movq_to_sse_rm128(RBX, (int64_t*)&test_value);


			// testing
			//e->movq_to_x64_mr128((int64_t*)&v4.uw0, RBX);
			//e->movq_to_x64_mr128((int64_t*)&v4.uq1, RCX);


			// testing
			//e->ldmxcsr((int32_t*)&macflag);

			// convert result(rax) to float -> rcx
			e->psllq2regimm(RBX, RAX, 1);
			e->psrlq2regimm(RBX, RBX, 63);
			e->psllq2regimm(RBX, RBX, 52);
			e->psubq2regreg(RDX, RAX, RBX);
			e->cvtpd2ps2regreg(RDX, RDX);


			// convert back (rdx) -> r4
			e->cvtps2pd2regreg(4, RDX);


			// testing
			//e->movdqa1_memreg((void*)&v0.uq0, RCX);
			//e->movdqa1_memreg((void*)&v1.uq0, 5);


			// restore clamped value -> rbx
			e->paddq2regreg(RBX, RBX, 4);


			// store result (rcx)
			//e->movdqa1_memreg((void*)&vd.uw0, RCX);


			// get overflow -> rcx
			// clamped result in (rbx)
			// un-clamped result in (rax)
			e->pand2regreg(RCX, RAX, RBX);
			e->cmpnepd(RCX, RCX, RBX);

			// get underflow -> rax
			e->pxor1regreg(4, 4, 4);
			e->cmpeqpd(RAX, RAX, 4);
			e->cmpeqpd(RAX, RAX, RBX);


			// if sub, then negate the result
			if (bSub)
			{
				e->vsubpd_rrr256(RBX, 4, RBX);
			}


			// save sticky underflow
			e->movmskpd2regreg(RAX, RAX);

			// zero flag -> rcx
			// sign flag -> r4
			//e->cmpeqps(RCX, RDX, 5);
			//e->cmpltps(4, RDX, 5);

			// get underflow sticky flag
			e->MovReg32ImmX(RDX, 0x100);
			e->AndReg32ImmX(RAX, i.xyzw);
			e->CmovERegReg32(RDX, RAX);

			// load acc -> rax
			//e->movdqa1_regmem(RAX, (void*)&vd.uw0);
			e->pshufd1regmemimm(RAX, (void*)&VU0::_VU0->dACC[0].l, (0 << 6) | (1 << 4) | (2 << 2) | (3 << 0));
			e->vsubps(RDX, RAX, RAX);
			e->psrld1regimm(RDX, RDX, 7);
			e->psubd1regreg(RAX, RAX, RDX);
			e->cvtps2pd2regreg(RAX, RAX);
			e->pmovsxdq2regreg(RDX, RDX);
			e->psllq2regimm(RDX, RDX, 29);
			e->paddq2regreg(RAX, RAX, RDX);


			// copy mul result (rbx) to acc (r5) on overflow (rcx) -> rcx
			e->pblendvb2regreg(RCX, RAX, RBX, RCX);

			// check for acc overflow
			//e->psllq2regimm(5, 5, 29);
			//e->psubq2regreg(5, RCX, 5);
			//e->psllq2regimm(5, 5, 5);
			//e->pcmpeqq2regreg(RDX, 4, 5);



			// check for acc overflow
			e->MovReg64ImmX(RAX, (int64_t)max_double_float);
			e->movq_to_sse128(4, RAX);

			// need to broadcast
			e->vpbroadcastq2regreg(4, 4);

			//e->psllq2regimm(RCX, 5, 1);
			//e->psrlq2regimm(RCX, RCX, 1);
			//e->cmpeqpd(4, 4, RCX);
			e->pand2regreg(5, 4, RCX);
			e->pcmpeqq2regreg(RDX, 4, 5);

			// copy acc(r5) to result(rbx) on overflow (r4) -> rax
			e->pblendvb2regreg(RAX, RBX, RCX, RDX);


			// get guard mask
			e->pxor2regreg(RBX, RAX, RCX);
			e->psrlq2regimm(RBX, RBX, 63);
			e->psllq2regimm(RBX, RBX, 27);


			e->vaddpd2(RAX, RAX, RCX);


			e->paddq2regreg(RAX, RAX, RBX);


			// testing value
			//e->movq_to_sse_rm128(RBX, (int64_t*)&test_value);


			// testing
			//e->movq_to_x64_mr128((int64_t*)&v4.uw0, RBX);
			//e->movq_to_x64_mr128((int64_t*)&v4.uq1, RCX);


			// testing
			//e->ldmxcsr((int32_t*)&macflag);

			// convert result(rax) to float -> rcx
			e->psllq2regimm(RBX, RAX, 1);
			e->psrlq2regimm(RBX, RBX, 63);
			e->psllq2regimm(RBX, RBX, 52);
			e->psubq2regreg(RCX, RAX, RBX);
			e->cvtpd2ps2regreg(RCX, RCX);


			// convert back (rcx) -> r4
			e->cvtps2pd2regreg(4, RCX);


			// these two only needed when writing back as float
			// result -> rcx
			// todo: need pshufps ?
			e->psrlq2regimm(RDX, RBX, 29);

			// pshufps
			e->vextracti128regreg(5, RDX, 1);


			// testing
			//e->movdqa1_memreg((void*)&v0.uq0, RCX);
			//e->movdqa1_memreg((void*)&v1.uq0, 5);


			e->pshufps1regregimm(RDX, RDX, 5, 0x88);

			e->paddd1regreg(RDX, RDX, RCX);


			// restore clamped value -> rbx
			e->paddq2regreg(RBX, RBX, 4);


			// store float result (rdx)
			//e->movdqa1_memreg((void*)&vd.uw0, RDX);
			e->pshufd1regregimm(RDX, RDX, (0 << 6) | (1 << 4) | (2 << 2) | (3 << 0));

#ifdef USE_NEW_VECTOR_DISPATCH_VMADD_R5900

			if (pFd)
			{
				Dispatch_Result_AVX2(i, true, RDX, i.Fd);
			}
			else
			{
				Dispatch_Result_AVX2(i, false, RDX, i.Fd);
			}

#else

			if (i.xyzw != 0xf)
			{
				if (pFd)
				{
					e->pblendw1regmemimm(RDX, RDX, pFd, ~((i.destx * 0x03) | (i.desty * 0x0c) | (i.destz * 0x30) | (i.destw * 0xc0)));
				}
				else
				{
					if (i.Fd)
					{
						e->pblendw1regmemimm(RDX, RDX, &VU0::_VU0->vf[i.Fd].sw0, ~((i.destx * 0x03) | (i.desty * 0x0c) | (i.destz * 0x30) | (i.destw * 0xc0)));
					}
				}
			}

			if (pFd)
			{
				e->movdqa1_memreg(pFd, RDX);
			}
			else
			{
				if (i.Fd)
				{
					e->movdqa1_memreg(&VU0::_VU0->vf[i.Fd].sw0, RDX);
				}
			}

#endif


			// get overflow -> r4
			// clamped result in (rbx)
			// un-clamped result in (rax)
			e->pand2regreg(4, RAX, RBX);
			e->cmpnepd(4, 4, RBX);

			// get underflow -> rax
			e->pxor2regreg(RDX, RDX, RDX);
			e->cmpeqpd(RAX, RAX, RDX);
			e->cmpeqpd(RAX, RAX, RBX);

			// overflow (r4) -> rbx
			// underflow (rax) -> rax
			e->cvtpd2ps2regreg(RBX, 4);
			e->cvtpd2ps2regreg(RAX, RAX);


			// sign flag -> r4
			// zero flag -> rcx
			//e->cmpgtps(4, RDX, RCX);
			e->pcmpgtd1regreg(4, RDX, RCX);
			e->cmpeqps(RCX, RDX, RCX);

			// testing
			//e->stmxcsr((int32_t*)& macflag);


			// testing
			//e->movq_to_x64_mr128((int64_t*)&v3.uq0, RAX);
			//e->movq_to_x64_mr128((int64_t*)&v3.uq1, RBX);


			// get flags
			// could combine sign(r4) | zero(rcx) here for simd ->rcx
			e->packsdw1regreg(RCX, RCX, 4);
			e->packsdw1regreg(RAX, RAX, RBX);


			// flags
			if (i.xyzw != 0xf)
			{
				e->pblendw1regregimm(RCX, RCX, RDX, ~((i.destx * 0x88) | (i.desty * 0x44) | (i.destz * 0x22) | (i.destw * 0x11)));
				e->pblendw1regregimm(RAX, RAX, RDX, ~((i.destx * 0x88) | (i.desty * 0x44) | (i.destz * 0x22) | (i.destw * 0x11)));
			}

			e->packswb1regreg(RAX, RCX, RAX);

			// now get stat
			e->psrld1regimm(RCX, RAX, 7);
			e->pcmpgtd1regreg(RCX, RCX, RDX);


			// now pull mac(RAX)->RCX and stat(RCX)->RAX
			e->movmskb1regreg(RCX, RAX);
			e->movmskps1regreg(RAX, RCX);

			// store mac
			// set MAC flags (RCX)
			//e->MovMemReg32((int32_t*)&macflag, RCX);
			ret = e->MovMemReg32((int32_t*)&VU0::_VU0->vi[VU::REG_MACFLAG].s, RCX);

			// update stat
			// check if the lower instruction set stat flag already (there's only like one instruction that does this)
			//if (!v->SetStatus_Flag)
			{
				e->MovRegReg32(RCX, RAX);

				e->ShlRegImm32(RAX, 6);
				//e->OrRegMem32(RAX, (int32_t*)&statflag);
				e->OrRegMem32(RAX, (int32_t*)&VU0::_VU0->vi[VU::REG_STATUSFLAG].s);

				// these two instructions are if you need to set non-sticky flags
				e->AndReg32ImmX(RAX, ~0xf);
				e->OrRegReg32(RAX, RCX);

				// add sticky underflow
				e->OrRegReg32(RAX, RDX);

				//e->MovMemReg32((int32_t*)&statflag, RAX);
				ret = e->MovMemReg32((int32_t*)&VU0::_VU0->vi[VU::REG_STATUSFLAG].s, RAX);

			}	// end if ( !v->SetStatus_Flag )


#else
			if (pFt)
			{
				e->vpbroadcastd1regmem(RCX, (int32_t*)pFt);
			}
			else
			{
				e->pshufd1regmemimm(RCX, &VU0::_VU0->vf[i.Ft].sw0, FtComponentp);
			}

			e->pshufd1regmemimm(RAX, &VU0::_VU0->vf[i.Fs].sw0, FsComponentp);


			// create mask
			e->pcmpeqb2regreg(5, 5, 5);

#define ENABLE_MUL_INACCURACY_AVX2
#ifdef ENABLE_MUL_INACCURACY_AVX2
			// do x*y adjustment here
			e->psrld1regimm(4, 5, 9);
			e->pand1regreg(RDX, RCX, 4);
			e->pcmpeqd1regreg(RDX, RDX, 4);
			e->paddd1regreg(RCX, RCX, RDX);
#endif

			// get sign ->rdx
			e->pxor1regreg(RDX, RAX, RCX);

			// cvt w/ sign extend
			e->pmovsxdq2regreg(RAX, RAX);
			e->pmovsxdq2regreg(RCX, RCX);

			// cvt float to double
			e->psllq2regimm(RAX, RAX, 33);
			e->psrlq2regimm(RAX, RAX, 4);
			e->psllq2regimm(RCX, RCX, 33);
			e->psrlq2regimm(RCX, RCX, 4);


			// get multipliers
			// 1023+1023 << 52 ->r4
			e->psrlq2regimm(4, 5, 54);
			e->psllq2regimm(4, 4, 53);

			// use multiplier
			e->vmulpd2(RCX, RCX, 4);


			// mul
			e->vmulpd2(RAX, RAX, RCX);


			// get zero ->r4
			e->pxor2regreg(4, 4, 4);

			// get sign
			//e->pcmpgtd1regreg(RDX, 4, RDX);

			// get result ->rax
			e->psrlq2regimm(RAX, RAX, 29);


			// check for zero before ->rcx
			e->pcmpeqq2regreg(RCX, RAX, 4);

			// get multipliers
			// 127 << 23 ->rbx
			e->psrlq2regimm(RBX, 5, 57);
			e->psllq2regimm(RBX, RBX, 23);


			// subtract 127(rbx) from exponent
			e->psubq2regreg(RAX, RAX, RBX);

			// clear result(rax) if it was originally zero(rcx)
			e->pandn2regreg(RAX, RCX, RAX);


			// get underflow ->rbx
			e->pshufd2regregimm(RAX, RAX, 0xd8);
			e->vextracti128regreg(RCX, RAX, 1);
			e->punpckhqdq1regreg(RBX, RAX, RCX);

			// get float result ->rax
			e->punpcklqdq1regreg(RAX, RAX, RCX);

			// check for zero exponent ->rcx
			e->psrld1regimm(RCX, RAX, 23);
			e->pcmpeqd1regreg(RCX, RCX, 4);

			// also zero(rcx) on underflow(rbx)
			e->por1regreg(RCX, RCX, RBX);

			// clear result(rax) on zero(rcx)
			e->pandn1regreg(RAX, RCX, RAX);

			// could combine sign(rdx) | zero(rcx) here for simd ->rcx
			//e->packsdw1regreg(RCX, RCX, RDX);


			// now pull mac(RAX)->RCX and stat(RCX)->RAX
			e->movmskps1regreg(RAX, RBX);


			// get overflow ->rbx
			// might need to use the first method for simd
			e->pcmpgtd1regreg(RBX, 4, RAX);

			// max result(rax) on overflow(r5)
			e->por1regreg(RAX, RAX, RBX);

			// combine overflow(r5) | underflow(rbx) ->rbx
			//e->packsdw1regreg(RBX, RBX, 5);

			// testing
			//e->movdqa1_memreg((void*)&vs1, RBX);

			// get mask ->r4
			e->pslld1regimm(4, 5, 31);

			// clear sign bit in result(RAX)
			//e->paddd1regreg(RAX, RAX, RAX);
			//e->psrld1regimm(RAX, RAX, 1);
			e->pandn1regreg(RAX, 4, RAX);

			// add sign(rdx)
			e->pand1regreg(RDX, RDX, 4);
			//e->pslld1regimm(RDX, RDX, 31);
			e->por1regreg(RAX, RAX, RDX);


			// store underflow flag
			e->MovReg32ImmX(RDX, 0x100);
			e->AndReg32ImmX(RAX, i.xyzw);
			e->CmovERegReg32(RDX, RAX);



			// load accumulator
			//e->movdqa1_regmem(RCX, (void*)&vd.uw0);
			e->pshufd1regmemimm(RCX, (void*)&VU0::_VU0->dACC[0].l, (0 << 6) | (1 << 4) | (2 << 2) | (3 << 0));

			// check if doing subtraction instead of addition
			if (bSub)
			{
				// toggle the sign on RCX (right-hand argument) for subtraction for now
				e->pxor1regreg(RAX, RAX, 4);
			}


			// check for multiply overflow
			e->pblendvb1regreg(RCX, RCX, RAX, RBX);


			// testing
			//e->movdqa1_memreg((void*)&vs0, RCX);


			// copy +/-max values from ACC
			// ACC exp -> RBX
			e->pandn1regreg(RBX, 4, RCX);
			e->psrld1regimm(RDX, 5, 1);
			e->pcmpeqd1regreg(RBX, RBX, RDX);

			// multiply result or +/-max ACC -> RCX
			e->pblendvb1regreg(RAX, RAX, RCX, RBX);


			// get mask
			e->psrlq2regimm(4, 5, 61);
			e->psllq2regimm(4, 4, 60);


			// testing
			//e->movdqa1_memreg((void*)&vs1, RAX);
			//e->movdqa1_memreg((void*)&vs2, RCX);


			// cvt w/ sign extend
			e->pmovsxdq2regreg(RAX, RAX);
			e->pmovsxdq2regreg(RCX, RCX);


			// cvt float to double
			e->psllq2regimm(RAX, RAX, 29);
			e->psllq2regimm(RCX, RCX, 29);
			e->pandn2regreg(RAX, 4, RAX);
			e->pandn2regreg(RCX, 4, RCX);

			// get multipliers
			// 127 << 23 ->rbx
			// 1023+127 << 52 ->r4
			e->psrlq2regimm(4, 5, 54);
			e->psrlq2regimm(RBX, 5, 57);
			e->paddq2regreg(4, 4, RBX);
			e->psllq2regimm(RBX, RBX, 23);
			e->psllq2regimm(4, 4, 52);

			// get guard mask
			e->pxor2regreg(RDX, RAX, RCX);
			e->psrlq2regimm(RDX, RDX, 63);
			e->psllq2regimm(RDX, RDX, 27);

			// use multiplier
			e->vmulpd2(RAX, RAX, 4);
			e->vmulpd2(RCX, RCX, 4);

			// add
			e->vaddpd2(RAX, RAX, RCX);

			// adjust ??
			e->paddq2regreg(RAX, RAX, RDX);

			// get zero ->r4
			e->pxor2regreg(4, 4, 4);

			// get sign ->rdx
			//e->pcmpgtq2regreg(RDX, 4, RAX);
			//e->vextracti128regreg(RCX, RDX, 1);
			//e->packsdw1regreg(RDX, RDX, RCX);
			e->vextracti128regreg(RDX, RAX, 1);
			e->packsdw1regreg(RDX, RAX, RDX);

			// get result ->rax
			e->paddq2regreg(RAX, RAX, RAX);
			e->psrlq2regimm(RAX, RAX, 30);

			// check for zero before ->rcx
			e->pcmpeqq2regreg(RCX, RAX, 4);

			// subtract 127(rbx) from exponent
			e->psubq2regreg(RAX, RAX, RBX);

			// clear result(rax) if it was originally zero(rcx)
			e->pandn2regreg(RAX, RCX, RAX);

			// get underflow ->rbx
			e->pshufd2regregimm(RAX, RAX, 0xd8);
			e->vextracti128regreg(RCX, RAX, 1);
			e->punpckhqdq1regreg(RBX, RAX, RCX);

			// get float result ->rax
			e->punpcklqdq1regreg(RAX, RAX, RCX);

			// check for zero exponent ->rcx
			e->psrld1regimm(RCX, RAX, 23);
			e->pcmpeqd1regreg(RCX, RCX, 4);


			// also zero(rcx) on underflow(rbx)
			e->por1regreg(RCX, RCX, RBX);

			// clear result(rax) on zero(rcx)
			e->pandn1regreg(RAX, RCX, RAX);

			// mask sign(rdx) ->rdx
			e->psrld1regimm(5, 5, 1);
			e->pandn1regreg(RDX, 5, RDX);

			// max result on overflow ->r5
			e->pminud1regreg(5, 5, RAX);

			// combine overflow(rax) | underflow(rbx) ->rbx
			e->pcmpgtd1regreg(RAX, 4, RAX);
			e->packsdw1regreg(RBX, RBX, RAX);

			// combine sign(rdx) and result(r5) ->rax
			e->por1regreg(RAX, RDX, 5);

			// combine sign(rdx) | zero(rcx) here for simd ->rcx
			// sign flag set on negative number not zero
			e->pandn1regreg(5, RCX, RDX);
			e->packsdw1regreg(RCX, RCX, 5);


			// get overflow ->r5
			// might need to use the first method for simd
			//e->pcmpgtd1regreg(5, 4, RAX);

			// max result(rax) on overflow(r5)
			//e->por1regreg(RAX, RAX, 5);

			// combine overflow(r5) | underflow(rbx) ->rbx
			//e->packsdw1regreg(RBX, RBX, 5);


			// clear sign bit in result(RAX)
			//e->paddd1regreg(RAX, RAX, RAX);
			//e->psrld1regimm(RAX, RAX, 1);

			// add sign(rdx)
			//e->pslld1regimm(RDX, RDX, 31);
			//e->por1regreg(RAX, RAX, RDX);


			// set result
			e->pshufd1regregimm(RAX, RAX, (0 << 6) | (1 << 4) | (2 << 2) | (3 << 0));

			if (i.xyzw != 0xf)
			{
				if (pFd)
				{
					e->pblendw1regmemimm(RAX, RAX, pFd, ~((i.destx * 0x03) | (i.desty * 0x0c) | (i.destz * 0x30) | (i.destw * 0xc0)));
				}
				else
				{
					if (i.Fd)
					{
						e->pblendw1regmemimm(RAX, RAX, &VU0::_VU0->vf[i.Fd].sw0, ~((i.destx * 0x03) | (i.desty * 0x0c) | (i.destz * 0x30) | (i.destw * 0xc0)));
					}
				}
			}

			if (pFd)
			{
				e->movdqa1_memreg(pFd, RAX);
			}
			else
			{
				if (i.Fd)
				{
					e->movdqa1_memreg(&VU0::_VU0->vf[i.Fd].sw0, RAX);
				}
			}

			// flags
			if (i.xyzw != 0xf)
			{
				e->pblendw1regregimm(RCX, RCX, 4, ~((i.destx * 0x88) | (i.desty * 0x44) | (i.destz * 0x22) | (i.destw * 0x11)));
				e->pblendw1regregimm(RBX, RBX, 4, ~((i.destx * 0x88) | (i.desty * 0x44) | (i.destz * 0x22) | (i.destw * 0x11)));
			}

			e->packswb1regreg(RAX, RCX, RBX);

			// now get stat
			e->psrld1regimm(RCX, RAX, 7);
			e->pcmpgtd1regreg(RCX, RCX, 4);


			// now pull mac(RAX)->RCX and stat(RCX)->RAX
			e->movmskb1regreg(RCX, RAX);
			e->movmskps1regreg(RAX, RCX);


			// store mac
			// set MAC flags (RCX)
			//e->MovMemReg32((int32_t*)&macflag, RCX);
			ret = e->MovMemReg32((int32_t*)&VU0::_VU0->vi[VU::REG_MACFLAG].s, RCX);

			// update stat
			// check if the lower instruction set stat flag already (there's only like one instruction that does this)
			//if (!v->SetStatus_Flag)
			{
				e->MovRegReg32(RCX, RAX);

				e->ShlRegImm32(RAX, 6);
				//e->OrRegMem32(RAX, (int32_t*)&statflag);
				e->OrRegMem32(RAX, (int32_t*)&VU0::_VU0->vi[VU::REG_STATUSFLAG].s);

				// these two instructions are if you need to set non-sticky flags
				e->AndReg32ImmX(RAX, ~0xf);
				e->OrRegReg32(RAX, RCX);

				// orr with sticky underflow
				e->OrRegReg32(RAX, RDX);

				//e->MovMemReg32((int32_t*)&statflag, RAX);
				ret = e->MovMemReg32((int32_t*)&VU0::_VU0->vi[VU::REG_STATUSFLAG].s, RAX);

			}	// end if ( !v->SetStatus_Flag )

#endif	// end #ifdef USE_NEW_VMADD_AVX2

		}	// end else if (iVectorType == VECTOR_TYPE_AVX2)


#endif	// end #ifdef ALLOW_AVX2_MADDX1

	}	// end if ( i.xyzw )

	return ret;
}



int32_t R5900::Recompiler::Generate_VMAX ( R5900::Instruction::Format i, u32 Address, u32 FdComponent, u32 FsComponent, u32 FtComponent, u32 *pFt )
{
	int32_t ret;
	
	ret = 1;
	
	// check if that component is set to output
	if ( i.Value & ( 1 << ( ( FdComponent ^ 3 ) + 21 ) ) )
	{
		if ( !i.Fd )
		{
			// can't write to register zero
			return 1;
		}
		else
		{
			//e->MovRegMem32 ( RAX, ( &VU0::_VU0->vf [ i.Fs ].sw0 ) + Component );
			//e->AndReg32ImmX ( RAX, 0x7fffffff );
			//e->MovMemReg32 ( ( &VU0::_VU0->vf [ i.Fd ].sw0 ) + Component, RAX );
			
			//lfs = ( lfs >= 0 ) ? lfs : ~( lfs & 0x7fffffff );
			//lft = ( lft >= 0 ) ? lft : ~( lft & 0x7fffffff );
			// compare as integer and return original value?
			//fResult = ( ( lfs > lft ) ? fs : ft );
			if ( !i.Fs )
			{
				if ( FsComponent < 3 )
				{
					e->XorRegReg32 ( RAX, RAX );
				}
				else
				{
					e->MovRegImm32 ( RAX, 0x3f800000 );
				}
			}
			else
			{
				e->MovRegMem32 ( RAX, ( &VU0::_VU0->vf [ i.Fs ].sw0 ) + FsComponent );
			}
			
			e->Cdq ();
			e->MovRegReg32 ( 9, RAX );
			e->AndReg32ImmX ( RAX, 0x7fffffff );
			e->XorRegReg32 ( RDX, RAX );
			e->MovRegReg32 ( RCX, RDX );
			
			if ( pFt )
			{
				e->MovRegMem32 ( RAX, (int32_t*) pFt );
			}
			else
			{
				if ( !i.Ft )
				{
					if ( FtComponent < 3 )
					{
						e->XorRegReg32 ( RAX, RAX );
					}
					else
					{
						e->MovRegImm32 ( RAX, 0x3f800000 );
					}
				}
				else
				{
					e->MovRegMem32 ( RAX, ( &VU0::_VU0->vf [ i.Ft ].sw0 ) + FtComponent );
				}
			}
			
			e->Cdq ();
			e->MovRegReg32 ( 8, RAX );
			e->AndReg32ImmX ( RAX, 0x7fffffff );
			e->XorRegReg32 ( RDX, RAX );
			e->CmpRegReg32 ( RCX, RDX );
			e->CmovGRegReg32 ( 8, 9 );
			ret = e->MovMemReg32 ( ( & VU0::_VU0->vf [ i.Fd ].sw0 ) + FdComponent, 8 );
		}
		
	}
	
	return ret;
}



int32_t R5900::Recompiler::Generate_VMIN ( R5900::Instruction::Format i, u32 Address, u32 FdComponent, u32 FsComponent, u32 FtComponent, u32 *pFt )
{
	int32_t ret;
	
	ret = 1;
	
	// check if that component is set to output
	if ( i.Value & ( 1 << ( ( FdComponent ^ 3 ) + 21 ) ) )
	{
		if ( !i.Fd )
		{
			// can't write to register zero
			return 1;
		}
		else
		{
			//e->MovRegMem32 ( RAX, ( &VU0::_VU0->vf [ i.Fs ].sw0 ) + Component );
			//e->AndReg32ImmX ( RAX, 0x7fffffff );
			//e->MovMemReg32 ( ( &VU0::_VU0->vf [ i.Fd ].sw0 ) + Component, RAX );
			
			//lfs = ( lfs >= 0 ) ? lfs : ~( lfs & 0x7fffffff );
			//lft = ( lft >= 0 ) ? lft : ~( lft & 0x7fffffff );
			// compare as integer and return original value?
			//fResult = ( ( lfs > lft ) ? fs : ft );
			if ( !i.Fs )
			{
				if ( FsComponent < 3 )
				{
					e->XorRegReg32 ( RAX, RAX );
				}
				else
				{
					e->MovRegImm32 ( RAX, 0x3f800000 );
				}
			}
			else
			{
				e->MovRegMem32 ( RAX, ( &VU0::_VU0->vf [ i.Fs ].sw0 ) + FsComponent );
			}
			
			e->Cdq ();
			e->MovRegReg32 ( 9, RAX );
			e->AndReg32ImmX ( RAX, 0x7fffffff );
			e->XorRegReg32 ( RDX, RAX );
			e->MovRegReg32 ( RCX, RDX );
			
			if ( pFt )
			{
				e->MovRegMem32 ( RAX, (int32_t*) pFt );
			}
			else
			{
				if ( !i.Ft )
				{
					if ( FtComponent < 3 )
					{
						e->XorRegReg32 ( RAX, RAX );
					}
					else
					{
						e->MovRegImm32 ( RAX, 0x3f800000 );
					}
				}
				else
				{
					e->MovRegMem32 ( RAX, ( &VU0::_VU0->vf [ i.Ft ].sw0 ) + FtComponent );
				}
			}
			
			e->Cdq ();
			e->MovRegReg32 ( 8, RAX );
			e->AndReg32ImmX ( RAX, 0x7fffffff );
			e->XorRegReg32 ( RDX, RAX );
			e->CmpRegReg32 ( RCX, RDX );
			e->CmovLRegReg32 ( 8, 9 );
			ret = e->MovMemReg32 ( ( & VU0::_VU0->vf [ i.Fd ].sw0 ) + FdComponent, 8 );
		}
		
	}
	
	return ret;
}


int32_t R5900::Recompiler::Generate_VFTOI0 ( R5900::Instruction::Format i, u32 Address, u32 FtComponent, u32 FsComponent )
{
	int32_t ret;
	
	ret = 1;

	if ( i.Value & ( 1 << ( ( FtComponent ^ 3 ) + 21 ) ) )
	{
		if ( i.Ft )
		{
			// flush ps2 float to zero
			if ( !i.Fs )
			{
				if ( FsComponent < 3 )
				{
					//e->XorRegReg32 ( RAX, RAX );
					e->MovMemImm32 ( ( & VU0::_VU0->vf [ i.Ft ].sw0 ) + FtComponent, 0 );
				}
				else
				{
					//e->MovRegImm32 ( RAX, 1 );
					e->MovMemImm32 ( ( & VU0::_VU0->vf [ i.Ft ].sw0 ) + FtComponent, 1 );
				}
			}
			else
			{
				e->MovRegMem32 ( RAX, &VU0::_VU0->vf [ i.Fs ].sw0 );
				
				//e->MovRegReg32 ( RCX, RAX );
				//e->AndReg32ImmX ( RAX, 0x7f800000 );
				//e->CmovNERegReg32 ( RAX, RCX );
				
				// move the registers now to floating point unit
				e->movd_to_sse ( RAX, RAX );
				
				// convert single precision to signed 
				e->cvttss2si ( RCX, RAX );
				
				
				e->Cdq ();
				e->AndReg32ImmX ( RAX, 0x7f800000 );
				e->CmovERegReg32 ( RDX, RAX );
				
				// compare exponent of magnitude and maximize if needed
				e->CmpReg32ImmX ( RAX, 0x4e800000 );
				e->MovReg32ImmX ( RAX, 0x7fffffff );
				e->CmovLERegReg32 ( RAX, RCX );
				e->ShlRegImm32 ( RDX, 31 );
				e->OrRegReg32 ( RAX, RDX );
				
				// set result
				ret = e->MovMemReg32 ( ( & VU0::_VU0->vf [ i.Ft ].sw0 ) + FtComponent, RAX );
			}
			
		}
	}

	return ret;
}



int32_t R5900::Recompiler::Generate_VFTOIX ( R5900::Instruction::Format i, u32 Address, u32 FtComponent, u32 FsComponent, u32 IX )
{
	int32_t ret;
	
	ret = 1;

	if ( i.Value & ( 1 << ( ( FtComponent ^ 3 ) + 21 ) ) )
	{
		if ( i.Ft )
		{
			// flush ps2 float to zero
			if ( !i.Fs )
			{
				if ( FsComponent < 3 )
				{
					e->MovMemImm32 ( ( & VU0::_VU0->vf [ i.Ft ].sw0 ) + FtComponent, 0 );
				}
				else
				{
					e->MovMemImm32 ( ( & VU0::_VU0->vf [ i.Ft ].sw0 ) + FtComponent, 1 << IX );
				}
			}
			else
			{
				e->MovRegMem32 ( RAX, ( &VU0::_VU0->vf [ i.Fs ].sw0 ) + FsComponent );
				
				//e->MovRegReg32 ( RCX, RAX );
				//e->AndReg32ImmX ( RAX, 0x7f800000 );
				//e->CmovNERegReg32 ( RAX, RCX );
				
				e->MovRegReg32 ( RCX, RAX );
				e->AddReg32ImmX ( RCX, IX << 23 );
				
				// move the registers now to floating point unit
				e->movd_to_sse ( RAX, RCX );
				
				// convert single precision to signed 
				e->cvttss2si ( RCX, RAX );
				
				
				e->Cdq ();
				e->AndReg32ImmX ( RAX, 0x7f800000 );
				e->CmovERegReg32 ( RDX, RAX );
				//e->CmovERegReg32 ( RCX, RAX );
				
				// compare exponent of magnitude and maximize if needed
				e->CmpReg32ImmX ( RAX, 0x4e800000 - ( IX << 23 ) );
				e->MovReg32ImmX ( RAX, 0x7fffffff );
				e->CmovLERegReg32 ( RAX, RCX );
				e->ShlRegImm32 ( RDX, 31 );
				e->OrRegReg32 ( RAX, RDX );
				
				// set result
				ret = e->MovMemReg32 ( ( & VU0::_VU0->vf [ i.Ft ].sw0 ) + FtComponent, RAX );
			}
			
		}
	}

	return ret;
}



int32_t R5900::Recompiler::Generate_VITOFX ( R5900::Instruction::Format i, u32 Address, u32 FtComponent, u32 FsComponent, u64 FX )
{
	int32_t ret;
	
	ret = 1;

	if ( i.Value & ( 1 << ( ( FtComponent ^ 3 ) + 21 ) ) )
	{
		if ( i.Ft )
		{
			// flush ps2 float to zero
			if ( !i.Fs )
			{
				if ( FsComponent < 3 )
				{
					e->MovMemImm32 ( ( & VU0::_VU0->vf [ i.Ft ].sw0 ) + FtComponent, 0 );
				}
				else
				{
					e->MovMemImm32 ( ( & VU0::_VU0->vf [ i.Ft ].sw0 ) + FtComponent, 0x4e7e0000 );
				}
			}
			else
			{
				// flush ps2 float to zero
				e->MovRegMem32 ( RAX, ( &VU0::_VU0->vf [ i.Fs ].sw0 ) + FsComponent );
				
				// convert single precision to signed 
				e->cvtsi2sd ( RAX, RAX );
				e->movq_from_sse ( RAX, RAX );
				
				
				e->MovReg64ImmX ( RCX, ( 896ull << 23 ) + ( FX << 23 ) );
				e->Cqo();
				e->ShrRegImm64 ( RAX, 29 );
				e->CmovERegReg64 ( RCX, RDX );
				e->SubRegReg64 ( RAX, RCX );
				
				
				//e->CmovSRegReg32 ( RAX, RDX );
				e->ShlRegImm32 ( RDX, 31 );
				e->OrRegReg32 ( RAX, RDX );
				
				// set result
				ret = e->MovMemReg32 ( ( &VU0::_VU0->vf [ i.Ft ].sw0 ) + FtComponent, RAX );
			}
			
		}
	}

	return ret;
}



int32_t R5900::Recompiler::Generate_VMOVE ( R5900::Instruction::Format i, u32 Address, u32 FtComponent, u32 FsComponent )
{
	int32_t ret;
	
	ret = 1;

	if ( i.Value & ( 1 << ( ( FtComponent ^ 3 ) + 21 ) ) )
	{
		if ( i.Ft )
		{
			// flush ps2 float to zero
			if ( !i.Fs )
			{
				if ( FsComponent < 3 )
				{
					e->MovMemImm32 ( ( & VU0::_VU0->vf [ i.Ft ].sw0 ) + FtComponent, 0 );
				}
				else
				{
					e->MovMemImm32 ( ( & VU0::_VU0->vf [ i.Ft ].sw0 ) + FtComponent, 0x3f800000 );
				}
			}
			else if ( i.Ft != i.Fs )
			{
				// flush ps2 float to zero
				e->MovRegMem32 ( RAX, ( &VU0::_VU0->vf [ i.Fs ].sw0 ) + FsComponent );
				
				// set result
				ret = e->MovMemReg32 ( ( &VU0::_VU0->vf [ i.Ft ].sw0 ) + FtComponent, RAX );
			}
			
		}
	}

	return ret;
}


int32_t R5900::Recompiler::Generate_VMR32_Load ( R5900::Instruction::Format i, u32 Address, u32 FsComponent )
{
	int32_t ret;
	
	ret = 1;

	if ( i.Value & ( 1 << ( ( FsComponent ^ 3 ) + 21 ) ) )
	{
		if ( i.Ft )
		{
			// flush ps2 float to zero
			if ( !i.Fs )
			{
				//if ( FsComponent < 3 )
				//{
				//	e->MovMemImm32 ( ( & VU0::_VU0->vf [ i.Ft ].sw0 ) + FtComponent, 0 );
				//}
				//else
				//{
				//	e->MovMemImm32 ( ( & VU0::_VU0->vf [ i.Ft ].sw0 ) + FtComponent, 0x3f800000 );
				//}
			}
			else
			{
				switch ( FsComponent )
				{
					case 0:
						e->MovRegMem32 ( RAX, ( &VU0::_VU0->vf [ i.Fs ].sw0 ) + ( ( FsComponent + 1 ) & 3 ) );
						break;
				
					case 1:
						e->MovRegMem32 ( RCX, ( &VU0::_VU0->vf [ i.Fs ].sw0 ) + ( ( FsComponent + 1 ) & 3 ) );
						break;
					case 2:
						e->MovRegMem32 ( RDX, ( &VU0::_VU0->vf [ i.Fs ].sw0 ) + ( ( FsComponent + 1 ) & 3 ) );
						break;
					case 3:
						e->MovRegMem32 ( 8, ( &VU0::_VU0->vf [ i.Fs ].sw0 ) + ( ( FsComponent + 1 ) & 3 ) );
						break;
				}
				
				// set result
				//ret = e->MovMemReg32 ( ( &VU0::_VU0->vf [ i.Ft ].sw0 ) + FtComponent, RAX );
			}
			
		}
	}

	return ret;
}


int32_t R5900::Recompiler::Generate_VMR32_Store ( R5900::Instruction::Format i, u32 Address, u32 FtComponent )
{
	int32_t ret;
	
	ret = 1;

	if ( i.Value & ( 1 << ( ( FtComponent ^ 3 ) + 21 ) ) )
	{
		if ( i.Ft )
		{
			// flush ps2 float to zero
			if ( !i.Fs )
			{
				if ( FtComponent != 2 )
				{
					e->MovMemImm32 ( ( & VU0::_VU0->vf [ i.Ft ].sw0 ) + FtComponent, 0 );
				}
				else
				{
					e->MovMemImm32 ( ( & VU0::_VU0->vf [ i.Ft ].sw0 ) + FtComponent, 0x3f800000 );
				}
			}
			else
			{
				switch ( FtComponent )
				{
					case 0:
						//e->MovRegMem32 ( RAX, ( &VU0::_VU0->vf [ i.Fs ].sw0 ) + ( ( FsComponent + 1 ) & 3 ) );
						ret = e->MovMemReg32 ( ( &VU0::_VU0->vf [ i.Ft ].sw0 ) + FtComponent, RAX );
						break;
					case 1:
						//e->MovRegMem32 ( RCX, ( &VU0::_VU0->vf [ i.Fs ].sw0 ) + ( ( FsComponent + 1 ) & 3 ) );
						ret = e->MovMemReg32 ( ( &VU0::_VU0->vf [ i.Ft ].sw0 ) + FtComponent, RCX );
						break;
					case 2:
						//e->MovRegMem32 ( RDX, ( &VU0::_VU0->vf [ i.Fs ].sw0 ) + ( ( FsComponent + 1 ) & 3 ) );
						ret = e->MovMemReg32 ( ( &VU0::_VU0->vf [ i.Ft ].sw0 ) + FtComponent, RDX );
						break;
					case 3:
						//e->MovRegMem32 ( 8, ( &VU0::_VU0->vf [ i.Fs ].sw0 ) + ( ( FsComponent + 1 ) & 3 ) );
						ret = e->MovMemReg32 ( ( &VU0::_VU0->vf [ i.Ft ].sw0 ) + FtComponent, 8 );
						break;
				}
				
				// set result
				//ret = e->MovMemReg32 ( ( &VU0::_VU0->vf [ i.Ft ].sw0 ) + FtComponent, RAX );
			}
			
		}
	}

	return ret;
}


int32_t R5900::Recompiler::Generate_VMFIR ( R5900::Instruction::Format i, u32 Address, u32 FtComponent )
{
	int32_t ret;
	
	ret = 1;

	if ( i.Value & ( 1 << ( ( FtComponent ^ 3 ) + 21 ) ) )
	{
		if ( i.Ft )
		{
			// flush ps2 float to zero
			if ( !i.is )
			{
				e->MovMemImm32 ( ( & VU0::_VU0->vf [ i.Ft ].sw0 ) + FtComponent, 0 );
			}
			else
			{
				// flush ps2 float to zero
				e->MovRegMem32 ( RAX, ( &VU0::_VU0->vi [ i.is ].s ) );
				
				// sign-extend from 16-bit to 32-bit
				e->Cwde();
				
				// set result
				ret = e->MovMemReg32 ( ( &VU0::_VU0->vf [ i.Ft ].sw0 ) + FtComponent, RAX );
			}
			
		}
	}

	return ret;
}


int32_t R5900::Recompiler::Generate_VADD ( R5900::Instruction::Format i, u32 Address, u32 FdComponent, u32 FsComponent, u32 FtComponent, u32 *pFd, u32 *pFt )
{
	int32_t ret;
	
	ret = 1;


	// only clear non-sticky bits in status flag the first go around
	// also clear MAC flag (set to zero for components that are not calculated)
	if ( !FdComponent )
	{
		// clear bits 14 and 15 in the flag register first
		e->AndMem32ImmX ( &VU0::_VU0->vi [ VU::REG_STATUSFLAG ].s, ~0x00000030 );
		
		// clear MAC flags
		//ret = e->MovMemImm32 ( &VU0::_VU0->vi [ VU::REG_MACFLAG ].s, 0 );
		
		// R10 will be MAC flag
		e->XorRegReg32 ( 10, 10 );
		
		// R11 will be zero register
		e->XorRegReg32 ( 11, 11 );
	}


	
	// check if that component is set to output
	if ( i.Value & ( 1 << ( ( FdComponent ^ 3 ) + 21 ) ) )
	{
		// clear bits 14 and 15 in the flag register first
		//e->AndMem32ImmX ( &VU0::_VU0->vi [ VU::REG_STATUSFLAG ].s, ~0x00000030 );
		
		if ( ( !i.Fs ) && ( FsComponent < 3 ) )
		{
			// Fs is zero register
			
			if ( ( !i.Ft ) && ( !pFt ) )
			{
				if ( FtComponent < 3 )
				{
					// set zero flag
					ret = e->OrReg32ImmX ( 10, 0x0001 << ( FdComponent ^ 3 ) );
					
					if ( i.Fd )
					{
						// set 0x00000000 as result
						ret = e->MovMemReg32 ( ( &VU0::_VU0->vf [ i.Fd ].sw0 ) + FdComponent, 11 );
					}
				}
				else
				{
					if ( i.Fd )
					{
						// set 0x3f800000 as result
						ret = e->MovMemImm32 ( ( &VU0::_VU0->vf [ i.Fd ].sw0 ) + FdComponent, 0x3f800000 );
					}
				}
			}
			else
			{
				if ( pFt )
				{
					e->MovRegMem32 ( RAX, (int32_t*) pFt );
				}
				else
				{
					e->MovRegMem32 ( RAX, ( &VU0::_VU0->vf [ i.Ft ].sw0 ) + FtComponent );
				}
				
				e->MovReg32ImmX ( RCX, 0x0010 << ( FdComponent ^ 3 ) );
				e->MovReg32ImmX ( RDX, 0x0001 << ( FdComponent ^ 3 ) );
				e->OrRegReg32 ( RAX, RAX );
				e->CmovNSRegReg32 ( RCX, 11 );
				
				e->TestReg32ImmX ( RAX, 0x7f800000 );
				e->CmovERegReg32 ( RCX, RDX );
				
				// set MAC flag
				e->OrRegReg32 ( 10, RCX );
				
				if ( i.Fd )
				{
					// set result
					ret = e->MovMemReg32 ( ( &VU0::_VU0->vf [ i.Fd ].sw0 ) + FdComponent, RAX );
				}
			}
		}
		else if ( ( !i.Ft ) && ( !pFt ) && ( FtComponent < 3 ) )
		{
			if ( !i.Fs )
			{
				if ( FsComponent < 3 )
				{
					// set zero flag
					ret = e->OrReg32ImmX ( 10, 0x0001 << ( FdComponent ^ 3 ) );
					
					if ( i.Fd )
					{
						// set 0x00000000 as result
						ret = e->MovMemReg32 ( ( &VU0::_VU0->vf [ i.Fd ].sw0 ) + FdComponent, 11 );
					}
				}
				else
				{
					if ( i.Fd )
					{
						// set 0x3f800000 as result
						ret = e->MovMemImm32 ( ( &VU0::_VU0->vf [ i.Fd ].sw0 ) + FdComponent, 0x3f800000 );
					}
				}
			}
			else
			{
				e->MovRegMem32 ( RAX, ( &VU0::_VU0->vf [ i.Fs ].sw0 ) + FsComponent );
				
				e->MovReg32ImmX ( RCX, 0x0010 << ( FdComponent ^ 3 ) );
				e->MovReg32ImmX ( RDX, 0x0001 << ( FdComponent ^ 3 ) );
				e->OrRegReg32 ( RAX, RAX );
				e->CmovNSRegReg32 ( RCX, 11 );
				
				e->TestReg32ImmX ( RAX, 0x7f800000 );
				e->CmovERegReg32 ( RCX, RDX );
				
				// set MAC flag
				e->OrRegReg32 ( 10, RCX );
				
				if ( i.Fd )
				{
					// set result
					ret = e->MovMemReg32 ( ( &VU0::_VU0->vf [ i.Fd ].sw0 ) + FdComponent, RAX );
				}
			}
		}
		else
		{
			
			// flush ps2 float to zero
			
			// pshufl+pshufh
			if ( pFt )
			{
				e->MovRegMem32 ( RAX, (int32_t*) pFt );
			}
			else
			{
				e->MovRegMem32 ( RAX, ( &VU0::_VU0->vf [ i.Ft ].sw0 ) + FtComponent );
			}
			
			e->Cdq();
			e->AndReg32ImmX ( RAX, 0x7fffffff );
			e->MovRegReg32 ( RCX, RAX );
			e->AndReg32ImmX ( RAX, 0x7f800000 );
			e->MovRegReg32 ( 9, RAX );
			e->CmovERegReg32 ( RCX, RAX );
			e->ShlRegImm64 ( RDX, 63 );
			e->ShlRegImm64 ( RCX, 29 );
			e->OrRegReg64 ( RCX, RDX );
			

			e->MovRegMem32 ( RAX, ( &VU0::_VU0->vf [ i.Fs ].sw0 ) + FsComponent );
			e->Cdq();
			e->AndReg32ImmX ( RAX, 0x7fffffff );
			e->MovRegReg32 ( 8, RAX );
			e->AndReg32ImmX ( 8, 0x7f800000 );
			//e->MovRegReg32 ( 8, RAX );
			//e->CmovNERegReg32 ( RAX, 10 );
			e->CmovERegReg32 ( RAX, 8 );
			e->ShlRegImm64 ( RDX, 63 );
			e->ShlRegImm64 ( RAX, 29 );
			e->OrRegReg64 ( RAX, RDX );
			
			// check if shift is more than 24, then zero
			//e->XorRegReg32 ( 11, 11 );
			e->SubRegReg32 ( 8, 9 );
			e->CmpRegImm32 ( 8, 24 << 23 );
			
			// if greater than +24, then R9 has higher magnitude, so zero RAX
			e->CmovGERegReg64 ( RCX, 11 );
			
			// if less than -24, then R11 has higher magnitude, so zero R8
			e->CmpReg32ImmX ( 8, -24 << 23 );
			e->CmovLERegReg64 ( RAX, 11 );
			
			// move the registers now to floating point unit
			e->movq_to_sse ( RAX, RAX );
			e->movq_to_sse ( RCX, RCX );
			
			
			// add
			e->addsd ( RAX, RCX );
			e->movq_from_sse ( RAX, RAX );
			
			// save sign
			e->Cqo();

			// set sign
			e->ShlRegImm32 ( RDX, 31 );
			
			// set sign MAC flag
			
			// put MAC flag in R8
			
			// sign flag
			e->MovReg32ImmX ( 8, 0x0010 << ( FdComponent ^ 3 ) );
			
			// clear sign flags if not sign
			e->CmovNSRegReg32 ( 8, 11 );
			
			// shift back down without sign
			e->ShrRegImm64 ( RAX, 29 );
			
			// set MAC flag for underflow and zero in R10
			
			// zero MAC flag
			e->MovReg32ImmX ( 9, 0x0001 << ( FdComponent ^ 3 ) );
			
			// if zero, then put in zero flag
			e->CmovERegReg32 ( 8, 9 );
			
			// underflow+zero MAC flag
			e->MovReg32ImmX ( 9, 0x0101 << ( FdComponent ^ 3 ) );
			
			
			// if zero or underflow, then clear result
			
			// underflow status flag is 0x4 and sticky flag is 0x100 = 0x104
			//e->MovReg32ImmX ( RCX, 0x104 );
			
			// zero status flag is 0x1 and sticky flag is 0x40 = 0x41
			//e->MovReg32ImmX ( 8, 0x41 );
			
			// check for zero
			//e->OrRegReg32 ( RAX, RAX );
			
			// if zero, then not underflow
			//e->CmovERegReg32 ( RCX, RAX );
			//e->CmovERegReg32 ( 9, RAX );
			
			e->CmpReg32ImmX ( RAX, 0x00800000 );
			//e->CmovAERegReg32 ( RCX, 11 );
			
			// if underflow, then set result to zero
			e->CmovBRegReg32 ( RAX, 11 );
			
			// if above or equal, then not underflow or zero
			//e->CmovAERegReg32 ( 8, 11 );
			e->CmovAERegReg32 ( 9, 11 );
			//e->CmovAERegReg32 ( 10, 11 );
			
			// combine underflow and zero MAC flags
			e->OrRegReg32 ( 8, 9 );
			
			
			// check for overflow
			
			e->MovReg32ImmX ( RCX, 0x7fffffff );
			e->CmpRegReg32 ( RAX, RCX );
			
			// if unsigned above, then overflow
			e->CmovARegReg32 ( RAX, RCX );
			//e->CmovARegReg32 ( RCX, 9 );
			
			// set MAC flag for overflow (if overflow, then definitely not zero or underflow)
			e->MovReg32ImmX ( 9, 0x1000 << ( FdComponent ^ 3 ) );
			e->CmovBERegReg32 ( 9, 11 );
			
			// combine MAC flags
			e->OrRegReg32 ( 8, 9 );
			
			// set MAC flags
			//e->OrMemReg32 ( &VU0::_VU0->vi [ VU::REG_MACFLAG ].s, 8 );
			e->OrRegReg32 ( 10, 8 );
			
			// set sign
			//e->ShlRegImm32 ( RDX, 31 );
			e->OrRegReg32 ( RAX, RDX );
			
			if ( pFd )
			{
				ret = e->MovMemReg32 ( (int32_t*) pFd, RAX );
			}
			else
			{
				// don't write to the zero register
				if ( i.Fd )
				{
					// set result
					ret = e->MovMemReg32 ( ( &VU0::_VU0->vf [ i.Fd ].sw0 ) + FdComponent, RAX );
				}
			}
			
		}
		
	}


	if ( FdComponent == 3 )
	{
		// set MAC flags
		e->MovMemReg32 ( &VU0::_VU0->vi [ VU::REG_MACFLAG ].s, 10 );
		
		// MAC flag is in R10
		
		// zero flag
		e->MovReg32ImmX ( RAX, 0x41 );
		e->TestReg32ImmX ( 10, 0x000f );
		e->CmovERegReg32 ( RAX, 11 );
		
		// sign flag
		e->MovReg32ImmX ( RCX, 0x82 );
		e->TestReg32ImmX ( 10, 0x00f0 );
		e->CmovERegReg32 ( RCX, 11 );
		e->OrRegReg32 ( RAX, RCX );

		// underflow flag
		e->MovReg32ImmX ( RCX, 0x104 );
		e->TestReg32ImmX ( 10, 0x0f00 );
		e->CmovERegReg32 ( RCX, 11 );
		e->OrRegReg32 ( RAX, RCX );
		
		// overflow flag
		e->MovReg32ImmX ( RCX, 0x208 );
		e->TestReg32ImmX ( 10, 0xf000 );
		e->CmovERegReg32 ( RCX, 11 );
		e->OrRegReg32 ( RAX, RCX );
		
		// set status flag
		ret = e->OrMemReg32 ( &VU0::_VU0->vi [ VU::REG_STATUSFLAG ].s, RAX );
	}


	
	return ret;
}



int32_t R5900::Recompiler::Generate_VSUB ( R5900::Instruction::Format i, u32 Address, u32 FdComponent, u32 FsComponent, u32 FtComponent, u32 *pFd, u32 *pFt )
{
	int32_t ret;
	
	ret = 1;
	
	// only clear non-sticky bits in status flag the first go around
	// also clear MAC flag (set to zero for components that are not calculated)
	if ( !FdComponent )
	{
		// clear bits 14 and 15 in the flag register first
		e->AndMem32ImmX ( &VU0::_VU0->vi [ VU::REG_STATUSFLAG ].s, ~0x00000030 );
		
		// clear MAC flags
		//ret = e->MovMemImm32 ( &VU0::_VU0->vi [ VU::REG_MACFLAG ].s, 0 );
		
		// R10 will be MAC flag
		e->XorRegReg32 ( 10, 10 );
		
		// R11 will be zero register
		e->XorRegReg32 ( 11, 11 );
	}


	
	// check if that component is set to output
	if ( i.Value & ( 1 << ( ( FdComponent ^ 3 ) + 21 ) ) )
	{
		// clear bits 14 and 15 in the flag register first
		//e->AndMem32ImmX ( &VU0::_VU0->vi [ VU::REG_STATUSFLAG ].s, ~0x00000030 );
		
		if ( ( !i.Fs ) && ( FsComponent < 3 ) )
		{
			// Fs is zero register
			
			if ( ( !i.Ft ) && ( !pFt ) )
			{
				if ( FtComponent < 3 )
				{
					// set zero flag
					ret = e->OrReg32ImmX ( 10, 0x0001 << ( FdComponent ^ 3 ) );
					
					if ( i.Fd )
					{
						// set 0x00000000 as result
						ret = e->MovMemReg32 ( ( &VU0::_VU0->vf [ i.Fd ].sw0 ) + FdComponent, 11 );
					}
				}
				else
				{
					// set sign flag
					ret = e->OrReg32ImmX ( 10, 0x0010 << ( FdComponent ^ 3 ) );
					
					if ( i.Fd )
					{
						// set 0x3f800000 as result
						ret = e->MovMemImm32 ( ( &VU0::_VU0->vf [ i.Fd ].sw0 ) + FdComponent, 0xbf800000 );
					}
				}
			}
			else
			{
				if ( pFt )
				{
					e->MovRegMem32 ( RAX, (int32_t*) pFt );
				}
				else
				{
					e->MovRegMem32 ( RAX, ( &VU0::_VU0->vf [ i.Ft ].sw0 ) + FtComponent );
				}
				
				e->MovReg32ImmX ( RCX, 0x0010 << ( FdComponent ^ 3 ) );
				e->MovReg32ImmX ( RDX, 0x0001 << ( FdComponent ^ 3 ) );
				e->XorReg32ImmX ( RAX, 0x80000000 );
				e->CmovNSRegReg32 ( RCX, 11 );
				
				e->TestReg32ImmX ( RAX, 0x7f800000 );
				e->CmovERegReg32 ( RCX, RDX );
				e->CmovERegReg32 ( RAX, 11 );
				
				// set MAC flag
				e->OrRegReg32 ( 10, RCX );
				
				if ( i.Fd )
				{
					// set result
					ret = e->MovMemReg32 ( ( &VU0::_VU0->vf [ i.Fd ].sw0 ) + FdComponent, RAX );
				}
			}
		}
		else if ( ( !i.Ft ) && ( !pFt ) && ( FtComponent < 3 ) )
		{
			if ( !i.Fs )
			{
				if ( FsComponent < 3 )
				{
					// set zero flag
					ret = e->OrReg32ImmX ( 10, 0x0001 << ( FdComponent ^ 3 ) );
					
					if ( i.Fd )
					{
						// set 0x00000000 as result
						ret = e->MovMemReg32 ( ( &VU0::_VU0->vf [ i.Fd ].sw0 ) + FdComponent, 11 );
					}
				}
				else
				{
					if ( i.Fd )
					{
						// set 0x3f800000 as result
						ret = e->MovMemImm32 ( ( &VU0::_VU0->vf [ i.Fd ].sw0 ) + FdComponent, 0x3f800000 );
					}
				}
			}
			else
			{
				e->MovRegMem32 ( RAX, ( &VU0::_VU0->vf [ i.Fs ].sw0 ) + FsComponent );
				
				e->MovReg32ImmX ( RCX, 0x0010 << ( FdComponent ^ 3 ) );
				e->MovReg32ImmX ( RDX, 0x0001 << ( FdComponent ^ 3 ) );
				e->OrRegReg32 ( RAX, RAX );
				e->CmovNSRegReg32 ( RCX, 11 );
				
				e->TestReg32ImmX ( RAX, 0x7f800000 );
				e->CmovERegReg32 ( RCX, RDX );
				
				// set MAC flag
				e->OrRegReg32 ( 10, RCX );
				
				if ( i.Fd )
				{
					// set result
					ret = e->MovMemReg32 ( ( &VU0::_VU0->vf [ i.Fd ].sw0 ) + FdComponent, RAX );
				}
			}
		}
		else
		{
			
			// flush ps2 float to zero
			if ( pFt )
			{
				e->MovRegMem32 ( RAX, (int32_t*) pFt );
			}
			else
			{
				e->MovRegMem32 ( RAX, ( &VU0::_VU0->vf [ i.Ft ].sw0 ) + FtComponent );
			}
			
			e->Cdq();
			e->AndReg32ImmX ( RAX, 0x7fffffff );
			e->MovRegReg32 ( RCX, RAX );
			e->AndReg32ImmX ( RAX, 0x7f800000 );
			e->MovRegReg32 ( 9, RAX );
			e->CmovERegReg32 ( RCX, RAX );
			e->ShlRegImm64 ( RDX, 63 );
			e->ShlRegImm64 ( RCX, 29 );
			e->OrRegReg64 ( RCX, RDX );
			

			e->MovRegMem32 ( RAX, ( &VU0::_VU0->vf [ i.Fs ].sw0 ) + FsComponent );
			e->Cdq();
			e->AndReg32ImmX ( RAX, 0x7fffffff );
			e->MovRegReg32 ( 8, RAX );
			e->AndReg32ImmX ( 8, 0x7f800000 );
			//e->MovRegReg32 ( 8, RAX );
			//e->CmovNERegReg32 ( RAX, 10 );
			e->CmovERegReg32 ( RAX, 8 );
			e->ShlRegImm64 ( RDX, 63 );
			e->ShlRegImm64 ( RAX, 29 );
			e->OrRegReg64 ( RAX, RDX );
			
			// check if shift is more than 24, then zero
			//e->XorRegReg32 ( 11, 11 );
			e->SubRegReg32 ( 8, 9 );
			e->CmpRegImm32 ( 8, 24 << 23 );
			
			// if greater than +24, then R9 has higher magnitude, so zero RAX
			e->CmovGERegReg64 ( RCX, 11 );
			
			// if less than -24, then R11 has higher magnitude, so zero R8
			e->CmpReg32ImmX ( 8, -24 << 23 );
			e->CmovLERegReg64 ( RAX, 11 );
			
			// move the registers now to floating point unit
			e->movq_to_sse ( RAX, RAX );
			e->movq_to_sse ( RCX, RCX );
			
			
			// add
			e->subsd ( RAX, RCX );
			e->movq_from_sse ( RAX, RAX );
			
			// save sign
			e->Cqo();

			// set sign
			e->ShlRegImm32 ( RDX, 31 );
			
			// set sign MAC flag
			
			// put MAC flag in R8
			
			// sign flag
			e->MovReg32ImmX ( 8, 0x0010 << ( FdComponent ^ 3 ) );
			
			// clear sign flags if not sign
			e->CmovNSRegReg32 ( 8, 11 );
			
			// shift back down without sign
			e->ShrRegImm64 ( RAX, 29 );
			
			// set MAC flag for underflow and zero in R10
			
			// zero MAC flag
			e->MovReg32ImmX ( 9, 0x0001 << ( FdComponent ^ 3 ) );
			
			// if zero, then put in zero flag
			e->CmovERegReg32 ( 8, 9 );
			
			// underflow+zero MAC flag
			e->MovReg32ImmX ( 9, 0x0101 << ( FdComponent ^ 3 ) );
			
			
			// if zero or underflow, then clear result
			
			// underflow status flag is 0x4 and sticky flag is 0x100 = 0x104
			//e->MovReg32ImmX ( RCX, 0x104 );
			
			// zero status flag is 0x1 and sticky flag is 0x40 = 0x41
			//e->MovReg32ImmX ( 8, 0x41 );
			
			// check for zero
			//e->OrRegReg32 ( RAX, RAX );
			
			// if zero, then not underflow
			//e->CmovERegReg32 ( RCX, RAX );
			//e->CmovERegReg32 ( 9, RAX );
			
			e->CmpReg32ImmX ( RAX, 0x00800000 );
			//e->CmovAERegReg32 ( RCX, 11 );
			
			// if underflow, then set result to zero
			e->CmovBRegReg32 ( RAX, 11 );
			
			// if above or equal, then not underflow or zero
			//e->CmovAERegReg32 ( 8, 11 );
			e->CmovAERegReg32 ( 9, 11 );
			//e->CmovAERegReg32 ( 10, 11 );
			
			// combine underflow and zero MAC flags
			e->OrRegReg32 ( 8, 9 );
			
			
			// check for overflow
			
			e->MovReg32ImmX ( RCX, 0x7fffffff );
			e->CmpRegReg32 ( RAX, RCX );
			
			// if unsigned above, then overflow
			e->CmovARegReg32 ( RAX, RCX );
			//e->CmovARegReg32 ( RCX, 9 );
			
			// set MAC flag for overflow (if overflow, then definitely not zero or underflow)
			e->MovReg32ImmX ( 9, 0x1000 << ( FdComponent ^ 3 ) );
			e->CmovBERegReg32 ( 9, 11 );
			
			// combine MAC flags
			e->OrRegReg32 ( 8, 9 );
			
			// set MAC flags
			//e->OrMemReg32 ( &VU0::_VU0->vi [ VU::REG_MACFLAG ].s, 8 );
			e->OrRegReg32 ( 10, 8 );
			
			// set sign
			//e->ShlRegImm32 ( RDX, 31 );
			e->OrRegReg32 ( RAX, RDX );
			
			if ( pFd )
			{
				ret = e->MovMemReg32 ( (int32_t*) pFd, RAX );
			}
			else
			{
				// don't write to the zero register
				if ( i.Fd )
				{
					// set result
					ret = e->MovMemReg32 ( ( &VU0::_VU0->vf [ i.Fd ].sw0 ) + FdComponent, RAX );
				}
			}
			
		}
	}


	if ( FdComponent == 3 )
	{
		// set MAC flags
		e->MovMemReg32 ( &VU0::_VU0->vi [ VU::REG_MACFLAG ].s, 10 );
		
		// MAC flag is in R10
		
		// zero flag
		e->MovReg32ImmX ( RAX, 0x41 );
		e->TestReg32ImmX ( 10, 0x000f );
		e->CmovERegReg32 ( RAX, 11 );
		
		// sign flag
		e->MovReg32ImmX ( RCX, 0x82 );
		e->TestReg32ImmX ( 10, 0x00f0 );
		e->CmovERegReg32 ( RCX, 11 );
		e->OrRegReg32 ( RAX, RCX );

		// underflow flag
		e->MovReg32ImmX ( RCX, 0x104 );
		e->TestReg32ImmX ( 10, 0x0f00 );
		e->CmovERegReg32 ( RCX, 11 );
		e->OrRegReg32 ( RAX, RCX );
		
		// overflow flag
		e->MovReg32ImmX ( RCX, 0x208 );
		e->TestReg32ImmX ( 10, 0xf000 );
		e->CmovERegReg32 ( RCX, 11 );
		e->OrRegReg32 ( RAX, RCX );
		
		// set status flag
		ret = e->OrMemReg32 ( &VU0::_VU0->vi [ VU::REG_STATUSFLAG ].s, RAX );
	}
	
	return ret;
}




int32_t R5900::Recompiler::Generate_VMUL ( R5900::Instruction::Format i, u32 Address, u32 FdComponent, u32 FsComponent, u32 FtComponent, u32 *pFd, u32 *pFt )
{
	int32_t ret;
	
	ret = 1;
	
	// only clear non-sticky bits in status flag the first go around
	// also clear MAC flag (set to zero for components that are not calculated)
	if ( !FdComponent )
	{
		// clear bits 14 and 15 in the flag register first
		e->AndMem32ImmX ( &VU0::_VU0->vi [ VU::REG_STATUSFLAG ].s, ~0x00000030 );
		
		// clear MAC flags
		//ret = e->MovMemImm32 ( &VU0::_VU0->vi [ VU::REG_MACFLAG ].s, 0 );
		
		// R10 will be MAC flag
		e->XorRegReg32 ( 10, 10 );
		
		// R11 will be zero register
		e->XorRegReg32 ( 11, 11 );
	}
	
	// check if that component is set to output
	if ( i.Value & ( 1 << ( ( FdComponent ^ 3 ) + 21 ) ) )
	{
		if ( !i.Fs )
		{
			// Fs is zero register
			
			if ( FsComponent < 3 )
			{
				// get Ft
				if ( pFt )
				{
					e->MovRegMem32 ( RAX, (int32_t*) pFt );
				}
				else
				{
					e->MovRegMem32 ( RAX, ( &VU0::_VU0->vf [ i.Ft ].sw0 ) + FtComponent );
				}
				
				// set zero flag
				ret = e->OrReg32ImmX ( 10, 0x0001 << ( FdComponent ^ 3 ) );
				
				// get sign of result
				e->AndReg32ImmX ( RAX, 0x80000000 );
					
				if ( i.Fd )
				{
					// set 0x00000000 as result
					ret = e->MovMemReg32 ( ( &VU0::_VU0->vf [ i.Fd ].sw0 ) + FdComponent, RAX );
				}
			}
			else
			{
				if ( pFt )
				{
					e->MovRegMem32 ( RAX, (int32_t*) pFt );
				}
				else
				{
					e->MovRegMem32 ( RAX, ( &VU0::_VU0->vf [ i.Ft ].sw0 ) + FtComponent );
				}
				
				e->MovReg32ImmX ( RCX, 0x0010 << ( FdComponent ^ 3 ) );
				e->MovReg32ImmX ( RDX, 0x0001 << ( FdComponent ^ 3 ) );
				e->OrRegReg32 ( RAX, RAX );
				e->CmovNSRegReg32 ( RCX, 11 );
				
				e->TestReg32ImmX ( RAX, 0x7f800000 );
				e->CmovERegReg32 ( RCX, RDX );
				e->MovRegReg32 ( RDX, RAX );
				e->CmovERegReg32 ( RAX, 11 );
				
				// preserve sign of zero ??
				e->AndReg32ImmX ( RDX, 0x80000000 );
				e->OrRegReg32 ( RAX, RDX );
				
				// set MAC flag
				e->OrRegReg32 ( 10, RCX );
				
				if ( i.Fd )
				{
					// set result
					ret = e->MovMemReg32 ( ( &VU0::_VU0->vf [ i.Fd ].sw0 ) + FdComponent, RAX );
				}
			}
		}
		else if ( ( !i.Ft ) && ( !pFt ) )
		{
			// Ft is zero register
			
			if ( FtComponent < 3 )
			{
				// get Fs
				e->MovRegMem32 ( RAX, ( &VU0::_VU0->vf [ i.Fs ].sw0 ) + FsComponent );
				
				// set zero flag
				ret = e->OrReg32ImmX ( 10, 0x0001 << ( FdComponent ^ 3 ) );
				
				// get sign of result
				e->AndReg32ImmX ( RAX, 0x80000000 );
					
				if ( i.Fd )
				{
					// set 0x00000000 as result
					ret = e->MovMemReg32 ( ( &VU0::_VU0->vf [ i.Fd ].sw0 ) + FdComponent, RAX );
				}
			}
			else
			{
				e->MovRegMem32 ( RAX, ( &VU0::_VU0->vf [ i.Fs ].sw0 ) + FsComponent );
				
				e->MovReg32ImmX ( RCX, 0x0010 << ( FdComponent ^ 3 ) );
				e->MovReg32ImmX ( RDX, 0x0001 << ( FdComponent ^ 3 ) );
				e->OrRegReg32 ( RAX, RAX );
				e->CmovNSRegReg32 ( RCX, 11 );
				
				e->TestReg32ImmX ( RAX, 0x7f800000 );
				e->CmovERegReg32 ( RCX, RDX );
				e->MovRegReg32 ( RDX, RAX );
				e->CmovERegReg32 ( RAX, 11 );
				
				// preserve sign of zero ??
				e->AndReg32ImmX ( RDX, 0x80000000 );
				e->OrRegReg32 ( RAX, RDX );
				
				// set MAC flag
				e->OrRegReg32 ( 10, RCX );
				
				if ( i.Fd )
				{
					// set result
					ret = e->MovMemReg32 ( ( &VU0::_VU0->vf [ i.Fd ].sw0 ) + FdComponent, RAX );
				}
			}
		}
		else
		{
			// flush ps2 float to zero
			if ( pFt )
			{
				e->MovRegMem32 ( RAX, (int32_t*) pFt );
			}
			else
			{
				e->MovRegMem32 ( RAX, ( &VU0::_VU0->vf [ i.Ft ].sw0 ) + FtComponent );
			}
			//e->XorRegReg32 ( 11, 11 );
			e->Cdq ();
			e->MovReg64ImmX ( RCX, 896ULL << 23 );
			e->AndReg32ImmX ( RAX, 0x7fffffff );
			//e->AddRegReg64 ( RCX, RAX );
			e->TestReg32ImmX ( RAX, 0x7f800000 );
			e->LeaRegRegReg64 ( RAX, RAX, RCX );
			e->CmovERegReg64 ( RAX, 11 );
			//e->ShrRegImm32 ( 8, 31 );
			//e->ShlRegImm64 ( RDX, 63 );
			e->ShlRegImm64 ( RAX, 29 );
			//e->OrRegReg64 ( RAX, RDX );
			e->movq_to_sse ( RCX, RAX );

			
			e->MovRegMem32 ( RAX, ( &VU0::_VU0->vf [ i.Fs ].sw0 ) + FsComponent );
			e->XorRegReg32 ( RDX, RAX );
			//e->Cdq ();
			//e->MovRegImm64 ( RAX, 896 << 23 );
			e->AndReg32ImmX ( RAX, 0x7fffffff );
			//e->MovRegReg64 ( RCX, RAX );
			e->TestReg32ImmX ( RAX, 0x7f800000 );
			e->LeaRegRegReg64 ( RAX, RAX, RCX );
			e->CmovERegReg64 ( RAX, 11 );
			//e->ShrRegImm32 ( 8, 31 );
			//e->ShlRegImm64 ( RDX, 63 );
			e->ShlRegImm64 ( RAX, 29 );
			//e->OrRegReg64 ( RAX, RDX );
			e->movq_to_sse ( RAX, RAX );
			
			// debug
			//e->MovMemReg64 ( &ll1, RAX );
			
			// multiply
			e->mulsd ( RAX, RCX );
			e->movq_from_sse ( RAX, RAX );
			
			// debug
			//e->MovMemReg64 ( &ll2, RAX );

			
			// set sign
			e->AndReg32ImmX ( RDX, 0x80000000 );

			// set sign MAC flag
			
			// put MAC flag in R8
			
			// sign flag
			e->MovReg32ImmX ( 8, 0x0010 << ( FdComponent ^ 3 ) );
			
			// clear sign flags if not sign
			e->CmovNSRegReg32 ( 8, 11 );
			
			// shift back down without sign
			//e->ShlRegImm64 ( RAX, 1 );
			e->ShrRegImm64 ( RAX, 29 );
			e->CmovERegReg64 ( RCX, RAX );
			
			
			// also set zero flag if zero (which here, would also clear the sign flag ??)
			e->MovRegReg32 ( 9, 0x0001 << ( FdComponent ^ 3 ) );
			e->CmovERegReg32 ( 8, 9 );

			// save mantissa
			e->MovRegReg64 ( 9, RAX );
			e->AndReg32ImmX ( 9, 0x007fffff );
			
			
			
			e->AndReg64ImmX ( RAX, ~0x007fffff );
			//e->CmpReg32ImmX ( RAX, 0x00800000 );
			e->SubRegReg64 ( RAX, RCX );
			e->LeaRegRegReg32 ( RAX, RAX, 9 );
			
			// underflow+zero MAC flag
			e->MovReg32ImmX ( 9, 0x0101 << ( FdComponent ^ 3 ) );
			e->CmovGRegReg32 ( 9, 11 );
			
			// set result to zero on underflow
			e->CmovLERegReg32 ( RAX, 11 );
			//e->CmovGRegReg32 ( 9, 11 );
			//e->CmovLERegReg32 ( 10, 11 );
			//e->CmovBRegReg32 ( RAX, 11 );
			
			
			// combine sign/zero/underflow MAC flags
			e->OrRegReg32 ( 8, 9 );
			
			// check for overflow
			e->MovReg32ImmX ( RCX, 0x7fffffff );
			e->CmpRegReg32 ( RAX, RCX );
			e->CmovARegReg32 ( RAX, RCX );
			e->LeaRegRegReg32 ( RAX, RAX, RDX );
			//e->MovReg32ImmX ( RDX, 0x208 );		//0x8010 );
			//e->CmovBERegReg32 ( RDX, 8 );


			// set overflow MAC flag
			e->MovReg32ImmX ( 9, 0x1000 << ( FdComponent ^ 3 ) );
			e->CmovBERegReg32 ( 9, 11 );
			
			// combine all MAC flags
			e->OrRegReg32 ( 8, 9 );


			// set MAC flags
			//ret = e->OrMemReg32 ( &VU0::_VU0->vi [ VU::REG_MACFLAG ].s, 8 );
			e->OrRegReg32 ( 10, 8 );
			
			// set status flags
			//e->OrMemReg32 ( &VU0::_VU0->vi [ VU::REG_STATUSFLAG ].s, RDX );
			
			// set result
			if ( pFd )
			{
				ret = e->MovMemReg32 ( (int32_t*) pFd, RAX );
			}
			else
			{
				// don't write to the zero register
				if ( i.Fd )
				{
					// set result
					ret = e->MovMemReg32 ( ( &VU0::_VU0->vf [ i.Fd ].sw0 ) + FdComponent, RAX );
				}
			}
		}
	}
	
	
	if ( FdComponent == 3 )
	{
		// set MAC flags
		e->MovMemReg32 ( &VU0::_VU0->vi [ VU::REG_MACFLAG ].s, 10 );
		
		// MAC flag is in R10
		
		// zero flag
		e->MovReg32ImmX ( RAX, 0x41 );
		e->TestReg32ImmX ( 10, 0x000f );
		e->CmovERegReg32 ( RAX, 11 );
		
		// sign flag
		e->MovReg32ImmX ( RCX, 0x82 );
		e->TestReg32ImmX ( 10, 0x00f0 );
		e->CmovERegReg32 ( RCX, 11 );
		e->OrRegReg32 ( RAX, RCX );

		// underflow flag
		e->MovReg32ImmX ( RCX, 0x104 );
		e->TestReg32ImmX ( 10, 0x0f00 );
		e->CmovERegReg32 ( RCX, 11 );
		e->OrRegReg32 ( RAX, RCX );
		
		// overflow flag
		e->MovReg32ImmX ( RCX, 0x208 );
		e->TestReg32ImmX ( 10, 0xf000 );
		e->CmovERegReg32 ( RCX, 11 );
		e->OrRegReg32 ( RAX, RCX );
		
		// set status flag
		ret = e->OrMemReg32 ( &VU0::_VU0->vi [ VU::REG_STATUSFLAG ].s, RAX );
	}
	
	return ret;
}




int32_t R5900::Recompiler::Generate_VMADD ( R5900::Instruction::Format i, u32 Address, u32 FdComponent, u32 FsComponent, u32 FtComponent, u32 *pFd, u32 *pFt )
{
	int32_t ret;
	
	ret = 1;
	
	// only clear non-sticky bits in status flag the first go around
	// also clear MAC flag (set to zero for components that are not calculated)
	if ( !FdComponent )
	{
		// clear bits 14 and 15 in the flag register first
		e->AndMem32ImmX ( &VU0::_VU0->vi [ VU::REG_STATUSFLAG ].s, ~0x00000030 );
		
		// clear MAC flags
		//ret = e->MovMemImm32 ( &VU0::_VU0->vi [ VU::REG_MACFLAG ].s, 0 );
		
		// R10 will be MAC flag
		e->XorRegReg32 ( 10, 10 );
		
		// R11 will be zero register
		e->XorRegReg32 ( 11, 11 );
	}
	
	// check if that component is set to output
	if ( i.Value & ( 1 << ( ( FdComponent ^ 3 ) + 21 ) ) )
	{
			// flush ps2 float to zero
			if ( pFt )
			{
				e->MovRegMem32 ( RAX, (int32_t*) pFt );
			}
			else
			{
				e->MovRegMem32 ( RAX, ( &VU0::_VU0->vf [ i.Ft ].sw0 ) + FtComponent );
			}
			// flush ps2 float to zero
			//e->MovRegMem32 ( RAX, &r->CPR1 [ i.Ft ].s );
			//e->XorRegReg32 ( 11, 11 );
			e->MovRegReg32 ( 9, RAX );
			//e->Cdq ();
			e->MovReg64ImmX ( RCX, 896ULL << 23 );
			e->AndReg32ImmX ( RAX, 0x7fffffff );
			e->LeaRegRegReg64 ( RDX, RAX, RCX );
			//e->AddRegReg64 ( RCX, RAX );
			e->AndReg32ImmX ( RAX, 0x7f800000 );
			e->CmovNERegReg64 ( RAX, RDX );
			//e->ShrRegImm32 ( 8, 31 );
			//e->ShlRegImm64 ( RDX, 63 );
			e->ShlRegImm64 ( RAX, 29 );
			//e->OrRegReg64 ( RAX, RDX );
			e->movq_to_sse ( RCX, RAX );

			
			e->MovRegMem32 ( RAX, ( &VU0::_VU0->vf [ i.Fs ].sw0 ) + FsComponent );
			e->XorRegReg32 ( 9, RAX );
			//e->Cdq ();
			//e->MovRegImm64 ( RAX, 896 << 23 );
			e->AndReg32ImmX ( RAX, 0x7fffffff );
			e->LeaRegRegReg64 ( RDX, RAX, RCX );
			//e->MovRegReg64 ( RCX, RAX );
			e->AndReg32ImmX ( RAX, 0x7f800000 );
			e->CmovNERegReg64 ( RAX, RDX );
			//e->ShrRegImm32 ( 8, 31 );
			//e->ShlRegImm64 ( RDX, 63 );
			e->ShlRegImm64 ( RAX, 29 );
			//e->OrRegReg64 ( RAX, RDX );
			e->movq_to_sse ( RAX, RAX );
			
			
			// get sign
			e->AndReg32ImmX ( 9, 0x80000000 );
			
			// multiply
			e->mulsd ( RAX, RCX );
			e->movq_from_sse ( RAX, RAX );
			
			
			// shift back down without sign
			//e->ShlRegImm64 ( RAX, 1 );
			e->ShrRegImm64 ( RAX, 29 );
			e->CmovERegReg64 ( RCX, RAX );

			
			// if zero or underflow, then clear result
			e->MovReg32ImmX ( RDX, 0x0008 );

			// save mantissa
			e->MovRegReg64 ( 10, RAX );
			e->AndReg32ImmX ( 10, 0x007fffff );

			
			e->AndReg64ImmX ( RAX, ~0x007fffff );
			//e->CmpReg32ImmX ( RAX, 0x00800000 );
			e->SubRegReg64 ( RAX, RCX );
			e->CmovLERegReg32 ( RAX, 11 );
			e->CmovLERegReg32 ( 10, 11 );
			e->CmovGERegReg32 ( RDX, 11 );
			//e->CmovBRegReg32 ( RAX, 11 );

			
			// get ACC
			e->MovRegMem32 ( 8, ( &VU0::_VU0->dACC[ 0 ].l ) + FdComponent );
			
			
			// running out of registers.. combine sign and mantissa
			e->OrRegReg32 ( 9, 10 );

			
			
			
			// if multiply underflow, then go ahead and set result to ACC here
			e->OrRegReg32 ( RDX, RDX );
			e->CmovNERegReg32 ( 9, 8 );
			e->CmovNERegReg32 ( RAX, 11 );
			
			
			
			
			// get multi-use constant for later
			e->MovReg32ImmX ( RCX, 0x7fffffff );
			
			// test for ACC overflow
			e->MovRegReg32 ( 10, 8 );
			e->AndRegReg32 ( 10, RCX );
			e->CmpRegReg32 ( 10, RCX );
			
			
			// if ACC overflow, then set result to acc and set overflow
			//e->CmovERegReg32 ( RAX, RCX );
			e->CmovERegReg32 ( RAX, 8 );
			e->MovReg32ImmX ( 10, 0x8010 );
			e->CmovNERegReg32 ( 10, 11 );
			e->OrRegReg32 ( RDX, 10 );
			
			
			// test for multiply overflow
			//e->CmpRegReg32 ( RAX, RCX );
			e->OrRegReg32 ( RAX, RAX );
			
			// if multiply overflow, then set result to +/-max and set flags
			e->CmovSRegReg32 ( RAX, RCX );
			e->MovReg32ImmX ( RCX, 0x8010 );
			e->CmovNSRegReg32 ( RCX, 11 );
			
			
			// set sign/mantissa
			e->OrRegReg32 ( RAX, 9 );
			
			// or in the flag from the last overflow check
			e->OrRegReg32 ( RCX, RDX );
			
			
			// done
			e->Jmp_NE ( 0, 1 );
			//e->Jmp8_NE ( 0, 1 );
			
			
			
			
			// *** perform the ADD operation *** //
			
			
			// flush ps2 float to zero
			//e->MovRegMem32 ( RAX, &b );
			e->Cdq();
			e->AndReg32ImmX ( RAX, 0x7fffffff );
			e->MovRegReg32 ( RCX, RAX );
			e->AndReg32ImmX ( RAX, 0x7f800000 );
			e->MovRegReg32 ( 9, RAX );
			e->CmovERegReg32 ( RCX, RAX );
			e->ShlRegImm64 ( RDX, 63 );
			e->ShlRegImm64 ( RCX, 29 );
			e->OrRegReg64 ( RCX, RDX );

			
			//e->MovRegMem32 ( RAX, &a );
			e->MovRegReg32 ( RAX, 8 );
			e->Cdq();
			e->AndReg32ImmX ( RAX, 0x7fffffff );
			e->MovRegReg32 ( 8, RAX );
			e->AndReg32ImmX ( 8, 0x7f800000 );
			//e->MovRegReg32 ( 8, RAX );
			e->CmovERegReg32 ( RAX, 8 );
			e->ShlRegImm64 ( RDX, 63 );
			e->ShlRegImm64 ( RAX, 29 );
			e->OrRegReg64 ( RAX, RDX );
			
			// check if shift is more than 24, then zero
			//e->XorRegReg32 ( 11, 11 );
			e->SubRegReg32 ( 8, 9 );
			e->CmpRegImm32 ( 8, 24 << 23 );
			
			// if greater than +24, then R9 has higher magnitude, so zero RAX
			e->CmovGERegReg64 ( RCX, 11 );
			
			// if less than -24, then R11 has higher magnitude, so zero R8
			e->CmpReg32ImmX ( 8, -24 << 23 );
			e->CmovLERegReg64 ( RAX, 11 );
			
			// move the registers now to floating point unit
			e->movq_to_sse ( RAX, RAX );
			e->movq_to_sse ( RCX, RCX );
			
			
			// add
			e->addsd ( RAX, RCX );
			e->movq_from_sse ( RAX, RAX );
			
			// save sign
			e->Cqo();
			
			// shift back down without sign
			e->ShrRegImm64 ( RAX, 29 );
			
			
			// if zero or underflow, then clear result
			e->MovReg32ImmX ( RCX, 0x4008 );
			e->OrRegReg32 ( RAX, RAX );
			e->CmovERegReg32 ( RCX, RAX );
			e->CmpReg32ImmX ( RAX, 0x00800000 );
			e->CmovAERegReg32 ( RCX, 11 );
			e->CmovBRegReg32 ( RAX, 11 );
			
			// check for overflow
			e->MovReg32ImmX ( 8, 0x7fffffff );
			e->MovReg32ImmX ( 9, 0x8010 );
			e->CmpRegReg32 ( RAX, 8 );
			e->CmovARegReg32 ( RAX, 8 );
			e->CmovARegReg32 ( RCX, 9 );
			
			// set sign
			e->ShlRegImm32 ( RDX, 31 );
			e->OrRegReg32 ( RAX, RDX );

			
			// finish here
			e->SetJmpTarget ( 1 );
			//e->SetJmpTarget8 ( 1 );

			
			// set flags
			e->OrMemReg32 ( &r->CPC1 [ 31 ], RCX );
			
			
			// set result
			//ret = e->MovMemReg32 ( &r->CPR1 [ i.Fd ].s, RAX );
			
			// set result
			if ( pFd )
			{
				ret = e->MovMemReg32 ( (int32_t*) pFd, RAX );
			}
			else
			{
				// don't write to the zero register
				if ( i.Fd )
				{
					// set result
					ret = e->MovMemReg32 ( ( &VU0::_VU0->vf [ i.Fd ].sw0 ) + FdComponent, RAX );
				}
			}
			
	}
	
	
	if ( FdComponent == 3 )
	{
		// set MAC flags
		e->MovMemReg32 ( &VU0::_VU0->vi [ VU::REG_MACFLAG ].s, 10 );
		
		// MAC flag is in R10
		
		// zero flag
		e->MovReg32ImmX ( RAX, 0x41 );
		e->TestReg32ImmX ( 10, 0x000f );
		e->CmovERegReg32 ( RAX, 11 );
		
		// sign flag
		e->MovReg32ImmX ( RCX, 0x82 );
		e->TestReg32ImmX ( 10, 0x00f0 );
		e->CmovERegReg32 ( RCX, 11 );
		e->OrRegReg32 ( RAX, RCX );

		// underflow flag
		e->MovReg32ImmX ( RCX, 0x104 );
		e->TestReg32ImmX ( 10, 0x0f00 );
		e->CmovERegReg32 ( RCX, 11 );
		e->OrRegReg32 ( RAX, RCX );
		
		// overflow flag
		e->MovReg32ImmX ( RCX, 0x208 );
		e->TestReg32ImmX ( 10, 0xf000 );
		e->CmovERegReg32 ( RCX, 11 );
		e->OrRegReg32 ( RAX, RCX );
		
		// set status flag
		ret = e->OrMemReg32 ( &VU0::_VU0->vi [ VU::REG_STATUSFLAG ].s, RAX );
	}
	
	return ret;
}






// VABS //

int32_t R5900::Recompiler::VABS ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "VABS";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VABS;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
			
#ifdef USE_NEW_VABS_CODE
		case 1:
			
			Generate_VPrefix ( Address );
			ret = Generate_VABSp ( i );
			break;
#endif
			
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}


// VADD //

int32_t R5900::Recompiler::VADD ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "VADD";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VADD;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VADD_CODE
		case 1:

			Generate_VPrefix ( Address );
			ret = Generate_VADDp ( 0, i );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::VADDi ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "VADDi";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VADDi;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VADDi_CODE
		case 1:

			Generate_VPrefix ( Address );
			ret = Generate_VADDp ( 0, i, 0, NULL, &VU0::_VU0->vi [ VU::REG_I ].u );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::VADDq ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "VADDq";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VADDq;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VADDq_CODE
		case 1:

			Generate_VPrefix ( Address );
			ret = Generate_VADDp ( 0, i, 0, NULL, &VU0::_VU0->vi [ VU::REG_Q ].u );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::VADDBCX ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "VADDBCX";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VADDBCX;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VADDX_CODE
		case 1:

			Generate_VPrefix ( Address );
			ret = Generate_VADDp(0, i, 0, NULL, &VU0::_VU0->vf[i.Ft].vuw[i.bc]);
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::VADDBCY ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "VADDBCY";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VADDBCY;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VADDY_CODE
		case 1:

			Generate_VPrefix ( Address );
			ret = Generate_VADDp(0, i, 0, NULL, &VU0::_VU0->vf[i.Ft].vuw[i.bc]);
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::VADDBCZ ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "VADDBCZ";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VADDBCZ;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VADDZ_CODE
		case 1:

			Generate_VPrefix ( Address );
			ret = Generate_VADDp(0, i, 0, NULL, &VU0::_VU0->vf[i.Ft].vuw[i.bc]);
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::VADDBCW ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "VADDBCW";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VADDBCW;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VADDW_CODE
		case 1:

			Generate_VPrefix ( Address );
			ret = Generate_VADDp(0, i, 0, NULL, &VU0::_VU0->vf[i.Ft].vuw[i.bc]);
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}


// VADDA //

int32_t R5900::Recompiler::VADDA ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "VADDA";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VADDA;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VADDA_CODE
		case 1:

			Generate_VPrefix ( Address );
			ret = Generate_VADDp ( 0, i, -1, &VU0::_VU0->dACC[ 0 ].l );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::VADDAi ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "VADDAi";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VADDAi;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VADDAi_CODE
		case 1:

			Generate_VPrefix ( Address );
			ret = Generate_VADDp ( 0, i, 0, &VU0::_VU0->dACC[ 0 ].l, &VU0::_VU0->vi [ VU::REG_I ].u );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::VADDAq ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "VADDAq";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VADDAq;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VADDAq_CODE
		case 1:

			Generate_VPrefix ( Address );
			ret = Generate_VADDp ( 0, i, 0, &VU0::_VU0->dACC[ 0 ].l, &VU0::_VU0->vi [ VU::REG_Q ].u );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::VADDABCX ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "VADDABCX";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VADDABCX;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VADDAX_CODE
		case 1:

			Generate_VPrefix ( Address );
			ret = Generate_VADDp(0, i, 0, &VU0::_VU0->dACC[0].l, &VU0::_VU0->vf[i.Ft].vuw[i.bc]);
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::VADDABCY ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "VADDABCY";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VADDABCY;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VADDAY_CODE
		case 1:

			Generate_VPrefix ( Address );
			ret = Generate_VADDp(0, i, 0, &VU0::_VU0->dACC[0].l, &VU0::_VU0->vf[i.Ft].vuw[i.bc]);
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::VADDABCZ ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "VADDABCZ";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VADDABCZ;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VADDAZ_CODE
		case 1:

			Generate_VPrefix ( Address );
			ret = Generate_VADDp(0, i, 0, &VU0::_VU0->dACC[0].l, &VU0::_VU0->vf[i.Ft].vuw[i.bc]);
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::VADDABCW ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "VADDABCW";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VADDABCW;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VADDAW_CODE
		case 1:

			Generate_VPrefix ( Address );
			ret = Generate_VADDp(0, i, 0, &VU0::_VU0->dACC[0].l, &VU0::_VU0->vf[i.Ft].vuw[i.bc]);
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}





// VSUB //

int32_t R5900::Recompiler::VSUB ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "VSUB";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VSUB;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VSUB_CODE
		case 1:

			Generate_VPrefix ( Address );
			ret = Generate_VADDp ( 1, i );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::VSUBi ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "VSUBi";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VSUBi;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VSUBi_CODE
		case 1:

			Generate_VPrefix ( Address );
			ret = Generate_VADDp ( 1, i, 0, NULL, &VU0::_VU0->vi [ VU::REG_I ].u );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::VSUBq ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "VSUBq";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VSUBq;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VSUBq_CODE
		case 1:

			Generate_VPrefix ( Address );
			ret = Generate_VADDp ( 1, i, 0, NULL, &VU0::_VU0->vi [ VU::REG_Q ].u );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::VSUBBCX ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "VSUBBCX";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VSUBBCX;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VSUBX_CODE
		case 1:

			Generate_VPrefix ( Address );
			ret = Generate_VADDp(1, i, 0, NULL, &VU0::_VU0->vf[i.Ft].vuw[i.bc]);
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::VSUBBCY ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "VSUBBCY";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VSUBBCY;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VSUBY_CODE
		case 1:

			Generate_VPrefix ( Address );
			ret = Generate_VADDp(1, i, 0, NULL, &VU0::_VU0->vf[i.Ft].vuw[i.bc]);
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::VSUBBCZ ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "VSUBBCZ";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VSUBBCZ;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VSUBZ_CODE
		case 1:

			Generate_VPrefix ( Address );
			ret = Generate_VADDp(1, i, 0, NULL, &VU0::_VU0->vf[i.Ft].vuw[i.bc]);
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::VSUBBCW ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "VSUBBCW";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VSUBBCW;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VSUBW_CODE
		case 1:

			Generate_VPrefix ( Address );
			ret = Generate_VADDp(1, i, 0, NULL, &VU0::_VU0->vf[i.Ft].vuw[i.bc]);
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}




// VMADD //

int32_t R5900::Recompiler::VMADD ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "VMADD";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VMADD;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
#ifdef USE_NEW_VMADD_CODE
		case 1:

			Generate_VPrefix ( Address );
			ret = Generate_VMADDp ( 0, i );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::VMADDi ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "VMADDi";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VMADDi;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VMADDi_CODE
		case 1:

			Generate_VPrefix ( Address );
			ret = Generate_VMADDp ( 0, i, 0, NULL, &VU0::_VU0->vi [ VU::REG_I ].u );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::VMADDq ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "VMADDq";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VMADDq;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VMADDq_CODE
		case 1:

			Generate_VPrefix ( Address );
			ret = Generate_VMADDp ( 0, i, 0, NULL, &VU0::_VU0->vi [ VU::REG_Q ].u );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::VMADDBCX ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "VMADDBCX";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VMADDBCX;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VMADDX_CODE
		case 1:

			Generate_VPrefix ( Address );
			ret = Generate_VMADDp(0, i, 0, NULL, &VU0::_VU0->vf[i.Ft].vuw[i.bc]);
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::VMADDBCY ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "VMADDBCY";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VMADDBCY;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
#ifdef USE_NEW_VMADDY_CODE
		case 1:

			Generate_VPrefix ( Address );
			ret = Generate_VMADDp(0, i, 0, NULL, &VU0::_VU0->vf[i.Ft].vuw[i.bc]);
			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::VMADDBCZ ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "VMADDBCZ";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VMADDBCZ;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VMADDZ_CODE
		case 1:

			Generate_VPrefix ( Address );
			ret = Generate_VMADDp(0, i, 0, NULL, &VU0::_VU0->vf[i.Ft].vuw[i.bc]);
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::VMADDBCW ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "VMADDBCW";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VMADDBCW;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VMADDW_CODE
		case 1:

			Generate_VPrefix ( Address );
			ret = Generate_VMADDp(0, i, 0, NULL, &VU0::_VU0->vf[i.Ft].vuw[i.bc]);
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}




// VMSUB //

int32_t R5900::Recompiler::VMSUB ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "VMSUB";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VMSUB;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VMSUB_CODE
		case 1:

			Generate_VPrefix ( Address );
			ret = Generate_VMADDp ( 1, i );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::VMSUBi ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "VMSUBi";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VMSUBi;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VMSUBi_CODE
		case 1:

			Generate_VPrefix ( Address );
			ret = Generate_VMADDp ( 1, i, 0, NULL, &VU0::_VU0->vi [ VU::REG_I ].u );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::VMSUBq ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "VMSUBq";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VMSUBq;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VMSUBq_CODE
		case 1:

			Generate_VPrefix ( Address );
			ret = Generate_VMADDp ( 1, i, 0, NULL, &VU0::_VU0->vi [ VU::REG_Q ].u );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::VMSUBBCX ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "VMSUBBCX";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VMSUBBCX;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VMSUBX_CODE
		case 1:

			Generate_VPrefix ( Address );
			ret = Generate_VMADDp(1, i, 0, NULL, &VU0::_VU0->vf[i.Ft].vuw[i.bc]);
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::VMSUBBCY ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "VMSUBBCY";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VMSUBBCY;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VMSUBY_CODE
		case 1:

			Generate_VPrefix ( Address );
			ret = Generate_VMADDp(1, i, 0, NULL, &VU0::_VU0->vf[i.Ft].vuw[i.bc]);
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::VMSUBBCZ ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "VMSUBBCZ";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VMSUBBCZ;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VMSUBZ_CODE
		case 1:

			Generate_VPrefix ( Address );
			ret = Generate_VMADDp(1, i, 0, NULL, &VU0::_VU0->vf[i.Ft].vuw[i.bc]);
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::VMSUBBCW ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "VMSUBBCW";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VMSUBBCW;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VMSUBW_CODE
		case 1:

			Generate_VPrefix ( Address );
			ret = Generate_VMADDp(1, i, 0, NULL, &VU0::_VU0->vf[i.Ft].vuw[i.bc]);
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}




// VMAX //

int32_t R5900::Recompiler::VMAX ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "VMAX";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VMAX;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VMAX_CODE
		case 1:
			Generate_VPrefix ( Address );
			ret = Generate_VMAXp ( i );
			break;
#endif
			
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::VMAXi ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "VMAXi";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VMAXi;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

			
#ifdef USE_NEW_VMAX_CODE
		case 1:
			Generate_VPrefix ( Address );
			ret = Generate_VMAXp ( i, &VU0::_VU0->vi [ VU::REG_I ].u );
			break;
#endif

			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::VMAXBCX ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "VMAXBCX";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VMAXBCX;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;


#ifdef USE_NEW_VMAX_CODE
		case 1:
			Generate_VPrefix ( Address );
			ret = Generate_VMAXp ( i, &VU0::_VU0->vf [ i.Ft ].uw0 );
			break;
#endif

			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::VMAXBCY ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "VMAXBCY";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VMAXBCY;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
#ifdef USE_NEW_VMAX_CODE
		case 1:
			Generate_VPrefix ( Address );
			ret = Generate_VMAXp ( i, &VU0::_VU0->vf [ i.Ft ].uw1 );
			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::VMAXBCZ ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "VMAXBCZ";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VMAXBCZ;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
#ifdef USE_NEW_VMAX_CODE
		case 1:
			Generate_VPrefix ( Address );
			ret = Generate_VMAXp ( i, &VU0::_VU0->vf [ i.Ft ].uw2 );
			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::VMAXBCW ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "VMAXBCW";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VMAXBCW;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
#ifdef USE_NEW_VMAX_CODE
		case 1:
			Generate_VPrefix ( Address );
			ret = Generate_VMAXp ( i, &VU0::_VU0->vf [ i.Ft ].uw3 );
			break;
#endif
			
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}




// VMINI //

int32_t R5900::Recompiler::VMINI ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "VMINI";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VMINI;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
#ifdef USE_NEW_VMIN_CODE
		case 1:
			Generate_VPrefix ( Address );
			ret = Generate_VMINp ( i );
			break;
#endif
			
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::VMINIi ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "VMINIi";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VMINIi;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
#ifdef USE_NEW_VMIN_CODE
		case 1:
			Generate_VPrefix ( Address );
			ret = Generate_VMINp ( i, &VU0::_VU0->vi [ VU::REG_I ].u );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::VMINIBCX ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "VMINIBCX";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VMINIBCX;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VMIN_CODE
		case 1:
			Generate_VPrefix ( Address );
			ret = Generate_VMINp ( i, &VU0::_VU0->vf [ i.Ft ].uw0 );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::VMINIBCY ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "VMINIBCY";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VMINIBCY;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VMIN_CODE
		case 1:
			Generate_VPrefix ( Address );
			ret = Generate_VMINp ( i, &VU0::_VU0->vf [ i.Ft ].uw1 );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::VMINIBCZ ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "VMINIBCZ";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VMINIBCZ;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VMIN_CODE
		case 1:
			Generate_VPrefix ( Address );
			ret = Generate_VMINp ( i, &VU0::_VU0->vf [ i.Ft ].uw2 );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::VMINIBCW ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "VMINIBCW";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VMINIBCW;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
#ifdef USE_NEW_VMIN_CODE
		case 1:
			Generate_VPrefix ( Address );
			ret = Generate_VMINp ( i, &VU0::_VU0->vf [ i.Ft ].uw3 );
			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}




// VMUL //

int32_t R5900::Recompiler::VMUL ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "VMUL";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VMUL;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VMUL_CODE
		case 1:

			Generate_VPrefix ( Address );
			ret = Generate_VMULp ( i );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::VMULi ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "VMULi";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VMULi;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VMULi_CODE
		case 1:

			Generate_VPrefix ( Address );
			ret = Generate_VMULp ( i, 0, NULL, &VU0::_VU0->vi [ VU::REG_I ].u );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::VMULq ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "VMULq";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VMULq;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VMULq_CODE
		case 1:

			Generate_VPrefix ( Address );
			ret = Generate_VMULp ( i, 0, NULL, &VU0::_VU0->vi [ VU::REG_Q ].u );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::VMULBCX ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "VMULBCX";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VMULBCX;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VMULX_CODE
		case 1:

			Generate_VPrefix ( Address );
			ret = Generate_VMULp(i, 0, NULL, &VU0::_VU0->vf[i.Ft].vuw[i.bc]);
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::VMULBCY ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "VMULBCY";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VMULBCY;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VMULY_CODE
		case 1:

			Generate_VPrefix ( Address );
			ret = Generate_VMULp(i, 0, NULL, &VU0::_VU0->vf[i.Ft].vuw[i.bc]);
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::VMULBCZ ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "VMULBCZ";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VMULBCZ;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VMULZ_CODE
		case 1:

			Generate_VPrefix ( Address );
			ret = Generate_VMULp(i, 0, NULL, &VU0::_VU0->vf[i.Ft].vuw[i.bc]);
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::VMULBCW ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "VMULBCW";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VMULBCW;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VMULW_CODE
		case 1:

			Generate_VPrefix ( Address );
			ret = Generate_VMULp(i, 0, NULL, &VU0::_VU0->vf[i.Ft].vuw[i.bc]);
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}






int32_t R5900::Recompiler::VOPMSUB ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "VOPMSUB";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VOPMSUB;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VOPMSUB_CODE
		case 1:

			Generate_VPrefix ( Address );
			ret = Generate_VMADDp ( 1, i, 0x84, NULL, NULL, 0x60 );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::VIADD ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "VIADD";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VIADD;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
#ifdef USE_NEW_VIADD_CODE
		case 1:
			Generate_VPrefix ( Address );
			if ( i.id & 0xf )
			{
				if ( ( !( i.is & 0xf ) ) && ( !( i.it & 0xf ) ) )
				{
					e->MovMemImm16 ( (s16*) &VU0::_VU0->vi [ i.id & 0xf ].s, 0 );
				}
				else if ( ( !( i.is & 0xf ) ) || ( !( i.it & 0xf ) ) )
				{
					e->MovRegMem16 ( RAX, (s16*) &VU0::_VU0->vi [ ( i.is & 0xf ) + ( i.it & 0xf ) ].s );
					e->MovMemReg16 ( (s16*) &VU0::_VU0->vi [ i.id & 0xf ].s, RAX );
				}
				else if ( ( i.id & 0xf ) == ( i.is & 0xf ) )
				{
					e->MovRegMem16 ( RAX, (s16*) &VU0::_VU0->vi [ i.it & 0xf ].s );
					e->AddMemReg16 ( (s16*) &VU0::_VU0->vi [ i.id & 0xf ].s, RAX );
				}
				else if ( ( i.id & 0xf ) == ( i.it & 0xf ) )
				{
					e->MovRegMem16 ( RAX, (s16*) &VU0::_VU0->vi [ i.is & 0xf ].s );
					e->AddMemReg16 ( (s16*) &VU0::_VU0->vi [ i.id & 0xf ].s, RAX );
				}
				else if ( ( i.is & 0xf ) == ( i.it & 0xf ) )
				{
					e->MovRegMem16 ( RAX, (s16*) &VU0::_VU0->vi [ i.is & 0xf ].s );
					e->AddRegReg16 ( RAX, RAX );
					
					e->MovMemReg16 ( (s16*) &VU0::_VU0->vi [ i.id & 0xf ].s, RAX );
				}
				else
				{
					e->MovRegMem16 ( RAX, (s16*) &VU0::_VU0->vi [ i.is & 0xf ].s );
					e->AddRegMem16 ( RAX, (s16*) &VU0::_VU0->vi [ i.it & 0xf ].s );
					e->MovMemReg16 ( (s16*) &VU0::_VU0->vi [ i.id & 0xf ].s, RAX );
				}
			}
			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::VISUB ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "VISUB";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VISUB;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VISUB_CODE
		case 1:
			Generate_VPrefix ( Address );
			if ( i.id & 0xf )
			{
				if ( ( !( i.is & 0xf ) ) && ( !( i.it & 0xf ) ) )
				{
					e->MovMemImm16 ( (s16*) &VU0::_VU0->vi [ i.id & 0xf ].s, 0 );
				}
				else if ( ( i.is & 0xf ) == ( i.it & 0xf ) )
				{
					e->MovMemImm16 ( (s16*) &VU0::_VU0->vi [ i.id & 0xf ].s, 0 );
				}
				else if ( !( i.it & 0xf ) )
				{
					e->MovRegMem16 ( RAX, (s16*) &VU0::_VU0->vi [ i.is & 0xf ].s );
					e->MovMemReg16 ( (s16*) &VU0::_VU0->vi [ i.id & 0xf ].s, RAX );
				}
				else if ( !( i.is & 0xf ) )
				{
					e->MovRegMem16 ( RAX, (s16*) &VU0::_VU0->vi [ i.it & 0xf ].s );
					e->NegReg16 ( RAX );
					e->MovMemReg16 ( (s16*) &VU0::_VU0->vi [ i.id & 0xf ].s, RAX );
				}
				else if ( ( i.id & 0xf ) == ( i.is & 0xf ) )
				{
					e->MovRegMem16 ( RAX, (s16*) &VU0::_VU0->vi [ i.it & 0xf ].s );
					e->SubMemReg16 ( (s16*) &VU0::_VU0->vi [ i.id & 0xf ].s, RAX );
				}
				else
				{
					e->MovRegMem16 ( RAX, (s16*) &VU0::_VU0->vi [ i.is & 0xf ].s );
					e->SubRegMem16 ( RAX, (s16*) &VU0::_VU0->vi [ i.it & 0xf ].s );
					
					e->MovMemReg16 ( (s16*) &VU0::_VU0->vi [ i.id & 0xf ].s, RAX );
				}
			}
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::VIADDI ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "VIADDI";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VIADDI;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
	
#ifdef USE_NEW_VIADDI_CODE
		case 1:
			Generate_VPrefix ( Address );
			if ( i.it & 0xf )
			{
				if ( !( i.is & 0xf ) )
				{
					e->MovMemImm16 ( (s16*) &VU0::_VU0->vi [ i.it & 0xf ].s, ( (s16) i.Imm5 ) );
				}
				else if ( i.it == i.is )
				{
					e->AddMemImm16 ( (s16*) &VU0::_VU0->vi [ i.it & 0xf ].s, ( (s16) i.Imm5 ) );
				}
				else
				{
					e->MovRegMem16 ( RAX, (s16*) &VU0::_VU0->vi [ i.is & 0xf ].s );
					e->AddRegImm16 ( RAX, ( (s16) i.Imm5 ) );
					e->MovMemReg16 ( (s16*) &VU0::_VU0->vi [ i.it & 0xf ].s, RAX );
				}
			}
			break;
#endif
	
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::VIAND ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "VIAND";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VIAND;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VIAND_CODE
		case 1:
			Generate_VPrefix ( Address );
			if ( i.id & 0xf )
			{
				if ( ( !( i.is & 0xf ) ) || ( !( i.it & 0xf ) ) )
				{
					e->MovMemImm16 ( (s16*) &VU0::_VU0->vi [ i.id & 0xf ].s, 0 );
				}
				else if ( ( i.is & 0xf ) == ( i.it & 0xf ) )
				{
					e->MovRegMem16 ( RAX, (s16*) &VU0::_VU0->vi [ i.is & 0xf ].s );
					e->MovMemReg16 ( (s16*) &VU0::_VU0->vi [ i.id & 0xf ].s, RAX );
				}
				else if ( ( i.id & 0xf ) == ( i.is & 0xf ) )
				{
					e->MovRegMem16 ( RAX, (s16*) &VU0::_VU0->vi [ i.it & 0xf ].s );
					e->AndMemReg16 ( (s16*) &VU0::_VU0->vi [ i.id & 0xf ].s, RAX );
				}
				else if ( ( i.id & 0xf ) == ( i.it & 0xf ) )
				{
					e->MovRegMem16 ( RAX, (s16*) &VU0::_VU0->vi [ i.is & 0xf ].s );
					e->AndMemReg16 ( (s16*) &VU0::_VU0->vi [ i.id & 0xf ].s, RAX );
				}
				else
				{
					e->MovRegMem16 ( RAX, (s16*) &VU0::_VU0->vi [ i.is & 0xf ].s );
					e->AndRegMem16 ( RAX, (s16*) &VU0::_VU0->vi [ i.it & 0xf ].s );
					e->MovMemReg16 ( (s16*) &VU0::_VU0->vi [ i.id & 0xf ].s, RAX );
				}
			}
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::VIOR ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "VIOR";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VIOR;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VIOR_CODE
		case 1:
			Generate_VPrefix ( Address );
			if ( i.id & 0xf )
			{
				if ( ( !( i.is & 0xf ) ) && ( !( i.it & 0xf ) ) )
				{
					e->MovMemImm16 ( (s16*) &VU0::_VU0->vi [ i.id & 0xf ].s, 0 );
				}
				else if ( ( !( i.is & 0xf ) ) || ( !( i.it & 0xf ) ) )
				{
					e->MovRegMem16 ( RAX, (s16*) &VU0::_VU0->vi [ ( i.is & 0xf ) + ( i.it & 0xf ) ].s );
					e->MovMemReg16 ( (s16*) &VU0::_VU0->vi [ i.id & 0xf ].s, RAX );
				}
				else if ( ( i.is & 0xf ) == ( i.it & 0xf ) )
				{
					e->MovRegMem16 ( RAX, (s16*) &VU0::_VU0->vi [ i.is & 0xf ].s );
					e->MovMemReg16 ( (s16*) &VU0::_VU0->vi [ i.id & 0xf ].s, RAX );
				}
				else if ( ( i.id & 0xf ) == ( i.is & 0xf ) )
				{
					e->MovRegMem16 ( RAX, (s16*) &VU0::_VU0->vi [ i.it & 0xf ].s );
					e->OrMemReg16 ( (s16*) &VU0::_VU0->vi [ i.id & 0xf ].s, RAX );
				}
				else if ( ( i.id & 0xf ) == ( i.it & 0xf ) )
				{
					e->MovRegMem16 ( RAX, (s16*) &VU0::_VU0->vi [ i.is & 0xf ].s );
					e->OrMemReg16 ( (s16*) &VU0::_VU0->vi [ i.id & 0xf ].s, RAX );
				}
				else
				{
					e->MovRegMem16 ( RAX, (s16*) &VU0::_VU0->vi [ i.is & 0xf ].s );
					e->OrRegMem16 ( RAX, (s16*) &VU0::_VU0->vi [ i.it & 0xf ].s );
					e->MovMemReg16 ( (s16*) &VU0::_VU0->vi [ i.id & 0xf ].s, RAX );
				}
			}
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}



// VCALLMS //

int32_t R5900::Recompiler::VCALLMS ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "VCALLMS";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VCALLMS;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// should assume NextPC might get modified
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::VCALLMSR ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "VCALLMSR";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VCALLMSR;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// should assume NextPC might get modified
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}


// VFTOI //

int32_t R5900::Recompiler::VFTOI0 ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "VFTOI0";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VFTOI0;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VFTOI0_CODE
		case 1:

			Generate_VPrefix ( Address );
			Generate_VFTOIXp ( i, 0 );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::VFTOI4 ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "VFTOI4";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VFTOI4;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VFTOI4_CODE
		case 1:

			Generate_VPrefix ( Address );
			Generate_VFTOIXp ( i, 4 );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::VFTOI12 ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "VFTOI12";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VFTOI12;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VFTOI12_CODE
		case 1:

			Generate_VPrefix ( Address );
			Generate_VFTOIXp ( i, 12 );
			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::VFTOI15 ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "VFTOI15";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VFTOI15;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VFTOI15_CODE
		case 1:

			Generate_VPrefix ( Address );
			Generate_VFTOIXp ( i, 15 );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}


// VITOF //

int32_t R5900::Recompiler::VITOF0 ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "VITOF0";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VITOF0;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VITOF0_CODE
		case 1:
			Generate_VPrefix ( Address );
			Generate_VITOFXp ( i, 0 );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::VITOF4 ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "VITOF4";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VITOF4;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VITOF4_CODE
		case 1:
			Generate_VPrefix ( Address );
			Generate_VITOFXp ( i, 4 );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::VITOF12 ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "VITOF12";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VITOF12;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VITOF12_CODE
		case 1:
			Generate_VPrefix ( Address );
			Generate_VITOFXp ( i, 12 );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::VITOF15 ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "VITOF15";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VITOF15;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VITOF15_CODE
		case 1:
			Generate_VPrefix ( Address );
			Generate_VITOFXp ( i, 15 );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}





int32_t R5900::Recompiler::VMOVE ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "VMOVE";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VMOVE;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VMOVE_CODE
		case 1:
			Generate_VPrefix ( Address );
			ret = Generate_VMOVEp ( i );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::VLQI ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "VLQI";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VLQI;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VLQI_CODE
		case 1:
			Generate_VPrefix ( Address );

			if ( i.Ft )
			{
				// add destination register to bitmap at end
				//Add_FDstReg ( i.Value, i.Ft );
				
				//LoadAddress = ( v->vi [ i.is & 0xf ].sLo + i.Imm11 ) << 2;
				e->MovRegMem32 ( RAX, & VU0::_VU0->vi [ i.is & 0xf ].s );
				
				
				//if ( i.xyzw != 0xf )
				//{
				//	e->movdqa_regmem ( RCX, & VU0::_VU0->vf [ i.Ft ].sw0 );
				//}

				//pVuMem32 = v->GetMemPtr ( LoadAddress );
				//return & ( VuMem32 [ Address32 & ( c_ulVuMem1_Mask >> 2 ) ] );
				//e->MovRegImm64 ( RCX, (u64) & v->VuMem32 [ 0 ] );
				e->LeaRegMem64 ( RCX, & VU0::_VU0->VuMem32 [ 0 ] );
				
				// special code for VU#0
				//if ( !v->Number )
				//{
					// check if Address & 0xf000 == 0x4000
					e->MovRegReg32 ( RDX, RAX );
					e->AndReg32ImmX ( RDX, 0xf000 >> 4 );
					e->CmpReg32ImmX ( RDX, 0x4000 >> 4 );
					
					// here it will be loading/storing from/to the registers for VU#1
					e->LeaRegMem64 ( RDX, & VU1::_VU1->vf [ 0 ].sw0 );
					e->CmovERegReg64 ( RCX, RDX );
					
				//}

				
				// post-inc
				e->LeaRegRegImm32 ( RDX, RAX, 1 );
				e->MovMemReg16 ( & VU0::_VU0->vi [ i.is & 0xf ].sLo, RDX );
				
				//if ( !v->Number )
				//{
					e->AndReg32ImmX ( RAX, VU::c_ulVuMem0_Mask >> 4 );
				//}
				//else
				//{
				//	e->AndReg32ImmX ( RAX, VU::c_ulVuMem1_Mask >> 4 );
				//}
				e->AddRegReg32 ( RAX, RAX );
				
				
				e->movdqa_from_mem128 ( RAX, RCX, RAX, SCALE_EIGHT, 0 );
				
#ifdef USE_NEW_VECTOR_DISPATCH_VLQI_R5900

				ret = Dispatch_Result_AVX2(i, false, RAX, i.Ft);

#else
				if ( i.xyzw != 0xf )
				{
					e->movdqa_regmem(RCX, &VU0::_VU0->vf[i.Ft].sw0);
					e->pblendwregregimm ( RAX, RCX, ~( ( i.destx * 0x03 ) | ( i.desty * 0x0c ) | ( i.destz * 0x30 ) | ( i.destw * 0xc0 ) ) );
				}
				
				ret = e->movdqa_memreg ( & VU0::_VU0->vf [ i.Ft ].sw0, RAX );
#endif
			}
			
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::VDIV ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "VDIV";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VDIV;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;


#ifdef USE_NEW_VDIV_CODE
		case 1:
		
			Generate_VPrefix ( Address );

			/*
			// set cycle# for VU
			e->MovRegMem64(RAX, (int64_t*)&r->CycleCount);
			e->MovMemReg64((int64_t*)&VU0::_VU0->CycleCount, RAX);

			// run vu0 instruction
			Vu::Recompiler::DIV(e, VU0::_VU0, { i.Value }, Address);

			// for now, do a wait q
			// ***todo*** need to do an update q for like addq,mulq,etc, and before vu0 micro mode
			Vu::Recompiler::Perform_WaitQ(e, VU0::_VU0, Address);

			// load new cycle#
			e->MovRegMem64(RAX, (int64_t*)&VU0::_VU0->CycleCount);
			e->MovMemReg64((int64_t*)&r->CycleCount, RAX);
			*/

			e->movd1_regmem(RAX, (int32_t*)&VU0::_VU0->vf[i.Fs].vsw[i.fsf]);
			e->movd1_regmem(RCX, (int32_t*)&VU0::_VU0->vf[i.Ft].vsw[i.ftf]);

			// make constant multiplier ->rbx
			//e->MovReg64ImmX(RAX, 127ull << 52);
			e->MovReg64ImmX(RAX, 896ull << 23);
			e->movq_to_sse128(RBX, RAX);

			// check if fs,ft is float zero
			// 0 -> r5
			e->pxor1regreg(RDX, RDX, RDX);
			e->paddd1regreg(4, RAX, RAX);
			e->pcmpeqb1regreg(4, 4, RDX);
			e->paddd1regreg(5, RCX, RCX);
			e->pcmpeqb1regreg(5, 5, RDX);

			// make masks
			e->pcmpgtd1regreg(4, RDX, 4);
			e->pcmpgtd1regreg(5, RDX, 5);


			// check if fs==0 and ft==0 -> invalid ->r4
			e->pand1regreg(4, 4, 5);

			// check if fs!=0 and ft==0 -> div by zero -> r5
			//e->pandn1regreg(5, 4, 5);

			e->movd_from_sse128(RAX, 4);
			e->movd_from_sse128(RCX, 5);

			// sign ->rdx
			e->pxor1regreg(RDX, RAX, RCX);

			// adjust fs if 0/0
			e->por1regreg(RAX, RAX, 4);


			// cvt float to double
			e->psllq1regimm(RAX, RAX, 33);
			e->psrlq1regimm(RAX, RAX, 4);
			e->psllq1regimm(RCX, RCX, 33);
			e->psrlq1regimm(RCX, RCX, 4);


			// divide
			e->vdivsd(RAX, RAX, RCX);

			// multiply with multiplier
			//e->vmulsd(RAX, RAX, RBX);

			// make adjustment ->r4
			e->MovReg64ImmX(RDX, 1ull << 28);
			e->movq_to_sse128(4, RDX);

			// check for 0/0 ->rax
			//e->psrad1regimm(5, RAX, 31);
			//e->pextrd1regreg(RAX, 5, 1);

			// check for x/0 ->rcx
			//e->pslld1regimm(RBX, RAX, 1);
			//e->psrad1regimm(RBX, RBX, 31);
			//e->pextrd1regreg(RCX, RBX, 1);

			// adjust result
			e->paddq1regreg(RAX, RAX, 4);

			// get result
			e->psrlq1regimm(RAX, RAX, 29);

			// offset exponent
			e->psubq1regreg(RAX, RAX, RBX);

			// clear on underflow or zero
			e->pxor1regreg(5, 5, 5);
			e->pcmpgtq1regreg(4, 5, RAX);
			e->pandn1regreg(RAX, 4, RAX);

			// maximize on overflow
			e->pcmpeqb1regreg(5, 5, 5);
			e->psrlq1regimm(4, 5, 33);
			e->pcmpgtq1regreg(RBX, RAX, 4);
			e->por1regreg(RAX, RAX, RBX);
			e->pand1regreg(RAX, RAX, 4);

			// put sign in
			e->pandn1regreg(RDX, 4, RDX);
			e->por1regreg(RAX, RAX, RDX);

			// store result
			e->movd1_memreg(&VU0::_VU0->vi[VU::REG_Q].s, RAX);
			e->movd1_memreg((int32_t*)&VU0::_VU0->NextQ.l, RAX);

			// clear bits 16 and 17 in the flag register first
			e->AndMem32ImmX(&VU0::_VU0->vi[VU::REG_STATUSFLAG].s, ~0x30);

			// get flags
			//e->MovRegMem32(RDX, (int32_t*)&statflag);
			e->XorRegReg32(RCX, RAX);
			e->AndReg32ImmX(RAX, 0x410);
			e->AndReg32ImmX(RCX, 0x820);
			e->OrRegReg32(RAX, RCX);
			//e->AndReg32ImmX(RDX, ~0x30000);
			//e->OrRegReg32(RAX, RDX);
			e->MovMemReg32((int32_t*)&VU0::_VU0->NextQ_Flag, RAX);
			e->OrMemReg32(&VU0::_VU0->vi[VU::REG_STATUSFLAG].s, RAX);

			break;
#endif
			

			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::VMTIR ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "VMTIR";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VMTIR;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VMTIR_CODE
		case 1:
			Generate_VPrefix ( Address );
			ret = Generate_VMTIRp ( i );
			break;
#endif
			
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::VRNEXT ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "VRNEXT";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VRNEXT;
	
	static const uint32_t c_ulRandMask = 0x7ffb18;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
#ifdef USE_NEW_VRNEXT_CODE
		case 1:
			if ( i.Ft && i.xyzw )
			{
				//e->movdqa_regmem ( RCX, & VU0::_VU0->vf [ i.Fs ].sw0 );
				
				// get new P register value if needed
				//e->movd_regmem ( RCX, & VU0::_VU0->vi [ VU::REG_R ].s );
				e->MovRegMem32 ( RAX, ( &VU0::_VU0->vi [ VU::REG_R ].s ) );
				
				e->MovRegReg32 ( RCX, RAX );
				e->AndReg32ImmX( RAX, c_ulRandMask );
				//e->Set_PO ( RCX );
				e->PopCnt32 ( RAX, RAX );
				e->AndReg32ImmX ( RAX, 1 );
				e->AddRegReg32 ( RCX, RCX );
				e->OrRegReg32 ( RAX, RCX );
				
				e->AndReg32ImmX ( RAX, 0x7fffff );
				e->OrReg32ImmX ( RAX, ( 0x7f << 23 ) );
				e->MovMemReg32 ( &VU0::_VU0->vi [ VU::REG_R ].s, RAX );
				
				e->movd_to_sse ( RCX, RAX );
				e->pshufdregregimm ( RCX, RCX, 0 );
				
				if ( i.xyzw != 0xf )
				{
					e->movdqa_regmem ( RAX, & VU0::_VU0->vf [ i.Ft ].sw0 );
					e->pblendwregregimm ( RCX, RAX, ~( ( i.destx * 0x03 ) | ( i.desty * 0x0c ) | ( i.destz * 0x30 ) | ( i.destw * 0xc0 ) ) );
				}
				
				ret = e->movdqa_memreg ( & VU0::_VU0->vf [ i.Ft ].sw0, RCX );
			}
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::VMR32 ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "VMR32";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VMR32;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VMR32_CODE
		case 1:
			Generate_VPrefix ( Address );
			ret = Generate_VMR32p ( i );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::VSQI ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "VSQI";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VSQI;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VSQI_CODE
		case 1:
			Generate_VPrefix ( Address );

			//LoadAddress = ( v->vi [ i.is & 0xf ].sLo + i.Imm11 ) << 2;
			e->MovRegMem32 ( RAX, & VU0::_VU0->vi [ i.it & 0xf ].s );
			
			e->movdqa_regmem ( RAX, & VU0::_VU0->vf [ i.Fs ].sw0 );

			//pVuMem32 = v->GetMemPtr ( LoadAddress );
			//return & ( VuMem32 [ Address32 & ( c_ulVuMem1_Mask >> 2 ) ] );
			//e->MovRegImm64 ( RCX, (u64) & v->VuMem32 [ 0 ] );
			e->LeaRegMem64 ( RCX, & VU0::_VU0->VuMem32 [ 0 ] );
			
			// special code for VU#0
			//if ( !v->Number )
			//{
				// check if Address & 0xf000 == 0x4000
				e->MovRegReg32 ( RDX, RAX );
				e->AndReg32ImmX ( RDX, 0xf000 >> 4 );
				e->CmpReg32ImmX ( RDX, 0x4000 >> 4 );
				
				// here it will be loading/storing from/to the registers for VU#1
				e->LeaRegMem64 ( RDX, & VU1::_VU1->vf [ 0 ].sw0 );
				e->CmovERegReg64 ( RCX, RDX );
				
				// ***TODO*** check if storing to TPC
			//}
			
			
			// post-inc
			e->LeaRegRegImm32 ( RDX, RAX, 1 );
			e->MovMemReg16 ( & VU0::_VU0->vi [ i.it & 0xf ].sLo, RDX );
			
			//if ( !v->Number )
			//{
				e->AndReg32ImmX ( RAX, VU::c_ulVuMem0_Mask >> 4 );
			//}
			//else
			//{
			//	e->AndReg32ImmX ( RAX, VU::c_ulVuMem1_Mask >> 4 );
			//}
			e->AddRegReg32 ( RAX, RAX );
			
#define ENABLE_VU_MASK_STORE_VSQI
#ifdef ENABLE_VU_MASK_STORE_VSQI

			if (i.xyzw != 0xf)
			{
				//e->movdqa_from_mem128(RCX, RCX, RAX, SCALE_EIGHT, 0);
				//e->pblendwregregimm(RAX, RCX, ~((i.destx * 0x03) | (i.desty * 0x0c) | (i.destz * 0x30) | (i.destw * 0xc0)));
				e->pcmpeqb1regreg(RCX, RCX, RCX);
				e->pxor1regreg(RDX, RDX, RDX);
				e->pblendw1regregimm(RCX, RCX, RDX, ~((i.destx * 0x03) | (i.desty * 0x0c) | (i.destz * 0x30) | (i.destw * 0xc0)));
				e->vmaskmovd1_memreg(RCX, RAX, RCX, RAX, SCALE_EIGHT, 0);
			}
			else
			{
				ret = e->movdqa_to_mem128(RAX, RCX, RAX, SCALE_EIGHT, 0);
			}

#else

			if ( i.xyzw != 0xf )
			{
				e->movdqa_from_mem128 ( RCX, RCX, RAX, SCALE_EIGHT, 0 );
				e->pblendwregregimm ( RAX, RCX, ~( ( i.destx * 0x03 ) | ( i.desty * 0x0c ) | ( i.destz * 0x30 ) | ( i.destw * 0xc0 ) ) );
			}
			
			ret = e->movdqa_to_mem128 ( RAX, RCX, RAX, SCALE_EIGHT, 0 );

#endif
			
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::VSQRT ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "VSQRT";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VSQRT;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VSQRT_CODE
		case 1:
			Generate_VPrefix ( Address );
			
			/*
			// set cycle# for VU
			e->MovRegMem64(RAX, (int64_t*)&r->CycleCount);
			e->MovMemReg64((int64_t*)&VU0::_VU0->CycleCount, RAX);

			// run vu0 instruction
			Vu::Recompiler::SQRT(e, VU0::_VU0, { i.Value }, Address);

			// for now, do a wait q
			// ***todo*** need to do an update q for like addq,mulq,etc, and before vu0 micro mode
			Vu::Recompiler::Perform_WaitQ(e, VU0::_VU0, Address);

			// load new cycle#
			e->MovRegMem64(RAX, (int64_t*)&VU0::_VU0->CycleCount);
			e->MovMemReg64((int64_t*)&r->CycleCount, RAX);
			*/

			e->movd1_regmem(RAX, (int32_t*)&VU0::_VU0->vf[i.Ft].vsw[i.ftf]);

			// make constant multiplier
			e->MovReg64ImmX(RAX, (1023ull + 896ull) << 52);
			e->movq_to_sse128(RBX, RAX);

			// make adjustment
			e->MovReg64ImmX(RAX, 3ull << 25);
			e->movq_to_sse128(RDX, RAX);

			// get initial I-flag ->r5
			e->psrad1regimm(5, RAX, 31);

			// cvt float to double
			e->psllq1regimm(RAX, RAX, 33);
			e->psrlq1regimm(RAX, RAX, 4);

			// multiply with multiplier
			e->vmulsd(RAX, RAX, RBX);

			// check for zero ->r4
			e->pxor1regreg(4, 4, 4);
			e->pcmpeqq1regreg(4, 4, RAX);

			// only set I-flag if negative number not zero ?
			e->pandn1regreg(5, 4, 5);

			// get final I-flag ->rcx
			e->movd_from_sse128(RCX, 5);

			// sqrt
			e->vsqrtsd(RAX, RAX);

			// adjust result
			e->paddq1regreg(RAX, RAX, RDX);

			// get result
			e->cvtsd2ss1regreg(RAX, RAX);

			// store result
			e->movd1_memreg((int32_t*)&VU0::_VU0->NextQ.l, RAX);
			e->movd1_memreg((int32_t*)&VU0::_VU0->vi[VU::REG_Q].s, RAX);

			// clear bits 16 and 17 in the flag register first
			e->AndMem32ImmX(&VU0::_VU0->vi[VU::REG_STATUSFLAG].s, ~0x30);

			// get flags
			e->AndReg32ImmX(RCX, 0x410);
			e->MovMemReg32((int32_t*)&VU0::_VU0->NextQ_Flag, RCX);
			e->OrMemReg32(&VU0::_VU0->vi[VU::REG_STATUSFLAG].s, RCX);

			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::VMFIR ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "VMFIR";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VMFIR;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VMFIR_CODE
		case 1:
			Generate_VPrefix ( Address );
			ret = Generate_VMFIRp ( i );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::VRGET ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "VRGET";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VRGET;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
#ifdef USE_NEW_VRGET_CODE
		case 1:
			if ( i.Ft && i.xyzw )
			{
				//e->movdqa_regmem ( RCX, & VU0::_VU0->vf [ i.Fs ].sw0 );
				
				// get new P register value if needed
				e->movd_regmem ( RCX, & VU0::_VU0->vi [ VU::REG_R ].s );
				
				//e->movd_to_sse ( RCX, RAX );
				e->pshufdregregimm ( RCX, RCX, 0 );
				
				if ( i.xyzw != 0xf )
				{
					e->movdqa_regmem ( RAX, & VU0::_VU0->vf [ i.Ft ].sw0 );
					e->pblendwregregimm ( RCX, RAX, ~( ( i.destx * 0x03 ) | ( i.desty * 0x0c ) | ( i.destz * 0x30 ) | ( i.destw * 0xc0 ) ) );
				}
				
				ret = e->movdqa_memreg ( & VU0::_VU0->vf [ i.Ft ].sw0, RCX );
			}
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}




// VSUBA //

int32_t R5900::Recompiler::VSUBA ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "VSUBA";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VSUBA;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VSUBA_CODE
		case 1:

			Generate_VPrefix ( Address );
			ret = Generate_VADDp ( 1, i, -1, &VU0::_VU0->dACC[ 0 ].l );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::VSUBAi ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "VSUBAi";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VSUBAi;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VSUBAi_CODE
		case 1:

			Generate_VPrefix ( Address );
			ret = Generate_VADDp ( 1, i, 0, &VU0::_VU0->dACC[ 0 ].l, &VU0::_VU0->vi [ VU::REG_I ].u );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::VSUBAq ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "VSUBAq";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VSUBAq;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VSUBAq_CODE
		case 1:

			Generate_VPrefix ( Address );
			ret = Generate_VADDp ( 1, i, 0, &VU0::_VU0->dACC[ 0 ].l, &VU0::_VU0->vi [ VU::REG_Q ].u );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::VSUBABCX ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "VSUBABCX";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VSUBABCX;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VSUBAX_CODE
		case 1:

			Generate_VPrefix ( Address );
			ret = Generate_VADDp(1, i, 0, &VU0::_VU0->dACC[0].l, &VU0::_VU0->vf[i.Ft].vuw[i.bc]);
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::VSUBABCY ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "VSUBABCY";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VSUBABCY;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VSUBAY_CODE
		case 1:

			Generate_VPrefix ( Address );
			ret = Generate_VADDp(1, i, 0, &VU0::_VU0->dACC[0].l, &VU0::_VU0->vf[i.Ft].vuw[i.bc]);
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::VSUBABCZ ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "VSUBABCZ";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VSUBABCZ;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VSUBAZ_CODE
		case 1:

			Generate_VPrefix ( Address );
			ret = Generate_VADDp(1, i, 0, &VU0::_VU0->dACC[0].l, &VU0::_VU0->vf[i.Ft].vuw[i.bc]);
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::VSUBABCW ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "VSUBABCW";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VSUBABCW;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VSUBAW_CODE
		case 1:

			Generate_VPrefix ( Address );
			ret = Generate_VADDp(1, i, 0, &VU0::_VU0->dACC[0].l, &VU0::_VU0->vf[i.Ft].vuw[i.bc]);
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}



// VMADDA //

int32_t R5900::Recompiler::VMADDA ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "VMADDA";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VMADDA;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VMADDA_CODE
		case 1:

			Generate_VPrefix ( Address );
			ret = Generate_VMADDp ( 0, i, 0x1b, &VU0::_VU0->dACC[ 0 ].l );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::VMADDAi ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "VMADDAi";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VMADDAi;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VMADDAi_CODE
		case 1:

			Generate_VPrefix ( Address );
			ret = Generate_VMADDp ( 0, i, 0, &VU0::_VU0->dACC[ 0 ].l, &VU0::_VU0->vi [ VU::REG_I ].u );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::VMADDAq ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "VMADDAq";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VMADDAq;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VMADDAq_CODE
		case 1:

			Generate_VPrefix ( Address );
			ret = Generate_VMADDp ( 0, i, 0, &VU0::_VU0->dACC[ 0 ].l, &VU0::_VU0->vi [ VU::REG_Q ].u );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::VMADDABCX ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "VMADDABCX";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VMADDABCX;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VMADDAX_CODE
		case 1:

			Generate_VPrefix ( Address );
			ret = Generate_VMADDp(0, i, 0, &VU0::_VU0->dACC[0].l, &VU0::_VU0->vf[i.Ft].vuw[i.bc]);
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::VMADDABCY ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "VMADDABCY";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VMADDABCY;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VMADDAY_CODE
		case 1:

			Generate_VPrefix ( Address );
			ret = Generate_VMADDp(0, i, 0, &VU0::_VU0->dACC[0].l, &VU0::_VU0->vf[i.Ft].vuw[i.bc]);
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::VMADDABCZ ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "VMADDABCZ";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VMADDABCZ;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VMADDAZ_CODE
		case 1:

			Generate_VPrefix ( Address );
			ret = Generate_VMADDp(0, i, 0, &VU0::_VU0->dACC[0].l, &VU0::_VU0->vf[i.Ft].vuw[i.bc]);
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::VMADDABCW ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "VMADDABCW";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VMADDABCW;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VMADDAW_CODE
		case 1:

			Generate_VPrefix ( Address );
			ret = Generate_VMADDp(0, i, 0, &VU0::_VU0->dACC[0].l, &VU0::_VU0->vf[i.Ft].vuw[i.bc]);
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}




// VMSUBA //

int32_t R5900::Recompiler::VMSUBA ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "VMSUBA";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VMSUBA;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VMSUBA_CODE
		case 1:

			Generate_VPrefix ( Address );
			ret = Generate_VMADDp ( 1, i, 0x1b, &VU0::_VU0->dACC[ 0 ].l );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::VMSUBAi ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "VMSUBAi";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VMSUBAi;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VMSUBAi_CODE
		case 1:

			Generate_VPrefix ( Address );
			ret = Generate_VMADDp ( 1, i, 0, &VU0::_VU0->dACC[ 0 ].l, &VU0::_VU0->vi [ VU::REG_I ].u );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::VMSUBAq ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "VMSUBAq";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VMSUBAq;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VMSUBAq_CODE
		case 1:

			Generate_VPrefix ( Address );
			ret = Generate_VMADDp ( 1, i, 0, &VU0::_VU0->dACC[ 0 ].l, &VU0::_VU0->vi [ VU::REG_Q ].u );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::VMSUBABCX ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "VMSUBABCX";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VMSUBABCX;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VMSUBAX_CODE
		case 1:

			Generate_VPrefix ( Address );
			ret = Generate_VMADDp(1, i, 0, &VU0::_VU0->dACC[0].l, &VU0::_VU0->vf[i.Ft].vuw[i.bc]);
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::VMSUBABCY ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "VMSUBABCY";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VMSUBABCY;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VMSUBAY_CODE
		case 1:

			Generate_VPrefix ( Address );
			ret = Generate_VMADDp(1, i, 0, &VU0::_VU0->dACC[0].l, &VU0::_VU0->vf[i.Ft].vuw[i.bc]);
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::VMSUBABCZ ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "VMSUBABCZ";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VMSUBABCZ;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VMSUBAZ_CODE
		case 1:

			Generate_VPrefix ( Address );
			ret = Generate_VMADDp(1, i, 0, &VU0::_VU0->dACC[0].l, &VU0::_VU0->vf[i.Ft].vuw[i.bc]);
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::VMSUBABCW ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "VMSUBABCW";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VMSUBABCW;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VMSUBAW_CODE
		case 1:

			Generate_VPrefix ( Address );
			ret = Generate_VMADDp(1, i, 0, &VU0::_VU0->dACC[0].l, &VU0::_VU0->vf[i.Ft].vuw[i.bc]);
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}





// VMULA //

int32_t R5900::Recompiler::VMULA ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "VMULA";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VMULA;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VMULA_CODE
		case 1:

			Generate_VPrefix ( Address );
			ret = Generate_VMULp ( i, 0x1b, &VU0::_VU0->dACC[ 0 ].l );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::VMULAi ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "VMULAi";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VMULAi;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VMULAi_CODE
		case 1:

			Generate_VPrefix ( Address );
			ret = Generate_VMULp ( i, 0, &VU0::_VU0->dACC[ 0 ].l, &VU0::_VU0->vi [ VU::REG_I ].u );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::VMULAq ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "VMULAq";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VMULAq;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VMULAq_CODE
		case 1:

			Generate_VPrefix ( Address );
			ret = Generate_VMULp ( i, 0, &VU0::_VU0->dACC[ 0 ].l, &VU0::_VU0->vi [ VU::REG_Q ].u );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::VMULABCX ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "VMULABCX";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VMULABCX;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VMULAX_CODE
		case 1:

			Generate_VPrefix ( Address );
			ret = Generate_VMULp(i, 0, &VU0::_VU0->dACC[0].l, &VU0::_VU0->vf[i.Ft].vuw[i.bc]);
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::VMULABCY ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "VMULABCY";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VMULABCY;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VMULAY_CODE
		case 1:

			Generate_VPrefix ( Address );
			ret = Generate_VMULp(i, 0, &VU0::_VU0->dACC[0].l, &VU0::_VU0->vf[i.Ft].vuw[i.bc]);
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::VMULABCZ ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "VMULABCZ";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VMULABCZ;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VMULAZ_CODE
		case 1:

			Generate_VPrefix ( Address );
			ret = Generate_VMULp(i, 0, &VU0::_VU0->dACC[0].l, &VU0::_VU0->vf[i.Ft].vuw[i.bc]);
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::VMULABCW ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "VMULABCW";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VMULABCW;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VMULAW_CODE
		case 1:

			Generate_VPrefix ( Address );
			ret = Generate_VMULp(i, 0, &VU0::_VU0->dACC[0].l, &VU0::_VU0->vf[i.Ft].vuw[i.bc]);
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}





int32_t R5900::Recompiler::VOPMULA ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "VOPMULA";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VOPMULA;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VOPMULA_CODE
		case 1:

			Generate_VPrefix ( Address );
			ret = Generate_VMULp ( i, 0x84, &VU0::_VU0->dACC[ 0 ].l, NULL, 0x60 );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::VLQD ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "VLQD";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VLQD;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VLQD_CODE
		case 1:
			Generate_VPrefix ( Address );

			if ( i.Ft )
			{
				// add destination register to bitmap at end
				//Add_FDstReg ( i.Value, i.Ft );
				
				//LoadAddress = ( v->vi [ i.is & 0xf ].sLo + i.Imm11 ) << 2;
				e->MovRegMem32 ( RAX, & VU0::_VU0->vi [ i.is & 0xf ].s );
				
				
				//pVuMem32 = v->GetMemPtr ( LoadAddress );
				//return & ( VuMem32 [ Address32 & ( c_ulVuMem1_Mask >> 2 ) ] );
				//e->MovRegImm64 ( RCX, (u64) & v->VuMem32 [ 0 ] );
				e->LeaRegMem64 ( RCX, & VU0::_VU0->VuMem32 [ 0 ] );
				
				// special code for VU#0
				//if ( !v->Number )
				//{
					// check if Address & 0xf000 == 0x4000
					e->MovRegReg32 ( RDX, RAX );
					e->AndReg32ImmX ( RDX, 0xf000 >> 4 );
					e->CmpReg32ImmX ( RDX, 0x4000 >> 4 );
					
					// here it will be loading/storing from/to the registers for VU#1
					e->LeaRegMem64 ( RDX, & VU1::_VU1->vf [ 0 ].sw0 );
					e->CmovERegReg64 ( RCX, RDX );
					
				//}
				
				
				// post-inc
				e->DecReg16 ( RAX );
				e->MovMemReg16 ( & VU0::_VU0->vi [ i.is & 0xf ].sLo, RAX );
				
				//if ( !v->Number )
				//{
					e->AndReg32ImmX ( RAX, VU::c_ulVuMem0_Mask >> 4 );
				//}
				//else
				//{
				//	e->AndReg32ImmX ( RAX, VU::c_ulVuMem1_Mask >> 4 );
				//}
				e->AddRegReg32 ( RAX, RAX );
				
				e->movdqa_from_mem128(RAX, RCX, RAX, SCALE_EIGHT, 0);

#ifdef USE_NEW_VECTOR_DISPATCH_VLQD_R5900

				ret = Dispatch_Result_AVX2(i, false, RAX, i.Ft);

#else

				if ( i.xyzw != 0xf )
				{
					e->movdqa_regmem(RCX, &VU0::_VU0->vf[i.Ft].sw0);
					e->pblendwregregimm ( RAX, RCX, ~( ( i.destx * 0x03 ) | ( i.desty * 0x0c ) | ( i.destz * 0x30 ) | ( i.destw * 0xc0 ) ) );
				}
				
				ret = e->movdqa_memreg ( & VU0::_VU0->vf [ i.Ft ].sw0, RAX );

#endif
			}
			
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::VRSQRT ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "VRSQRT";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VRSQRT;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VRSQRT_CODE
		case 1:
			Generate_VPrefix ( Address );
			
			/*
			// set cycle# for VU
			e->MovRegMem64(RAX, (int64_t*)&r->CycleCount);
			e->MovMemReg64((int64_t*)&VU0::_VU0->CycleCount, RAX);

			// run vu0 instruction
			Vu::Recompiler::DIV(e, VU0::_VU0, { i.Value }, Address);

			// for now, do a wait q
			// ***todo*** need to do an update q for like addq,mulq,etc, and before vu0 micro mode
			Vu::Recompiler::Perform_WaitQ(e, VU0::_VU0, Address);

			// load new cycle#
			e->MovRegMem64(RAX, (int64_t*)&VU0::_VU0->CycleCount);
			e->MovMemReg64((int64_t*)&r->CycleCount, RAX);
			*/

			e->movd1_regmem(RAX, (int32_t*)&VU0::_VU0->vf[i.Fs].vsw[i.fsf]);
			e->movd1_regmem(RCX, (int32_t*)&VU0::_VU0->vf[i.Ft].vsw[i.ftf]);

			// make constant multiplier
			e->MovReg64ImmX(RAX, (1023ull + 896ull) << 52);
			e->movq_to_sse128(RBX, RAX);

			// check if ft(rcx) is zero (D flag) (ft=0) ->r5
			e->pxor1regreg(RDX, RDX, RDX);
			e->paddd1regreg(5, RCX, RCX);
			e->pcmpeqb1regreg(5, 5, RDX);

			// check if fs(rax) is zero -> r4
			e->paddd1regreg(4, RAX, RAX);
			e->pcmpeqb1regreg(4, 4, RDX);

			// check if both fs==0 and ft==0 ->r4
			e->pand1regreg(4, 4, 5);

			// get full flags
			e->pcmpgtd1regreg(4, RDX, 4);
			e->pcmpgtd1regreg(5, RDX, 5);

			// if fs and ft are both float zero, adjust fs
			e->psrld1regimm(4, 4, 1);
			e->por1regreg(RAX, RAX, 4);


			// get I-flag (ft(rcx)<0) ->r4
			e->pcmpgtd1regreg(4, RDX, RCX);
			e->pandn1regreg(4, 5, 4);

			// get flags for later
			e->movd_from_sse128(RCX, 4);
			e->movd_from_sse128(RDX, 5);

			// make constant adjustment
			e->MovReg64ImmX(RAX, 3ull << 25);
			e->movq_to_sse128(RDX, RAX);

			// cvt float to double
			e->psllq1regimm(RCX, RCX, 33);
			e->psrlq1regimm(RCX, RCX, 4);


			// multiply with multiplier
			e->vmulsd(RCX, RCX, RBX);

			// sqrt
			e->vsqrtsd(RCX, RCX);

			// adjust result
			e->paddq1regreg(RCX, RCX, RDX);

			// get result
			e->cvtsd2ss1regreg(RCX, RCX);

			// save sign ->rdx
			e->psrad1regimm(RDX, RAX, 31);

			// make constant multiplier
			//e->MovReg64ImmX(RAX, 127ull << 52);
			e->MovReg64ImmX(RAX, 896ull << 23);
			e->movq_to_sse128(4, RAX);

			// convert sqrt back to double
			e->psllq1regimm(RAX, RAX, 33);
			e->psrlq1regimm(RAX, RAX, 4);
			e->psllq1regimm(RCX, RCX, 33);
			e->psrlq1regimm(RCX, RCX, 4);


			// divide
			e->vdivsd(RAX, RAX, RCX);


			// multiply with multiplier
			//e->vmulsd(RAX, RAX, 4);


			// adjust result
			//e->paddq1regreg(RAX, RAX, 4);

			// get result
			e->psrlq1regimm(RAX, RAX, 29);

			// offset exponent
			e->psubq1regreg(RAX, RAX, 4);

			// clear on underflow or zero
			e->pxor1regreg(5, 5, 5);
			e->pcmpgtq1regreg(4, 5, RAX);
			e->pandn1regreg(RAX, 4, RAX);

			// maximize on overflow
			e->pcmpeqb1regreg(5, 5, 5);
			e->psrlq1regimm(4, 5, 33);
			e->pcmpgtq1regreg(RBX, RAX, 4);
			e->por1regreg(RAX, RAX, RBX);
			e->pand1regreg(RAX, RAX, 4);


			// put sign in
			e->pandn1regreg(RDX, 4, RDX);
			e->por1regreg(RAX, RAX, RDX);

			// store result
			e->movd1_memreg((int32_t*)&VU0::_VU0->NextQ.l, RAX);
			e->movd1_memreg((int32_t*)&VU0::_VU0->vi[VU::REG_Q].s, RAX);


			// clear bits 14 and 15 in the flag register first
			e->AndMem32ImmX(&VU0::_VU0->vi[VU::REG_STATUSFLAG].s, ~0x00000030);

			// get flags
			e->AndReg32ImmX(RCX, 0x410);
			e->AndReg32ImmX(RDX, 0x820);
			e->OrRegReg32(RCX, RDX);
			e->MovMemReg32((int32_t*)&VU0::_VU0->NextQ_Flag, RCX);
			e->OrMemReg32(&VU0::_VU0->vi[VU::REG_STATUSFLAG].s, RCX);
			
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::VILWR ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "VILWR";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VILWR;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VILWR_CODE
		case 1:
			Generate_VPrefix ( Address );

			if ( i.it )
			{
				//LoadAddress = ( v->vi [ i.is & 0xf ].sLo + i.Imm11 ) << 2;
				e->MovRegMem32 ( RAX, & VU0::_VU0->vi [ i.is & 0xf ].s );
				
				
				//pVuMem32 = v->GetMemPtr ( LoadAddress );
				//return & ( VuMem32 [ Address32 & ( c_ulVuMem1_Mask >> 2 ) ] );
				//e->MovRegImm64 ( RCX, (u64) & v->VuMem32 [ 0 ] );
				e->LeaRegMem64 ( RCX, & VU0::_VU0->VuMem32 [ 0 ] );

				// special code for VU#0
				//if ( !v->Number )
				//{
					// check if Address & 0xf000 == 0x4000
					e->MovRegReg32 ( RDX, RAX );
					e->AndReg32ImmX ( RDX, 0xf000 >> 4 );
					e->CmpReg32ImmX ( RDX, 0x4000 >> 4 );
					
					// here it will be loading/storing from/to the registers for VU#1
					e->LeaRegMem64 ( RDX, & VU1::_VU1->vf [ 0 ].sw0 );
					e->CmovERegReg64 ( RCX, RDX );
					
					// ***TODO*** check if storing to TPC
				//}
				
				//if ( !v->Number )
				//{
				e->AndReg32ImmX ( RAX, VU::c_ulVuMem0_Mask >> 4 );
				//}
				//else
				//{
				//e->AndReg32ImmX ( RAX, VU::c_ulVuMem1_Mask >> 4 );
				//}
				e->AddRegReg32 ( RAX, RAX );
				
				switch( i.xyzw )
				{
					case 8:
						e->MovRegFromMem32 ( RAX, RCX, RAX, SCALE_EIGHT, 0 );
						break;
						
					case 4:
						e->MovRegFromMem32 ( RAX, RCX, RAX, SCALE_EIGHT, 4 );
						break;
						
					case 2:
						e->MovRegFromMem32 ( RAX, RCX, RAX, SCALE_EIGHT, 8 );
						break;
						
					case 1:
						e->MovRegFromMem32 ( RAX, RCX, RAX, SCALE_EIGHT, 12 );
						break;
						
					default:
						cout << "\nVU: Recompiler: ALERT: ILWR with illegal xyzw=" << hex << i.xyzw << "\n";
						break;
				}
				
				//if ( i.xyzw != 0xf )
				//{
				//	e->pblendwregregimm ( RAX, RCX, ~( ( i.destx * 0x03 ) | ( i.desty * 0x0c ) | ( i.destz * 0x30 ) | ( i.destw * 0xc0 ) ) );
				//}
				//ret = e->movdqa_memreg ( & v->vf [ i.Ft ].sw0, RAX );
				
				ret = e->MovMemReg32 ( & VU0::_VU0->vi [ i.it & 0xf ].s, RAX );
			}
			
			break;
#endif

			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::VRINIT ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "VRINIT";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VRINIT;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
#ifdef USE_NEW_VRINIT_CODE
		case 1:
			e->MovRegMem32 ( RAX, &VU0::_VU0->vf [ i.Fs ].vsw [ i.fsf ] );
			//e->XorRegMem32 ( RAX, &v->vi [ VU::REG_R ].s );
			e->AndReg32ImmX ( RAX, 0x7fffff );
			e->OrReg32ImmX ( RAX, ( 0x7f << 23 ) );
			e->MovMemReg32 ( &VU0::_VU0->vi [ VU::REG_R ].s, RAX );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::VCLIP ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "VCLIP";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VCLIP;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;


#ifdef USE_NEW_VCLIP_CODE
		case 1:
			Generate_VPrefix ( Address );
			
			// load clip flag
			e->MovRegMem32 ( RAX, &VU0::_VU0->vi [ VU::REG_CLIPFLAG ].s );
			
			// flush ps2 float to zero
			e->movdqa_regmem ( RBX, &VU0::_VU0->vf [ i.Ft ].sw0 );
			
			if ( !i.Fs )
			{
				e->pxorregreg ( RAX, RAX );
			}
			else if ( i.Fs == i.Ft )
			{
				e->movdqa_regreg ( RAX, RBX );
			}
			else
			{
				e->movdqa_regmem ( RAX, &VU0::_VU0->vf [ i.Fs ].sw0 );
			}
			
			// get w from ft
			e->pshufdregregimm ( RBX, RBX, 0xff );
			
			
			// get +w into RBX
			e->pslldregimm ( RBX, 1 );
			e->psrldregimm ( RBX, 1 );
			
			// get -w into RCX
			e->pcmpeqbregreg ( RCX, RCX );
			e->movdqa_regreg ( RDX, RCX );
			e->pxorregreg ( RCX, RBX );
			//e->psubdregreg ( RCX, RDX );
			
			// get x,y from fs into RDX
			e->pshufdregregimm ( RDX, RAX, ( 1 << 6 ) | ( 1 << 4 ) | ( 0 << 2 ) | ( 0 << 0 ) );
			e->movdqa_regreg ( 4, RDX );
			e->psradregimm ( 4, 31 );
			//e->pslldregimm ( RDX, 1 );
			//e->psrldregimm ( RDX, 1 );
			e->psrldregimm ( 4, 1 );
			e->pxorregreg ( RDX, 4 );
			//e->psubdregreg ( RDX, 4 );
			
			// get greater than +w into R4 and less than -w into R5
			e->movdqa_regreg ( 4, RDX );
			e->pcmpgtdregreg ( 4, RBX );
			e->movdqa_regreg ( 5, RCX );
			e->pcmpgtdregreg ( 5, RDX );
			
			// get x and y flags into R4
			e->pblendwregregimm ( 4, 5, 0xcc );
			
			
			// get z from fs into RAX
			e->pshufdregregimm ( RAX, RAX, ( 2 << 6 ) | ( 2 << 4 ) | ( 2 << 2 ) | ( 2 << 0 ) );
			e->movdqa_regreg ( 5, RAX );
			e->psradregimm ( 5, 31 );
			//e->pslldregimm ( RAX, 1 );
			//e->psrldregimm ( RAX, 1 );
			e->psrldregimm ( 5, 1 );
			e->pxorregreg ( RAX, 5 );
			//e->psubdregreg ( RAX, 5 );
			
			// get greater than into RAX and less than into RCX
			e->pcmpgtdregreg ( RCX, RAX );
			e->pcmpgtdregreg ( RAX, RBX );
			
			// get z flags into RAX
			e->pblendwregregimm ( RAX, RCX, 0xcc );
			
			// pull flags
			e->movmskpsregreg ( RCX, 4 );
			e->movmskpsregreg ( RDX, RAX );
			
			// combine flags
			e->ShlRegImm32 ( RDX, 4 );
			e->OrRegReg32 ( RCX, RDX );
			e->AndReg32ImmX ( RCX, 0x3f );
			
			// combine into rest of the clipping flags
			e->ShlRegImm32 ( RAX, 6 );
			e->OrRegReg32 ( RAX, RCX );
			e->AndReg32ImmX ( RAX, 0x00ffffff );
			
			// write back to clipping flag
			e->MovMemReg32 ( &VU0::_VU0->vi [ VU::REG_CLIPFLAG ].s, RAX );
			
			break;
#endif

			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::VNOP ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "VNOP";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VNOP;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
#ifdef USE_NEW_VNOP_CODE
		case 1:
			Generate_VPrefix ( Address );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::VSQD ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "VSQD";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VSQD;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VSQD_CODE
		case 1:
			Generate_VPrefix ( Address );

			//LoadAddress = ( v->vi [ i.is & 0xf ].sLo + i.Imm11 ) << 2;
			e->MovRegMem32 ( RAX, & VU0::_VU0->vi [ i.it & 0xf ].s );
			
			
			e->movdqa_regmem ( RAX, & VU0::_VU0->vf [ i.Fs ].sw0 );
			
			//pVuMem32 = v->GetMemPtr ( LoadAddress );
			//return & ( VuMem32 [ Address32 & ( c_ulVuMem1_Mask >> 2 ) ] );
			//e->MovRegImm64 ( RCX, (u64) & v->VuMem32 [ 0 ] );
			e->LeaRegMem64 ( RCX, & VU0::_VU0->VuMem32 [ 0 ] );

			// special code for VU#0
			//if ( !v->Number )
			//{
				// check if Address & 0xf000 == 0x4000
				e->MovRegReg32 ( RDX, RAX );
				e->AndReg32ImmX ( RDX, 0xf000 >> 4 );
				e->CmpReg32ImmX ( RDX, 0x4000 >> 4 );
				
				// here it will be loading/storing from/to the registers for VU#1
				e->LeaRegMem64 ( RDX, & VU1::_VU1->vf [ 0 ].sw0 );
				e->CmovERegReg64 ( RCX, RDX );
				
				// ***TODO*** check if storing to TPC
			//}
			
			// post-inc
			e->DecReg32 ( RAX );
			e->MovMemReg16 ( & VU0::_VU0->vi [ i.it & 0xf ].sLo, RAX );
			
			//if ( !v->Number )
			//{
				e->AndReg32ImmX ( RAX, VU::c_ulVuMem0_Mask >> 4 );
			//}
			//else
			//{
			//	e->AndReg32ImmX ( RAX, VU::c_ulVuMem1_Mask >> 4 );
			//}
			e->AddRegReg32 ( RAX, RAX );
			
#define ENABLE_VU_MASK_STORE_VSQD
#ifdef ENABLE_VU_MASK_STORE_VSQD

			if (i.xyzw != 0xf)
			{
				//e->movdqa_from_mem128(RCX, RCX, RAX, SCALE_EIGHT, 0);
				//e->pblendwregregimm(RAX, RCX, ~((i.destx * 0x03) | (i.desty * 0x0c) | (i.destz * 0x30) | (i.destw * 0xc0)));
				e->pcmpeqb1regreg(RCX, RCX, RCX);
				e->pxor1regreg(RDX, RDX, RDX);
				e->pblendw1regregimm(RCX, RCX, RDX, ~((i.destx * 0x03) | (i.desty * 0x0c) | (i.destz * 0x30) | (i.destw * 0xc0)));
				e->vmaskmovd1_memreg(RCX, RAX, RCX, RAX, SCALE_EIGHT, 0);
			}
			else
			{
				ret = e->movdqa_to_mem128(RAX, RCX, RAX, SCALE_EIGHT, 0);
			}

#else

			if ( i.xyzw != 0xf )
			{
				e->movdqa_from_mem128 ( RCX, RCX, RAX, SCALE_EIGHT, 0 );
				e->pblendwregregimm ( RAX, RCX, ~( ( i.destx * 0x03 ) | ( i.desty * 0x0c ) | ( i.destz * 0x30 ) | ( i.destw * 0xc0 ) ) );
			}
			
			ret = e->movdqa_to_mem128 ( RAX, RCX, RAX, SCALE_EIGHT, 0 );

#endif
			
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::VWAITQ ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "VWAITQ";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VWAITQ;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

		case 1:

			Generate_VPrefix(Address);

			// set cycle# for VU
			//e->MovRegMem64(RAX, (int64_t*)&r->CycleCount);
			//e->MovMemReg64((int64_t*)&VU0::_VU0->CycleCount, RAX);

			// run vu0 instruction
			Vu::Recompiler::WAITQ(e, VU0::_VU0, { i.Value }, Address);

			// load new cycle#
			//e->MovRegMem64(RAX, (int64_t*)&VU0::_VU0->CycleCount);
			//e->MovMemReg64((int64_t*)&r->CycleCount, RAX);

			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::VISWR ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "VISWR";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VISWR;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VISWR_CODE
		case 1:
			Generate_VPrefix ( Address );

			//LoadAddress = ( v->vi [ i.is & 0xf ].sLo + i.Imm11 ) << 2;
			e->MovRegMem32 ( RAX, & VU0::_VU0->vi [ i.is & 0xf ].s );
			e->movd_regmem ( RAX, & VU0::_VU0->vi [ i.it & 0xf ].s );
			
			//e->movdqa_regmem ( RAX, & v->vf [ i.Fs ].sw0 );
			
			//pVuMem32 = v->GetMemPtr ( LoadAddress );
			//return & ( VuMem32 [ Address32 & ( c_ulVuMem1_Mask >> 2 ) ] );
			//e->MovRegImm64 ( RCX, (u64) & v->VuMem32 [ 0 ] );
			e->LeaRegMem64 ( RCX, & VU0::_VU0->VuMem32 [ 0 ] );

			// special code for VU#0
			//if ( !v->Number )
			//{
				// check if Address & 0xf000 == 0x4000
				e->MovRegReg32 ( RDX, RAX );
				e->AndReg32ImmX ( RDX, 0xf000 >> 4 );
				e->CmpReg32ImmX ( RDX, 0x4000 >> 4 );
				
				// here it will be loading/storing from/to the registers for VU#1
				e->LeaRegMem64 ( RDX, & VU1::_VU1->vf [ 0 ].sw0 );
				e->CmovERegReg64 ( RCX, RDX );
				
				// ***TODO*** check if storing to TPC
			//}
			
			//if ( !v->Number )
			//{
			e->AndReg32ImmX ( RAX, VU::c_ulVuMem0_Mask >> 4 );
			//}
			//else
			//{
			//e->AndReg32ImmX ( RAX, VU::c_ulVuMem1_Mask >> 4 );
			//}
			e->AddRegReg32 ( RAX, RAX );

			if ( i.xyzw != 0xf )
			{
				e->movdqa_from_mem128 ( RCX, RCX, RAX, SCALE_EIGHT, 0 );
			}
			
			e->pmovzxwdregreg ( RAX, RAX );
			e->pshufdregregimm ( RAX, RAX, 0 );
			//e->pslldregimm ( RAX, 16 );
			//e->psrldregimm ( RAX, 16 );
			
			if ( i.xyzw != 0xf )
			{
				//e->movdqa_from_mem128 ( RCX, RCX, RAX, SCALE_EIGHT, 0 );
				e->pblendwregregimm ( RAX, RCX, ~( ( i.destx * 0x03 ) | ( i.desty * 0x0c ) | ( i.destz * 0x30 ) | ( i.destw * 0xc0 ) ) );
			}
			
			//ret = e->movdqa_memreg ( & v->vf [ i.Ft ].sw0, RAX );
			ret = e->movdqa_to_mem128 ( RAX, RCX, RAX, SCALE_EIGHT, 0 );
			
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

int32_t R5900::Recompiler::VRXOR ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr const char *c_sName = "VRXOR";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VRXOR;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
#ifdef USE_NEW_VRXOR_CODE
		case 1:
			e->MovRegMem32 ( RAX, &VU0::_VU0->vf [ i.Fs ].vsw [ i.fsf ] );
			e->XorRegMem32 ( RAX, &VU0::_VU0->vi [ VU::REG_R ].s );
			e->AndReg32ImmX ( RAX, 0x7fffff );
			e->OrReg32ImmX ( RAX, ( 0x7f << 23 ) );
			e->MovMemReg32 ( &VU0::_VU0->vi [ VU::REG_R ].s, RAX );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}






const R5900::Recompiler::Function R5900::Recompiler::FunctionList []
{
	// instructions on both R3000A and R5900
	// 1 + 56 + 6 = 63 instructions //
	R5900::Recompiler::Invalid,
	R5900::Recompiler::J, R5900::Recompiler::JAL, R5900::Recompiler::JR, R5900::Recompiler::JALR, R5900::Recompiler::BEQ, R5900::Recompiler::BNE, R5900::Recompiler::BGTZ, R5900::Recompiler::BGEZ,
	R5900::Recompiler::BLTZ, R5900::Recompiler::BLEZ, R5900::Recompiler::BGEZAL, R5900::Recompiler::BLTZAL, R5900::Recompiler::ADD, R5900::Recompiler::ADDI, R5900::Recompiler::ADDU, R5900::Recompiler::ADDIU,
	R5900::Recompiler::SUB, R5900::Recompiler::SUBU, R5900::Recompiler::MULT, R5900::Recompiler::MULTU, R5900::Recompiler::DIV, R5900::Recompiler::DIVU, R5900::Recompiler::AND, R5900::Recompiler::ANDI,
	R5900::Recompiler::OR, R5900::Recompiler::ORI, R5900::Recompiler::XOR, R5900::Recompiler::XORI, R5900::Recompiler::NOR, R5900::Recompiler::LUI, R5900::Recompiler::SLL, R5900::Recompiler::SRL,
	R5900::Recompiler::SRA, R5900::Recompiler::SLLV, R5900::Recompiler::SRLV, R5900::Recompiler::SRAV, R5900::Recompiler::SLT, R5900::Recompiler::SLTI, R5900::Recompiler::SLTU, R5900::Recompiler::SLTIU,
	R5900::Recompiler::LB, R5900::Recompiler::LBU, R5900::Recompiler::LH, R5900::Recompiler::LHU, R5900::Recompiler::LW, R5900::Recompiler::LWL, R5900::Recompiler::LWR, R5900::Recompiler::SB,
	R5900::Recompiler::SH, R5900::Recompiler::SW, R5900::Recompiler::SWL, R5900::Recompiler::SWR, R5900::Recompiler::MFHI, R5900::Recompiler::MTHI, R5900::Recompiler::MFLO, R5900::Recompiler::MTLO,
	R5900::Recompiler::MFC0, R5900::Recompiler::MTC0,
	R5900::Recompiler::CFC2_I, R5900::Recompiler::CTC2_I, R5900::Recompiler::CFC2_NI, R5900::Recompiler::CTC2_NI,
	R5900::Recompiler::SYSCALL, R5900::Recompiler::BREAK,
	
	// instructions on R3000A ONLY
	//R5900::Recompiler::MFC2, R5900::Recompiler::MTC2, R5900::Recompiler::LWC2, R5900::Recompiler::SWC2, R5900::Recompiler::RFE,
	//R5900::Recompiler::RTPS, R5900::Recompiler::RTPT, R5900::Recompiler::CC, R5900::Recompiler::CDP, R5900::Recompiler::DCPL, R5900::Recompiler::DPCS, R5900::Recompiler::DPCT, R5900::Recompiler::NCS,
	//R5900::Recompiler::NCT, R5900::Recompiler::NCDS, R5900::Recompiler::NCDT, R5900::Recompiler::NCCS, R5900::Recompiler::NCCT, R5900::Recompiler::GPF, R5900::Recompiler::GPL, R5900::Recompiler::AVSZ3,
	//R5900::Recompiler::AVSZ4, R5900::Recompiler::SQR, R5900::Recompiler::OP, R5900::Recompiler::NCLIP, R5900::Recompiler::INTPL, R5900::Recompiler::MVMVA
	
	// instructions on R5900 ONLY
	// (24*8) + 4 + 6 = 192 + 10 = 202 instructions //
	R5900::Recompiler::BEQL, R5900::Recompiler::BNEL, R5900::Recompiler::BGEZL, R5900::Recompiler::BGTZL, R5900::Recompiler::BLEZL, R5900::Recompiler::BLTZL, R5900::Recompiler::BGEZALL, R5900::Recompiler::BLTZALL,
	R5900::Recompiler::DADD, R5900::Recompiler::DADDI, R5900::Recompiler::DADDU, R5900::Recompiler::DADDIU, R5900::Recompiler::DSUB, R5900::Recompiler::DSUBU, R5900::Recompiler::DSLL, R5900::Recompiler::DSLL32,
	R5900::Recompiler::DSLLV, R5900::Recompiler::DSRA, R5900::Recompiler::DSRA32, R5900::Recompiler::DSRAV, R5900::Recompiler::DSRL, R5900::Recompiler::DSRL32, R5900::Recompiler::DSRLV, R5900::Recompiler::LD,
	R5900::Recompiler::LDL, R5900::Recompiler::LDR, R5900::Recompiler::LWU, R5900::Recompiler::LQ, R5900::Recompiler::PREF, R5900::Recompiler::SD, R5900::Recompiler::SDL, R5900::Recompiler::SDR,
	R5900::Recompiler::SQ, R5900::Recompiler::TEQ, R5900::Recompiler::TEQI, R5900::Recompiler::TNE, R5900::Recompiler::TNEI, R5900::Recompiler::TGE, R5900::Recompiler::TGEI, R5900::Recompiler::TGEU,
	R5900::Recompiler::TGEIU, R5900::Recompiler::TLT, R5900::Recompiler::TLTI, R5900::Recompiler::TLTU, R5900::Recompiler::TLTIU, R5900::Recompiler::MOVN, R5900::Recompiler::MOVZ, R5900::Recompiler::MULT1,
	R5900::Recompiler::MULTU1, R5900::Recompiler::DIV1, R5900::Recompiler::DIVU1, R5900::Recompiler::MADD, R5900::Recompiler::MADD1, R5900::Recompiler::MADDU, R5900::Recompiler::MADDU1, R5900::Recompiler::MFHI1,
	R5900::Recompiler::MTHI1, R5900::Recompiler::MFLO1, R5900::Recompiler::MTLO1, R5900::Recompiler::MFSA, R5900::Recompiler::MTSA, R5900::Recompiler::MTSAB, R5900::Recompiler::MTSAH,
	R5900::Recompiler::PABSH, R5900::Recompiler::PABSW, R5900::Recompiler::PADDB, R5900::Recompiler::PADDH, R5900::Recompiler::PADDW, R5900::Recompiler::PADDSB, R5900::Recompiler::PADDSH, R5900::Recompiler::PADDSW,
	R5900::Recompiler::PADDUB, R5900::Recompiler::PADDUH, R5900::Recompiler::PADDUW, R5900::Recompiler::PADSBH, R5900::Recompiler::PAND, R5900::Recompiler::POR, R5900::Recompiler::PXOR, R5900::Recompiler::PNOR,
	R5900::Recompiler::PCEQB, R5900::Recompiler::PCEQH, R5900::Recompiler::PCEQW, R5900::Recompiler::PCGTB, R5900::Recompiler::PCGTH, R5900::Recompiler::PCGTW, R5900::Recompiler::PCPYH, R5900::Recompiler::PCPYLD,
	R5900::Recompiler::PCPYUD, R5900::Recompiler::PDIVBW, R5900::Recompiler::PDIVUW, R5900::Recompiler::PDIVW, R5900::Recompiler::PEXCH, R5900::Recompiler::PEXCW, R5900::Recompiler::PEXEH, R5900::Recompiler::PEXEW,
	R5900::Recompiler::PEXT5, R5900::Recompiler::PEXTLB, R5900::Recompiler::PEXTLH, R5900::Recompiler::PEXTLW, R5900::Recompiler::PEXTUB, R5900::Recompiler::PEXTUH, R5900::Recompiler::PEXTUW, R5900::Recompiler::PHMADH,
	R5900::Recompiler::PHMSBH, R5900::Recompiler::PINTEH, R5900::Recompiler::PINTH, R5900::Recompiler::PLZCW, R5900::Recompiler::PMADDH, R5900::Recompiler::PMADDW, R5900::Recompiler::PMADDUW, R5900::Recompiler::PMAXH,
	R5900::Recompiler::PMAXW, R5900::Recompiler::PMINH, R5900::Recompiler::PMINW, R5900::Recompiler::PMFHI, R5900::Recompiler::PMFLO, R5900::Recompiler::PMTHI, R5900::Recompiler::PMTLO, R5900::Recompiler::PMFHL_LH,
	R5900::Recompiler::PMFHL_SH, R5900::Recompiler::PMFHL_LW, R5900::Recompiler::PMFHL_UW, R5900::Recompiler::PMFHL_SLW, R5900::Recompiler::PMTHL_LW, R5900::Recompiler::PMSUBH, R5900::Recompiler::PMSUBW, R5900::Recompiler::PMULTH,
	R5900::Recompiler::PMULTW, R5900::Recompiler::PMULTUW, R5900::Recompiler::PPAC5, R5900::Recompiler::PPACB, R5900::Recompiler::PPACH, R5900::Recompiler::PPACW, R5900::Recompiler::PREVH, R5900::Recompiler::PROT3W,
	R5900::Recompiler::PSLLH, R5900::Recompiler::PSLLVW, R5900::Recompiler::PSLLW, R5900::Recompiler::PSRAH, R5900::Recompiler::PSRAW, R5900::Recompiler::PSRAVW, R5900::Recompiler::PSRLH, R5900::Recompiler::PSRLW,
	R5900::Recompiler::PSRLVW, R5900::Recompiler::PSUBB, R5900::Recompiler::PSUBH, R5900::Recompiler::PSUBW, R5900::Recompiler::PSUBSB, R5900::Recompiler::PSUBSH, R5900::Recompiler::PSUBSW, R5900::Recompiler::PSUBUB,
	R5900::Recompiler::PSUBUH, R5900::Recompiler::PSUBUW,
	R5900::Recompiler::QFSRV, R5900::Recompiler::SYNC,
	
	R5900::Recompiler::DI, R5900::Recompiler::EI, R5900::Recompiler::ERET, R5900::Recompiler::CACHE, R5900::Recompiler::TLBP, R5900::Recompiler::TLBR, R5900::Recompiler::TLBWI, R5900::Recompiler::TLBWR,
	R5900::Recompiler::CFC0, R5900::Recompiler::CTC0,
	
	R5900::Recompiler::BC0T, R5900::Recompiler::BC0TL, R5900::Recompiler::BC0F, R5900::Recompiler::BC0FL, R5900::Recompiler::BC1T, R5900::Recompiler::BC1TL, R5900::Recompiler::BC1F, R5900::Recompiler::BC1FL,
	R5900::Recompiler::BC2T, R5900::Recompiler::BC2TL, R5900::Recompiler::BC2F, R5900::Recompiler::BC2FL,
	
	// COP1 floating point instructions
	R5900::Recompiler::LWC1, R5900::Recompiler::SWC1, R5900::Recompiler::MFC1, R5900::Recompiler::MTC1, R5900::Recompiler::CFC1, R5900::Recompiler::CTC1,
	R5900::Recompiler::ABS_S, R5900::Recompiler::ADD_S, R5900::Recompiler::ADDA_S, R5900::Recompiler::C_EQ_S, R5900::Recompiler::C_F_S, R5900::Recompiler::C_LE_S, R5900::Recompiler::C_LT_S, R5900::Recompiler::CVT_S_W,
	R5900::Recompiler::CVT_W_S, R5900::Recompiler::DIV_S, R5900::Recompiler::MADD_S, R5900::Recompiler::MADDA_S, R5900::Recompiler::MAX_S, R5900::Recompiler::MIN_S, R5900::Recompiler::MOV_S, R5900::Recompiler::MSUB_S,
	R5900::Recompiler::MSUBA_S, R5900::Recompiler::MUL_S, R5900::Recompiler::MULA_S, R5900::Recompiler::NEG_S, R5900::Recompiler::RSQRT_S, R5900::Recompiler::SQRT_S, R5900::Recompiler::SUB_S, R5900::Recompiler::SUBA_S,
	
	// VU macro mode instructions
	R5900::Recompiler::QMFC2_NI, R5900::Recompiler::QMFC2_I, R5900::Recompiler::QMTC2_NI, R5900::Recompiler::QMTC2_I, R5900::Recompiler::LQC2, R5900::Recompiler::SQC2,
	
	R5900::Recompiler::VABS,
	R5900::Recompiler::VADD, R5900::Recompiler::VADDi, R5900::Recompiler::VADDq, R5900::Recompiler::VADDBCX, R5900::Recompiler::VADDBCY, R5900::Recompiler::VADDBCZ, R5900::Recompiler::VADDBCW,
	R5900::Recompiler::VADDA, R5900::Recompiler::VADDAi, R5900::Recompiler::VADDAq, R5900::Recompiler::VADDABCX, R5900::Recompiler::VADDABCY, R5900::Recompiler::VADDABCZ, R5900::Recompiler::VADDABCW,
	R5900::Recompiler::VCALLMS, R5900::Recompiler::VCALLMSR, R5900::Recompiler::VCLIP, R5900::Recompiler::VDIV,
	R5900::Recompiler::VFTOI0, R5900::Recompiler::VFTOI4, R5900::Recompiler::VFTOI12, R5900::Recompiler::VFTOI15,
	R5900::Recompiler::VIADD, R5900::Recompiler::VIADDI, R5900::Recompiler::VIAND, R5900::Recompiler::VILWR, R5900::Recompiler::VIOR, R5900::Recompiler::VISUB, R5900::Recompiler::VISWR,
	R5900::Recompiler::VITOF0, R5900::Recompiler::VITOF4, R5900::Recompiler::VITOF12, R5900::Recompiler::VITOF15,
	R5900::Recompiler::VLQD, R5900::Recompiler::VLQI,
	
	R5900::Recompiler::VMADD, R5900::Recompiler::VMADDi, R5900::Recompiler::VMADDq, R5900::Recompiler::VMADDBCX, R5900::Recompiler::VMADDBCY, R5900::Recompiler::VMADDBCZ, R5900::Recompiler::VMADDBCW,
	R5900::Recompiler::VMADDA, R5900::Recompiler::VMADDAi, R5900::Recompiler::VMADDAq, R5900::Recompiler::VMADDABCX, R5900::Recompiler::VMADDABCY, R5900::Recompiler::VMADDABCZ, R5900::Recompiler::VMADDABCW,
	R5900::Recompiler::VMAX, R5900::Recompiler::VMAXi, R5900::Recompiler::VMAXBCX, R5900::Recompiler::VMAXBCY, R5900::Recompiler::VMAXBCZ, R5900::Recompiler::VMAXBCW,
	R5900::Recompiler::VMFIR,
	R5900::Recompiler::VMINI, R5900::Recompiler::VMINIi, R5900::Recompiler::VMINIBCX, R5900::Recompiler::VMINIBCY, R5900::Recompiler::VMINIBCZ, R5900::Recompiler::VMINIBCW,
	R5900::Recompiler::VMOVE, R5900::Recompiler::VMR32,
	
	R5900::Recompiler::VMSUB, R5900::Recompiler::VMSUBi, R5900::Recompiler::VMSUBq, R5900::Recompiler::VMSUBBCX, R5900::Recompiler::VMSUBBCY, R5900::Recompiler::VMSUBBCZ, R5900::Recompiler::VMSUBBCW,
	R5900::Recompiler::VMSUBA, R5900::Recompiler::VMSUBAi, R5900::Recompiler::VMSUBAq, R5900::Recompiler::VMSUBABCX, R5900::Recompiler::VMSUBABCY, R5900::Recompiler::VMSUBABCZ, R5900::Recompiler::VMSUBABCW,
	R5900::Recompiler::VMTIR,
	R5900::Recompiler::VMUL, R5900::Recompiler::VMULi, R5900::Recompiler::VMULq, R5900::Recompiler::VMULBCX, R5900::Recompiler::VMULBCY, R5900::Recompiler::VMULBCZ, R5900::Recompiler::VMULBCW,
	R5900::Recompiler::VMULA, R5900::Recompiler::VMULAi, R5900::Recompiler::VMULAq, R5900::Recompiler::VMULABCX, R5900::Recompiler::VMULABCY, R5900::Recompiler::VMULABCZ, R5900::Recompiler::VMULABCW,
	R5900::Recompiler::VNOP, R5900::Recompiler::VOPMSUB, R5900::Recompiler::VOPMULA, R5900::Recompiler::VRGET, R5900::Recompiler::VRINIT, R5900::Recompiler::VRNEXT, R5900::Recompiler::VRSQRT, R5900::Recompiler::VRXOR,
	R5900::Recompiler::VSQD, R5900::Recompiler::VSQI, R5900::Recompiler::VSQRT,
	R5900::Recompiler::VSUB, R5900::Recompiler::VSUBi, R5900::Recompiler::VSUBq, R5900::Recompiler::VSUBBCX, R5900::Recompiler::VSUBBCY, R5900::Recompiler::VSUBBCZ, R5900::Recompiler::VSUBBCW,
	R5900::Recompiler::VSUBA, R5900::Recompiler::VSUBAi, R5900::Recompiler::VSUBAq, R5900::Recompiler::VSUBABCX, R5900::Recompiler::VSUBABCY, R5900::Recompiler::VSUBABCZ, R5900::Recompiler::VSUBABCW,
	R5900::Recompiler::VWAITQ,
	R5900::Recompiler::COP2
};
